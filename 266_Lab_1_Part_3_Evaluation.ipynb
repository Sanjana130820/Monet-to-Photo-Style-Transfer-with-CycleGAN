{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7bd374-bf47-49db-9727-6d0a6e2228a9",
   "metadata": {},
   "source": [
    "### Evaluation Dataset Link: https://drive.google.com/file/d/1NaDz3Y4j01GrnJRY2ln2DN9gfG9QgSl_/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84697196-a25e-4a8b-8496-6c90dba76947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.5,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.26.2)\n",
      "Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a581b319-a5df-4a00-8414-b49fdb50279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f917cdd9-7b57-4fb6-92fd-e3313ce9748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from scipy.spatial.distance import cosine\n",
    "import math\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Define paths for local machine\n",
    "REAL_MONET_PATH = \"eval\"  # Update with actual path for real Monet images\n",
    "GENERATED_MONET_PATH = \"submission\"  # Update with actual path for generated Monet images\n",
    "batch_size = 64 \n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0c7759-cb3e-4bc4-a7eb-b37198685b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load images\n",
    "def load_images(image_paths, transform):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        \n",
    "        # Ensure images are 256x256\n",
    "        if image.size != (256, 256):\n",
    "            raise ValueError(f\"Image {path} is not 256x256 in size.\")\n",
    "        \n",
    "        # Ensure images are in .jpg format\n",
    "        if not path.lower().endswith('.jpg'):\n",
    "            raise ValueError(f\"Image {path} is not in .jpg format.\")\n",
    "        \n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "    \n",
    "    return torch.stack(images)\n",
    "\n",
    "# Helper function to calculate activations using InceptionV3\n",
    "def calculate_activations(images, model, device):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(images)\n",
    "    return features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7247043-b0df-4c5b-856a-332cab4f40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to subsample the larger dataset (real or generated)\n",
    "def subsample_datasets(real_image_paths, generated_image_paths):\n",
    "    # Determine the smaller and larger dataset\n",
    "    real_count = len(real_image_paths)\n",
    "    generated_count = len(generated_image_paths)\n",
    "\n",
    "    if real_count > generated_count:\n",
    "        # Subsample the real images to match the number of generated images\n",
    "        print(f\"Subsampling real images from {real_count} to {generated_count}\")\n",
    "        real_image_paths = random.sample(real_image_paths, generated_count)\n",
    "    elif generated_count > real_count:\n",
    "        # Subsample the generated images to match the number of real images\n",
    "        print(f\"Subsampling generated images from {generated_count} to {real_count}\")\n",
    "        generated_image_paths = random.sample(generated_image_paths, real_count)\n",
    "    \n",
    "    return real_image_paths, generated_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85961d87-29df-4240-95e8-36f86bc752d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute FID and MiFID\n",
    "def calculate_mifid(real_image_paths, generated_image_paths, batch_size=32):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load InceptionV3 model\n",
    "    inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "    inception.fc = nn.Identity()  # Remove classification layer\n",
    "    inception.eval()\n",
    "    inception = inception.to(device)\n",
    "\n",
    "    # Define the image transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(int(256 * 1.33)),  # Resize with scaling\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # ImageNet stats\n",
    "    ])\n",
    "\n",
    "    # Subsample datasets if needed\n",
    "    real_image_paths, generated_image_paths = subsample_datasets(real_image_paths, generated_image_paths)\n",
    "\n",
    "    # Process real images in batches\n",
    "    real_activations = []\n",
    "    for i in tqdm(range(0, len(real_image_paths), batch_size), desc=\"Processing Real Images\"):\n",
    "        batch_paths = real_image_paths[i:i+batch_size]\n",
    "        batch_images = load_images(batch_paths, transform)\n",
    "        real_activations.append(calculate_activations(batch_images, inception, device))\n",
    "    real_activations = np.concatenate(real_activations, axis=0)\n",
    "\n",
    "    # Process generated images in batches\n",
    "    generated_activations = []\n",
    "    for i in tqdm(range(0, len(generated_image_paths), batch_size), desc=\"Processing Generated Images\"):\n",
    "        batch_paths = generated_image_paths[i:i+batch_size]\n",
    "        batch_images = load_images(batch_paths, transform)\n",
    "        generated_activations.append(calculate_activations(batch_images, inception, device))\n",
    "    generated_activations = np.concatenate(generated_activations, axis=0)\n",
    "\n",
    "    # Calculate mean and covariance\n",
    "    real_mu = np.mean(real_activations, axis=0)\n",
    "    generated_mu = np.mean(generated_activations, axis=0)\n",
    "    real_sigma = np.cov(real_activations, rowvar=False)\n",
    "    generated_sigma = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "    # Compute FID\n",
    "    diff = real_mu - generated_mu\n",
    "    covmean, _ = scipy.linalg.sqrtm(real_sigma.dot(generated_sigma), disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = diff.dot(diff) + np.trace(real_sigma + generated_sigma - 2 * covmean)\n",
    "\n",
    "    # Calculate MiFID\n",
    "    # Calculate the memorization distance between each generated image and the real images\n",
    "    memorization_distances = [\n",
    "        min([cosine(g_feat, r_feat) for r_feat in real_activations])\n",
    "        for g_feat in generated_activations\n",
    "    ]\n",
    "    # Calculate the MiFID as the mean memorization distance\n",
    "    mifid = np.mean(memorization_distances)\n",
    "\n",
    "    print(f\"MiFID Score: {mifid}\")\n",
    "    return fid, mifid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e965c3c-9790-4e3c-983f-e52dd465c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:01<00:00, 58.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampling generated images from 1500 to 933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Real Images: 100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "Processing Generated Images: 100%|██████████| 15/15 [00:05<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiFID Score: 0.2221461160288526\n",
      "   ID        FID     MiFID\n",
      "0   1  46.215857  0.222146\n",
      "Results saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Main function for evaluation\n",
    "def evaluate():\n",
    "    # Get list of real and generated images\n",
    "    real_image_paths = sorted([os.path.join(REAL_MONET_PATH, f) for f in os.listdir(REAL_MONET_PATH) if f.endswith('.jpg')])\n",
    "    generated_image_paths = sorted([os.path.join(GENERATED_MONET_PATH, f) for f in os.listdir(GENERATED_MONET_PATH) if f.endswith('.jpg')])\n",
    "\n",
    "    # Check that there are more than 300 generated images\n",
    "    if len(generated_image_paths) < 300:\n",
    "        raise ValueError(\"The number of generated images should be greater than 300.\")\n",
    "\n",
    "    # Compute FID and MiFID scores\n",
    "    fid_score, mifid_score = calculate_mifid(real_image_paths, generated_image_paths, batch_size=batch_size)\n",
    "\n",
    "    # Save results to CSV\n",
    "    result_df = pd.DataFrame({\n",
    "        'ID': [1],  \n",
    "        'FID': [fid_score],\n",
    "        'MiFID': [mifid_score]\n",
    "    })\n",
    "\n",
    "    result_df.to_csv('submission.csv', index=False)\n",
    "    print(result_df)\n",
    "    print(\"Results saved to 'submission.csv'\")\n",
    "\n",
    "# Run the evaluation\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698f5cb-66e5-4fbd-9106-acdb3f452cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da74ff-bdd3-4296-8e63-5576fcb53588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
