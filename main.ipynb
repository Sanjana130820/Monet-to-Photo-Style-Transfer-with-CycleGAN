{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torchvision.utils as vutils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 3  \n",
    "LR = 0.0002\n",
    "BETA1 = 0.5\n",
    "NUM_EPOCHS = 200\n",
    "LAMBDA_CYCLE = 10.0\n",
    "LAMBDA_PERCEPTUAL = 5.0  \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, photo_dir, monet_dir, transform=None):\n",
    "        self.photo_dir = photo_dir\n",
    "        self.monet_dir = monet_dir\n",
    "        self.transform = transform\n",
    "        self.photos = sorted(os.listdir(photo_dir))\n",
    "        self.monets = sorted(os.listdir(monet_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.photos), len(self.monets))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        photo_path = os.path.join(self.photo_dir, self.photos[idx % len(self.photos)])\n",
    "        monet_path = os.path.join(self.monet_dir, self.monets[idx % len(self.monets)])\n",
    "\n",
    "        photo = Image.open(photo_path).convert('RGB')\n",
    "        monet = Image.open(monet_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            photo = self.transform(photo)\n",
    "            monet = self.transform(monet)\n",
    "\n",
    "        return {'photo': photo, 'monet': monet}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Resnet Block, Generator and Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator (U-Net with ResNet blocks)\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, 3, 1, 1, bias=False),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(dim, dim, 3, 1, 1, bias=False),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 1, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            *[ResNetBlock(256) for _ in range(9)],\n",
    "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 3, 7, 1, 3, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Discriminator (PatchGAN)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(256, 512, 4, 1, 1, bias=False),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight Initialization and Image Buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "# Image buffer\n",
    "class ImageBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        self.buffer = []\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def push_and_pop(self, images):\n",
    "        to_return = []\n",
    "        for image in images:\n",
    "            image = image.unsqueeze(0)\n",
    "            if len(self.buffer) < self.max_size:\n",
    "                self.buffer.append(image)\n",
    "                to_return.append(image)\n",
    "            else:\n",
    "                if np.random.uniform(0, 1) > 0.5:\n",
    "                    i = np.random.randint(0, self.max_size)\n",
    "                    to_return.append(self.buffer[i].clone())\n",
    "                    self.buffer[i] = image\n",
    "                else:\n",
    "                    to_return.append(image)\n",
    "        return torch.cat(to_return, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining CycleGAN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h4oNnr0ZZsZs",
    "outputId": "6d1f98dd-7f63-43df-8822-5aad1283d535"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_cycle_gan(photo_dir, monet_dir, output_dir, models_dir=\"models\"):\n",
    "    # Create separate directories\n",
    "    os.makedirs(output_dir, exist_ok=True)    # For generated images\n",
    "    os.makedirs(models_dir, exist_ok=True)    # For model checkpoints\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE + 30, IMG_SIZE + 30)),\n",
    "        transforms.RandomCrop(IMG_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    dataset = ImageDataset(photo_dir, monet_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Initialize models\n",
    "    G = Generator().to(DEVICE)\n",
    "    F = Generator().to(DEVICE)\n",
    "    D_X = Discriminator().to(DEVICE)\n",
    "    D_Y = Discriminator().to(DEVICE)\n",
    "\n",
    "    G.apply(weights_init)\n",
    "    F.apply(weights_init)\n",
    "    D_X.apply(weights_init)\n",
    "    D_Y.apply(weights_init)\n",
    "\n",
    "    # Optimizers with learning rate scheduling\n",
    "    optimizer_G = optim.Adam(itertools.chain(G.parameters(), F.parameters()), lr=LR, betas=(BETA1, 0.999))\n",
    "    optimizer_D_X = optim.Adam(D_X.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
    "    optimizer_D_Y = optim.Adam(D_Y.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
    "    lr_scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=100, gamma=0.1)\n",
    "    lr_scheduler_D_X = optim.lr_scheduler.StepLR(optimizer_D_X, step_size=100, gamma=0.1)\n",
    "    lr_scheduler_D_Y = optim.lr_scheduler.StepLR(optimizer_D_Y, step_size=100, gamma=0.1)\n",
    "\n",
    "    # Loss functions\n",
    "    criterion_GAN = nn.MSELoss()\n",
    "    criterion_cycle = nn.L1Loss()\n",
    "    criterion_perceptual = nn.L1Loss()\n",
    "    vgg = models.vgg16(pretrained=True).features[:16].to(DEVICE).eval()  \n",
    "\n",
    "    # Image buffers\n",
    "    fake_photo_buffer = ImageBuffer()\n",
    "    fake_monet_buffer = ImageBuffer()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            real_photo = batch['photo'].to(DEVICE)\n",
    "            real_monet = batch['monet'].to(DEVICE)\n",
    "\n",
    "            # Ground truth for GAN loss\n",
    "            real_label = torch.ones((real_photo.size(0), 1, 30, 30), device=DEVICE)\n",
    "            fake_label = torch.zeros((real_photo.size(0), 1, 30, 30), device=DEVICE)\n",
    "\n",
    "            # --- Train Generators ---\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_monet = G(real_photo)\n",
    "            fake_photo = F(real_monet)\n",
    "\n",
    "            # Reconstruct images\n",
    "            rec_photo = F(fake_monet)\n",
    "            rec_monet = G(fake_photo)\n",
    "\n",
    "            # Adversarial losses\n",
    "            loss_G = criterion_GAN(D_Y(fake_monet), real_label)\n",
    "            loss_F = criterion_GAN(D_X(fake_photo), real_label)\n",
    "\n",
    "            # Cycle losses\n",
    "            loss_cycle_photo = criterion_cycle(rec_photo, real_photo)\n",
    "            loss_cycle_monet = criterion_cycle(rec_monet, real_monet)\n",
    "\n",
    "            # Perceptual losses\n",
    "            with torch.no_grad():\n",
    "                vgg_real_photo = vgg(real_photo)\n",
    "                vgg_real_monet = vgg(real_monet)\n",
    "            loss_perceptual_photo = criterion_perceptual(vgg(rec_photo), vgg_real_photo)\n",
    "            loss_perceptual_monet = criterion_perceptual(vgg(rec_monet), vgg_real_monet)\n",
    "\n",
    "            # Total generator loss\n",
    "            total_loss_G = (loss_G + loss_F +\n",
    "                           LAMBDA_CYCLE * (loss_cycle_photo + loss_cycle_monet) +\n",
    "                           LAMBDA_PERCEPTUAL * (loss_perceptual_photo + loss_perceptual_monet))\n",
    "            total_loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # --- Train Discriminators ---\n",
    "            # Photo discriminator\n",
    "            optimizer_D_X.zero_grad()\n",
    "            real_loss_D_X = criterion_GAN(D_X(real_photo), real_label)\n",
    "            fake_photo_buffered = fake_photo_buffer.push_and_pop(fake_photo)\n",
    "            fake_loss_D_X = criterion_GAN(D_X(fake_photo_buffered.detach()), fake_label)\n",
    "            loss_D_X = (real_loss_D_X + fake_loss_D_X) * 0.5\n",
    "            loss_D_X.backward()\n",
    "            optimizer_D_X.step()\n",
    "\n",
    "            # Monet discriminator\n",
    "            optimizer_D_Y.zero_grad()\n",
    "            real_loss_D_Y = criterion_GAN(D_Y(real_monet), real_label)\n",
    "            fake_monet_buffered = fake_monet_buffer.push_and_pop(fake_monet)\n",
    "            fake_loss_D_Y = criterion_GAN(D_Y(fake_monet_buffered.detach()), fake_label)\n",
    "            loss_D_Y = (real_loss_D_Y + fake_loss_D_Y) * 0.5\n",
    "            loss_D_Y.backward()\n",
    "            optimizer_D_Y.step()\n",
    "\n",
    "            # Print all losses\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch [{i}/{len(dataloader)}]\")\n",
    "                print(f\"Discriminator Losses:\")\n",
    "                print(f\"  D_X Real: {real_loss_D_X.item():.4f}, D_X Fake: {fake_loss_D_X.item():.4f}, D_X Total: {loss_D_X.item():.4f}\")\n",
    "                print(f\"  D_Y Real: {real_loss_D_Y.item():.4f}, D_Y Fake: {fake_loss_D_Y.item():.4f}, D_Y Total: {loss_D_Y.item():.4f}\")\n",
    "                print(f\"Generator Losses:\")\n",
    "                print(f\"  G Adv: {loss_G.item():.4f}, F Adv: {loss_F.item():.4f}\")\n",
    "                print(f\"  Cycle Photo: {loss_cycle_photo.item():.4f}, Cycle Monet: {loss_cycle_monet.item():.4f}\")\n",
    "                print(f\"  Perceptual Photo: {loss_perceptual_photo.item():.4f}, Perceptual Monet: {loss_perceptual_monet.item():.4f}\")\n",
    "                print(f\"  Total G Loss: {total_loss_G.item():.4f}\")\n",
    "\n",
    "        # Learning rate step\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_X.step()\n",
    "        lr_scheduler_D_Y.step()\n",
    "\n",
    "\n",
    "    # Save model checkpoints every 20 epochs\n",
    "        if epoch % 20 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'G_state_dict': G.state_dict(),\n",
    "                'F_state_dict': F.state_dict(),\n",
    "                'D_X_state_dict': D_X.state_dict(),\n",
    "                'D_Y_state_dict': D_Y.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_X_state_dict': optimizer_D_X.state_dict(),\n",
    "                'optimizer_D_Y_state_dict': optimizer_D_Y.state_dict(),\n",
    "            }, f\"{models_dir}/checkpoint_epoch_{epoch}.pth\")\n",
    "            print(f\"Saved checkpoint at epoch {epoch}\")\n",
    "\n",
    "    # Save final models\n",
    "    torch.save(G.state_dict(), f\"{output_dir}/G.pth\")\n",
    "    torch.save(F.state_dict(), f\"{output_dir}/F.pth\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Image Generation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(photo_dir, submission_dir, model_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((286, 286)),\n",
    "        transforms.RandomCrop((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    G = Generator().to(DEVICE)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    G.load_state_dict(checkpoint['G_state_dict'])\n",
    "    G.eval()\n",
    "\n",
    "    os.makedirs(submission_dir, exist_ok=True)\n",
    "    photos = sorted(os.listdir(photo_dir))\n",
    "\n",
    "    with torch.no_grad():\n",
    "     for i, photo_name in enumerate(photos[:1500]):  # Limit to first 1500 images\n",
    "         photo_path = os.path.join(photo_dir, photo_name)\n",
    "         photo = Image.open(photo_path).convert('RGB')\n",
    "         photo = transform(photo).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "         fake_monet = G(photo)\n",
    "         fake_monet = (fake_monet * 0.5 + 0.5).clamp(0, 1)  # Denormalize\n",
    "         img = transforms.ToPILImage()(fake_monet.squeeze(0).cpu()).convert('RGB')\n",
    "         img.save(f\"{submission_dir}/image_{i:04d}.jpg\", 'JPEG', quality=95)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 2.5162, D_X Fake: 1.4217, D_X Total: 1.9689\n",
      "  D_Y Real: 3.7201, D_Y Fake: 1.7277, D_Y Total: 2.7239\n",
      "Generator Losses:\n",
      "  G Adv: 3.6381, F Adv: 2.7290\n",
      "  Cycle Photo: 0.5885, Cycle Monet: 0.4899\n",
      "  Perceptual Photo: 0.8593, Perceptual Monet: 0.7638\n",
      "  Total G Loss: 25.2676\n",
      "Epoch [0/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2482, D_X Fake: 0.2374, D_X Total: 0.2428\n",
      "  D_Y Real: 0.3509, D_Y Fake: 0.1672, D_Y Total: 0.2590\n",
      "Generator Losses:\n",
      "  G Adv: 0.4380, F Adv: 0.3347\n",
      "  Cycle Photo: 0.2553, Cycle Monet: 0.2322\n",
      "  Perceptual Photo: 0.6317, Perceptual Monet: 0.4966\n",
      "  Total G Loss: 11.2887\n",
      "Epoch [0/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1693, D_X Fake: 0.2272, D_X Total: 0.1982\n",
      "  D_Y Real: 0.2334, D_Y Fake: 0.2788, D_Y Total: 0.2561\n",
      "Generator Losses:\n",
      "  G Adv: 0.3360, F Adv: 0.3305\n",
      "  Cycle Photo: 0.3167, Cycle Monet: 0.2567\n",
      "  Perceptual Photo: 0.5626, Perceptual Monet: 0.6078\n",
      "  Total G Loss: 12.2527\n",
      "Epoch [0/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2364, D_X Fake: 0.3109, D_X Total: 0.2737\n",
      "  D_Y Real: 0.1122, D_Y Fake: 0.1522, D_Y Total: 0.1322\n",
      "Generator Losses:\n",
      "  G Adv: 0.4722, F Adv: 0.5292\n",
      "  Cycle Photo: 0.2820, Cycle Monet: 0.1971\n",
      "  Perceptual Photo: 0.4989, Perceptual Monet: 0.5778\n",
      "  Total G Loss: 11.1755\n",
      "Epoch [0/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1907, D_X Fake: 0.2279, D_X Total: 0.2093\n",
      "  D_Y Real: 0.0941, D_Y Fake: 0.3858, D_Y Total: 0.2399\n",
      "Generator Losses:\n",
      "  G Adv: 0.1486, F Adv: 0.3517\n",
      "  Cycle Photo: 0.2589, Cycle Monet: 0.2049\n",
      "  Perceptual Photo: 0.5545, Perceptual Monet: 0.4922\n",
      "  Total G Loss: 10.3713\n",
      "Epoch [0/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2193, D_X Fake: 0.2656, D_X Total: 0.2424\n",
      "  D_Y Real: 0.2647, D_Y Fake: 0.0903, D_Y Total: 0.1775\n",
      "Generator Losses:\n",
      "  G Adv: 0.3838, F Adv: 0.3506\n",
      "  Cycle Photo: 0.2029, Cycle Monet: 0.1860\n",
      "  Perceptual Photo: 0.4889, Perceptual Monet: 0.5286\n",
      "  Total G Loss: 9.7110\n",
      "Epoch [0/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3065, D_X Fake: 0.1399, D_X Total: 0.2232\n",
      "  D_Y Real: 0.2103, D_Y Fake: 0.2087, D_Y Total: 0.2095\n",
      "Generator Losses:\n",
      "  G Adv: 0.3611, F Adv: 0.3517\n",
      "  Cycle Photo: 0.2213, Cycle Monet: 0.2565\n",
      "  Perceptual Photo: 0.4545, Perceptual Monet: 0.4863\n",
      "  Total G Loss: 10.1946\n",
      "Epoch [0/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1716, D_X Fake: 0.2581, D_X Total: 0.2148\n",
      "  D_Y Real: 0.1601, D_Y Fake: 0.1543, D_Y Total: 0.1572\n",
      "Generator Losses:\n",
      "  G Adv: 0.4458, F Adv: 0.3003\n",
      "  Cycle Photo: 0.2523, Cycle Monet: 0.1866\n",
      "  Perceptual Photo: 0.5126, Perceptual Monet: 0.4530\n",
      "  Total G Loss: 9.9628\n",
      "Epoch [0/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2665, D_X Fake: 0.2147, D_X Total: 0.2406\n",
      "  D_Y Real: 0.3245, D_Y Fake: 0.1190, D_Y Total: 0.2217\n",
      "Generator Losses:\n",
      "  G Adv: 0.5262, F Adv: 0.4662\n",
      "  Cycle Photo: 0.2035, Cycle Monet: 0.2408\n",
      "  Perceptual Photo: 0.5574, Perceptual Monet: 0.5100\n",
      "  Total G Loss: 10.7720\n",
      "Epoch [0/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1909, D_X Fake: 0.1578, D_X Total: 0.1743\n",
      "  D_Y Real: 0.1849, D_Y Fake: 0.2139, D_Y Total: 0.1994\n",
      "Generator Losses:\n",
      "  G Adv: 0.2882, F Adv: 0.4058\n",
      "  Cycle Photo: 0.2196, Cycle Monet: 0.2470\n",
      "  Perceptual Photo: 0.4622, Perceptual Monet: 0.4633\n",
      "  Total G Loss: 9.9875\n",
      "Epoch [0/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2635, D_X Fake: 0.1249, D_X Total: 0.1942\n",
      "  D_Y Real: 0.4365, D_Y Fake: 0.0767, D_Y Total: 0.2566\n",
      "Generator Losses:\n",
      "  G Adv: 0.5006, F Adv: 0.4822\n",
      "  Cycle Photo: 0.3009, Cycle Monet: 0.1779\n",
      "  Perceptual Photo: 0.4130, Perceptual Monet: 0.4565\n",
      "  Total G Loss: 10.1185\n",
      "Epoch [0/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2152, D_X Fake: 0.1975, D_X Total: 0.2063\n",
      "  D_Y Real: 0.4562, D_Y Fake: 0.1695, D_Y Total: 0.3129\n",
      "Generator Losses:\n",
      "  G Adv: 0.4455, F Adv: 0.3251\n",
      "  Cycle Photo: 0.2389, Cycle Monet: 0.1968\n",
      "  Perceptual Photo: 0.3965, Perceptual Monet: 0.4748\n",
      "  Total G Loss: 9.4838\n",
      "Epoch [0/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3508, D_X Fake: 0.5218, D_X Total: 0.4363\n",
      "  D_Y Real: 0.1003, D_Y Fake: 0.3245, D_Y Total: 0.2124\n",
      "Generator Losses:\n",
      "  G Adv: 0.2898, F Adv: 0.5484\n",
      "  Cycle Photo: 0.2547, Cycle Monet: 0.1921\n",
      "  Perceptual Photo: 0.4291, Perceptual Monet: 0.4413\n",
      "  Total G Loss: 9.6588\n",
      "Epoch [0/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1907, D_X Fake: 0.2433, D_X Total: 0.2170\n",
      "  D_Y Real: 0.3964, D_Y Fake: 0.3748, D_Y Total: 0.3856\n",
      "Generator Losses:\n",
      "  G Adv: 0.5782, F Adv: 0.2915\n",
      "  Cycle Photo: 0.1495, Cycle Monet: 0.2062\n",
      "  Perceptual Photo: 0.4731, Perceptual Monet: 0.5006\n",
      "  Total G Loss: 9.2951\n",
      "Epoch [0/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4445, D_X Fake: 0.1473, D_X Total: 0.2959\n",
      "  D_Y Real: 0.1130, D_Y Fake: 0.4595, D_Y Total: 0.2863\n",
      "Generator Losses:\n",
      "  G Adv: 0.1594, F Adv: 0.6554\n",
      "  Cycle Photo: 0.1580, Cycle Monet: 0.2254\n",
      "  Perceptual Photo: 0.5057, Perceptual Monet: 0.4679\n",
      "  Total G Loss: 9.5168\n",
      "Epoch [0/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2684, D_X Fake: 0.1644, D_X Total: 0.2164\n",
      "  D_Y Real: 0.2235, D_Y Fake: 0.1891, D_Y Total: 0.2063\n",
      "Generator Losses:\n",
      "  G Adv: 0.2951, F Adv: 0.4553\n",
      "  Cycle Photo: 0.1573, Cycle Monet: 0.1637\n",
      "  Perceptual Photo: 0.4000, Perceptual Monet: 0.4358\n",
      "  Total G Loss: 8.1394\n",
      "Epoch [0/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1628, D_X Fake: 0.1746, D_X Total: 0.1687\n",
      "  D_Y Real: 0.0777, D_Y Fake: 0.2455, D_Y Total: 0.1616\n",
      "Generator Losses:\n",
      "  G Adv: 0.3196, F Adv: 0.3649\n",
      "  Cycle Photo: 0.1923, Cycle Monet: 0.1896\n",
      "  Perceptual Photo: 0.4544, Perceptual Monet: 0.5159\n",
      "  Total G Loss: 9.3550\n",
      "Epoch [0/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2746, D_X Fake: 0.2237, D_X Total: 0.2491\n",
      "  D_Y Real: 0.1500, D_Y Fake: 0.1479, D_Y Total: 0.1489\n",
      "Generator Losses:\n",
      "  G Adv: 0.5193, F Adv: 0.3836\n",
      "  Cycle Photo: 0.1821, Cycle Monet: 0.1985\n",
      "  Perceptual Photo: 0.4188, Perceptual Monet: 0.3985\n",
      "  Total G Loss: 8.7955\n",
      "Epoch [0/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3718, D_X Fake: 0.1865, D_X Total: 0.2792\n",
      "  D_Y Real: 0.0769, D_Y Fake: 0.2573, D_Y Total: 0.1671\n",
      "Generator Losses:\n",
      "  G Adv: 0.1922, F Adv: 0.3649\n",
      "  Cycle Photo: 0.1726, Cycle Monet: 0.2391\n",
      "  Perceptual Photo: 0.3659, Perceptual Monet: 0.3723\n",
      "  Total G Loss: 8.3647\n",
      "Epoch [0/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5859, D_X Fake: 0.1168, D_X Total: 0.3513\n",
      "  D_Y Real: 0.2636, D_Y Fake: 0.2247, D_Y Total: 0.2441\n",
      "Generator Losses:\n",
      "  G Adv: 0.4080, F Adv: 0.8320\n",
      "  Cycle Photo: 0.2140, Cycle Monet: 0.1966\n",
      "  Perceptual Photo: 0.3636, Perceptual Monet: 0.4027\n",
      "  Total G Loss: 9.1777\n",
      "Epoch [0/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1792, D_X Fake: 0.1724, D_X Total: 0.1758\n",
      "  D_Y Real: 0.1498, D_Y Fake: 0.2569, D_Y Total: 0.2033\n",
      "Generator Losses:\n",
      "  G Adv: 0.2916, F Adv: 0.5804\n",
      "  Cycle Photo: 0.2173, Cycle Monet: 0.1613\n",
      "  Perceptual Photo: 0.3220, Perceptual Monet: 0.4391\n",
      "  Total G Loss: 8.4630\n",
      "Epoch [0/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5267, D_X Fake: 0.0428, D_X Total: 0.2847\n",
      "  D_Y Real: 0.1204, D_Y Fake: 0.2327, D_Y Total: 0.1766\n",
      "Generator Losses:\n",
      "  G Adv: 0.3325, F Adv: 0.7492\n",
      "  Cycle Photo: 0.1214, Cycle Monet: 0.2189\n",
      "  Perceptual Photo: 0.3277, Perceptual Monet: 0.3983\n",
      "  Total G Loss: 8.1156\n",
      "Epoch [0/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1673, D_X Fake: 0.0691, D_X Total: 0.1182\n",
      "  D_Y Real: 0.1628, D_Y Fake: 0.0984, D_Y Total: 0.1306\n",
      "Generator Losses:\n",
      "  G Adv: 0.7451, F Adv: 0.5558\n",
      "  Cycle Photo: 0.1858, Cycle Monet: 0.1992\n",
      "  Perceptual Photo: 0.3919, Perceptual Monet: 0.3541\n",
      "  Total G Loss: 8.8817\n",
      "Epoch [0/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2891, D_X Fake: 0.1028, D_X Total: 0.1959\n",
      "  D_Y Real: 0.1857, D_Y Fake: 0.1591, D_Y Total: 0.1724\n",
      "Generator Losses:\n",
      "  G Adv: 0.3474, F Adv: 0.3730\n",
      "  Cycle Photo: 0.1673, Cycle Monet: 0.2393\n",
      "  Perceptual Photo: 0.3374, Perceptual Monet: 0.4471\n",
      "  Total G Loss: 8.7096\n",
      "Saved checkpoint at epoch 0\n",
      "Epoch [1/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2540, D_X Fake: 0.1733, D_X Total: 0.2137\n",
      "  D_Y Real: 0.2294, D_Y Fake: 0.0753, D_Y Total: 0.1523\n",
      "Generator Losses:\n",
      "  G Adv: 0.3162, F Adv: 0.3354\n",
      "  Cycle Photo: 0.1361, Cycle Monet: 0.1711\n",
      "  Perceptual Photo: 0.5048, Perceptual Monet: 0.4095\n",
      "  Total G Loss: 8.2945\n",
      "Epoch [1/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4632, D_X Fake: 0.0936, D_X Total: 0.2784\n",
      "  D_Y Real: 0.2170, D_Y Fake: 0.1030, D_Y Total: 0.1600\n",
      "Generator Losses:\n",
      "  G Adv: 0.4017, F Adv: 0.5846\n",
      "  Cycle Photo: 0.1974, Cycle Monet: 0.1713\n",
      "  Perceptual Photo: 0.4136, Perceptual Monet: 0.4993\n",
      "  Total G Loss: 9.2380\n",
      "Epoch [1/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4795, D_X Fake: 0.0429, D_X Total: 0.2612\n",
      "  D_Y Real: 0.0699, D_Y Fake: 0.3752, D_Y Total: 0.2225\n",
      "Generator Losses:\n",
      "  G Adv: 0.2404, F Adv: 0.5553\n",
      "  Cycle Photo: 0.1833, Cycle Monet: 0.1501\n",
      "  Perceptual Photo: 0.4736, Perceptual Monet: 0.3928\n",
      "  Total G Loss: 8.4621\n",
      "Epoch [1/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2391, D_X Fake: 0.2874, D_X Total: 0.2632\n",
      "  D_Y Real: 0.3562, D_Y Fake: 0.1615, D_Y Total: 0.2589\n",
      "Generator Losses:\n",
      "  G Adv: 0.5239, F Adv: 0.3708\n",
      "  Cycle Photo: 0.1507, Cycle Monet: 0.1419\n",
      "  Perceptual Photo: 0.3708, Perceptual Monet: 0.3799\n",
      "  Total G Loss: 7.5736\n",
      "Epoch [1/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1132, D_X Fake: 0.1865, D_X Total: 0.1498\n",
      "  D_Y Real: 0.3408, D_Y Fake: 0.1172, D_Y Total: 0.2290\n",
      "Generator Losses:\n",
      "  G Adv: 0.7475, F Adv: 0.2844\n",
      "  Cycle Photo: 0.1850, Cycle Monet: 0.1728\n",
      "  Perceptual Photo: 0.3967, Perceptual Monet: 0.3884\n",
      "  Total G Loss: 8.5357\n",
      "Epoch [1/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3674, D_X Fake: 0.1643, D_X Total: 0.2659\n",
      "  D_Y Real: 0.0638, D_Y Fake: 0.2090, D_Y Total: 0.1364\n",
      "Generator Losses:\n",
      "  G Adv: 0.2599, F Adv: 0.3855\n",
      "  Cycle Photo: 0.1523, Cycle Monet: 0.1832\n",
      "  Perceptual Photo: 0.3500, Perceptual Monet: 0.3881\n",
      "  Total G Loss: 7.6920\n",
      "Epoch [1/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1205, D_X Fake: 0.1497, D_X Total: 0.1351\n",
      "  D_Y Real: 0.2161, D_Y Fake: 0.2583, D_Y Total: 0.2372\n",
      "Generator Losses:\n",
      "  G Adv: 0.4470, F Adv: 0.3901\n",
      "  Cycle Photo: 0.1980, Cycle Monet: 0.1895\n",
      "  Perceptual Photo: 0.3455, Perceptual Monet: 0.4689\n",
      "  Total G Loss: 8.7842\n",
      "Epoch [1/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0474, D_X Fake: 0.3999, D_X Total: 0.2237\n",
      "  D_Y Real: 0.1827, D_Y Fake: 0.1069, D_Y Total: 0.1448\n",
      "Generator Losses:\n",
      "  G Adv: 0.4911, F Adv: 0.1623\n",
      "  Cycle Photo: 0.2136, Cycle Monet: 0.1308\n",
      "  Perceptual Photo: 0.3972, Perceptual Monet: 0.4388\n",
      "  Total G Loss: 8.2775\n",
      "Epoch [1/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1490, D_X Fake: 0.3566, D_X Total: 0.2528\n",
      "  D_Y Real: 0.6826, D_Y Fake: 0.0666, D_Y Total: 0.3746\n",
      "Generator Losses:\n",
      "  G Adv: 0.6789, F Adv: 0.2496\n",
      "  Cycle Photo: 0.1098, Cycle Monet: 0.1121\n",
      "  Perceptual Photo: 0.3557, Perceptual Monet: 0.4099\n",
      "  Total G Loss: 6.9755\n",
      "Epoch [1/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4455, D_X Fake: 0.0287, D_X Total: 0.2371\n",
      "  D_Y Real: 0.0912, D_Y Fake: 0.1917, D_Y Total: 0.1414\n",
      "Generator Losses:\n",
      "  G Adv: 0.2444, F Adv: 1.1047\n",
      "  Cycle Photo: 0.1828, Cycle Monet: 0.1785\n",
      "  Perceptual Photo: 0.3360, Perceptual Monet: 0.4005\n",
      "  Total G Loss: 8.6447\n",
      "Epoch [1/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2717, D_X Fake: 0.2824, D_X Total: 0.2770\n",
      "  D_Y Real: 0.4946, D_Y Fake: 0.0664, D_Y Total: 0.2805\n",
      "Generator Losses:\n",
      "  G Adv: 0.5469, F Adv: 0.5061\n",
      "  Cycle Photo: 0.1255, Cycle Monet: 0.1470\n",
      "  Perceptual Photo: 0.3810, Perceptual Monet: 0.4462\n",
      "  Total G Loss: 7.9142\n",
      "Epoch [1/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0706, D_X Fake: 0.3285, D_X Total: 0.1995\n",
      "  D_Y Real: 0.1599, D_Y Fake: 0.1819, D_Y Total: 0.1709\n",
      "Generator Losses:\n",
      "  G Adv: 0.2986, F Adv: 0.2064\n",
      "  Cycle Photo: 0.2046, Cycle Monet: 0.1110\n",
      "  Perceptual Photo: 0.4298, Perceptual Monet: 0.4029\n",
      "  Total G Loss: 7.8247\n",
      "Epoch [1/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0872, D_X Fake: 0.3504, D_X Total: 0.2188\n",
      "  D_Y Real: 0.3624, D_Y Fake: 0.3100, D_Y Total: 0.3362\n",
      "Generator Losses:\n",
      "  G Adv: 0.6837, F Adv: 0.1877\n",
      "  Cycle Photo: 0.1898, Cycle Monet: 0.1782\n",
      "  Perceptual Photo: 0.4095, Perceptual Monet: 0.3794\n",
      "  Total G Loss: 8.4969\n",
      "Epoch [1/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2674, D_X Fake: 0.2010, D_X Total: 0.2342\n",
      "  D_Y Real: 0.2415, D_Y Fake: 0.0383, D_Y Total: 0.1399\n",
      "Generator Losses:\n",
      "  G Adv: 0.5231, F Adv: 0.4916\n",
      "  Cycle Photo: 0.1545, Cycle Monet: 0.1043\n",
      "  Perceptual Photo: 0.3696, Perceptual Monet: 0.3653\n",
      "  Total G Loss: 7.2771\n",
      "Epoch [1/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2275, D_X Fake: 0.0941, D_X Total: 0.1608\n",
      "  D_Y Real: 0.3578, D_Y Fake: 0.0400, D_Y Total: 0.1989\n",
      "Generator Losses:\n",
      "  G Adv: 0.7063, F Adv: 0.4932\n",
      "  Cycle Photo: 0.1399, Cycle Monet: 0.1490\n",
      "  Perceptual Photo: 0.3621, Perceptual Monet: 0.4166\n",
      "  Total G Loss: 7.9821\n",
      "Epoch [1/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1487, D_X Fake: 0.2813, D_X Total: 0.2150\n",
      "  D_Y Real: 0.1867, D_Y Fake: 0.3381, D_Y Total: 0.2624\n",
      "Generator Losses:\n",
      "  G Adv: 0.2026, F Adv: 0.2691\n",
      "  Cycle Photo: 0.1663, Cycle Monet: 0.1452\n",
      "  Perceptual Photo: 0.2717, Perceptual Monet: 0.2955\n",
      "  Total G Loss: 6.4233\n",
      "Epoch [1/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0982, D_X Fake: 0.4953, D_X Total: 0.2968\n",
      "  D_Y Real: 0.1522, D_Y Fake: 0.2590, D_Y Total: 0.2056\n",
      "Generator Losses:\n",
      "  G Adv: 0.1590, F Adv: 0.1105\n",
      "  Cycle Photo: 0.2247, Cycle Monet: 0.1998\n",
      "  Perceptual Photo: 0.3428, Perceptual Monet: 0.4030\n",
      "  Total G Loss: 8.2436\n",
      "Epoch [1/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2588, D_X Fake: 0.1576, D_X Total: 0.2082\n",
      "  D_Y Real: 0.0852, D_Y Fake: 0.2613, D_Y Total: 0.1733\n",
      "Generator Losses:\n",
      "  G Adv: 0.2602, F Adv: 0.3940\n",
      "  Cycle Photo: 0.2223, Cycle Monet: 0.1333\n",
      "  Perceptual Photo: 0.3695, Perceptual Monet: 0.4450\n",
      "  Total G Loss: 8.2837\n",
      "Epoch [1/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1311, D_X Fake: 0.0717, D_X Total: 0.1014\n",
      "  D_Y Real: 0.0900, D_Y Fake: 0.1263, D_Y Total: 0.1082\n",
      "Generator Losses:\n",
      "  G Adv: 0.1676, F Adv: 0.3866\n",
      "  Cycle Photo: 0.1788, Cycle Monet: 0.1378\n",
      "  Perceptual Photo: 0.3353, Perceptual Monet: 0.3930\n",
      "  Total G Loss: 7.3615\n",
      "Epoch [1/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2392, D_X Fake: 0.0596, D_X Total: 0.1494\n",
      "  D_Y Real: 0.5695, D_Y Fake: 0.0564, D_Y Total: 0.3130\n",
      "Generator Losses:\n",
      "  G Adv: 0.7924, F Adv: 0.3663\n",
      "  Cycle Photo: 0.1858, Cycle Monet: 0.1602\n",
      "  Perceptual Photo: 0.4972, Perceptual Monet: 0.3417\n",
      "  Total G Loss: 8.8126\n",
      "Epoch [1/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2598, D_X Fake: 0.2925, D_X Total: 0.2762\n",
      "  D_Y Real: 0.1338, D_Y Fake: 0.4994, D_Y Total: 0.3166\n",
      "Generator Losses:\n",
      "  G Adv: 0.1562, F Adv: 0.1384\n",
      "  Cycle Photo: 0.1882, Cycle Monet: 0.1227\n",
      "  Perceptual Photo: 0.3536, Perceptual Monet: 0.3277\n",
      "  Total G Loss: 6.8099\n",
      "Epoch [1/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2664, D_X Fake: 0.2646, D_X Total: 0.2655\n",
      "  D_Y Real: 0.2433, D_Y Fake: 0.1463, D_Y Total: 0.1948\n",
      "Generator Losses:\n",
      "  G Adv: 0.4071, F Adv: 0.3539\n",
      "  Cycle Photo: 0.1502, Cycle Monet: 0.1618\n",
      "  Perceptual Photo: 0.3945, Perceptual Monet: 0.3282\n",
      "  Total G Loss: 7.4946\n",
      "Epoch [1/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1115, D_X Fake: 0.6527, D_X Total: 0.3821\n",
      "  D_Y Real: 0.2806, D_Y Fake: 0.0674, D_Y Total: 0.1740\n",
      "Generator Losses:\n",
      "  G Adv: 0.7301, F Adv: 0.1027\n",
      "  Cycle Photo: 0.1305, Cycle Monet: 0.1348\n",
      "  Perceptual Photo: 0.2750, Perceptual Monet: 0.4559\n",
      "  Total G Loss: 7.1398\n",
      "Epoch [1/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2675, D_X Fake: 0.1875, D_X Total: 0.2275\n",
      "  D_Y Real: 0.0760, D_Y Fake: 0.1946, D_Y Total: 0.1353\n",
      "Generator Losses:\n",
      "  G Adv: 0.3647, F Adv: 0.4769\n",
      "  Cycle Photo: 0.1397, Cycle Monet: 0.1316\n",
      "  Perceptual Photo: 0.3013, Perceptual Monet: 0.3453\n",
      "  Total G Loss: 6.7875\n",
      "Epoch [2/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1137, D_X Fake: 0.2531, D_X Total: 0.1834\n",
      "  D_Y Real: 0.2315, D_Y Fake: 0.1846, D_Y Total: 0.2080\n",
      "Generator Losses:\n",
      "  G Adv: 0.4552, F Adv: 0.2986\n",
      "  Cycle Photo: 0.2051, Cycle Monet: 0.1091\n",
      "  Perceptual Photo: 0.5140, Perceptual Monet: 0.4260\n",
      "  Total G Loss: 8.5961\n",
      "Epoch [2/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1968, D_X Fake: 0.0838, D_X Total: 0.1403\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.3476, D_Y Total: 0.1961\n",
      "Generator Losses:\n",
      "  G Adv: 0.1467, F Adv: 0.5147\n",
      "  Cycle Photo: 0.2319, Cycle Monet: 0.1161\n",
      "  Perceptual Photo: 0.3615, Perceptual Monet: 0.3992\n",
      "  Total G Loss: 7.9458\n",
      "Epoch [2/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3675, D_X Fake: 0.0945, D_X Total: 0.2310\n",
      "  D_Y Real: 0.0633, D_Y Fake: 0.2514, D_Y Total: 0.1573\n",
      "Generator Losses:\n",
      "  G Adv: 0.2591, F Adv: 0.5354\n",
      "  Cycle Photo: 0.0937, Cycle Monet: 0.1386\n",
      "  Perceptual Photo: 0.2944, Perceptual Monet: 0.4402\n",
      "  Total G Loss: 6.7905\n",
      "Epoch [2/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1030, D_X Fake: 0.1769, D_X Total: 0.1400\n",
      "  D_Y Real: 0.2088, D_Y Fake: 0.1057, D_Y Total: 0.1573\n",
      "Generator Losses:\n",
      "  G Adv: 0.5715, F Adv: 0.3524\n",
      "  Cycle Photo: 0.1942, Cycle Monet: 0.1153\n",
      "  Perceptual Photo: 0.2667, Perceptual Monet: 0.3861\n",
      "  Total G Loss: 7.2834\n",
      "Epoch [2/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2153, D_X Fake: 0.2369, D_X Total: 0.2261\n",
      "  D_Y Real: 0.0905, D_Y Fake: 0.1787, D_Y Total: 0.1346\n",
      "Generator Losses:\n",
      "  G Adv: 0.2034, F Adv: 0.3756\n",
      "  Cycle Photo: 0.1373, Cycle Monet: 0.1361\n",
      "  Perceptual Photo: 0.2932, Perceptual Monet: 0.3671\n",
      "  Total G Loss: 6.6150\n",
      "Epoch [2/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1739, D_X Fake: 0.0792, D_X Total: 0.1265\n",
      "  D_Y Real: 0.4247, D_Y Fake: 0.0453, D_Y Total: 0.2350\n",
      "Generator Losses:\n",
      "  G Adv: 0.6532, F Adv: 0.3308\n",
      "  Cycle Photo: 0.1326, Cycle Monet: 0.1312\n",
      "  Perceptual Photo: 0.3466, Perceptual Monet: 0.3867\n",
      "  Total G Loss: 7.2892\n",
      "Epoch [2/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3026, D_X Fake: 0.0751, D_X Total: 0.1889\n",
      "  D_Y Real: 0.2534, D_Y Fake: 0.1317, D_Y Total: 0.1926\n",
      "Generator Losses:\n",
      "  G Adv: 0.3838, F Adv: 0.5665\n",
      "  Cycle Photo: 0.1124, Cycle Monet: 0.0984\n",
      "  Perceptual Photo: 0.3724, Perceptual Monet: 0.3582\n",
      "  Total G Loss: 6.7115\n",
      "Epoch [2/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1831, D_X Fake: 0.1173, D_X Total: 0.1502\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.2501, D_Y Total: 0.1457\n",
      "Generator Losses:\n",
      "  G Adv: 0.2522, F Adv: 0.3634\n",
      "  Cycle Photo: 0.1455, Cycle Monet: 0.1704\n",
      "  Perceptual Photo: 0.3274, Perceptual Monet: 0.2780\n",
      "  Total G Loss: 6.8021\n",
      "Epoch [2/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3316, D_X Fake: 0.0731, D_X Total: 0.2024\n",
      "  D_Y Real: 0.1629, D_Y Fake: 0.1873, D_Y Total: 0.1751\n",
      "Generator Losses:\n",
      "  G Adv: 0.2361, F Adv: 0.4880\n",
      "  Cycle Photo: 0.1029, Cycle Monet: 0.1296\n",
      "  Perceptual Photo: 0.3277, Perceptual Monet: 0.3462\n",
      "  Total G Loss: 6.4186\n",
      "Epoch [2/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3304, D_X Fake: 0.2805, D_X Total: 0.3055\n",
      "  D_Y Real: 0.0859, D_Y Fake: 0.2184, D_Y Total: 0.1521\n",
      "Generator Losses:\n",
      "  G Adv: 0.2469, F Adv: 0.3053\n",
      "  Cycle Photo: 0.0993, Cycle Monet: 0.1386\n",
      "  Perceptual Photo: 0.2971, Perceptual Monet: 0.3653\n",
      "  Total G Loss: 6.2430\n",
      "Epoch [2/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0488, D_X Fake: 0.4970, D_X Total: 0.2729\n",
      "  D_Y Real: 0.2984, D_Y Fake: 0.0325, D_Y Total: 0.1654\n",
      "Generator Losses:\n",
      "  G Adv: 0.8007, F Adv: 0.1784\n",
      "  Cycle Photo: 0.2177, Cycle Monet: 0.1334\n",
      "  Perceptual Photo: 0.2808, Perceptual Monet: 0.3113\n",
      "  Total G Loss: 7.4507\n",
      "Epoch [2/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2404, D_X Fake: 0.1416, D_X Total: 0.1910\n",
      "  D_Y Real: 0.2447, D_Y Fake: 0.1137, D_Y Total: 0.1792\n",
      "Generator Losses:\n",
      "  G Adv: 0.4782, F Adv: 0.4637\n",
      "  Cycle Photo: 0.1616, Cycle Monet: 0.1523\n",
      "  Perceptual Photo: 0.3858, Perceptual Monet: 0.4693\n",
      "  Total G Loss: 8.3565\n",
      "Epoch [2/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2742, D_X Fake: 0.3167, D_X Total: 0.2955\n",
      "  D_Y Real: 0.2308, D_Y Fake: 0.0243, D_Y Total: 0.1275\n",
      "Generator Losses:\n",
      "  G Adv: 0.2790, F Adv: 0.2147\n",
      "  Cycle Photo: 0.1160, Cycle Monet: 0.0900\n",
      "  Perceptual Photo: 0.3697, Perceptual Monet: 0.3447\n",
      "  Total G Loss: 6.1267\n",
      "Epoch [2/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0693, D_X Fake: 0.4026, D_X Total: 0.2359\n",
      "  D_Y Real: 0.1216, D_Y Fake: 0.1743, D_Y Total: 0.1479\n",
      "Generator Losses:\n",
      "  G Adv: 0.3070, F Adv: 0.2833\n",
      "  Cycle Photo: 0.1472, Cycle Monet: 0.1526\n",
      "  Perceptual Photo: 0.3286, Perceptual Monet: 0.3678\n",
      "  Total G Loss: 7.0698\n",
      "Epoch [2/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2415, D_X Fake: 0.0374, D_X Total: 0.1394\n",
      "  D_Y Real: 0.2960, D_Y Fake: 0.1667, D_Y Total: 0.2313\n",
      "Generator Losses:\n",
      "  G Adv: 0.4493, F Adv: 0.5746\n",
      "  Cycle Photo: 0.1206, Cycle Monet: 0.1177\n",
      "  Perceptual Photo: 0.5119, Perceptual Monet: 0.3711\n",
      "  Total G Loss: 7.8218\n",
      "Epoch [2/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1375, D_X Fake: 0.1709, D_X Total: 0.1542\n",
      "  D_Y Real: 0.2575, D_Y Fake: 0.2046, D_Y Total: 0.2310\n",
      "Generator Losses:\n",
      "  G Adv: 0.4816, F Adv: 0.3705\n",
      "  Cycle Photo: 0.1150, Cycle Monet: 0.1445\n",
      "  Perceptual Photo: 0.3086, Perceptual Monet: 0.4294\n",
      "  Total G Loss: 7.1371\n",
      "Epoch [2/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4190, D_X Fake: 0.0714, D_X Total: 0.2452\n",
      "  D_Y Real: 0.2346, D_Y Fake: 0.1478, D_Y Total: 0.1912\n",
      "Generator Losses:\n",
      "  G Adv: 0.3985, F Adv: 0.4726\n",
      "  Cycle Photo: 0.1339, Cycle Monet: 0.1569\n",
      "  Perceptual Photo: 0.3395, Perceptual Monet: 0.4044\n",
      "  Total G Loss: 7.4988\n",
      "Epoch [2/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2035, D_X Fake: 0.1362, D_X Total: 0.1699\n",
      "  D_Y Real: 0.2856, D_Y Fake: 0.1191, D_Y Total: 0.2023\n",
      "Generator Losses:\n",
      "  G Adv: 0.6440, F Adv: 0.5389\n",
      "  Cycle Photo: 0.1137, Cycle Monet: 0.1016\n",
      "  Perceptual Photo: 0.3812, Perceptual Monet: 0.3759\n",
      "  Total G Loss: 7.1218\n",
      "Epoch [2/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2695, D_X Fake: 0.1461, D_X Total: 0.2078\n",
      "  D_Y Real: 0.2497, D_Y Fake: 0.0367, D_Y Total: 0.1432\n",
      "Generator Losses:\n",
      "  G Adv: 0.2425, F Adv: 0.2744\n",
      "  Cycle Photo: 0.1312, Cycle Monet: 0.0932\n",
      "  Perceptual Photo: 0.3355, Perceptual Monet: 0.3500\n",
      "  Total G Loss: 6.1881\n",
      "Epoch [2/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1127, D_X Fake: 0.3768, D_X Total: 0.2447\n",
      "  D_Y Real: 0.1011, D_Y Fake: 0.1185, D_Y Total: 0.1098\n",
      "Generator Losses:\n",
      "  G Adv: 0.4430, F Adv: 0.1089\n",
      "  Cycle Photo: 0.0887, Cycle Monet: 0.1332\n",
      "  Perceptual Photo: 0.3219, Perceptual Monet: 0.3406\n",
      "  Total G Loss: 6.0835\n",
      "Epoch [2/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0456, D_X Fake: 0.2259, D_X Total: 0.1358\n",
      "  D_Y Real: 0.0758, D_Y Fake: 0.0895, D_Y Total: 0.0827\n",
      "Generator Losses:\n",
      "  G Adv: 0.6249, F Adv: 0.1967\n",
      "  Cycle Photo: 0.1128, Cycle Monet: 0.1800\n",
      "  Perceptual Photo: 0.3337, Perceptual Monet: 0.3457\n",
      "  Total G Loss: 7.1463\n",
      "Epoch [2/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0440, D_X Fake: 0.3521, D_X Total: 0.1980\n",
      "  D_Y Real: 0.2829, D_Y Fake: 0.0575, D_Y Total: 0.1702\n",
      "Generator Losses:\n",
      "  G Adv: 0.7305, F Adv: 0.1894\n",
      "  Cycle Photo: 0.1223, Cycle Monet: 0.1012\n",
      "  Perceptual Photo: 0.2503, Perceptual Monet: 0.3355\n",
      "  Total G Loss: 6.0839\n",
      "Epoch [2/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1746, D_X Fake: 0.1316, D_X Total: 0.1531\n",
      "  D_Y Real: 0.0762, D_Y Fake: 0.1625, D_Y Total: 0.1193\n",
      "Generator Losses:\n",
      "  G Adv: 0.2761, F Adv: 0.2380\n",
      "  Cycle Photo: 0.0999, Cycle Monet: 0.1531\n",
      "  Perceptual Photo: 0.3413, Perceptual Monet: 0.3286\n",
      "  Total G Loss: 6.3935\n",
      "Epoch [2/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1931, D_X Fake: 0.4389, D_X Total: 0.3160\n",
      "  D_Y Real: 0.1380, D_Y Fake: 0.0826, D_Y Total: 0.1103\n",
      "Generator Losses:\n",
      "  G Adv: 0.6526, F Adv: 0.2118\n",
      "  Cycle Photo: 0.1069, Cycle Monet: 0.1104\n",
      "  Perceptual Photo: 0.3177, Perceptual Monet: 0.3611\n",
      "  Total G Loss: 6.4307\n",
      "Epoch [3/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1583, D_X Fake: 0.2572, D_X Total: 0.2078\n",
      "  D_Y Real: 0.0780, D_Y Fake: 0.1882, D_Y Total: 0.1331\n",
      "Generator Losses:\n",
      "  G Adv: 0.2701, F Adv: 0.2668\n",
      "  Cycle Photo: 0.1487, Cycle Monet: 0.1578\n",
      "  Perceptual Photo: 0.4216, Perceptual Monet: 0.3764\n",
      "  Total G Loss: 7.5917\n",
      "Epoch [3/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2830, D_X Fake: 0.0213, D_X Total: 0.1522\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.3893, D_Y Total: 0.2287\n",
      "Generator Losses:\n",
      "  G Adv: 0.1140, F Adv: 0.3791\n",
      "  Cycle Photo: 0.1040, Cycle Monet: 0.1278\n",
      "  Perceptual Photo: 0.3181, Perceptual Monet: 0.3267\n",
      "  Total G Loss: 6.0352\n",
      "Epoch [3/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2644, D_X Fake: 0.0725, D_X Total: 0.1685\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.2664, D_Y Total: 0.1532\n",
      "Generator Losses:\n",
      "  G Adv: 0.2673, F Adv: 0.5462\n",
      "  Cycle Photo: 0.1264, Cycle Monet: 0.1440\n",
      "  Perceptual Photo: 0.2932, Perceptual Monet: 0.3080\n",
      "  Total G Loss: 6.5234\n",
      "Epoch [3/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2075, D_X Fake: 0.1916, D_X Total: 0.1996\n",
      "  D_Y Real: 0.1707, D_Y Fake: 0.0456, D_Y Total: 0.1081\n",
      "Generator Losses:\n",
      "  G Adv: 0.5497, F Adv: 0.3248\n",
      "  Cycle Photo: 0.1140, Cycle Monet: 0.1631\n",
      "  Perceptual Photo: 0.3137, Perceptual Monet: 0.2948\n",
      "  Total G Loss: 6.6884\n",
      "Epoch [3/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0416, D_X Fake: 0.1176, D_X Total: 0.0796\n",
      "  D_Y Real: 0.2025, D_Y Fake: 0.1406, D_Y Total: 0.1715\n",
      "Generator Losses:\n",
      "  G Adv: 0.6253, F Adv: 0.3725\n",
      "  Cycle Photo: 0.1445, Cycle Monet: 0.1269\n",
      "  Perceptual Photo: 0.2714, Perceptual Monet: 0.3902\n",
      "  Total G Loss: 7.0201\n",
      "Epoch [3/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4507, D_X Fake: 0.0291, D_X Total: 0.2399\n",
      "  D_Y Real: 0.1524, D_Y Fake: 0.1626, D_Y Total: 0.1575\n",
      "Generator Losses:\n",
      "  G Adv: 0.4152, F Adv: 0.8896\n",
      "  Cycle Photo: 0.1350, Cycle Monet: 0.0934\n",
      "  Perceptual Photo: 0.3480, Perceptual Monet: 0.3659\n",
      "  Total G Loss: 7.1580\n",
      "Epoch [3/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0969, D_X Fake: 0.8036, D_X Total: 0.4503\n",
      "  D_Y Real: 0.0550, D_Y Fake: 0.2660, D_Y Total: 0.1605\n",
      "Generator Losses:\n",
      "  G Adv: 0.2095, F Adv: 0.0857\n",
      "  Cycle Photo: 0.1027, Cycle Monet: 0.1216\n",
      "  Perceptual Photo: 0.3510, Perceptual Monet: 0.3086\n",
      "  Total G Loss: 5.8363\n",
      "Epoch [3/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1708, D_X Fake: 0.1234, D_X Total: 0.1471\n",
      "  D_Y Real: 0.3196, D_Y Fake: 0.1745, D_Y Total: 0.2471\n",
      "Generator Losses:\n",
      "  G Adv: 0.6862, F Adv: 0.3790\n",
      "  Cycle Photo: 0.0851, Cycle Monet: 0.1400\n",
      "  Perceptual Photo: 0.2731, Perceptual Monet: 0.3611\n",
      "  Total G Loss: 6.4879\n",
      "Epoch [3/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2226, D_X Fake: 0.1312, D_X Total: 0.1769\n",
      "  D_Y Real: 0.1128, D_Y Fake: 0.2696, D_Y Total: 0.1912\n",
      "Generator Losses:\n",
      "  G Adv: 0.2448, F Adv: 0.3033\n",
      "  Cycle Photo: 0.1455, Cycle Monet: 0.0790\n",
      "  Perceptual Photo: 0.3104, Perceptual Monet: 0.3519\n",
      "  Total G Loss: 6.1039\n",
      "Epoch [3/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0659, D_X Fake: 0.3020, D_X Total: 0.1839\n",
      "  D_Y Real: 0.2874, D_Y Fake: 0.1089, D_Y Total: 0.1981\n",
      "Generator Losses:\n",
      "  G Adv: 0.4008, F Adv: 0.1738\n",
      "  Cycle Photo: 0.1015, Cycle Monet: 0.1328\n",
      "  Perceptual Photo: 0.3086, Perceptual Monet: 0.3591\n",
      "  Total G Loss: 6.2560\n",
      "Epoch [3/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1491, D_X Fake: 0.0580, D_X Total: 0.1036\n",
      "  D_Y Real: 0.1394, D_Y Fake: 0.0762, D_Y Total: 0.1078\n",
      "Generator Losses:\n",
      "  G Adv: 0.3714, F Adv: 0.6195\n",
      "  Cycle Photo: 0.1077, Cycle Monet: 0.1160\n",
      "  Perceptual Photo: 0.2492, Perceptual Monet: 0.3363\n",
      "  Total G Loss: 6.1559\n",
      "Epoch [3/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2567, D_X Fake: 0.2477, D_X Total: 0.2522\n",
      "  D_Y Real: 0.0606, D_Y Fake: 0.3119, D_Y Total: 0.1863\n",
      "Generator Losses:\n",
      "  G Adv: 0.3543, F Adv: 0.3091\n",
      "  Cycle Photo: 0.1091, Cycle Monet: 0.0941\n",
      "  Perceptual Photo: 0.3308, Perceptual Monet: 0.3737\n",
      "  Total G Loss: 6.2181\n",
      "Epoch [3/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2351, D_X Fake: 0.1571, D_X Total: 0.1961\n",
      "  D_Y Real: 0.0868, D_Y Fake: 0.2413, D_Y Total: 0.1641\n",
      "Generator Losses:\n",
      "  G Adv: 0.1884, F Adv: 0.4542\n",
      "  Cycle Photo: 0.0946, Cycle Monet: 0.0946\n",
      "  Perceptual Photo: 0.2733, Perceptual Monet: 0.3300\n",
      "  Total G Loss: 5.5509\n",
      "Epoch [3/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1521, D_X Fake: 0.0872, D_X Total: 0.1196\n",
      "  D_Y Real: 0.2702, D_Y Fake: 0.1635, D_Y Total: 0.2168\n",
      "Generator Losses:\n",
      "  G Adv: 0.4011, F Adv: 0.3324\n",
      "  Cycle Photo: 0.1198, Cycle Monet: 0.1168\n",
      "  Perceptual Photo: 0.4212, Perceptual Monet: 0.2612\n",
      "  Total G Loss: 6.5118\n",
      "Epoch [3/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1233, D_X Fake: 0.1025, D_X Total: 0.1129\n",
      "  D_Y Real: 0.2572, D_Y Fake: 0.0747, D_Y Total: 0.1660\n",
      "Generator Losses:\n",
      "  G Adv: 0.5241, F Adv: 0.2935\n",
      "  Cycle Photo: 0.1364, Cycle Monet: 0.0981\n",
      "  Perceptual Photo: 0.3239, Perceptual Monet: 0.3382\n",
      "  Total G Loss: 6.4727\n",
      "Epoch [3/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1479, D_X Fake: 0.1041, D_X Total: 0.1260\n",
      "  D_Y Real: 0.0705, D_Y Fake: 0.2010, D_Y Total: 0.1357\n",
      "Generator Losses:\n",
      "  G Adv: 0.1679, F Adv: 0.1946\n",
      "  Cycle Photo: 0.1519, Cycle Monet: 0.0859\n",
      "  Perceptual Photo: 0.3715, Perceptual Monet: 0.3735\n",
      "  Total G Loss: 6.4651\n",
      "Epoch [3/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1992, D_X Fake: 0.0937, D_X Total: 0.1464\n",
      "  D_Y Real: 0.1748, D_Y Fake: 0.2076, D_Y Total: 0.1912\n",
      "Generator Losses:\n",
      "  G Adv: 0.2795, F Adv: 0.4280\n",
      "  Cycle Photo: 0.1110, Cycle Monet: 0.1203\n",
      "  Perceptual Photo: 0.3046, Perceptual Monet: 0.3754\n",
      "  Total G Loss: 6.4206\n",
      "Epoch [3/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1926, D_X Fake: 0.1182, D_X Total: 0.1554\n",
      "  D_Y Real: 0.2033, D_Y Fake: 0.1592, D_Y Total: 0.1813\n",
      "Generator Losses:\n",
      "  G Adv: 0.3561, F Adv: 0.3728\n",
      "  Cycle Photo: 0.1736, Cycle Monet: 0.1096\n",
      "  Perceptual Photo: 0.3435, Perceptual Monet: 0.3286\n",
      "  Total G Loss: 6.9223\n",
      "Epoch [3/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1629, D_X Fake: 0.1013, D_X Total: 0.1321\n",
      "  D_Y Real: 0.3138, D_Y Fake: 0.0387, D_Y Total: 0.1762\n",
      "Generator Losses:\n",
      "  G Adv: 0.6936, F Adv: 0.4741\n",
      "  Cycle Photo: 0.1078, Cycle Monet: 0.1733\n",
      "  Perceptual Photo: 0.2351, Perceptual Monet: 0.4294\n",
      "  Total G Loss: 7.3019\n",
      "Epoch [3/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3316, D_X Fake: 0.0927, D_X Total: 0.2121\n",
      "  D_Y Real: 0.1202, D_Y Fake: 0.0717, D_Y Total: 0.0960\n",
      "Generator Losses:\n",
      "  G Adv: 0.4777, F Adv: 0.6831\n",
      "  Cycle Photo: 0.1318, Cycle Monet: 0.1147\n",
      "  Perceptual Photo: 0.2967, Perceptual Monet: 0.3783\n",
      "  Total G Loss: 7.0003\n",
      "Epoch [3/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3153, D_X Fake: 0.0319, D_X Total: 0.1736\n",
      "  D_Y Real: 0.0734, D_Y Fake: 0.3024, D_Y Total: 0.1879\n",
      "Generator Losses:\n",
      "  G Adv: 0.1650, F Adv: 0.7034\n",
      "  Cycle Photo: 0.1615, Cycle Monet: 0.1534\n",
      "  Perceptual Photo: 0.3584, Perceptual Monet: 0.3093\n",
      "  Total G Loss: 7.3565\n",
      "Epoch [3/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3545, D_X Fake: 0.0538, D_X Total: 0.2041\n",
      "  D_Y Real: 0.0659, D_Y Fake: 0.3843, D_Y Total: 0.2251\n",
      "Generator Losses:\n",
      "  G Adv: 0.1282, F Adv: 0.5008\n",
      "  Cycle Photo: 0.1150, Cycle Monet: 0.1048\n",
      "  Perceptual Photo: 0.3134, Perceptual Monet: 0.3179\n",
      "  Total G Loss: 5.9836\n",
      "Epoch [3/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1298, D_X Fake: 0.2250, D_X Total: 0.1774\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.3754, D_Y Total: 0.2076\n",
      "Generator Losses:\n",
      "  G Adv: 0.1139, F Adv: 0.2279\n",
      "  Cycle Photo: 0.1111, Cycle Monet: 0.0878\n",
      "  Perceptual Photo: 0.2470, Perceptual Monet: 0.3071\n",
      "  Total G Loss: 5.1010\n",
      "Epoch [3/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3996, D_X Fake: 0.0612, D_X Total: 0.2304\n",
      "  D_Y Real: 0.1197, D_Y Fake: 0.1240, D_Y Total: 0.1219\n",
      "Generator Losses:\n",
      "  G Adv: 0.3052, F Adv: 0.5086\n",
      "  Cycle Photo: 0.1187, Cycle Monet: 0.0886\n",
      "  Perceptual Photo: 0.2882, Perceptual Monet: 0.3241\n",
      "  Total G Loss: 5.9478\n",
      "Epoch [4/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1987, D_X Fake: 0.1472, D_X Total: 0.1729\n",
      "  D_Y Real: 0.2483, D_Y Fake: 0.0568, D_Y Total: 0.1526\n",
      "Generator Losses:\n",
      "  G Adv: 0.1804, F Adv: 0.4113\n",
      "  Cycle Photo: 0.0791, Cycle Monet: 0.1031\n",
      "  Perceptual Photo: 0.3555, Perceptual Monet: 0.3564\n",
      "  Total G Loss: 5.9727\n",
      "Epoch [4/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0783, D_X Fake: 0.3522, D_X Total: 0.2152\n",
      "  D_Y Real: 0.0826, D_Y Fake: 0.2240, D_Y Total: 0.1533\n",
      "Generator Losses:\n",
      "  G Adv: 0.2466, F Adv: 0.1970\n",
      "  Cycle Photo: 0.1327, Cycle Monet: 0.1045\n",
      "  Perceptual Photo: 0.3090, Perceptual Monet: 0.2994\n",
      "  Total G Loss: 5.8582\n",
      "Epoch [4/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1423, D_X Fake: 0.1320, D_X Total: 0.1371\n",
      "  D_Y Real: 0.3430, D_Y Fake: 0.0473, D_Y Total: 0.1951\n",
      "Generator Losses:\n",
      "  G Adv: 0.4493, F Adv: 0.3950\n",
      "  Cycle Photo: 0.1170, Cycle Monet: 0.0856\n",
      "  Perceptual Photo: 0.3123, Perceptual Monet: 0.3243\n",
      "  Total G Loss: 6.0530\n",
      "Epoch [4/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1260, D_X Fake: 0.1824, D_X Total: 0.1542\n",
      "  D_Y Real: 0.1008, D_Y Fake: 0.0449, D_Y Total: 0.0728\n",
      "Generator Losses:\n",
      "  G Adv: 0.3520, F Adv: 0.4577\n",
      "  Cycle Photo: 0.1091, Cycle Monet: 0.1117\n",
      "  Perceptual Photo: 0.3733, Perceptual Monet: 0.3337\n",
      "  Total G Loss: 6.5526\n",
      "Epoch [4/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5421, D_X Fake: 0.0378, D_X Total: 0.2899\n",
      "  D_Y Real: 0.4589, D_Y Fake: 0.1217, D_Y Total: 0.2903\n",
      "Generator Losses:\n",
      "  G Adv: 0.5586, F Adv: 0.7519\n",
      "  Cycle Photo: 0.1070, Cycle Monet: 0.1111\n",
      "  Perceptual Photo: 0.2819, Perceptual Monet: 0.3272\n",
      "  Total G Loss: 6.5370\n",
      "Epoch [4/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1180, D_X Fake: 0.3371, D_X Total: 0.2275\n",
      "  D_Y Real: 0.3124, D_Y Fake: 0.0278, D_Y Total: 0.1701\n",
      "Generator Losses:\n",
      "  G Adv: 0.5223, F Adv: 0.1700\n",
      "  Cycle Photo: 0.1157, Cycle Monet: 0.1525\n",
      "  Perceptual Photo: 0.3592, Perceptual Monet: 0.3458\n",
      "  Total G Loss: 6.8988\n",
      "Epoch [4/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2313, D_X Fake: 0.2191, D_X Total: 0.2252\n",
      "  D_Y Real: 0.1550, D_Y Fake: 0.4546, D_Y Total: 0.3048\n",
      "Generator Losses:\n",
      "  G Adv: 0.1607, F Adv: 0.2024\n",
      "  Cycle Photo: 0.0881, Cycle Monet: 0.0679\n",
      "  Perceptual Photo: 0.2908, Perceptual Monet: 0.3340\n",
      "  Total G Loss: 5.0471\n",
      "Epoch [4/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1298, D_X Fake: 0.0973, D_X Total: 0.1135\n",
      "  D_Y Real: 0.1412, D_Y Fake: 0.0600, D_Y Total: 0.1006\n",
      "Generator Losses:\n",
      "  G Adv: 0.6471, F Adv: 0.5360\n",
      "  Cycle Photo: 0.0822, Cycle Monet: 0.0988\n",
      "  Perceptual Photo: 0.1920, Perceptual Monet: 0.3144\n",
      "  Total G Loss: 5.5249\n",
      "Epoch [4/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2485, D_X Fake: 0.0749, D_X Total: 0.1617\n",
      "  D_Y Real: 0.1761, D_Y Fake: 0.1241, D_Y Total: 0.1501\n",
      "Generator Losses:\n",
      "  G Adv: 0.1877, F Adv: 0.3994\n",
      "  Cycle Photo: 0.0694, Cycle Monet: 0.1191\n",
      "  Perceptual Photo: 0.2232, Perceptual Monet: 0.3324\n",
      "  Total G Loss: 5.2504\n",
      "Epoch [4/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1686, D_X Fake: 0.1706, D_X Total: 0.1696\n",
      "  D_Y Real: 0.0815, D_Y Fake: 0.5326, D_Y Total: 0.3071\n",
      "Generator Losses:\n",
      "  G Adv: 0.0851, F Adv: 0.3671\n",
      "  Cycle Photo: 0.1015, Cycle Monet: 0.0899\n",
      "  Perceptual Photo: 0.3042, Perceptual Monet: 0.3120\n",
      "  Total G Loss: 5.4474\n",
      "Epoch [4/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0415, D_X Fake: 0.2909, D_X Total: 0.1662\n",
      "  D_Y Real: 0.2184, D_Y Fake: 0.1025, D_Y Total: 0.1604\n",
      "Generator Losses:\n",
      "  G Adv: 0.5749, F Adv: 0.1757\n",
      "  Cycle Photo: 0.2044, Cycle Monet: 0.0955\n",
      "  Perceptual Photo: 0.3195, Perceptual Monet: 0.3361\n",
      "  Total G Loss: 7.0273\n",
      "Epoch [4/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3570, D_X Fake: 0.0976, D_X Total: 0.2273\n",
      "  D_Y Real: 0.1954, D_Y Fake: 0.0987, D_Y Total: 0.1470\n",
      "Generator Losses:\n",
      "  G Adv: 0.5766, F Adv: 0.5247\n",
      "  Cycle Photo: 0.1246, Cycle Monet: 0.1109\n",
      "  Perceptual Photo: 0.3093, Perceptual Monet: 0.2394\n",
      "  Total G Loss: 6.2004\n",
      "Epoch [4/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.3695, D_X Total: 0.2253\n",
      "  D_Y Real: 0.2518, D_Y Fake: 0.0793, D_Y Total: 0.1655\n",
      "Generator Losses:\n",
      "  G Adv: 0.6869, F Adv: 0.1030\n",
      "  Cycle Photo: 0.1023, Cycle Monet: 0.1017\n",
      "  Perceptual Photo: 0.2407, Perceptual Monet: 0.3042\n",
      "  Total G Loss: 5.5548\n",
      "Epoch [4/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0653, D_X Fake: 0.3053, D_X Total: 0.1853\n",
      "  D_Y Real: 0.3160, D_Y Fake: 0.0578, D_Y Total: 0.1869\n",
      "Generator Losses:\n",
      "  G Adv: 0.7222, F Adv: 0.2084\n",
      "  Cycle Photo: 0.1193, Cycle Monet: 0.1247\n",
      "  Perceptual Photo: 0.3111, Perceptual Monet: 0.3096\n",
      "  Total G Loss: 6.4746\n",
      "Epoch [4/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0588, D_X Fake: 0.1895, D_X Total: 0.1241\n",
      "  D_Y Real: 0.3435, D_Y Fake: 0.0682, D_Y Total: 0.2058\n",
      "Generator Losses:\n",
      "  G Adv: 0.5303, F Adv: 0.1636\n",
      "  Cycle Photo: 0.1371, Cycle Monet: 0.1362\n",
      "  Perceptual Photo: 0.3032, Perceptual Monet: 0.3423\n",
      "  Total G Loss: 6.6543\n",
      "Epoch [4/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4664, D_X Fake: 0.0627, D_X Total: 0.2645\n",
      "  D_Y Real: 0.1031, D_Y Fake: 0.2075, D_Y Total: 0.1553\n",
      "Generator Losses:\n",
      "  G Adv: 0.2364, F Adv: 0.6784\n",
      "  Cycle Photo: 0.0879, Cycle Monet: 0.1212\n",
      "  Perceptual Photo: 0.2739, Perceptual Monet: 0.3629\n",
      "  Total G Loss: 6.1893\n",
      "Epoch [4/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0445, D_X Fake: 0.1915, D_X Total: 0.1180\n",
      "  D_Y Real: 0.3006, D_Y Fake: 0.0626, D_Y Total: 0.1816\n",
      "Generator Losses:\n",
      "  G Adv: 0.6348, F Adv: 0.2669\n",
      "  Cycle Photo: 0.0774, Cycle Monet: 0.1065\n",
      "  Perceptual Photo: 0.1812, Perceptual Monet: 0.2571\n",
      "  Total G Loss: 4.9318\n",
      "Epoch [4/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1808, D_X Fake: 0.1792, D_X Total: 0.1800\n",
      "  D_Y Real: 0.2958, D_Y Fake: 0.1624, D_Y Total: 0.2291\n",
      "Generator Losses:\n",
      "  G Adv: 0.3993, F Adv: 0.2776\n",
      "  Cycle Photo: 0.0953, Cycle Monet: 0.1078\n",
      "  Perceptual Photo: 0.3445, Perceptual Monet: 0.3189\n",
      "  Total G Loss: 6.0245\n",
      "Epoch [4/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0906, D_X Fake: 0.2685, D_X Total: 0.1796\n",
      "  D_Y Real: 0.0441, D_Y Fake: 0.2092, D_Y Total: 0.1266\n",
      "Generator Losses:\n",
      "  G Adv: 0.2447, F Adv: 0.2454\n",
      "  Cycle Photo: 0.0944, Cycle Monet: 0.1093\n",
      "  Perceptual Photo: 0.3450, Perceptual Monet: 0.3020\n",
      "  Total G Loss: 5.7621\n",
      "Epoch [4/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1021, D_X Fake: 0.1716, D_X Total: 0.1369\n",
      "  D_Y Real: 0.1634, D_Y Fake: 0.1495, D_Y Total: 0.1565\n",
      "Generator Losses:\n",
      "  G Adv: 0.5326, F Adv: 0.2809\n",
      "  Cycle Photo: 0.1093, Cycle Monet: 0.0939\n",
      "  Perceptual Photo: 0.2085, Perceptual Monet: 0.3090\n",
      "  Total G Loss: 5.4341\n",
      "Epoch [4/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2089, D_X Fake: 0.1324, D_X Total: 0.1707\n",
      "  D_Y Real: 0.0583, D_Y Fake: 0.1586, D_Y Total: 0.1085\n",
      "Generator Losses:\n",
      "  G Adv: 0.3530, F Adv: 0.5347\n",
      "  Cycle Photo: 0.1100, Cycle Monet: 0.1298\n",
      "  Perceptual Photo: 0.2536, Perceptual Monet: 0.2685\n",
      "  Total G Loss: 5.8965\n",
      "Epoch [4/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2250, D_X Fake: 0.1339, D_X Total: 0.1794\n",
      "  D_Y Real: 0.1335, D_Y Fake: 0.1892, D_Y Total: 0.1613\n",
      "Generator Losses:\n",
      "  G Adv: 0.3199, F Adv: 0.3144\n",
      "  Cycle Photo: 0.1041, Cycle Monet: 0.0935\n",
      "  Perceptual Photo: 0.3186, Perceptual Monet: 0.3184\n",
      "  Total G Loss: 5.7955\n",
      "Epoch [4/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0600, D_X Fake: 0.5956, D_X Total: 0.3278\n",
      "  D_Y Real: 0.0783, D_Y Fake: 0.1948, D_Y Total: 0.1366\n",
      "Generator Losses:\n",
      "  G Adv: 0.2373, F Adv: 0.1267\n",
      "  Cycle Photo: 0.0953, Cycle Monet: 0.0945\n",
      "  Perceptual Photo: 0.2733, Perceptual Monet: 0.2925\n",
      "  Total G Loss: 5.0915\n",
      "Epoch [4/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1728, D_X Fake: 0.2093, D_X Total: 0.1911\n",
      "  D_Y Real: 0.1484, D_Y Fake: 0.1221, D_Y Total: 0.1353\n",
      "Generator Losses:\n",
      "  G Adv: 0.3493, F Adv: 0.2512\n",
      "  Cycle Photo: 0.1329, Cycle Monet: 0.1093\n",
      "  Perceptual Photo: 0.2932, Perceptual Monet: 0.2642\n",
      "  Total G Loss: 5.8088\n",
      "Epoch [5/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1893, D_X Fake: 0.0562, D_X Total: 0.1227\n",
      "  D_Y Real: 0.1547, D_Y Fake: 0.1588, D_Y Total: 0.1567\n",
      "Generator Losses:\n",
      "  G Adv: 0.3397, F Adv: 0.6307\n",
      "  Cycle Photo: 0.0834, Cycle Monet: 0.0815\n",
      "  Perceptual Photo: 0.2400, Perceptual Monet: 0.3229\n",
      "  Total G Loss: 5.4336\n",
      "Epoch [5/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2325, D_X Fake: 0.0313, D_X Total: 0.1319\n",
      "  D_Y Real: 0.4031, D_Y Fake: 0.0542, D_Y Total: 0.2287\n",
      "Generator Losses:\n",
      "  G Adv: 0.6123, F Adv: 0.2993\n",
      "  Cycle Photo: 0.1504, Cycle Monet: 0.1176\n",
      "  Perceptual Photo: 0.2483, Perceptual Monet: 0.2809\n",
      "  Total G Loss: 6.2379\n",
      "Epoch [5/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1886, D_X Fake: 0.1769, D_X Total: 0.1827\n",
      "  D_Y Real: 0.0649, D_Y Fake: 0.3663, D_Y Total: 0.2156\n",
      "Generator Losses:\n",
      "  G Adv: 0.0875, F Adv: 0.4806\n",
      "  Cycle Photo: 0.0821, Cycle Monet: 0.0924\n",
      "  Perceptual Photo: 0.2172, Perceptual Monet: 0.2663\n",
      "  Total G Loss: 4.7309\n",
      "Epoch [5/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2516, D_X Fake: 0.2646, D_X Total: 0.2581\n",
      "  D_Y Real: 0.0840, D_Y Fake: 0.1699, D_Y Total: 0.1269\n",
      "Generator Losses:\n",
      "  G Adv: 0.2931, F Adv: 0.4212\n",
      "  Cycle Photo: 0.1249, Cycle Monet: 0.0784\n",
      "  Perceptual Photo: 0.3793, Perceptual Monet: 0.2682\n",
      "  Total G Loss: 5.9845\n",
      "Epoch [5/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2001, D_X Fake: 0.1854, D_X Total: 0.1928\n",
      "  D_Y Real: 0.1305, D_Y Fake: 0.1107, D_Y Total: 0.1206\n",
      "Generator Losses:\n",
      "  G Adv: 0.2999, F Adv: 0.3218\n",
      "  Cycle Photo: 0.0914, Cycle Monet: 0.0831\n",
      "  Perceptual Photo: 0.2860, Perceptual Monet: 0.3380\n",
      "  Total G Loss: 5.4875\n",
      "Epoch [5/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2855, D_X Fake: 0.1007, D_X Total: 0.1931\n",
      "  D_Y Real: 0.1280, D_Y Fake: 0.1957, D_Y Total: 0.1619\n",
      "Generator Losses:\n",
      "  G Adv: 0.4097, F Adv: 0.5036\n",
      "  Cycle Photo: 0.1365, Cycle Monet: 0.1127\n",
      "  Perceptual Photo: 0.3363, Perceptual Monet: 0.3598\n",
      "  Total G Loss: 6.8860\n",
      "Epoch [5/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.1901, D_X Total: 0.1516\n",
      "  D_Y Real: 0.0941, D_Y Fake: 0.1854, D_Y Total: 0.1398\n",
      "Generator Losses:\n",
      "  G Adv: 0.2559, F Adv: 0.2739\n",
      "  Cycle Photo: 0.0993, Cycle Monet: 0.1072\n",
      "  Perceptual Photo: 0.2980, Perceptual Monet: 0.2893\n",
      "  Total G Loss: 5.5308\n",
      "Epoch [5/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.1012, D_X Total: 0.1164\n",
      "  D_Y Real: 0.2131, D_Y Fake: 0.0742, D_Y Total: 0.1436\n",
      "Generator Losses:\n",
      "  G Adv: 0.6401, F Adv: 0.3736\n",
      "  Cycle Photo: 0.1069, Cycle Monet: 0.1020\n",
      "  Perceptual Photo: 0.3620, Perceptual Monet: 0.3056\n",
      "  Total G Loss: 6.4406\n",
      "Epoch [5/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1761, D_X Fake: 0.2373, D_X Total: 0.2067\n",
      "  D_Y Real: 0.0977, D_Y Fake: 0.3241, D_Y Total: 0.2109\n",
      "Generator Losses:\n",
      "  G Adv: 0.2251, F Adv: 0.2269\n",
      "  Cycle Photo: 0.0968, Cycle Monet: 0.1175\n",
      "  Perceptual Photo: 0.2892, Perceptual Monet: 0.2958\n",
      "  Total G Loss: 5.5208\n",
      "Epoch [5/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2170, D_X Fake: 0.2638, D_X Total: 0.2404\n",
      "  D_Y Real: 0.5033, D_Y Fake: 0.0776, D_Y Total: 0.2905\n",
      "Generator Losses:\n",
      "  G Adv: 0.8989, F Adv: 0.1768\n",
      "  Cycle Photo: 0.0970, Cycle Monet: 0.0742\n",
      "  Perceptual Photo: 0.3768, Perceptual Monet: 0.2989\n",
      "  Total G Loss: 6.1666\n",
      "Epoch [5/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2342, D_X Fake: 0.1801, D_X Total: 0.2071\n",
      "  D_Y Real: 0.2255, D_Y Fake: 0.1862, D_Y Total: 0.2058\n",
      "Generator Losses:\n",
      "  G Adv: 0.3583, F Adv: 0.3639\n",
      "  Cycle Photo: 0.0964, Cycle Monet: 0.1181\n",
      "  Perceptual Photo: 0.3341, Perceptual Monet: 0.2964\n",
      "  Total G Loss: 6.0196\n",
      "Epoch [5/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3205, D_X Fake: 0.1646, D_X Total: 0.2425\n",
      "  D_Y Real: 0.2713, D_Y Fake: 0.2671, D_Y Total: 0.2692\n",
      "Generator Losses:\n",
      "  G Adv: 0.1702, F Adv: 0.4200\n",
      "  Cycle Photo: 0.0991, Cycle Monet: 0.0981\n",
      "  Perceptual Photo: 0.2915, Perceptual Monet: 0.3498\n",
      "  Total G Loss: 5.7688\n",
      "Epoch [5/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0841, D_X Fake: 0.1209, D_X Total: 0.1025\n",
      "  D_Y Real: 0.2803, D_Y Fake: 0.2334, D_Y Total: 0.2568\n",
      "Generator Losses:\n",
      "  G Adv: 0.3019, F Adv: 0.2374\n",
      "  Cycle Photo: 0.0930, Cycle Monet: 0.0957\n",
      "  Perceptual Photo: 0.2820, Perceptual Monet: 0.3812\n",
      "  Total G Loss: 5.7424\n",
      "Epoch [5/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3256, D_X Fake: 0.1100, D_X Total: 0.2178\n",
      "  D_Y Real: 0.2646, D_Y Fake: 0.2311, D_Y Total: 0.2479\n",
      "Generator Losses:\n",
      "  G Adv: 0.2966, F Adv: 0.5271\n",
      "  Cycle Photo: 0.0846, Cycle Monet: 0.0897\n",
      "  Perceptual Photo: 0.3914, Perceptual Monet: 0.3096\n",
      "  Total G Loss: 6.0717\n",
      "Epoch [5/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1178, D_X Fake: 0.2023, D_X Total: 0.1600\n",
      "  D_Y Real: 0.2649, D_Y Fake: 0.2163, D_Y Total: 0.2406\n",
      "Generator Losses:\n",
      "  G Adv: 0.3186, F Adv: 0.3056\n",
      "  Cycle Photo: 0.1017, Cycle Monet: 0.0920\n",
      "  Perceptual Photo: 0.2758, Perceptual Monet: 0.2793\n",
      "  Total G Loss: 5.3364\n",
      "Epoch [5/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.2137, D_X Total: 0.1421\n",
      "  D_Y Real: 0.2625, D_Y Fake: 0.2563, D_Y Total: 0.2594\n",
      "Generator Losses:\n",
      "  G Adv: 0.2707, F Adv: 0.1886\n",
      "  Cycle Photo: 0.0995, Cycle Monet: 0.0750\n",
      "  Perceptual Photo: 0.2900, Perceptual Monet: 0.2812\n",
      "  Total G Loss: 5.0607\n",
      "Epoch [5/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1383, D_X Fake: 0.1611, D_X Total: 0.1497\n",
      "  D_Y Real: 0.2300, D_Y Fake: 0.2416, D_Y Total: 0.2358\n",
      "Generator Losses:\n",
      "  G Adv: 0.2717, F Adv: 0.2970\n",
      "  Cycle Photo: 0.1202, Cycle Monet: 0.1104\n",
      "  Perceptual Photo: 0.2730, Perceptual Monet: 0.2870\n",
      "  Total G Loss: 5.6750\n",
      "Epoch [5/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2060, D_X Fake: 0.1783, D_X Total: 0.1921\n",
      "  D_Y Real: 0.1350, D_Y Fake: 0.3922, D_Y Total: 0.2636\n",
      "Generator Losses:\n",
      "  G Adv: 0.1572, F Adv: 0.3083\n",
      "  Cycle Photo: 0.1269, Cycle Monet: 0.1215\n",
      "  Perceptual Photo: 0.3264, Perceptual Monet: 0.2982\n",
      "  Total G Loss: 6.0724\n",
      "Epoch [5/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1540, D_X Fake: 0.1243, D_X Total: 0.1392\n",
      "  D_Y Real: 0.2828, D_Y Fake: 0.1669, D_Y Total: 0.2248\n",
      "Generator Losses:\n",
      "  G Adv: 0.3097, F Adv: 0.4893\n",
      "  Cycle Photo: 0.0992, Cycle Monet: 0.1067\n",
      "  Perceptual Photo: 0.2498, Perceptual Monet: 0.3392\n",
      "  Total G Loss: 5.8024\n",
      "Epoch [5/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1862, D_X Fake: 0.0377, D_X Total: 0.1120\n",
      "  D_Y Real: 0.2371, D_Y Fake: 0.1939, D_Y Total: 0.2155\n",
      "Generator Losses:\n",
      "  G Adv: 0.2760, F Adv: 0.5036\n",
      "  Cycle Photo: 0.0895, Cycle Monet: 0.0905\n",
      "  Perceptual Photo: 0.2009, Perceptual Monet: 0.3056\n",
      "  Total G Loss: 5.1122\n",
      "Epoch [5/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3666, D_X Fake: 0.1730, D_X Total: 0.2698\n",
      "  D_Y Real: 0.2139, D_Y Fake: 0.2858, D_Y Total: 0.2499\n",
      "Generator Losses:\n",
      "  G Adv: 0.2246, F Adv: 0.4702\n",
      "  Cycle Photo: 0.0988, Cycle Monet: 0.0743\n",
      "  Perceptual Photo: 0.3131, Perceptual Monet: 0.2689\n",
      "  Total G Loss: 5.3359\n",
      "Epoch [5/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1328, D_X Fake: 0.1177, D_X Total: 0.1253\n",
      "  D_Y Real: 0.4320, D_Y Fake: 0.2093, D_Y Total: 0.3207\n",
      "Generator Losses:\n",
      "  G Adv: 0.4431, F Adv: 0.3069\n",
      "  Cycle Photo: 0.1272, Cycle Monet: 0.1027\n",
      "  Perceptual Photo: 0.2363, Perceptual Monet: 0.2595\n",
      "  Total G Loss: 5.5287\n",
      "Epoch [5/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3519, D_X Fake: 0.0588, D_X Total: 0.2053\n",
      "  D_Y Real: 0.3235, D_Y Fake: 0.2158, D_Y Total: 0.2697\n",
      "Generator Losses:\n",
      "  G Adv: 0.3320, F Adv: 0.7118\n",
      "  Cycle Photo: 0.0852, Cycle Monet: 0.0806\n",
      "  Perceptual Photo: 0.2650, Perceptual Monet: 0.2897\n",
      "  Total G Loss: 5.4758\n",
      "Epoch [5/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1445, D_X Fake: 0.1763, D_X Total: 0.1604\n",
      "  D_Y Real: 0.3397, D_Y Fake: 0.1526, D_Y Total: 0.2462\n",
      "Generator Losses:\n",
      "  G Adv: 0.3880, F Adv: 0.4463\n",
      "  Cycle Photo: 0.0989, Cycle Monet: 0.0927\n",
      "  Perceptual Photo: 0.2227, Perceptual Monet: 0.2436\n",
      "  Total G Loss: 5.0818\n",
      "Epoch [6/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0339, D_X Fake: 0.1955, D_X Total: 0.1147\n",
      "  D_Y Real: 0.2041, D_Y Fake: 0.2666, D_Y Total: 0.2353\n",
      "Generator Losses:\n",
      "  G Adv: 0.2864, F Adv: 0.4027\n",
      "  Cycle Photo: 0.1241, Cycle Monet: 0.0687\n",
      "  Perceptual Photo: 0.2120, Perceptual Monet: 0.2370\n",
      "  Total G Loss: 4.8620\n",
      "Epoch [6/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1084, D_X Fake: 0.3313, D_X Total: 0.2198\n",
      "  D_Y Real: 0.2619, D_Y Fake: 0.2844, D_Y Total: 0.2732\n",
      "Generator Losses:\n",
      "  G Adv: 0.2810, F Adv: 0.2083\n",
      "  Cycle Photo: 0.0965, Cycle Monet: 0.0857\n",
      "  Perceptual Photo: 0.2137, Perceptual Monet: 0.2618\n",
      "  Total G Loss: 4.6893\n",
      "Epoch [6/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3024, D_X Fake: 0.0253, D_X Total: 0.1639\n",
      "  D_Y Real: 0.2580, D_Y Fake: 0.2553, D_Y Total: 0.2566\n",
      "Generator Losses:\n",
      "  G Adv: 0.2402, F Adv: 0.6857\n",
      "  Cycle Photo: 0.1008, Cycle Monet: 0.0899\n",
      "  Perceptual Photo: 0.2180, Perceptual Monet: 0.3102\n",
      "  Total G Loss: 5.4740\n",
      "Epoch [6/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1346, D_X Fake: 0.2685, D_X Total: 0.2016\n",
      "  D_Y Real: 0.2846, D_Y Fake: 0.1780, D_Y Total: 0.2313\n",
      "Generator Losses:\n",
      "  G Adv: 0.4042, F Adv: 0.3275\n",
      "  Cycle Photo: 0.0830, Cycle Monet: 0.0742\n",
      "  Perceptual Photo: 0.1875, Perceptual Monet: 0.2708\n",
      "  Total G Loss: 4.5946\n",
      "Epoch [6/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1098, D_X Fake: 0.3586, D_X Total: 0.2342\n",
      "  D_Y Real: 0.3133, D_Y Fake: 0.1796, D_Y Total: 0.2465\n",
      "Generator Losses:\n",
      "  G Adv: 0.3627, F Adv: 0.2534\n",
      "  Cycle Photo: 0.0598, Cycle Monet: 0.0879\n",
      "  Perceptual Photo: 0.2104, Perceptual Monet: 0.2731\n",
      "  Total G Loss: 4.5106\n",
      "Epoch [6/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4366, D_X Fake: 0.0866, D_X Total: 0.2616\n",
      "  D_Y Real: 0.2451, D_Y Fake: 0.1818, D_Y Total: 0.2135\n",
      "Generator Losses:\n",
      "  G Adv: 0.2944, F Adv: 0.6040\n",
      "  Cycle Photo: 0.0878, Cycle Monet: 0.0866\n",
      "  Perceptual Photo: 0.3083, Perceptual Monet: 0.3157\n",
      "  Total G Loss: 5.7621\n",
      "Epoch [6/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0930, D_X Fake: 0.2592, D_X Total: 0.1761\n",
      "  D_Y Real: 0.1996, D_Y Fake: 0.2012, D_Y Total: 0.2004\n",
      "Generator Losses:\n",
      "  G Adv: 0.2862, F Adv: 0.2381\n",
      "  Cycle Photo: 0.1014, Cycle Monet: 0.1051\n",
      "  Perceptual Photo: 0.2376, Perceptual Monet: 0.2466\n",
      "  Total G Loss: 5.0100\n",
      "Epoch [6/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3433, D_X Fake: 0.1015, D_X Total: 0.2224\n",
      "  D_Y Real: 0.3316, D_Y Fake: 0.2047, D_Y Total: 0.2681\n",
      "Generator Losses:\n",
      "  G Adv: 0.3335, F Adv: 0.4881\n",
      "  Cycle Photo: 0.0700, Cycle Monet: 0.0983\n",
      "  Perceptual Photo: 0.1982, Perceptual Monet: 0.2674\n",
      "  Total G Loss: 4.8324\n",
      "Epoch [6/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3890, D_X Fake: 0.1221, D_X Total: 0.2556\n",
      "  D_Y Real: 0.1424, D_Y Fake: 0.3448, D_Y Total: 0.2436\n",
      "Generator Losses:\n",
      "  G Adv: 0.1927, F Adv: 0.6955\n",
      "  Cycle Photo: 0.1028, Cycle Monet: 0.0920\n",
      "  Perceptual Photo: 0.2761, Perceptual Monet: 0.2493\n",
      "  Total G Loss: 5.4628\n",
      "Epoch [6/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1642, D_X Fake: 0.1400, D_X Total: 0.1521\n",
      "  D_Y Real: 0.2668, D_Y Fake: 0.2391, D_Y Total: 0.2530\n",
      "Generator Losses:\n",
      "  G Adv: 0.3158, F Adv: 0.5181\n",
      "  Cycle Photo: 0.1265, Cycle Monet: 0.0717\n",
      "  Perceptual Photo: 0.2860, Perceptual Monet: 0.2719\n",
      "  Total G Loss: 5.6056\n",
      "Epoch [6/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1680, D_X Fake: 0.1437, D_X Total: 0.1558\n",
      "  D_Y Real: 0.3886, D_Y Fake: 0.1101, D_Y Total: 0.2494\n",
      "Generator Losses:\n",
      "  G Adv: 0.4986, F Adv: 0.3316\n",
      "  Cycle Photo: 0.1093, Cycle Monet: 0.0761\n",
      "  Perceptual Photo: 0.2892, Perceptual Monet: 0.2810\n",
      "  Total G Loss: 5.5354\n",
      "Epoch [6/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1188, D_X Fake: 0.1719, D_X Total: 0.1454\n",
      "  D_Y Real: 0.1951, D_Y Fake: 0.3346, D_Y Total: 0.2649\n",
      "Generator Losses:\n",
      "  G Adv: 0.1892, F Adv: 0.3158\n",
      "  Cycle Photo: 0.0931, Cycle Monet: 0.0923\n",
      "  Perceptual Photo: 0.1762, Perceptual Monet: 0.2602\n",
      "  Total G Loss: 4.5404\n",
      "Epoch [6/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1518, D_X Fake: 0.2828, D_X Total: 0.2173\n",
      "  D_Y Real: 0.2420, D_Y Fake: 0.3707, D_Y Total: 0.3063\n",
      "Generator Losses:\n",
      "  G Adv: 0.2358, F Adv: 0.2619\n",
      "  Cycle Photo: 0.1051, Cycle Monet: 0.0758\n",
      "  Perceptual Photo: 0.2546, Perceptual Monet: 0.3158\n",
      "  Total G Loss: 5.1592\n",
      "Epoch [6/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4454, D_X Fake: 0.0587, D_X Total: 0.2521\n",
      "  D_Y Real: 0.2584, D_Y Fake: 0.1608, D_Y Total: 0.2096\n",
      "Generator Losses:\n",
      "  G Adv: 0.3057, F Adv: 0.5397\n",
      "  Cycle Photo: 0.0797, Cycle Monet: 0.0804\n",
      "  Perceptual Photo: 0.2939, Perceptual Monet: 0.2628\n",
      "  Total G Loss: 5.2302\n",
      "Epoch [6/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.6807, D_X Fake: 0.0510, D_X Total: 0.3659\n",
      "  D_Y Real: 0.3092, D_Y Fake: 0.2287, D_Y Total: 0.2690\n",
      "Generator Losses:\n",
      "  G Adv: 0.4013, F Adv: 0.7802\n",
      "  Cycle Photo: 0.0664, Cycle Monet: 0.0752\n",
      "  Perceptual Photo: 0.2359, Perceptual Monet: 0.2437\n",
      "  Total G Loss: 4.9957\n",
      "Epoch [6/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2307, D_X Fake: 0.2068, D_X Total: 0.2187\n",
      "  D_Y Real: 0.4153, D_Y Fake: 0.1770, D_Y Total: 0.2961\n",
      "Generator Losses:\n",
      "  G Adv: 0.3851, F Adv: 0.2427\n",
      "  Cycle Photo: 0.1315, Cycle Monet: 0.1195\n",
      "  Perceptual Photo: 0.2602, Perceptual Monet: 0.3286\n",
      "  Total G Loss: 6.0823\n",
      "Epoch [6/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3919, D_X Fake: 0.0456, D_X Total: 0.2188\n",
      "  D_Y Real: 0.2489, D_Y Fake: 0.2191, D_Y Total: 0.2340\n",
      "Generator Losses:\n",
      "  G Adv: 0.3207, F Adv: 0.7117\n",
      "  Cycle Photo: 0.1191, Cycle Monet: 0.1027\n",
      "  Perceptual Photo: 0.2572, Perceptual Monet: 0.2998\n",
      "  Total G Loss: 6.0355\n",
      "Epoch [6/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0960, D_X Fake: 0.0912, D_X Total: 0.0936\n",
      "  D_Y Real: 0.3142, D_Y Fake: 0.0659, D_Y Total: 0.1900\n",
      "Generator Losses:\n",
      "  G Adv: 0.3474, F Adv: 0.4496\n",
      "  Cycle Photo: 0.1135, Cycle Monet: 0.1169\n",
      "  Perceptual Photo: 0.2204, Perceptual Monet: 0.2610\n",
      "  Total G Loss: 5.5086\n",
      "Epoch [6/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0774, D_X Fake: 0.1335, D_X Total: 0.1054\n",
      "  D_Y Real: 0.2142, D_Y Fake: 0.2184, D_Y Total: 0.2163\n",
      "Generator Losses:\n",
      "  G Adv: 0.2831, F Adv: 0.4519\n",
      "  Cycle Photo: 0.0891, Cycle Monet: 0.0931\n",
      "  Perceptual Photo: 0.2115, Perceptual Monet: 0.3057\n",
      "  Total G Loss: 5.1427\n",
      "Epoch [6/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1634, D_X Fake: 0.1096, D_X Total: 0.1365\n",
      "  D_Y Real: 0.2556, D_Y Fake: 0.3069, D_Y Total: 0.2813\n",
      "Generator Losses:\n",
      "  G Adv: 0.2401, F Adv: 0.3037\n",
      "  Cycle Photo: 0.1098, Cycle Monet: 0.0925\n",
      "  Perceptual Photo: 0.2683, Perceptual Monet: 0.2335\n",
      "  Total G Loss: 5.0757\n",
      "Epoch [6/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1716, D_X Fake: 0.0627, D_X Total: 0.1172\n",
      "  D_Y Real: 0.1740, D_Y Fake: 0.3498, D_Y Total: 0.2619\n",
      "Generator Losses:\n",
      "  G Adv: 0.2357, F Adv: 0.4071\n",
      "  Cycle Photo: 0.1269, Cycle Monet: 0.0795\n",
      "  Perceptual Photo: 0.2146, Perceptual Monet: 0.2921\n",
      "  Total G Loss: 5.2391\n",
      "Epoch [6/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1190, D_X Fake: 0.3834, D_X Total: 0.2512\n",
      "  D_Y Real: 0.2447, D_Y Fake: 0.1609, D_Y Total: 0.2028\n",
      "Generator Losses:\n",
      "  G Adv: 0.3700, F Adv: 0.1354\n",
      "  Cycle Photo: 0.0624, Cycle Monet: 0.0797\n",
      "  Perceptual Photo: 0.1891, Perceptual Monet: 0.2478\n",
      "  Total G Loss: 4.1116\n",
      "Epoch [6/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0966, D_X Fake: 0.3607, D_X Total: 0.2287\n",
      "  D_Y Real: 0.2675, D_Y Fake: 0.1029, D_Y Total: 0.1852\n",
      "Generator Losses:\n",
      "  G Adv: 0.4699, F Adv: 0.1687\n",
      "  Cycle Photo: 0.0752, Cycle Monet: 0.0809\n",
      "  Perceptual Photo: 0.2077, Perceptual Monet: 0.2245\n",
      "  Total G Loss: 4.3601\n",
      "Epoch [6/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0771, D_X Fake: 0.1592, D_X Total: 0.1182\n",
      "  D_Y Real: 0.2811, D_Y Fake: 0.2751, D_Y Total: 0.2781\n",
      "Generator Losses:\n",
      "  G Adv: 0.3012, F Adv: 0.4631\n",
      "  Cycle Photo: 0.0886, Cycle Monet: 0.0981\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.2743\n",
      "  Total G Loss: 4.7956\n",
      "Epoch [7/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1077, D_X Fake: 0.1227, D_X Total: 0.1152\n",
      "  D_Y Real: 0.2459, D_Y Fake: 0.1440, D_Y Total: 0.1949\n",
      "Generator Losses:\n",
      "  G Adv: 0.3532, F Adv: 0.3776\n",
      "  Cycle Photo: 0.1025, Cycle Monet: 0.0827\n",
      "  Perceptual Photo: 0.2066, Perceptual Monet: 0.2821\n",
      "  Total G Loss: 5.0261\n",
      "Epoch [7/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2865, D_X Fake: 0.0858, D_X Total: 0.1862\n",
      "  D_Y Real: 0.1974, D_Y Fake: 0.1912, D_Y Total: 0.1943\n",
      "Generator Losses:\n",
      "  G Adv: 0.3019, F Adv: 0.5883\n",
      "  Cycle Photo: 0.0726, Cycle Monet: 0.0912\n",
      "  Perceptual Photo: 0.2721, Perceptual Monet: 0.2713\n",
      "  Total G Loss: 5.2454\n",
      "Epoch [7/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3222, D_X Fake: 0.0992, D_X Total: 0.2107\n",
      "  D_Y Real: 0.3702, D_Y Fake: 0.1773, D_Y Total: 0.2738\n",
      "Generator Losses:\n",
      "  G Adv: 0.2991, F Adv: 0.3784\n",
      "  Cycle Photo: 0.0599, Cycle Monet: 0.0814\n",
      "  Perceptual Photo: 0.2001, Perceptual Monet: 0.2688\n",
      "  Total G Loss: 4.4351\n",
      "Epoch [7/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2310, D_X Fake: 0.3232, D_X Total: 0.2771\n",
      "  D_Y Real: 0.1902, D_Y Fake: 0.0964, D_Y Total: 0.1433\n",
      "Generator Losses:\n",
      "  G Adv: 0.4475, F Adv: 0.3006\n",
      "  Cycle Photo: 0.1309, Cycle Monet: 0.0977\n",
      "  Perceptual Photo: 0.3237, Perceptual Monet: 0.2791\n",
      "  Total G Loss: 6.0485\n",
      "Epoch [7/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1378, D_X Fake: 0.1426, D_X Total: 0.1402\n",
      "  D_Y Real: 0.2435, D_Y Fake: 0.1259, D_Y Total: 0.1847\n",
      "Generator Losses:\n",
      "  G Adv: 0.5415, F Adv: 0.3553\n",
      "  Cycle Photo: 0.0982, Cycle Monet: 0.0785\n",
      "  Perceptual Photo: 0.1908, Perceptual Monet: 0.2603\n",
      "  Total G Loss: 4.9200\n",
      "Epoch [7/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3217, D_X Fake: 0.1469, D_X Total: 0.2343\n",
      "  D_Y Real: 0.0620, D_Y Fake: 0.2199, D_Y Total: 0.1409\n",
      "Generator Losses:\n",
      "  G Adv: 0.2988, F Adv: 0.6099\n",
      "  Cycle Photo: 0.1000, Cycle Monet: 0.0743\n",
      "  Perceptual Photo: 0.2574, Perceptual Monet: 0.2658\n",
      "  Total G Loss: 5.2679\n",
      "Epoch [7/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1041, D_X Fake: 0.3198, D_X Total: 0.2119\n",
      "  D_Y Real: 0.3396, D_Y Fake: 0.1325, D_Y Total: 0.2360\n",
      "Generator Losses:\n",
      "  G Adv: 0.3582, F Adv: 0.2677\n",
      "  Cycle Photo: 0.0876, Cycle Monet: 0.0895\n",
      "  Perceptual Photo: 0.2524, Perceptual Monet: 0.2689\n",
      "  Total G Loss: 5.0034\n",
      "Epoch [7/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3093, D_X Fake: 0.0657, D_X Total: 0.1875\n",
      "  D_Y Real: 0.3160, D_Y Fake: 0.0933, D_Y Total: 0.2046\n",
      "Generator Losses:\n",
      "  G Adv: 0.6253, F Adv: 0.5758\n",
      "  Cycle Photo: 0.0903, Cycle Monet: 0.0702\n",
      "  Perceptual Photo: 0.2533, Perceptual Monet: 0.2519\n",
      "  Total G Loss: 5.3323\n",
      "Epoch [7/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0914, D_X Fake: 0.1493, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0699, D_Y Fake: 0.1475, D_Y Total: 0.1087\n",
      "Generator Losses:\n",
      "  G Adv: 0.3858, F Adv: 0.3288\n",
      "  Cycle Photo: 0.1134, Cycle Monet: 0.0957\n",
      "  Perceptual Photo: 0.2033, Perceptual Monet: 0.2622\n",
      "  Total G Loss: 5.1328\n",
      "Epoch [7/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1227, D_X Fake: 0.3129, D_X Total: 0.2178\n",
      "  D_Y Real: 0.5231, D_Y Fake: 0.0658, D_Y Total: 0.2945\n",
      "Generator Losses:\n",
      "  G Adv: 0.9030, F Adv: 0.2153\n",
      "  Cycle Photo: 0.1027, Cycle Monet: 0.0846\n",
      "  Perceptual Photo: 0.2645, Perceptual Monet: 0.2676\n",
      "  Total G Loss: 5.6521\n",
      "Epoch [7/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1497, D_X Fake: 0.1195, D_X Total: 0.1346\n",
      "  D_Y Real: 0.0886, D_Y Fake: 0.1791, D_Y Total: 0.1338\n",
      "Generator Losses:\n",
      "  G Adv: 0.3123, F Adv: 0.4120\n",
      "  Cycle Photo: 0.0780, Cycle Monet: 0.0932\n",
      "  Perceptual Photo: 0.2041, Perceptual Monet: 0.2642\n",
      "  Total G Loss: 4.7775\n",
      "Epoch [7/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1672, D_X Fake: 0.1790, D_X Total: 0.1731\n",
      "  D_Y Real: 0.0897, D_Y Fake: 0.3862, D_Y Total: 0.2380\n",
      "Generator Losses:\n",
      "  G Adv: 0.2178, F Adv: 0.4090\n",
      "  Cycle Photo: 0.0646, Cycle Monet: 0.1072\n",
      "  Perceptual Photo: 0.1930, Perceptual Monet: 0.2705\n",
      "  Total G Loss: 4.6629\n",
      "Epoch [7/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1203, D_X Fake: 0.1570, D_X Total: 0.1387\n",
      "  D_Y Real: 0.1863, D_Y Fake: 0.0745, D_Y Total: 0.1304\n",
      "Generator Losses:\n",
      "  G Adv: 0.6259, F Adv: 0.3413\n",
      "  Cycle Photo: 0.0638, Cycle Monet: 0.0654\n",
      "  Perceptual Photo: 0.2731, Perceptual Monet: 0.2529\n",
      "  Total G Loss: 4.8892\n",
      "Epoch [7/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4026, D_X Fake: 0.1273, D_X Total: 0.2650\n",
      "  D_Y Real: 0.2962, D_Y Fake: 0.1245, D_Y Total: 0.2103\n",
      "Generator Losses:\n",
      "  G Adv: 0.5008, F Adv: 0.4395\n",
      "  Cycle Photo: 0.0747, Cycle Monet: 0.0540\n",
      "  Perceptual Photo: 0.2491, Perceptual Monet: 0.2122\n",
      "  Total G Loss: 4.5344\n",
      "Epoch [7/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0542, D_X Fake: 0.2267, D_X Total: 0.1405\n",
      "  D_Y Real: 0.0914, D_Y Fake: 0.3268, D_Y Total: 0.2091\n",
      "Generator Losses:\n",
      "  G Adv: 0.3246, F Adv: 0.3294\n",
      "  Cycle Photo: 0.0647, Cycle Monet: 0.0698\n",
      "  Perceptual Photo: 0.1659, Perceptual Monet: 0.2798\n",
      "  Total G Loss: 4.2275\n",
      "Epoch [7/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1762, D_X Fake: 0.1652, D_X Total: 0.1707\n",
      "  D_Y Real: 0.1291, D_Y Fake: 0.1120, D_Y Total: 0.1206\n",
      "Generator Losses:\n",
      "  G Adv: 0.4517, F Adv: 0.4241\n",
      "  Cycle Photo: 0.0828, Cycle Monet: 0.0901\n",
      "  Perceptual Photo: 0.2053, Perceptual Monet: 0.2531\n",
      "  Total G Loss: 4.8975\n",
      "Epoch [7/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2477, D_X Fake: 0.1256, D_X Total: 0.1867\n",
      "  D_Y Real: 0.2635, D_Y Fake: 0.1699, D_Y Total: 0.2167\n",
      "Generator Losses:\n",
      "  G Adv: 0.4670, F Adv: 0.3373\n",
      "  Cycle Photo: 0.1186, Cycle Monet: 0.0768\n",
      "  Perceptual Photo: 0.2205, Perceptual Monet: 0.2772\n",
      "  Total G Loss: 5.2465\n",
      "Epoch [7/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1041, D_X Fake: 0.0838, D_X Total: 0.0940\n",
      "  D_Y Real: 0.2627, D_Y Fake: 0.1164, D_Y Total: 0.1896\n",
      "Generator Losses:\n",
      "  G Adv: 0.4904, F Adv: 0.5699\n",
      "  Cycle Photo: 0.0672, Cycle Monet: 0.0852\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.2576\n",
      "  Total G Loss: 4.7612\n",
      "Epoch [7/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2807, D_X Fake: 0.0855, D_X Total: 0.1831\n",
      "  D_Y Real: 0.2643, D_Y Fake: 0.0747, D_Y Total: 0.1695\n",
      "Generator Losses:\n",
      "  G Adv: 0.7440, F Adv: 0.5517\n",
      "  Cycle Photo: 0.1291, Cycle Monet: 0.0688\n",
      "  Perceptual Photo: 0.2831, Perceptual Monet: 0.2371\n",
      "  Total G Loss: 5.8766\n",
      "Epoch [7/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1001, D_X Fake: 0.2773, D_X Total: 0.1887\n",
      "  D_Y Real: 0.1132, D_Y Fake: 0.3626, D_Y Total: 0.2379\n",
      "Generator Losses:\n",
      "  G Adv: 0.1710, F Adv: 0.3514\n",
      "  Cycle Photo: 0.1028, Cycle Monet: 0.0804\n",
      "  Perceptual Photo: 0.1759, Perceptual Monet: 0.2516\n",
      "  Total G Loss: 4.4926\n",
      "Epoch [7/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1141, D_X Fake: 0.1469, D_X Total: 0.1305\n",
      "  D_Y Real: 0.1649, D_Y Fake: 0.0788, D_Y Total: 0.1219\n",
      "Generator Losses:\n",
      "  G Adv: 0.2519, F Adv: 0.5159\n",
      "  Cycle Photo: 0.0998, Cycle Monet: 0.0811\n",
      "  Perceptual Photo: 0.2337, Perceptual Monet: 0.2547\n",
      "  Total G Loss: 5.0188\n",
      "Epoch [7/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3239, D_X Fake: 0.1019, D_X Total: 0.2129\n",
      "  D_Y Real: 0.0612, D_Y Fake: 0.3020, D_Y Total: 0.1816\n",
      "Generator Losses:\n",
      "  G Adv: 0.2118, F Adv: 0.5163\n",
      "  Cycle Photo: 0.1181, Cycle Monet: 0.0675\n",
      "  Perceptual Photo: 0.2038, Perceptual Monet: 0.2392\n",
      "  Total G Loss: 4.7988\n",
      "Epoch [7/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3319, D_X Fake: 0.1565, D_X Total: 0.2442\n",
      "  D_Y Real: 0.1462, D_Y Fake: 0.2161, D_Y Total: 0.1811\n",
      "Generator Losses:\n",
      "  G Adv: 0.3447, F Adv: 0.5285\n",
      "  Cycle Photo: 0.0746, Cycle Monet: 0.0724\n",
      "  Perceptual Photo: 0.3040, Perceptual Monet: 0.2639\n",
      "  Total G Loss: 5.1823\n",
      "Epoch [7/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2092, D_X Fake: 0.1594, D_X Total: 0.1843\n",
      "  D_Y Real: 0.0885, D_Y Fake: 0.2235, D_Y Total: 0.1560\n",
      "Generator Losses:\n",
      "  G Adv: 0.2441, F Adv: 0.3790\n",
      "  Cycle Photo: 0.1068, Cycle Monet: 0.0975\n",
      "  Perceptual Photo: 0.2857, Perceptual Monet: 0.2827\n",
      "  Total G Loss: 5.5083\n",
      "Epoch [8/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0805, D_X Fake: 0.2048, D_X Total: 0.1427\n",
      "  D_Y Real: 0.1009, D_Y Fake: 0.2246, D_Y Total: 0.1628\n",
      "Generator Losses:\n",
      "  G Adv: 0.3277, F Adv: 0.3284\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0981\n",
      "  Perceptual Photo: 0.1764, Perceptual Monet: 0.3145\n",
      "  Total G Loss: 4.5673\n",
      "Epoch [8/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0483, D_X Fake: 0.3224, D_X Total: 0.1854\n",
      "  D_Y Real: 0.1200, D_Y Fake: 0.3049, D_Y Total: 0.2125\n",
      "Generator Losses:\n",
      "  G Adv: 0.2685, F Adv: 0.3128\n",
      "  Cycle Photo: 0.0887, Cycle Monet: 0.0739\n",
      "  Perceptual Photo: 0.1873, Perceptual Monet: 0.2349\n",
      "  Total G Loss: 4.3181\n",
      "Epoch [8/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1405, D_X Fake: 0.0487, D_X Total: 0.0946\n",
      "  D_Y Real: 0.0877, D_Y Fake: 0.2294, D_Y Total: 0.1586\n",
      "Generator Losses:\n",
      "  G Adv: 0.1702, F Adv: 0.6737\n",
      "  Cycle Photo: 0.0972, Cycle Monet: 0.0724\n",
      "  Perceptual Photo: 0.2869, Perceptual Monet: 0.2413\n",
      "  Total G Loss: 5.1808\n",
      "Epoch [8/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2091, D_X Fake: 0.2651, D_X Total: 0.2371\n",
      "  D_Y Real: 0.2222, D_Y Fake: 0.2515, D_Y Total: 0.2368\n",
      "Generator Losses:\n",
      "  G Adv: 0.1821, F Adv: 0.2963\n",
      "  Cycle Photo: 0.0745, Cycle Monet: 0.0775\n",
      "  Perceptual Photo: 0.2622, Perceptual Monet: 0.2481\n",
      "  Total G Loss: 4.5506\n",
      "Epoch [8/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2811, D_X Fake: 0.0904, D_X Total: 0.1857\n",
      "  D_Y Real: 0.1228, D_Y Fake: 0.2664, D_Y Total: 0.1946\n",
      "Generator Losses:\n",
      "  G Adv: 0.2801, F Adv: 0.4614\n",
      "  Cycle Photo: 0.0670, Cycle Monet: 0.0892\n",
      "  Perceptual Photo: 0.2666, Perceptual Monet: 0.2831\n",
      "  Total G Loss: 5.0519\n",
      "Epoch [8/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1221, D_X Fake: 0.1951, D_X Total: 0.1586\n",
      "  D_Y Real: 0.1572, D_Y Fake: 0.2296, D_Y Total: 0.1934\n",
      "Generator Losses:\n",
      "  G Adv: 0.4353, F Adv: 0.2375\n",
      "  Cycle Photo: 0.0976, Cycle Monet: 0.0633\n",
      "  Perceptual Photo: 0.2040, Perceptual Monet: 0.2615\n",
      "  Total G Loss: 4.6094\n",
      "Epoch [8/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2219, D_X Fake: 0.1748, D_X Total: 0.1984\n",
      "  D_Y Real: 0.1821, D_Y Fake: 0.0666, D_Y Total: 0.1243\n",
      "Generator Losses:\n",
      "  G Adv: 0.2240, F Adv: 0.3910\n",
      "  Cycle Photo: 0.0887, Cycle Monet: 0.0854\n",
      "  Perceptual Photo: 0.1904, Perceptual Monet: 0.3055\n",
      "  Total G Loss: 4.8352\n",
      "Epoch [8/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1535, D_X Fake: 0.0640, D_X Total: 0.1088\n",
      "  D_Y Real: 0.1521, D_Y Fake: 0.1349, D_Y Total: 0.1435\n",
      "Generator Losses:\n",
      "  G Adv: 0.4953, F Adv: 0.5429\n",
      "  Cycle Photo: 0.1048, Cycle Monet: 0.0849\n",
      "  Perceptual Photo: 0.2646, Perceptual Monet: 0.2695\n",
      "  Total G Loss: 5.6057\n",
      "Epoch [8/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3129, D_X Fake: 0.0885, D_X Total: 0.2007\n",
      "  D_Y Real: 0.2098, D_Y Fake: 0.2103, D_Y Total: 0.2101\n",
      "Generator Losses:\n",
      "  G Adv: 0.4008, F Adv: 0.6907\n",
      "  Cycle Photo: 0.1089, Cycle Monet: 0.0815\n",
      "  Perceptual Photo: 0.2279, Perceptual Monet: 0.2108\n",
      "  Total G Loss: 5.1891\n",
      "Epoch [8/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1164, D_X Fake: 0.0475, D_X Total: 0.0820\n",
      "  D_Y Real: 0.1641, D_Y Fake: 0.1064, D_Y Total: 0.1352\n",
      "Generator Losses:\n",
      "  G Adv: 0.5594, F Adv: 0.6311\n",
      "  Cycle Photo: 0.0947, Cycle Monet: 0.0755\n",
      "  Perceptual Photo: 0.2402, Perceptual Monet: 0.2848\n",
      "  Total G Loss: 5.5177\n",
      "Epoch [8/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4756, D_X Fake: 0.1107, D_X Total: 0.2931\n",
      "  D_Y Real: 0.2509, D_Y Fake: 0.1800, D_Y Total: 0.2154\n",
      "Generator Losses:\n",
      "  G Adv: 0.2702, F Adv: 0.3712\n",
      "  Cycle Photo: 0.0566, Cycle Monet: 0.0699\n",
      "  Perceptual Photo: 0.2572, Perceptual Monet: 0.2610\n",
      "  Total G Loss: 4.4983\n",
      "Epoch [8/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2923, D_X Fake: 0.0783, D_X Total: 0.1853\n",
      "  D_Y Real: 0.2387, D_Y Fake: 0.1964, D_Y Total: 0.2175\n",
      "Generator Losses:\n",
      "  G Adv: 0.3551, F Adv: 0.8164\n",
      "  Cycle Photo: 0.1114, Cycle Monet: 0.1039\n",
      "  Perceptual Photo: 0.2396, Perceptual Monet: 0.2773\n",
      "  Total G Loss: 5.9083\n",
      "Epoch [8/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1245, D_X Fake: 0.1227, D_X Total: 0.1236\n",
      "  D_Y Real: 0.0747, D_Y Fake: 0.5939, D_Y Total: 0.3343\n",
      "Generator Losses:\n",
      "  G Adv: 0.0643, F Adv: 0.4921\n",
      "  Cycle Photo: 0.1357, Cycle Monet: 0.0818\n",
      "  Perceptual Photo: 0.2396, Perceptual Monet: 0.2772\n",
      "  Total G Loss: 5.3165\n",
      "Epoch [8/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2835, D_X Fake: 0.0851, D_X Total: 0.1843\n",
      "  D_Y Real: 0.1361, D_Y Fake: 0.1689, D_Y Total: 0.1525\n",
      "Generator Losses:\n",
      "  G Adv: 0.3930, F Adv: 0.4948\n",
      "  Cycle Photo: 0.0605, Cycle Monet: 0.0833\n",
      "  Perceptual Photo: 0.2239, Perceptual Monet: 0.3148\n",
      "  Total G Loss: 5.0196\n",
      "Epoch [8/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3446, D_X Fake: 0.2628, D_X Total: 0.3037\n",
      "  D_Y Real: 0.1071, D_Y Fake: 0.4296, D_Y Total: 0.2684\n",
      "Generator Losses:\n",
      "  G Adv: 0.1077, F Adv: 0.2695\n",
      "  Cycle Photo: 0.1180, Cycle Monet: 0.0889\n",
      "  Perceptual Photo: 0.2590, Perceptual Monet: 0.2227\n",
      "  Total G Loss: 4.8548\n",
      "Epoch [8/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2235, D_X Fake: 0.3117, D_X Total: 0.2676\n",
      "  D_Y Real: 0.2446, D_Y Fake: 0.1818, D_Y Total: 0.2132\n",
      "Generator Losses:\n",
      "  G Adv: 0.5405, F Adv: 0.2648\n",
      "  Cycle Photo: 0.1233, Cycle Monet: 0.0837\n",
      "  Perceptual Photo: 0.2213, Perceptual Monet: 0.2287\n",
      "  Total G Loss: 5.1255\n",
      "Epoch [8/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1898, D_X Fake: 0.2842, D_X Total: 0.2370\n",
      "  D_Y Real: 0.4413, D_Y Fake: 0.0440, D_Y Total: 0.2427\n",
      "Generator Losses:\n",
      "  G Adv: 0.6150, F Adv: 0.2328\n",
      "  Cycle Photo: 0.1233, Cycle Monet: 0.0929\n",
      "  Perceptual Photo: 0.2029, Perceptual Monet: 0.2515\n",
      "  Total G Loss: 5.2825\n",
      "Epoch [8/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2744, D_X Fake: 0.2980, D_X Total: 0.2862\n",
      "  D_Y Real: 0.1683, D_Y Fake: 0.1993, D_Y Total: 0.1838\n",
      "Generator Losses:\n",
      "  G Adv: 0.4371, F Adv: 0.2309\n",
      "  Cycle Photo: 0.1063, Cycle Monet: 0.0748\n",
      "  Perceptual Photo: 0.2692, Perceptual Monet: 0.2192\n",
      "  Total G Loss: 4.9209\n",
      "Epoch [8/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2439, D_X Fake: 0.4146, D_X Total: 0.3293\n",
      "  D_Y Real: 0.1047, D_Y Fake: 0.3113, D_Y Total: 0.2080\n",
      "Generator Losses:\n",
      "  G Adv: 0.2081, F Adv: 0.1699\n",
      "  Cycle Photo: 0.0728, Cycle Monet: 0.0645\n",
      "  Perceptual Photo: 0.2777, Perceptual Monet: 0.2141\n",
      "  Total G Loss: 4.2097\n",
      "Epoch [8/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2783, D_X Fake: 0.2654, D_X Total: 0.2718\n",
      "  D_Y Real: 0.0772, D_Y Fake: 0.1781, D_Y Total: 0.1276\n",
      "Generator Losses:\n",
      "  G Adv: 0.2575, F Adv: 0.2479\n",
      "  Cycle Photo: 0.0870, Cycle Monet: 0.0731\n",
      "  Perceptual Photo: 0.1805, Perceptual Monet: 0.2267\n",
      "  Total G Loss: 4.1416\n",
      "Epoch [8/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2627, D_X Fake: 0.2066, D_X Total: 0.2346\n",
      "  D_Y Real: 0.4408, D_Y Fake: 0.1026, D_Y Total: 0.2717\n",
      "Generator Losses:\n",
      "  G Adv: 0.8354, F Adv: 0.2728\n",
      "  Cycle Photo: 0.0752, Cycle Monet: 0.0629\n",
      "  Perceptual Photo: 0.2209, Perceptual Monet: 0.2512\n",
      "  Total G Loss: 4.8503\n",
      "Epoch [8/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2806, D_X Fake: 0.2355, D_X Total: 0.2581\n",
      "  D_Y Real: 0.2162, D_Y Fake: 0.0689, D_Y Total: 0.1426\n",
      "Generator Losses:\n",
      "  G Adv: 0.3685, F Adv: 0.2337\n",
      "  Cycle Photo: 0.0799, Cycle Monet: 0.0638\n",
      "  Perceptual Photo: 0.2264, Perceptual Monet: 0.1885\n",
      "  Total G Loss: 4.1133\n",
      "Epoch [8/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1334, D_X Fake: 0.3465, D_X Total: 0.2399\n",
      "  D_Y Real: 0.4166, D_Y Fake: 0.0522, D_Y Total: 0.2344\n",
      "Generator Losses:\n",
      "  G Adv: 1.2143, F Adv: 0.2173\n",
      "  Cycle Photo: 0.0563, Cycle Monet: 0.0905\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.2067\n",
      "  Total G Loss: 4.8471\n",
      "Epoch [8/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3424, D_X Fake: 0.2310, D_X Total: 0.2867\n",
      "  D_Y Real: 0.1383, D_Y Fake: 0.1481, D_Y Total: 0.1432\n",
      "Generator Losses:\n",
      "  G Adv: 0.2819, F Adv: 0.3865\n",
      "  Cycle Photo: 0.1027, Cycle Monet: 0.0792\n",
      "  Perceptual Photo: 0.1940, Perceptual Monet: 0.2537\n",
      "  Total G Loss: 4.7262\n",
      "Epoch [9/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2454, D_X Fake: 0.1669, D_X Total: 0.2062\n",
      "  D_Y Real: 0.1897, D_Y Fake: 0.1153, D_Y Total: 0.1525\n",
      "Generator Losses:\n",
      "  G Adv: 0.7353, F Adv: 0.3116\n",
      "  Cycle Photo: 0.0763, Cycle Monet: 0.0882\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.2173\n",
      "  Total G Loss: 4.6114\n",
      "Epoch [9/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1990, D_X Fake: 0.3329, D_X Total: 0.2659\n",
      "  D_Y Real: 0.0837, D_Y Fake: 0.4016, D_Y Total: 0.2426\n",
      "Generator Losses:\n",
      "  G Adv: 0.1861, F Adv: 0.2447\n",
      "  Cycle Photo: 0.0895, Cycle Monet: 0.0683\n",
      "  Perceptual Photo: 0.1825, Perceptual Monet: 0.2366\n",
      "  Total G Loss: 4.1043\n",
      "Epoch [9/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4425, D_X Fake: 0.1338, D_X Total: 0.2881\n",
      "  D_Y Real: 0.2692, D_Y Fake: 0.0298, D_Y Total: 0.1495\n",
      "Generator Losses:\n",
      "  G Adv: 0.3909, F Adv: 0.3969\n",
      "  Cycle Photo: 0.0984, Cycle Monet: 0.0931\n",
      "  Perceptual Photo: 0.2530, Perceptual Monet: 0.2266\n",
      "  Total G Loss: 5.1007\n",
      "Epoch [9/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2542, D_X Fake: 0.3320, D_X Total: 0.2931\n",
      "  D_Y Real: 0.1056, D_Y Fake: 0.1680, D_Y Total: 0.1368\n",
      "Generator Losses:\n",
      "  G Adv: 0.1514, F Adv: 0.2439\n",
      "  Cycle Photo: 0.1388, Cycle Monet: 0.0821\n",
      "  Perceptual Photo: 0.3264, Perceptual Monet: 0.2902\n",
      "  Total G Loss: 5.6869\n",
      "Epoch [9/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2181, D_X Fake: 0.1475, D_X Total: 0.1828\n",
      "  D_Y Real: 0.1940, D_Y Fake: 0.2647, D_Y Total: 0.2293\n",
      "Generator Losses:\n",
      "  G Adv: 0.3344, F Adv: 0.3995\n",
      "  Cycle Photo: 0.0886, Cycle Monet: 0.0653\n",
      "  Perceptual Photo: 0.2394, Perceptual Monet: 0.2565\n",
      "  Total G Loss: 4.7526\n",
      "Epoch [9/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1995, D_X Fake: 0.2087, D_X Total: 0.2041\n",
      "  D_Y Real: 0.1270, D_Y Fake: 0.1391, D_Y Total: 0.1331\n",
      "Generator Losses:\n",
      "  G Adv: 0.5270, F Adv: 0.3195\n",
      "  Cycle Photo: 0.0839, Cycle Monet: 0.0603\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.2382\n",
      "  Total G Loss: 4.2256\n",
      "Epoch [9/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3905, D_X Fake: 0.0767, D_X Total: 0.2336\n",
      "  D_Y Real: 0.0670, D_Y Fake: 0.2194, D_Y Total: 0.1432\n",
      "Generator Losses:\n",
      "  G Adv: 0.1812, F Adv: 0.6114\n",
      "  Cycle Photo: 0.0677, Cycle Monet: 0.0785\n",
      "  Perceptual Photo: 0.2407, Perceptual Monet: 0.2062\n",
      "  Total G Loss: 4.4898\n",
      "Epoch [9/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1969, D_X Fake: 0.1632, D_X Total: 0.1801\n",
      "  D_Y Real: 0.1237, D_Y Fake: 0.1692, D_Y Total: 0.1465\n",
      "Generator Losses:\n",
      "  G Adv: 0.2556, F Adv: 0.3089\n",
      "  Cycle Photo: 0.0872, Cycle Monet: 0.0746\n",
      "  Perceptual Photo: 0.2406, Perceptual Monet: 0.2391\n",
      "  Total G Loss: 4.5804\n",
      "Epoch [9/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2384, D_X Fake: 0.2174, D_X Total: 0.2279\n",
      "  D_Y Real: 0.1148, D_Y Fake: 0.1247, D_Y Total: 0.1198\n",
      "Generator Losses:\n",
      "  G Adv: 0.3274, F Adv: 0.5499\n",
      "  Cycle Photo: 0.0904, Cycle Monet: 0.0850\n",
      "  Perceptual Photo: 0.2365, Perceptual Monet: 0.2690\n",
      "  Total G Loss: 5.1590\n",
      "Epoch [9/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2618, D_X Fake: 0.0744, D_X Total: 0.1681\n",
      "  D_Y Real: 0.1369, D_Y Fake: 0.1997, D_Y Total: 0.1683\n",
      "Generator Losses:\n",
      "  G Adv: 0.3355, F Adv: 0.6858\n",
      "  Cycle Photo: 0.0698, Cycle Monet: 0.0845\n",
      "  Perceptual Photo: 0.1652, Perceptual Monet: 0.2383\n",
      "  Total G Loss: 4.5820\n",
      "Epoch [9/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1845, D_X Fake: 0.2897, D_X Total: 0.2371\n",
      "  D_Y Real: 0.1238, D_Y Fake: 0.2358, D_Y Total: 0.1798\n",
      "Generator Losses:\n",
      "  G Adv: 0.2320, F Adv: 0.3629\n",
      "  Cycle Photo: 0.1040, Cycle Monet: 0.0681\n",
      "  Perceptual Photo: 0.2526, Perceptual Monet: 0.2360\n",
      "  Total G Loss: 4.7594\n",
      "Epoch [9/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3503, D_X Fake: 0.1574, D_X Total: 0.2538\n",
      "  D_Y Real: 0.0445, D_Y Fake: 0.1117, D_Y Total: 0.0781\n",
      "Generator Losses:\n",
      "  G Adv: 0.1895, F Adv: 0.3659\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0647\n",
      "  Perceptual Photo: 0.2594, Perceptual Monet: 0.2382\n",
      "  Total G Loss: 4.2547\n",
      "Epoch [9/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1183, D_X Fake: 0.2092, D_X Total: 0.1638\n",
      "  D_Y Real: 0.2167, D_Y Fake: 0.1272, D_Y Total: 0.1720\n",
      "Generator Losses:\n",
      "  G Adv: 0.5277, F Adv: 0.2904\n",
      "  Cycle Photo: 0.0670, Cycle Monet: 0.0894\n",
      "  Perceptual Photo: 0.1702, Perceptual Monet: 0.2778\n",
      "  Total G Loss: 4.6224\n",
      "Epoch [9/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0978, D_X Fake: 0.3361, D_X Total: 0.2170\n",
      "  D_Y Real: 0.0595, D_Y Fake: 0.5695, D_Y Total: 0.3145\n",
      "Generator Losses:\n",
      "  G Adv: 0.2565, F Adv: 0.2109\n",
      "  Cycle Photo: 0.1293, Cycle Monet: 0.1160\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.3137\n",
      "  Total G Loss: 5.4036\n",
      "Epoch [9/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1875, D_X Fake: 0.1602, D_X Total: 0.1739\n",
      "  D_Y Real: 0.0262, D_Y Fake: 0.1616, D_Y Total: 0.0939\n",
      "Generator Losses:\n",
      "  G Adv: 0.3512, F Adv: 0.3428\n",
      "  Cycle Photo: 0.1179, Cycle Monet: 0.0618\n",
      "  Perceptual Photo: 0.3087, Perceptual Monet: 0.1947\n",
      "  Total G Loss: 5.0079\n",
      "Epoch [9/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1059, D_X Fake: 0.2113, D_X Total: 0.1586\n",
      "  D_Y Real: 0.0577, D_Y Fake: 0.4272, D_Y Total: 0.2425\n",
      "Generator Losses:\n",
      "  G Adv: 0.2182, F Adv: 0.3917\n",
      "  Cycle Photo: 0.1379, Cycle Monet: 0.0711\n",
      "  Perceptual Photo: 0.3019, Perceptual Monet: 0.2096\n",
      "  Total G Loss: 5.2584\n",
      "Epoch [9/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3531, D_X Fake: 0.1045, D_X Total: 0.2288\n",
      "  D_Y Real: 0.1283, D_Y Fake: 0.1820, D_Y Total: 0.1551\n",
      "Generator Losses:\n",
      "  G Adv: 0.1950, F Adv: 0.4313\n",
      "  Cycle Photo: 0.1017, Cycle Monet: 0.0794\n",
      "  Perceptual Photo: 0.2533, Perceptual Monet: 0.2280\n",
      "  Total G Loss: 4.8436\n",
      "Epoch [9/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4028, D_X Fake: 0.1947, D_X Total: 0.2988\n",
      "  D_Y Real: 0.3266, D_Y Fake: 0.0454, D_Y Total: 0.1860\n",
      "Generator Losses:\n",
      "  G Adv: 0.4506, F Adv: 0.3801\n",
      "  Cycle Photo: 0.1099, Cycle Monet: 0.0891\n",
      "  Perceptual Photo: 0.2616, Perceptual Monet: 0.2574\n",
      "  Total G Loss: 5.4155\n",
      "Epoch [9/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1266, D_X Fake: 0.1844, D_X Total: 0.1555\n",
      "  D_Y Real: 0.2320, D_Y Fake: 0.0810, D_Y Total: 0.1565\n",
      "Generator Losses:\n",
      "  G Adv: 0.5934, F Adv: 0.3818\n",
      "  Cycle Photo: 0.0829, Cycle Monet: 0.1073\n",
      "  Perceptual Photo: 0.2318, Perceptual Monet: 0.2543\n",
      "  Total G Loss: 5.3078\n",
      "Epoch [9/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1302, D_X Fake: 0.2487, D_X Total: 0.1894\n",
      "  D_Y Real: 0.0935, D_Y Fake: 0.0797, D_Y Total: 0.0866\n",
      "Generator Losses:\n",
      "  G Adv: 0.3760, F Adv: 0.1977\n",
      "  Cycle Photo: 0.0882, Cycle Monet: 0.0826\n",
      "  Perceptual Photo: 0.2699, Perceptual Monet: 0.2225\n",
      "  Total G Loss: 4.7429\n",
      "Epoch [9/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1248, D_X Fake: 0.2207, D_X Total: 0.1728\n",
      "  D_Y Real: 0.0948, D_Y Fake: 0.3061, D_Y Total: 0.2005\n",
      "Generator Losses:\n",
      "  G Adv: 0.3095, F Adv: 0.2368\n",
      "  Cycle Photo: 0.1035, Cycle Monet: 0.0678\n",
      "  Perceptual Photo: 0.2699, Perceptual Monet: 0.2399\n",
      "  Total G Loss: 4.8082\n",
      "Epoch [9/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1346, D_X Fake: 0.1359, D_X Total: 0.1352\n",
      "  D_Y Real: 0.0563, D_Y Fake: 0.0585, D_Y Total: 0.0574\n",
      "Generator Losses:\n",
      "  G Adv: 0.4347, F Adv: 0.4824\n",
      "  Cycle Photo: 0.0894, Cycle Monet: 0.0904\n",
      "  Perceptual Photo: 0.2392, Perceptual Monet: 0.2439\n",
      "  Total G Loss: 5.1307\n",
      "Epoch [9/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0869, D_X Fake: 0.2300, D_X Total: 0.1585\n",
      "  D_Y Real: 0.2780, D_Y Fake: 0.1496, D_Y Total: 0.2138\n",
      "Generator Losses:\n",
      "  G Adv: 0.5094, F Adv: 0.1179\n",
      "  Cycle Photo: 0.0573, Cycle Monet: 0.0750\n",
      "  Perceptual Photo: 0.1825, Perceptual Monet: 0.2906\n",
      "  Total G Loss: 4.3154\n",
      "Epoch [9/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1210, D_X Fake: 0.1386, D_X Total: 0.1298\n",
      "  D_Y Real: 0.0582, D_Y Fake: 0.2357, D_Y Total: 0.1470\n",
      "Generator Losses:\n",
      "  G Adv: 0.3040, F Adv: 0.3437\n",
      "  Cycle Photo: 0.1726, Cycle Monet: 0.1064\n",
      "  Perceptual Photo: 0.3199, Perceptual Monet: 0.2212\n",
      "  Total G Loss: 6.1429\n",
      "Epoch [10/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0687, D_X Fake: 0.2786, D_X Total: 0.1737\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.2466, D_Y Total: 0.1351\n",
      "Generator Losses:\n",
      "  G Adv: 0.4777, F Adv: 0.3182\n",
      "  Cycle Photo: 0.0840, Cycle Monet: 0.0662\n",
      "  Perceptual Photo: 0.1980, Perceptual Monet: 0.2274\n",
      "  Total G Loss: 4.4253\n",
      "Epoch [10/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2666, D_X Fake: 0.4157, D_X Total: 0.3412\n",
      "  D_Y Real: 0.1132, D_Y Fake: 0.3063, D_Y Total: 0.2097\n",
      "Generator Losses:\n",
      "  G Adv: 0.1498, F Adv: 0.2314\n",
      "  Cycle Photo: 0.0848, Cycle Monet: 0.0647\n",
      "  Perceptual Photo: 0.3088, Perceptual Monet: 0.2390\n",
      "  Total G Loss: 4.6156\n",
      "Epoch [10/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1709, D_X Fake: 0.2204, D_X Total: 0.1956\n",
      "  D_Y Real: 0.0497, D_Y Fake: 0.1887, D_Y Total: 0.1192\n",
      "Generator Losses:\n",
      "  G Adv: 0.3517, F Adv: 0.3652\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.1032\n",
      "  Perceptual Photo: 0.1502, Perceptual Monet: 0.2496\n",
      "  Total G Loss: 4.3335\n",
      "Epoch [10/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1359, D_X Fake: 0.2433, D_X Total: 0.1896\n",
      "  D_Y Real: 0.3520, D_Y Fake: 0.0930, D_Y Total: 0.2225\n",
      "Generator Losses:\n",
      "  G Adv: 0.7616, F Adv: 0.3350\n",
      "  Cycle Photo: 0.1078, Cycle Monet: 0.0739\n",
      "  Perceptual Photo: 0.1946, Perceptual Monet: 0.2184\n",
      "  Total G Loss: 4.9793\n",
      "Epoch [10/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1107, D_X Fake: 0.2137, D_X Total: 0.1622\n",
      "  D_Y Real: 0.2219, D_Y Fake: 0.1387, D_Y Total: 0.1803\n",
      "Generator Losses:\n",
      "  G Adv: 0.3613, F Adv: 0.1663\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0755\n",
      "  Perceptual Photo: 0.2060, Perceptual Monet: 0.1983\n",
      "  Total G Loss: 3.8954\n",
      "Epoch [10/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0588, D_X Fake: 0.2937, D_X Total: 0.1762\n",
      "  D_Y Real: 0.0460, D_Y Fake: 0.2067, D_Y Total: 0.1263\n",
      "Generator Losses:\n",
      "  G Adv: 0.1187, F Adv: 0.2007\n",
      "  Cycle Photo: 0.0659, Cycle Monet: 0.0785\n",
      "  Perceptual Photo: 0.2371, Perceptual Monet: 0.2217\n",
      "  Total G Loss: 4.0574\n",
      "Epoch [10/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2724, D_X Fake: 0.0863, D_X Total: 0.1793\n",
      "  D_Y Real: 0.2472, D_Y Fake: 0.1101, D_Y Total: 0.1787\n",
      "Generator Losses:\n",
      "  G Adv: 0.5792, F Adv: 0.4462\n",
      "  Cycle Photo: 0.1016, Cycle Monet: 0.0558\n",
      "  Perceptual Photo: 0.2062, Perceptual Monet: 0.2147\n",
      "  Total G Loss: 4.7033\n",
      "Epoch [10/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1368, D_X Fake: 0.2265, D_X Total: 0.1816\n",
      "  D_Y Real: 0.1390, D_Y Fake: 0.2395, D_Y Total: 0.1893\n",
      "Generator Losses:\n",
      "  G Adv: 0.2469, F Adv: 0.2331\n",
      "  Cycle Photo: 0.0901, Cycle Monet: 0.0694\n",
      "  Perceptual Photo: 0.2136, Perceptual Monet: 0.2577\n",
      "  Total G Loss: 4.4313\n",
      "Epoch [10/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1346, D_X Fake: 0.2875, D_X Total: 0.2111\n",
      "  D_Y Real: 0.1048, D_Y Fake: 0.2318, D_Y Total: 0.1683\n",
      "Generator Losses:\n",
      "  G Adv: 0.3286, F Adv: 0.4238\n",
      "  Cycle Photo: 0.1034, Cycle Monet: 0.0620\n",
      "  Perceptual Photo: 0.2452, Perceptual Monet: 0.2060\n",
      "  Total G Loss: 4.6623\n",
      "Epoch [10/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1461, D_X Fake: 0.2141, D_X Total: 0.1801\n",
      "  D_Y Real: 0.0793, D_Y Fake: 0.1316, D_Y Total: 0.1055\n",
      "Generator Losses:\n",
      "  G Adv: 0.4087, F Adv: 0.2678\n",
      "  Cycle Photo: 0.0809, Cycle Monet: 0.0816\n",
      "  Perceptual Photo: 0.2750, Perceptual Monet: 0.2470\n",
      "  Total G Loss: 4.9117\n",
      "Epoch [10/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1489, D_X Fake: 0.0696, D_X Total: 0.1092\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.2163, D_Y Total: 0.1248\n",
      "Generator Losses:\n",
      "  G Adv: 0.5426, F Adv: 0.7823\n",
      "  Cycle Photo: 0.0702, Cycle Monet: 0.0762\n",
      "  Perceptual Photo: 0.1812, Perceptual Monet: 0.2491\n",
      "  Total G Loss: 4.9394\n",
      "Epoch [10/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1291, D_X Fake: 0.2334, D_X Total: 0.1812\n",
      "  D_Y Real: 0.1161, D_Y Fake: 0.0930, D_Y Total: 0.1045\n",
      "Generator Losses:\n",
      "  G Adv: 0.5477, F Adv: 0.5874\n",
      "  Cycle Photo: 0.0901, Cycle Monet: 0.0888\n",
      "  Perceptual Photo: 0.1871, Perceptual Monet: 0.2550\n",
      "  Total G Loss: 5.1342\n",
      "Epoch [10/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2015, D_X Fake: 0.1052, D_X Total: 0.1533\n",
      "  D_Y Real: 0.1267, D_Y Fake: 0.1456, D_Y Total: 0.1361\n",
      "Generator Losses:\n",
      "  G Adv: 0.3679, F Adv: 0.4849\n",
      "  Cycle Photo: 0.0738, Cycle Monet: 0.0645\n",
      "  Perceptual Photo: 0.2437, Perceptual Monet: 0.2300\n",
      "  Total G Loss: 4.6041\n",
      "Epoch [10/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1656, D_X Fake: 0.3158, D_X Total: 0.2407\n",
      "  D_Y Real: 0.1751, D_Y Fake: 0.1291, D_Y Total: 0.1521\n",
      "Generator Losses:\n",
      "  G Adv: 0.4892, F Adv: 0.2825\n",
      "  Cycle Photo: 0.0950, Cycle Monet: 0.0587\n",
      "  Perceptual Photo: 0.2455, Perceptual Monet: 0.2218\n",
      "  Total G Loss: 4.6449\n",
      "Epoch [10/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1543, D_X Fake: 0.1351, D_X Total: 0.1447\n",
      "  D_Y Real: 0.1299, D_Y Fake: 0.1634, D_Y Total: 0.1467\n",
      "Generator Losses:\n",
      "  G Adv: 0.5517, F Adv: 0.5981\n",
      "  Cycle Photo: 0.0830, Cycle Monet: 0.0540\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.2282\n",
      "  Total G Loss: 4.5255\n",
      "Epoch [10/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4455, D_X Fake: 0.0583, D_X Total: 0.2519\n",
      "  D_Y Real: 0.1422, D_Y Fake: 0.1543, D_Y Total: 0.1482\n",
      "Generator Losses:\n",
      "  G Adv: 0.3680, F Adv: 0.5464\n",
      "  Cycle Photo: 0.0584, Cycle Monet: 0.0766\n",
      "  Perceptual Photo: 0.1760, Perceptual Monet: 0.2379\n",
      "  Total G Loss: 4.3336\n",
      "Epoch [10/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1970, D_X Fake: 0.0833, D_X Total: 0.1401\n",
      "  D_Y Real: 0.0758, D_Y Fake: 0.2091, D_Y Total: 0.1425\n",
      "Generator Losses:\n",
      "  G Adv: 0.2825, F Adv: 0.4517\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0644\n",
      "  Perceptual Photo: 0.2441, Perceptual Monet: 0.2045\n",
      "  Total G Loss: 4.1668\n",
      "Epoch [10/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0551, D_X Fake: 0.4590, D_X Total: 0.2570\n",
      "  D_Y Real: 0.5158, D_Y Fake: 0.0715, D_Y Total: 0.2936\n",
      "Generator Losses:\n",
      "  G Adv: 0.6983, F Adv: 0.1623\n",
      "  Cycle Photo: 0.0588, Cycle Monet: 0.0615\n",
      "  Perceptual Photo: 0.2034, Perceptual Monet: 0.1861\n",
      "  Total G Loss: 4.0112\n",
      "Epoch [10/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1909, D_X Fake: 0.0427, D_X Total: 0.1168\n",
      "  D_Y Real: 0.1108, D_Y Fake: 0.4219, D_Y Total: 0.2664\n",
      "Generator Losses:\n",
      "  G Adv: 0.2191, F Adv: 0.4346\n",
      "  Cycle Photo: 0.0748, Cycle Monet: 0.0834\n",
      "  Perceptual Photo: 0.2077, Perceptual Monet: 0.2667\n",
      "  Total G Loss: 4.6076\n",
      "Epoch [10/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1345, D_X Fake: 0.2849, D_X Total: 0.2097\n",
      "  D_Y Real: 0.2141, D_Y Fake: 0.0310, D_Y Total: 0.1225\n",
      "Generator Losses:\n",
      "  G Adv: 0.5656, F Adv: 0.3079\n",
      "  Cycle Photo: 0.1683, Cycle Monet: 0.0697\n",
      "  Perceptual Photo: 0.2437, Perceptual Monet: 0.2138\n",
      "  Total G Loss: 5.5412\n",
      "Epoch [10/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1131, D_X Fake: 0.2215, D_X Total: 0.1673\n",
      "  D_Y Real: 0.2715, D_Y Fake: 0.1708, D_Y Total: 0.2212\n",
      "Generator Losses:\n",
      "  G Adv: 0.2567, F Adv: 0.2718\n",
      "  Cycle Photo: 0.0778, Cycle Monet: 0.0727\n",
      "  Perceptual Photo: 0.2144, Perceptual Monet: 0.2509\n",
      "  Total G Loss: 4.3596\n",
      "Epoch [10/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0974, D_X Fake: 0.1098, D_X Total: 0.1036\n",
      "  D_Y Real: 0.1018, D_Y Fake: 0.3366, D_Y Total: 0.2192\n",
      "Generator Losses:\n",
      "  G Adv: 0.2189, F Adv: 0.3890\n",
      "  Cycle Photo: 0.1611, Cycle Monet: 0.0695\n",
      "  Perceptual Photo: 0.3252, Perceptual Monet: 0.2297\n",
      "  Total G Loss: 5.6880\n",
      "Epoch [10/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1775, D_X Fake: 0.3641, D_X Total: 0.2708\n",
      "  D_Y Real: 0.0718, D_Y Fake: 0.1484, D_Y Total: 0.1101\n",
      "Generator Losses:\n",
      "  G Adv: 0.2910, F Adv: 0.1372\n",
      "  Cycle Photo: 0.0866, Cycle Monet: 0.0646\n",
      "  Perceptual Photo: 0.2382, Perceptual Monet: 0.2353\n",
      "  Total G Loss: 4.3076\n",
      "Epoch [10/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4064, D_X Fake: 0.0466, D_X Total: 0.2265\n",
      "  D_Y Real: 0.0796, D_Y Fake: 0.2252, D_Y Total: 0.1524\n",
      "Generator Losses:\n",
      "  G Adv: 0.1954, F Adv: 0.7402\n",
      "  Cycle Photo: 0.0718, Cycle Monet: 0.1053\n",
      "  Perceptual Photo: 0.2154, Perceptual Monet: 0.3151\n",
      "  Total G Loss: 5.3590\n",
      "Epoch [11/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0517, D_X Fake: 0.2398, D_X Total: 0.1457\n",
      "  D_Y Real: 0.2137, D_Y Fake: 0.1318, D_Y Total: 0.1728\n",
      "Generator Losses:\n",
      "  G Adv: 0.3225, F Adv: 0.1953\n",
      "  Cycle Photo: 0.1021, Cycle Monet: 0.1015\n",
      "  Perceptual Photo: 0.1913, Perceptual Monet: 0.2440\n",
      "  Total G Loss: 4.7308\n",
      "Epoch [11/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4237, D_X Fake: 0.1161, D_X Total: 0.2699\n",
      "  D_Y Real: 0.0674, D_Y Fake: 0.3603, D_Y Total: 0.2138\n",
      "Generator Losses:\n",
      "  G Adv: 0.3098, F Adv: 0.5364\n",
      "  Cycle Photo: 0.0663, Cycle Monet: 0.0736\n",
      "  Perceptual Photo: 0.2108, Perceptual Monet: 0.2662\n",
      "  Total G Loss: 4.6296\n",
      "Epoch [11/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1511, D_X Fake: 0.2977, D_X Total: 0.2244\n",
      "  D_Y Real: 0.1373, D_Y Fake: 0.3139, D_Y Total: 0.2256\n",
      "Generator Losses:\n",
      "  G Adv: 0.4303, F Adv: 0.2695\n",
      "  Cycle Photo: 0.0607, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1728, Perceptual Monet: 0.2060\n",
      "  Total G Loss: 3.6786\n",
      "Epoch [11/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2517, D_X Fake: 0.1191, D_X Total: 0.1854\n",
      "  D_Y Real: 0.1828, D_Y Fake: 0.0964, D_Y Total: 0.1396\n",
      "Generator Losses:\n",
      "  G Adv: 0.2580, F Adv: 0.3487\n",
      "  Cycle Photo: 0.0763, Cycle Monet: 0.0692\n",
      "  Perceptual Photo: 0.2157, Perceptual Monet: 0.2165\n",
      "  Total G Loss: 4.2233\n",
      "Epoch [11/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0985, D_X Fake: 0.3152, D_X Total: 0.2069\n",
      "  D_Y Real: 0.1181, D_Y Fake: 0.0588, D_Y Total: 0.0885\n",
      "Generator Losses:\n",
      "  G Adv: 0.6563, F Adv: 0.3036\n",
      "  Cycle Photo: 0.0547, Cycle Monet: 0.0712\n",
      "  Perceptual Photo: 0.1561, Perceptual Monet: 0.2175\n",
      "  Total G Loss: 4.0870\n",
      "Epoch [11/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1017, D_X Fake: 0.3080, D_X Total: 0.2048\n",
      "  D_Y Real: 0.7146, D_Y Fake: 0.0395, D_Y Total: 0.3771\n",
      "Generator Losses:\n",
      "  G Adv: 0.7859, F Adv: 0.1443\n",
      "  Cycle Photo: 0.1181, Cycle Monet: 0.0857\n",
      "  Perceptual Photo: 0.2001, Perceptual Monet: 0.2161\n",
      "  Total G Loss: 5.0496\n",
      "Epoch [11/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1077, D_X Fake: 0.0693, D_X Total: 0.0885\n",
      "  D_Y Real: 0.1616, D_Y Fake: 0.3062, D_Y Total: 0.2339\n",
      "Generator Losses:\n",
      "  G Adv: 0.3476, F Adv: 0.3613\n",
      "  Cycle Photo: 0.0854, Cycle Monet: 0.0771\n",
      "  Perceptual Photo: 0.2173, Perceptual Monet: 0.2237\n",
      "  Total G Loss: 4.5388\n",
      "Epoch [11/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0526, D_X Fake: 0.2811, D_X Total: 0.1669\n",
      "  D_Y Real: 0.2648, D_Y Fake: 0.0432, D_Y Total: 0.1540\n",
      "Generator Losses:\n",
      "  G Adv: 0.9567, F Adv: 0.2534\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0790\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.2937\n",
      "  Total G Loss: 4.6231\n",
      "Epoch [11/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1907, D_X Fake: 0.2035, D_X Total: 0.1971\n",
      "  D_Y Real: 0.4841, D_Y Fake: 0.1811, D_Y Total: 0.3326\n",
      "Generator Losses:\n",
      "  G Adv: 0.3635, F Adv: 0.2922\n",
      "  Cycle Photo: 0.0722, Cycle Monet: 0.0467\n",
      "  Perceptual Photo: 0.2372, Perceptual Monet: 0.1928\n",
      "  Total G Loss: 3.9958\n",
      "Epoch [11/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2694, D_X Fake: 0.1327, D_X Total: 0.2011\n",
      "  D_Y Real: 0.0571, D_Y Fake: 0.3088, D_Y Total: 0.1829\n",
      "Generator Losses:\n",
      "  G Adv: 0.1848, F Adv: 0.4666\n",
      "  Cycle Photo: 0.0935, Cycle Monet: 0.0836\n",
      "  Perceptual Photo: 0.2101, Perceptual Monet: 0.2293\n",
      "  Total G Loss: 4.6193\n",
      "Epoch [11/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3326, D_X Fake: 0.0328, D_X Total: 0.1827\n",
      "  D_Y Real: 0.3156, D_Y Fake: 0.2193, D_Y Total: 0.2674\n",
      "Generator Losses:\n",
      "  G Adv: 0.4595, F Adv: 0.6489\n",
      "  Cycle Photo: 0.1063, Cycle Monet: 0.0875\n",
      "  Perceptual Photo: 0.2156, Perceptual Monet: 0.2366\n",
      "  Total G Loss: 5.3080\n",
      "Epoch [11/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1330, D_X Fake: 0.2437, D_X Total: 0.1884\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.3240, D_Y Total: 0.1778\n",
      "Generator Losses:\n",
      "  G Adv: 0.2702, F Adv: 0.3665\n",
      "  Cycle Photo: 0.1110, Cycle Monet: 0.0583\n",
      "  Perceptual Photo: 0.2050, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 4.2645\n",
      "Epoch [11/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1337, D_X Fake: 0.1062, D_X Total: 0.1200\n",
      "  D_Y Real: 0.1636, D_Y Fake: 0.0929, D_Y Total: 0.1283\n",
      "Generator Losses:\n",
      "  G Adv: 0.7274, F Adv: 0.6363\n",
      "  Cycle Photo: 0.0753, Cycle Monet: 0.0715\n",
      "  Perceptual Photo: 0.2421, Perceptual Monet: 0.2181\n",
      "  Total G Loss: 5.1323\n",
      "Epoch [11/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1907, D_X Fake: 0.2140, D_X Total: 0.2023\n",
      "  D_Y Real: 0.3568, D_Y Fake: 0.0679, D_Y Total: 0.2123\n",
      "Generator Losses:\n",
      "  G Adv: 0.5923, F Adv: 0.3973\n",
      "  Cycle Photo: 0.0631, Cycle Monet: 0.0575\n",
      "  Perceptual Photo: 0.2065, Perceptual Monet: 0.2168\n",
      "  Total G Loss: 4.3119\n",
      "Epoch [11/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0858, D_X Fake: 0.3027, D_X Total: 0.1942\n",
      "  D_Y Real: 0.2335, D_Y Fake: 0.1147, D_Y Total: 0.1741\n",
      "Generator Losses:\n",
      "  G Adv: 0.4342, F Adv: 0.2402\n",
      "  Cycle Photo: 0.0750, Cycle Monet: 0.0835\n",
      "  Perceptual Photo: 0.2464, Perceptual Monet: 0.2373\n",
      "  Total G Loss: 4.6783\n",
      "Epoch [11/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1554, D_X Fake: 0.1568, D_X Total: 0.1561\n",
      "  D_Y Real: 0.1730, D_Y Fake: 0.1189, D_Y Total: 0.1459\n",
      "Generator Losses:\n",
      "  G Adv: 0.4828, F Adv: 0.4184\n",
      "  Cycle Photo: 0.1093, Cycle Monet: 0.0745\n",
      "  Perceptual Photo: 0.2352, Perceptual Monet: 0.2682\n",
      "  Total G Loss: 5.2556\n",
      "Epoch [11/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0932, D_X Fake: 0.2099, D_X Total: 0.1516\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.1000, D_Y Total: 0.0686\n",
      "Generator Losses:\n",
      "  G Adv: 0.3774, F Adv: 0.4037\n",
      "  Cycle Photo: 0.0597, Cycle Monet: 0.0899\n",
      "  Perceptual Photo: 0.1811, Perceptual Monet: 0.2577\n",
      "  Total G Loss: 4.4710\n",
      "Epoch [11/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2371, D_X Fake: 0.1040, D_X Total: 0.1705\n",
      "  D_Y Real: 0.1389, D_Y Fake: 0.1833, D_Y Total: 0.1611\n",
      "Generator Losses:\n",
      "  G Adv: 0.3730, F Adv: 0.8540\n",
      "  Cycle Photo: 0.0688, Cycle Monet: 0.0794\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.2607\n",
      "  Total G Loss: 4.9158\n",
      "Epoch [11/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0997, D_X Fake: 0.1724, D_X Total: 0.1360\n",
      "  D_Y Real: 0.1602, D_Y Fake: 0.0937, D_Y Total: 0.1270\n",
      "Generator Losses:\n",
      "  G Adv: 0.5465, F Adv: 0.3937\n",
      "  Cycle Photo: 0.0742, Cycle Monet: 0.0645\n",
      "  Perceptual Photo: 0.1995, Perceptual Monet: 0.2184\n",
      "  Total G Loss: 4.4166\n",
      "Epoch [11/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1345, D_X Fake: 0.2788, D_X Total: 0.2067\n",
      "  D_Y Real: 0.0709, D_Y Fake: 0.3181, D_Y Total: 0.1945\n",
      "Generator Losses:\n",
      "  G Adv: 0.2189, F Adv: 0.2752\n",
      "  Cycle Photo: 0.0736, Cycle Monet: 0.0483\n",
      "  Perceptual Photo: 0.2215, Perceptual Monet: 0.2187\n",
      "  Total G Loss: 3.9140\n",
      "Epoch [11/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1574, D_X Fake: 0.1308, D_X Total: 0.1441\n",
      "  D_Y Real: 0.2529, D_Y Fake: 0.1309, D_Y Total: 0.1919\n",
      "Generator Losses:\n",
      "  G Adv: 0.3605, F Adv: 0.2479\n",
      "  Cycle Photo: 0.0497, Cycle Monet: 0.0872\n",
      "  Perceptual Photo: 0.2049, Perceptual Monet: 0.3064\n",
      "  Total G Loss: 4.5338\n",
      "Epoch [11/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.1360, D_X Total: 0.1277\n",
      "  D_Y Real: 0.1051, D_Y Fake: 0.1235, D_Y Total: 0.1143\n",
      "Generator Losses:\n",
      "  G Adv: 0.2952, F Adv: 0.4781\n",
      "  Cycle Photo: 0.0910, Cycle Monet: 0.0809\n",
      "  Perceptual Photo: 0.2294, Perceptual Monet: 0.2496\n",
      "  Total G Loss: 4.8872\n",
      "Epoch [11/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0456, D_X Fake: 0.2322, D_X Total: 0.1389\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.2099, D_Y Total: 0.1247\n",
      "Generator Losses:\n",
      "  G Adv: 0.3944, F Adv: 0.3375\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0592\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1988\n",
      "  Total G Loss: 3.7660\n",
      "Epoch [11/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2282, D_X Fake: 0.1291, D_X Total: 0.1787\n",
      "  D_Y Real: 0.1145, D_Y Fake: 0.1638, D_Y Total: 0.1391\n",
      "Generator Losses:\n",
      "  G Adv: 0.4739, F Adv: 0.5013\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0690\n",
      "  Perceptual Photo: 0.2027, Perceptual Monet: 0.2211\n",
      "  Total G Loss: 4.2661\n",
      "Epoch [12/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1721, D_X Fake: 0.2736, D_X Total: 0.2228\n",
      "  D_Y Real: 0.1068, D_Y Fake: 0.1770, D_Y Total: 0.1419\n",
      "Generator Losses:\n",
      "  G Adv: 0.2297, F Adv: 0.3945\n",
      "  Cycle Photo: 0.0724, Cycle Monet: 0.0605\n",
      "  Perceptual Photo: 0.2697, Perceptual Monet: 0.2205\n",
      "  Total G Loss: 4.4045\n",
      "Epoch [12/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2915, D_X Fake: 0.0700, D_X Total: 0.1808\n",
      "  D_Y Real: 0.1820, D_Y Fake: 0.0895, D_Y Total: 0.1358\n",
      "Generator Losses:\n",
      "  G Adv: 0.5443, F Adv: 0.7021\n",
      "  Cycle Photo: 0.0779, Cycle Monet: 0.0527\n",
      "  Perceptual Photo: 0.2142, Perceptual Monet: 0.2109\n",
      "  Total G Loss: 4.6777\n",
      "Epoch [12/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1632, D_X Fake: 0.2113, D_X Total: 0.1873\n",
      "  D_Y Real: 0.1037, D_Y Fake: 0.2010, D_Y Total: 0.1523\n",
      "Generator Losses:\n",
      "  G Adv: 0.2806, F Adv: 0.3550\n",
      "  Cycle Photo: 0.0817, Cycle Monet: 0.0744\n",
      "  Perceptual Photo: 0.1885, Perceptual Monet: 0.2597\n",
      "  Total G Loss: 4.4368\n",
      "Epoch [12/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1255, D_X Fake: 0.2512, D_X Total: 0.1883\n",
      "  D_Y Real: 0.1201, D_Y Fake: 0.2538, D_Y Total: 0.1869\n",
      "Generator Losses:\n",
      "  G Adv: 0.2016, F Adv: 0.2184\n",
      "  Cycle Photo: 0.0682, Cycle Monet: 0.0864\n",
      "  Perceptual Photo: 0.2312, Perceptual Monet: 0.2128\n",
      "  Total G Loss: 4.1866\n",
      "Epoch [12/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1407, D_X Fake: 0.2766, D_X Total: 0.2087\n",
      "  D_Y Real: 0.0880, D_Y Fake: 0.2374, D_Y Total: 0.1627\n",
      "Generator Losses:\n",
      "  G Adv: 0.2440, F Adv: 0.2696\n",
      "  Cycle Photo: 0.0556, Cycle Monet: 0.0783\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.2409\n",
      "  Total G Loss: 3.9218\n",
      "Epoch [12/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.1487, D_X Total: 0.1199\n",
      "  D_Y Real: 0.2070, D_Y Fake: 0.2176, D_Y Total: 0.2123\n",
      "Generator Losses:\n",
      "  G Adv: 0.3926, F Adv: 0.3157\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0578\n",
      "  Perceptual Photo: 0.1957, Perceptual Monet: 0.2255\n",
      "  Total G Loss: 3.8612\n",
      "Epoch [12/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0427, D_X Fake: 0.1970, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0512, D_Y Fake: 0.1618, D_Y Total: 0.1065\n",
      "Generator Losses:\n",
      "  G Adv: 0.4816, F Adv: 0.4138\n",
      "  Cycle Photo: 0.0925, Cycle Monet: 0.0641\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.2100\n",
      "  Total G Loss: 4.2489\n",
      "Epoch [12/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1247, D_X Fake: 0.1391, D_X Total: 0.1319\n",
      "  D_Y Real: 0.2579, D_Y Fake: 0.2694, D_Y Total: 0.2636\n",
      "Generator Losses:\n",
      "  G Adv: 0.4075, F Adv: 0.3944\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0600\n",
      "  Perceptual Photo: 0.1575, Perceptual Monet: 0.2024\n",
      "  Total G Loss: 3.6806\n",
      "Epoch [12/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0853, D_X Fake: 0.2563, D_X Total: 0.1708\n",
      "  D_Y Real: 0.1573, D_Y Fake: 0.1492, D_Y Total: 0.1533\n",
      "Generator Losses:\n",
      "  G Adv: 0.5512, F Adv: 0.4164\n",
      "  Cycle Photo: 0.0890, Cycle Monet: 0.0720\n",
      "  Perceptual Photo: 0.1939, Perceptual Monet: 0.2493\n",
      "  Total G Loss: 4.7935\n",
      "Epoch [12/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1156, D_X Fake: 0.2664, D_X Total: 0.1910\n",
      "  D_Y Real: 0.1474, D_Y Fake: 0.2181, D_Y Total: 0.1828\n",
      "Generator Losses:\n",
      "  G Adv: 0.3699, F Adv: 0.1884\n",
      "  Cycle Photo: 0.1005, Cycle Monet: 0.0771\n",
      "  Perceptual Photo: 0.2960, Perceptual Monet: 0.2232\n",
      "  Total G Loss: 4.9302\n",
      "Epoch [12/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0707, D_X Fake: 0.1107, D_X Total: 0.0907\n",
      "  D_Y Real: 0.0609, D_Y Fake: 0.0390, D_Y Total: 0.0500\n",
      "Generator Losses:\n",
      "  G Adv: 0.9258, F Adv: 0.5865\n",
      "  Cycle Photo: 0.0658, Cycle Monet: 0.0590\n",
      "  Perceptual Photo: 0.2067, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 4.6506\n",
      "Epoch [12/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0439, D_X Fake: 0.2194, D_X Total: 0.1316\n",
      "  D_Y Real: 0.2185, D_Y Fake: 0.0517, D_Y Total: 0.1351\n",
      "Generator Losses:\n",
      "  G Adv: 0.5826, F Adv: 0.1853\n",
      "  Cycle Photo: 0.0991, Cycle Monet: 0.0635\n",
      "  Perceptual Photo: 0.1959, Perceptual Monet: 0.2083\n",
      "  Total G Loss: 4.4147\n",
      "Epoch [12/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0939, D_X Fake: 0.1989, D_X Total: 0.1464\n",
      "  D_Y Real: 0.1165, D_Y Fake: 0.1914, D_Y Total: 0.1539\n",
      "Generator Losses:\n",
      "  G Adv: 0.3879, F Adv: 0.2076\n",
      "  Cycle Photo: 0.0687, Cycle Monet: 0.0675\n",
      "  Perceptual Photo: 0.2071, Perceptual Monet: 0.2163\n",
      "  Total G Loss: 4.0742\n",
      "Epoch [12/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2602, D_X Fake: 0.0607, D_X Total: 0.1604\n",
      "  D_Y Real: 0.0442, D_Y Fake: 0.1932, D_Y Total: 0.1187\n",
      "Generator Losses:\n",
      "  G Adv: 0.4736, F Adv: 1.1029\n",
      "  Cycle Photo: 0.0588, Cycle Monet: 0.0568\n",
      "  Perceptual Photo: 0.1842, Perceptual Monet: 0.2011\n",
      "  Total G Loss: 4.6588\n",
      "Epoch [12/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1588, D_X Fake: 0.1033, D_X Total: 0.1310\n",
      "  D_Y Real: 0.1695, D_Y Fake: 0.1255, D_Y Total: 0.1475\n",
      "Generator Losses:\n",
      "  G Adv: 0.3657, F Adv: 0.4688\n",
      "  Cycle Photo: 0.0795, Cycle Monet: 0.0711\n",
      "  Perceptual Photo: 0.2196, Perceptual Monet: 0.2687\n",
      "  Total G Loss: 4.7820\n",
      "Epoch [12/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1456, D_X Fake: 0.1653, D_X Total: 0.1555\n",
      "  D_Y Real: 0.1062, D_Y Fake: 0.1744, D_Y Total: 0.1403\n",
      "Generator Losses:\n",
      "  G Adv: 0.3115, F Adv: 0.3598\n",
      "  Cycle Photo: 0.1005, Cycle Monet: 0.0832\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.2630\n",
      "  Total G Loss: 4.6193\n",
      "Epoch [12/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1281, D_X Fake: 0.1028, D_X Total: 0.1154\n",
      "  D_Y Real: 0.0556, D_Y Fake: 0.1907, D_Y Total: 0.1231\n",
      "Generator Losses:\n",
      "  G Adv: 0.4108, F Adv: 0.4140\n",
      "  Cycle Photo: 0.0965, Cycle Monet: 0.0766\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.1971\n",
      "  Total G Loss: 4.4560\n",
      "Epoch [12/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0850, D_X Fake: 0.3047, D_X Total: 0.1949\n",
      "  D_Y Real: 0.2182, D_Y Fake: 0.0419, D_Y Total: 0.1300\n",
      "Generator Losses:\n",
      "  G Adv: 0.3812, F Adv: 0.1760\n",
      "  Cycle Photo: 0.0738, Cycle Monet: 0.0631\n",
      "  Perceptual Photo: 0.1881, Perceptual Monet: 0.2169\n",
      "  Total G Loss: 3.9512\n",
      "Epoch [12/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5148, D_X Fake: 0.0711, D_X Total: 0.2930\n",
      "  D_Y Real: 0.2019, D_Y Fake: 0.1643, D_Y Total: 0.1831\n",
      "Generator Losses:\n",
      "  G Adv: 0.5192, F Adv: 0.7850\n",
      "  Cycle Photo: 0.0623, Cycle Monet: 0.0570\n",
      "  Perceptual Photo: 0.1569, Perceptual Monet: 0.2024\n",
      "  Total G Loss: 4.2929\n",
      "Epoch [12/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0636, D_X Fake: 0.2403, D_X Total: 0.1520\n",
      "  D_Y Real: 0.2267, D_Y Fake: 0.0770, D_Y Total: 0.1518\n",
      "Generator Losses:\n",
      "  G Adv: 0.6602, F Adv: 0.3048\n",
      "  Cycle Photo: 0.0681, Cycle Monet: 0.0667\n",
      "  Perceptual Photo: 0.1948, Perceptual Monet: 0.2136\n",
      "  Total G Loss: 4.3547\n",
      "Epoch [12/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1717, D_X Fake: 0.1103, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.2566, D_Y Total: 0.1483\n",
      "Generator Losses:\n",
      "  G Adv: 0.1900, F Adv: 0.5484\n",
      "  Cycle Photo: 0.0745, Cycle Monet: 0.0748\n",
      "  Perceptual Photo: 0.1920, Perceptual Monet: 0.2212\n",
      "  Total G Loss: 4.2967\n",
      "Epoch [12/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1885, D_X Fake: 0.0973, D_X Total: 0.1429\n",
      "  D_Y Real: 0.1201, D_Y Fake: 0.3141, D_Y Total: 0.2171\n",
      "Generator Losses:\n",
      "  G Adv: 0.2698, F Adv: 0.4411\n",
      "  Cycle Photo: 0.0542, Cycle Monet: 0.0607\n",
      "  Perceptual Photo: 0.1812, Perceptual Monet: 0.2020\n",
      "  Total G Loss: 3.7762\n",
      "Epoch [12/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2164, D_X Fake: 0.0875, D_X Total: 0.1520\n",
      "  D_Y Real: 0.1593, D_Y Fake: 0.2710, D_Y Total: 0.2152\n",
      "Generator Losses:\n",
      "  G Adv: 0.3152, F Adv: 0.4552\n",
      "  Cycle Photo: 0.0622, Cycle Monet: 0.0534\n",
      "  Perceptual Photo: 0.1853, Perceptual Monet: 0.2153\n",
      "  Total G Loss: 3.9294\n",
      "Epoch [12/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1473, D_X Fake: 0.0237, D_X Total: 0.0855\n",
      "  D_Y Real: 0.0497, D_Y Fake: 0.2346, D_Y Total: 0.1422\n",
      "Generator Losses:\n",
      "  G Adv: 0.3463, F Adv: 0.6230\n",
      "  Cycle Photo: 0.0625, Cycle Monet: 0.0693\n",
      "  Perceptual Photo: 0.1909, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 4.0605\n",
      "Epoch [13/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2210, D_X Fake: 0.1156, D_X Total: 0.1683\n",
      "  D_Y Real: 0.2034, D_Y Fake: 0.0818, D_Y Total: 0.1426\n",
      "Generator Losses:\n",
      "  G Adv: 0.5370, F Adv: 0.4766\n",
      "  Cycle Photo: 0.0868, Cycle Monet: 0.0629\n",
      "  Perceptual Photo: 0.2531, Perceptual Monet: 0.2366\n",
      "  Total G Loss: 4.9585\n",
      "Epoch [13/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.4294, D_X Total: 0.2513\n",
      "  D_Y Real: 0.0978, D_Y Fake: 0.1511, D_Y Total: 0.1244\n",
      "Generator Losses:\n",
      "  G Adv: 0.4124, F Adv: 0.1715\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0524\n",
      "  Perceptual Photo: 0.1980, Perceptual Monet: 0.2354\n",
      "  Total G Loss: 3.8399\n",
      "Epoch [13/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1317, D_X Fake: 0.0431, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.1132, D_Y Total: 0.0689\n",
      "Generator Losses:\n",
      "  G Adv: 0.6828, F Adv: 0.6318\n",
      "  Cycle Photo: 0.0822, Cycle Monet: 0.0636\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1872\n",
      "  Total G Loss: 4.5228\n",
      "Epoch [13/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2613, D_X Fake: 0.1443, D_X Total: 0.2028\n",
      "  D_Y Real: 0.1262, D_Y Fake: 0.2724, D_Y Total: 0.1993\n",
      "Generator Losses:\n",
      "  G Adv: 0.4306, F Adv: 0.6839\n",
      "  Cycle Photo: 0.0675, Cycle Monet: 0.0794\n",
      "  Perceptual Photo: 0.2076, Perceptual Monet: 0.2489\n",
      "  Total G Loss: 4.8658\n",
      "Epoch [13/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1118, D_X Fake: 0.4747, D_X Total: 0.2932\n",
      "  D_Y Real: 0.2816, D_Y Fake: 0.1814, D_Y Total: 0.2315\n",
      "Generator Losses:\n",
      "  G Adv: 0.5344, F Adv: 0.1388\n",
      "  Cycle Photo: 0.0728, Cycle Monet: 0.0918\n",
      "  Perceptual Photo: 0.2051, Perceptual Monet: 0.2550\n",
      "  Total G Loss: 4.6192\n",
      "Epoch [13/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1111, D_X Fake: 0.1513, D_X Total: 0.1312\n",
      "  D_Y Real: 0.0756, D_Y Fake: 0.0671, D_Y Total: 0.0714\n",
      "Generator Losses:\n",
      "  G Adv: 0.4729, F Adv: 0.4949\n",
      "  Cycle Photo: 0.0819, Cycle Monet: 0.0537\n",
      "  Perceptual Photo: 0.1858, Perceptual Monet: 0.2145\n",
      "  Total G Loss: 4.3244\n",
      "Epoch [13/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1600, D_X Fake: 0.1149, D_X Total: 0.1374\n",
      "  D_Y Real: 0.3626, D_Y Fake: 0.1201, D_Y Total: 0.2414\n",
      "Generator Losses:\n",
      "  G Adv: 0.5224, F Adv: 0.5231\n",
      "  Cycle Photo: 0.0861, Cycle Monet: 0.0647\n",
      "  Perceptual Photo: 0.2553, Perceptual Monet: 0.2428\n",
      "  Total G Loss: 5.0444\n",
      "Epoch [13/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2955, D_X Fake: 0.0459, D_X Total: 0.1707\n",
      "  D_Y Real: 0.0499, D_Y Fake: 0.3879, D_Y Total: 0.2189\n",
      "Generator Losses:\n",
      "  G Adv: 0.1611, F Adv: 0.7218\n",
      "  Cycle Photo: 0.0621, Cycle Monet: 0.0718\n",
      "  Perceptual Photo: 0.2043, Perceptual Monet: 0.2178\n",
      "  Total G Loss: 4.3325\n",
      "Epoch [13/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2399, D_X Fake: 0.1638, D_X Total: 0.2018\n",
      "  D_Y Real: 0.0561, D_Y Fake: 0.2172, D_Y Total: 0.1366\n",
      "Generator Losses:\n",
      "  G Adv: 0.3160, F Adv: 0.3883\n",
      "  Cycle Photo: 0.0724, Cycle Monet: 0.0583\n",
      "  Perceptual Photo: 0.2462, Perceptual Monet: 0.1994\n",
      "  Total G Loss: 4.2396\n",
      "Epoch [13/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2781, D_X Fake: 0.0913, D_X Total: 0.1847\n",
      "  D_Y Real: 0.3485, D_Y Fake: 0.0929, D_Y Total: 0.2207\n",
      "Generator Losses:\n",
      "  G Adv: 0.6551, F Adv: 0.6098\n",
      "  Cycle Photo: 0.1021, Cycle Monet: 0.0701\n",
      "  Perceptual Photo: 0.2083, Perceptual Monet: 0.1952\n",
      "  Total G Loss: 5.0044\n",
      "Epoch [13/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1511, D_X Fake: 0.1776, D_X Total: 0.1644\n",
      "  D_Y Real: 0.1641, D_Y Fake: 0.0418, D_Y Total: 0.1030\n",
      "Generator Losses:\n",
      "  G Adv: 0.8355, F Adv: 0.5897\n",
      "  Cycle Photo: 0.0597, Cycle Monet: 0.0520\n",
      "  Perceptual Photo: 0.1904, Perceptual Monet: 0.2234\n",
      "  Total G Loss: 4.6112\n",
      "Epoch [13/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1092, D_X Fake: 0.1543, D_X Total: 0.1317\n",
      "  D_Y Real: 0.1068, D_Y Fake: 0.1805, D_Y Total: 0.1437\n",
      "Generator Losses:\n",
      "  G Adv: 0.4074, F Adv: 0.4281\n",
      "  Cycle Photo: 0.1277, Cycle Monet: 0.0715\n",
      "  Perceptual Photo: 0.1986, Perceptual Monet: 0.2265\n",
      "  Total G Loss: 4.9526\n",
      "Epoch [13/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1070, D_X Fake: 0.1570, D_X Total: 0.1320\n",
      "  D_Y Real: 0.1857, D_Y Fake: 0.0937, D_Y Total: 0.1397\n",
      "Generator Losses:\n",
      "  G Adv: 0.5470, F Adv: 0.5061\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0609\n",
      "  Perceptual Photo: 0.1672, Perceptual Monet: 0.2269\n",
      "  Total G Loss: 4.1736\n",
      "Epoch [13/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3316, D_X Fake: 0.0742, D_X Total: 0.2029\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.5462, D_Y Total: 0.2862\n",
      "Generator Losses:\n",
      "  G Adv: 0.1039, F Adv: 0.5712\n",
      "  Cycle Photo: 0.0580, Cycle Monet: 0.0522\n",
      "  Perceptual Photo: 0.2572, Perceptual Monet: 0.2102\n",
      "  Total G Loss: 4.1142\n",
      "Epoch [13/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1225, D_X Fake: 0.0382, D_X Total: 0.0803\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.1430, D_Y Total: 0.0892\n",
      "Generator Losses:\n",
      "  G Adv: 0.3718, F Adv: 0.5889\n",
      "  Cycle Photo: 0.0651, Cycle Monet: 0.0464\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.2002\n",
      "  Total G Loss: 3.8458\n",
      "Epoch [13/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2210, D_X Fake: 0.1789, D_X Total: 0.1999\n",
      "  D_Y Real: 0.1329, D_Y Fake: 0.2211, D_Y Total: 0.1770\n",
      "Generator Losses:\n",
      "  G Adv: 0.3103, F Adv: 0.3832\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0545\n",
      "  Perceptual Photo: 0.1783, Perceptual Monet: 0.2213\n",
      "  Total G Loss: 3.7051\n",
      "Epoch [13/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1035, D_X Fake: 0.0948, D_X Total: 0.0992\n",
      "  D_Y Real: 0.1227, D_Y Fake: 0.1225, D_Y Total: 0.1226\n",
      "Generator Losses:\n",
      "  G Adv: 0.4197, F Adv: 0.5915\n",
      "  Cycle Photo: 0.0697, Cycle Monet: 0.0678\n",
      "  Perceptual Photo: 0.2042, Perceptual Monet: 0.2635\n",
      "  Total G Loss: 4.7246\n",
      "Epoch [13/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2812, D_X Fake: 0.0891, D_X Total: 0.1852\n",
      "  D_Y Real: 0.2169, D_Y Fake: 0.1495, D_Y Total: 0.1832\n",
      "Generator Losses:\n",
      "  G Adv: 0.3842, F Adv: 0.8565\n",
      "  Cycle Photo: 0.0845, Cycle Monet: 0.0681\n",
      "  Perceptual Photo: 0.2523, Perceptual Monet: 0.2272\n",
      "  Total G Loss: 5.1645\n",
      "Epoch [13/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1006, D_X Fake: 0.0470, D_X Total: 0.0738\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.1851, D_Y Total: 0.1247\n",
      "Generator Losses:\n",
      "  G Adv: 0.3649, F Adv: 0.2657\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0500\n",
      "  Perceptual Photo: 0.2172, Perceptual Monet: 0.2148\n",
      "  Total G Loss: 3.7573\n",
      "Epoch [13/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0566, D_X Fake: 0.0802, D_X Total: 0.0684\n",
      "  D_Y Real: 0.1307, D_Y Fake: 0.1851, D_Y Total: 0.1579\n",
      "Generator Losses:\n",
      "  G Adv: 0.3806, F Adv: 0.4939\n",
      "  Cycle Photo: 0.0711, Cycle Monet: 0.0621\n",
      "  Perceptual Photo: 0.2014, Perceptual Monet: 0.2073\n",
      "  Total G Loss: 4.2496\n",
      "Epoch [13/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3298, D_X Fake: 0.0951, D_X Total: 0.2125\n",
      "  D_Y Real: 0.1039, D_Y Fake: 0.3097, D_Y Total: 0.2068\n",
      "Generator Losses:\n",
      "  G Adv: 0.3433, F Adv: 0.6836\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0738\n",
      "  Perceptual Photo: 0.1863, Perceptual Monet: 0.2209\n",
      "  Total G Loss: 4.3631\n",
      "Epoch [13/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1941, D_X Fake: 0.0470, D_X Total: 0.1206\n",
      "  D_Y Real: 0.0638, D_Y Fake: 0.0773, D_Y Total: 0.0705\n",
      "Generator Losses:\n",
      "  G Adv: 0.4337, F Adv: 0.8097\n",
      "  Cycle Photo: 0.0823, Cycle Monet: 0.0908\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.2734\n",
      "  Total G Loss: 5.1645\n",
      "Epoch [13/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1486, D_X Fake: 0.0847, D_X Total: 0.1166\n",
      "  D_Y Real: 0.1472, D_Y Fake: 0.0914, D_Y Total: 0.1193\n",
      "Generator Losses:\n",
      "  G Adv: 0.3874, F Adv: 0.4465\n",
      "  Cycle Photo: 0.0627, Cycle Monet: 0.0539\n",
      "  Perceptual Photo: 0.2333, Perceptual Monet: 0.2341\n",
      "  Total G Loss: 4.3367\n",
      "Epoch [13/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1241, D_X Fake: 0.0605, D_X Total: 0.0923\n",
      "  D_Y Real: 0.1627, D_Y Fake: 0.1199, D_Y Total: 0.1413\n",
      "Generator Losses:\n",
      "  G Adv: 0.2395, F Adv: 0.6525\n",
      "  Cycle Photo: 0.1115, Cycle Monet: 0.0702\n",
      "  Perceptual Photo: 0.1882, Perceptual Monet: 0.2440\n",
      "  Total G Loss: 4.8703\n",
      "Epoch [14/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0532, D_X Fake: 0.2843, D_X Total: 0.1687\n",
      "  D_Y Real: 0.2118, D_Y Fake: 0.2365, D_Y Total: 0.2242\n",
      "Generator Losses:\n",
      "  G Adv: 0.3603, F Adv: 0.2915\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0479\n",
      "  Perceptual Photo: 0.1643, Perceptual Monet: 0.1976\n",
      "  Total G Loss: 3.5048\n",
      "Epoch [14/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0896, D_X Fake: 0.1264, D_X Total: 0.1080\n",
      "  D_Y Real: 0.0893, D_Y Fake: 0.0860, D_Y Total: 0.0877\n",
      "Generator Losses:\n",
      "  G Adv: 0.9191, F Adv: 0.4853\n",
      "  Cycle Photo: 0.0768, Cycle Monet: 0.0637\n",
      "  Perceptual Photo: 0.1871, Perceptual Monet: 0.2369\n",
      "  Total G Loss: 4.9306\n",
      "Epoch [14/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1185, D_X Fake: 0.3300, D_X Total: 0.2242\n",
      "  D_Y Real: 0.1109, D_Y Fake: 0.2374, D_Y Total: 0.1742\n",
      "Generator Losses:\n",
      "  G Adv: 0.3728, F Adv: 0.3112\n",
      "  Cycle Photo: 0.1000, Cycle Monet: 0.0577\n",
      "  Perceptual Photo: 0.1788, Perceptual Monet: 0.2184\n",
      "  Total G Loss: 4.2476\n",
      "Epoch [14/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1203, D_X Fake: 0.0549, D_X Total: 0.0876\n",
      "  D_Y Real: 0.1613, D_Y Fake: 0.2018, D_Y Total: 0.1816\n",
      "Generator Losses:\n",
      "  G Adv: 0.4710, F Adv: 0.7255\n",
      "  Cycle Photo: 0.0792, Cycle Monet: 0.0502\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.2246\n",
      "  Total G Loss: 4.4496\n",
      "Epoch [14/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0825, D_X Fake: 0.4731, D_X Total: 0.2778\n",
      "  D_Y Real: 0.1132, D_Y Fake: 0.3403, D_Y Total: 0.2267\n",
      "Generator Losses:\n",
      "  G Adv: 0.2319, F Adv: 0.1391\n",
      "  Cycle Photo: 0.0581, Cycle Monet: 0.0583\n",
      "  Perceptual Photo: 0.1946, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.4263\n",
      "Epoch [14/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3083, D_X Fake: 0.1078, D_X Total: 0.2081\n",
      "  D_Y Real: 0.0552, D_Y Fake: 0.1058, D_Y Total: 0.0805\n",
      "Generator Losses:\n",
      "  G Adv: 0.3605, F Adv: 0.5439\n",
      "  Cycle Photo: 0.0850, Cycle Monet: 0.0579\n",
      "  Perceptual Photo: 0.2624, Perceptual Monet: 0.2327\n",
      "  Total G Loss: 4.8084\n",
      "Epoch [14/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0824, D_X Fake: 0.1423, D_X Total: 0.1124\n",
      "  D_Y Real: 0.1873, D_Y Fake: 0.0837, D_Y Total: 0.1355\n",
      "Generator Losses:\n",
      "  G Adv: 0.9519, F Adv: 0.3665\n",
      "  Cycle Photo: 0.1151, Cycle Monet: 0.0793\n",
      "  Perceptual Photo: 0.1979, Perceptual Monet: 0.2444\n",
      "  Total G Loss: 5.4745\n",
      "Epoch [14/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.0436, D_X Total: 0.1600\n",
      "  D_Y Real: 0.1006, D_Y Fake: 0.2021, D_Y Total: 0.1514\n",
      "Generator Losses:\n",
      "  G Adv: 0.2439, F Adv: 1.1348\n",
      "  Cycle Photo: 0.0678, Cycle Monet: 0.0550\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.2351\n",
      "  Total G Loss: 4.4011\n",
      "Epoch [14/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2104, D_X Fake: 0.1179, D_X Total: 0.1641\n",
      "  D_Y Real: 0.3219, D_Y Fake: 0.1726, D_Y Total: 0.2472\n",
      "Generator Losses:\n",
      "  G Adv: 0.6229, F Adv: 0.5726\n",
      "  Cycle Photo: 0.0631, Cycle Monet: 0.0534\n",
      "  Perceptual Photo: 0.1725, Perceptual Monet: 0.2069\n",
      "  Total G Loss: 4.2572\n",
      "Epoch [14/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0809, D_X Fake: 0.1791, D_X Total: 0.1300\n",
      "  D_Y Real: 0.1354, D_Y Fake: 0.1989, D_Y Total: 0.1671\n",
      "Generator Losses:\n",
      "  G Adv: 0.2680, F Adv: 0.3232\n",
      "  Cycle Photo: 0.0704, Cycle Monet: 0.0635\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.2266\n",
      "  Total G Loss: 3.7298\n",
      "Epoch [14/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.0696, D_X Total: 0.1006\n",
      "  D_Y Real: 0.1555, D_Y Fake: 0.1182, D_Y Total: 0.1369\n",
      "Generator Losses:\n",
      "  G Adv: 0.7183, F Adv: 0.5375\n",
      "  Cycle Photo: 0.0875, Cycle Monet: 0.0551\n",
      "  Perceptual Photo: 0.1330, Perceptual Monet: 0.2313\n",
      "  Total G Loss: 4.5024\n",
      "Epoch [14/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1463, D_X Fake: 0.1363, D_X Total: 0.1413\n",
      "  D_Y Real: 0.0736, D_Y Fake: 0.3868, D_Y Total: 0.2302\n",
      "Generator Losses:\n",
      "  G Adv: 0.2085, F Adv: 0.3307\n",
      "  Cycle Photo: 0.0822, Cycle Monet: 0.0647\n",
      "  Perceptual Photo: 0.2251, Perceptual Monet: 0.2218\n",
      "  Total G Loss: 4.2429\n",
      "Epoch [14/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1497, D_X Fake: 0.0538, D_X Total: 0.1017\n",
      "  D_Y Real: 0.2548, D_Y Fake: 0.1482, D_Y Total: 0.2015\n",
      "Generator Losses:\n",
      "  G Adv: 0.5219, F Adv: 0.5857\n",
      "  Cycle Photo: 0.1259, Cycle Monet: 0.0818\n",
      "  Perceptual Photo: 0.1892, Perceptual Monet: 0.2589\n",
      "  Total G Loss: 5.4251\n",
      "Epoch [14/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1745, D_X Fake: 0.2019, D_X Total: 0.1882\n",
      "  D_Y Real: 0.2026, D_Y Fake: 0.1100, D_Y Total: 0.1563\n",
      "Generator Losses:\n",
      "  G Adv: 0.5872, F Adv: 0.4348\n",
      "  Cycle Photo: 0.0702, Cycle Monet: 0.0559\n",
      "  Perceptual Photo: 0.2098, Perceptual Monet: 0.2105\n",
      "  Total G Loss: 4.3842\n",
      "Epoch [14/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1969, D_X Fake: 0.0387, D_X Total: 0.1178\n",
      "  D_Y Real: 0.2578, D_Y Fake: 0.1324, D_Y Total: 0.1951\n",
      "Generator Losses:\n",
      "  G Adv: 0.3996, F Adv: 0.7136\n",
      "  Cycle Photo: 0.1125, Cycle Monet: 0.0568\n",
      "  Perceptual Photo: 0.1861, Perceptual Monet: 0.2313\n",
      "  Total G Loss: 4.8936\n",
      "Epoch [14/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1562, D_X Fake: 0.2556, D_X Total: 0.2059\n",
      "  D_Y Real: 0.1878, D_Y Fake: 0.0387, D_Y Total: 0.1133\n",
      "Generator Losses:\n",
      "  G Adv: 0.5633, F Adv: 0.4502\n",
      "  Cycle Photo: 0.0652, Cycle Monet: 0.0731\n",
      "  Perceptual Photo: 0.2022, Perceptual Monet: 0.2591\n",
      "  Total G Loss: 4.7037\n",
      "Epoch [14/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1584, D_X Fake: 0.0498, D_X Total: 0.1041\n",
      "  D_Y Real: 0.3915, D_Y Fake: 0.0708, D_Y Total: 0.2311\n",
      "Generator Losses:\n",
      "  G Adv: 0.8010, F Adv: 0.7166\n",
      "  Cycle Photo: 0.0684, Cycle Monet: 0.0600\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.2267\n",
      "  Total G Loss: 4.7114\n",
      "Epoch [14/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2672, D_X Fake: 0.0513, D_X Total: 0.1592\n",
      "  D_Y Real: 0.1591, D_Y Fake: 0.1936, D_Y Total: 0.1764\n",
      "Generator Losses:\n",
      "  G Adv: 0.4105, F Adv: 0.7077\n",
      "  Cycle Photo: 0.0754, Cycle Monet: 0.0743\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.2499\n",
      "  Total G Loss: 4.6647\n",
      "Epoch [14/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0974, D_X Fake: 0.2135, D_X Total: 0.1554\n",
      "  D_Y Real: 0.1880, D_Y Fake: 0.1225, D_Y Total: 0.1553\n",
      "Generator Losses:\n",
      "  G Adv: 0.6902, F Adv: 0.6739\n",
      "  Cycle Photo: 0.0584, Cycle Monet: 0.0736\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.2446\n",
      "  Total G Loss: 4.7422\n",
      "Epoch [14/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1114, D_X Fake: 0.1060, D_X Total: 0.1087\n",
      "  D_Y Real: 0.1216, D_Y Fake: 0.1212, D_Y Total: 0.1214\n",
      "Generator Losses:\n",
      "  G Adv: 0.4832, F Adv: 0.6055\n",
      "  Cycle Photo: 0.0656, Cycle Monet: 0.0500\n",
      "  Perceptual Photo: 0.1600, Perceptual Monet: 0.2241\n",
      "  Total G Loss: 4.1651\n",
      "Epoch [14/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1657, D_X Fake: 0.2005, D_X Total: 0.1831\n",
      "  D_Y Real: 0.1180, D_Y Fake: 0.1612, D_Y Total: 0.1396\n",
      "Generator Losses:\n",
      "  G Adv: 0.3062, F Adv: 0.2344\n",
      "  Cycle Photo: 0.0741, Cycle Monet: 0.0719\n",
      "  Perceptual Photo: 0.2687, Perceptual Monet: 0.2677\n",
      "  Total G Loss: 4.6820\n",
      "Epoch [14/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3001, D_X Fake: 0.0546, D_X Total: 0.1773\n",
      "  D_Y Real: 0.1000, D_Y Fake: 0.0518, D_Y Total: 0.0759\n",
      "Generator Losses:\n",
      "  G Adv: 0.4225, F Adv: 1.0074\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0546\n",
      "  Perceptual Photo: 0.1507, Perceptual Monet: 0.2005\n",
      "  Total G Loss: 4.2534\n",
      "Epoch [14/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1901, D_X Fake: 0.1016, D_X Total: 0.1458\n",
      "  D_Y Real: 0.3987, D_Y Fake: 0.0754, D_Y Total: 0.2370\n",
      "Generator Losses:\n",
      "  G Adv: 0.6623, F Adv: 0.5462\n",
      "  Cycle Photo: 0.0943, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.2529, Perceptual Monet: 0.1976\n",
      "  Total G Loss: 4.8453\n",
      "Epoch [14/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2093, D_X Fake: 0.2509, D_X Total: 0.2301\n",
      "  D_Y Real: 0.2464, D_Y Fake: 0.1349, D_Y Total: 0.1906\n",
      "Generator Losses:\n",
      "  G Adv: 0.5156, F Adv: 0.3803\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0599\n",
      "  Perceptual Photo: 0.1882, Perceptual Monet: 0.2034\n",
      "  Total G Loss: 4.0812\n",
      "Epoch [15/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0835, D_X Fake: 0.2147, D_X Total: 0.1491\n",
      "  D_Y Real: 0.1871, D_Y Fake: 0.2530, D_Y Total: 0.2201\n",
      "Generator Losses:\n",
      "  G Adv: 0.6003, F Adv: 0.3195\n",
      "  Cycle Photo: 0.0614, Cycle Monet: 0.0494\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.2137\n",
      "  Total G Loss: 3.9354\n",
      "Epoch [15/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0840, D_X Fake: 0.1857, D_X Total: 0.1349\n",
      "  D_Y Real: 0.1144, D_Y Fake: 0.1424, D_Y Total: 0.1284\n",
      "Generator Losses:\n",
      "  G Adv: 0.5060, F Adv: 0.6871\n",
      "  Cycle Photo: 0.0515, Cycle Monet: 0.0597\n",
      "  Perceptual Photo: 0.2020, Perceptual Monet: 0.2124\n",
      "  Total G Loss: 4.3775\n",
      "Epoch [15/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2421, D_X Fake: 0.2048, D_X Total: 0.2235\n",
      "  D_Y Real: 0.1750, D_Y Fake: 0.4410, D_Y Total: 0.3080\n",
      "Generator Losses:\n",
      "  G Adv: 0.3098, F Adv: 0.3171\n",
      "  Cycle Photo: 0.0683, Cycle Monet: 0.0813\n",
      "  Perceptual Photo: 0.2334, Perceptual Monet: 0.2168\n",
      "  Total G Loss: 4.3741\n",
      "Epoch [15/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1973, D_X Fake: 0.0435, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0489, D_Y Fake: 0.2013, D_Y Total: 0.1251\n",
      "Generator Losses:\n",
      "  G Adv: 0.5709, F Adv: 0.5107\n",
      "  Cycle Photo: 0.1030, Cycle Monet: 0.0770\n",
      "  Perceptual Photo: 0.1811, Perceptual Monet: 0.2233\n",
      "  Total G Loss: 4.9031\n",
      "Epoch [15/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1541, D_X Fake: 0.1335, D_X Total: 0.1438\n",
      "  D_Y Real: 0.0603, D_Y Fake: 0.5911, D_Y Total: 0.3257\n",
      "Generator Losses:\n",
      "  G Adv: 0.2382, F Adv: 0.4408\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0596\n",
      "  Perceptual Photo: 0.2059, Perceptual Monet: 0.2306\n",
      "  Total G Loss: 4.0101\n",
      "Epoch [15/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2947, D_X Fake: 0.0684, D_X Total: 0.1816\n",
      "  D_Y Real: 0.0450, D_Y Fake: 0.4282, D_Y Total: 0.2366\n",
      "Generator Losses:\n",
      "  G Adv: 0.1950, F Adv: 0.7176\n",
      "  Cycle Photo: 0.0621, Cycle Monet: 0.0672\n",
      "  Perceptual Photo: 0.2270, Perceptual Monet: 0.1939\n",
      "  Total G Loss: 4.3096\n",
      "Epoch [15/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1212, D_X Fake: 0.2011, D_X Total: 0.1612\n",
      "  D_Y Real: 0.1005, D_Y Fake: 0.3605, D_Y Total: 0.2305\n",
      "Generator Losses:\n",
      "  G Adv: 0.2572, F Adv: 0.5404\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0709\n",
      "  Perceptual Photo: 0.1956, Perceptual Monet: 0.2588\n",
      "  Total G Loss: 4.2927\n",
      "Epoch [15/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0978, D_X Fake: 0.1374, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0642, D_Y Fake: 0.1947, D_Y Total: 0.1295\n",
      "Generator Losses:\n",
      "  G Adv: 0.4163, F Adv: 0.5403\n",
      "  Cycle Photo: 0.0990, Cycle Monet: 0.0631\n",
      "  Perceptual Photo: 0.2444, Perceptual Monet: 0.2144\n",
      "  Total G Loss: 4.8708\n",
      "Epoch [15/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2565, D_X Fake: 0.1358, D_X Total: 0.1962\n",
      "  D_Y Real: 0.0608, D_Y Fake: 0.2423, D_Y Total: 0.1515\n",
      "Generator Losses:\n",
      "  G Adv: 0.2585, F Adv: 0.4937\n",
      "  Cycle Photo: 0.0663, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.2271, Perceptual Monet: 0.2080\n",
      "  Total G Loss: 4.0495\n",
      "Epoch [15/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0828, D_X Fake: 0.2664, D_X Total: 0.1746\n",
      "  D_Y Real: 0.0945, D_Y Fake: 0.1198, D_Y Total: 0.1071\n",
      "Generator Losses:\n",
      "  G Adv: 0.4624, F Adv: 0.4057\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0662\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.2290\n",
      "  Total G Loss: 3.9089\n",
      "Epoch [15/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1361, D_X Fake: 0.0979, D_X Total: 0.1170\n",
      "  D_Y Real: 0.3226, D_Y Fake: 0.1207, D_Y Total: 0.2216\n",
      "Generator Losses:\n",
      "  G Adv: 0.6598, F Adv: 0.3902\n",
      "  Cycle Photo: 0.0537, Cycle Monet: 0.0771\n",
      "  Perceptual Photo: 0.1729, Perceptual Monet: 0.2685\n",
      "  Total G Loss: 4.5654\n",
      "Epoch [15/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 16.7061, D_X Fake: 30.3555, D_X Total: 23.5308\n",
      "  D_Y Real: 0.0894, D_Y Fake: 0.1406, D_Y Total: 0.1150\n",
      "Generator Losses:\n",
      "  G Adv: 0.4392, F Adv: 9.5582\n",
      "  Cycle Photo: 0.3849, Cycle Monet: 0.2500\n",
      "  Perceptual Photo: 0.5299, Perceptual Monet: 0.4593\n",
      "  Total G Loss: 21.2923\n",
      "Epoch [15/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2257, D_X Fake: 0.2670, D_X Total: 0.2464\n",
      "  D_Y Real: 0.1662, D_Y Fake: 0.0697, D_Y Total: 0.1179\n",
      "Generator Losses:\n",
      "  G Adv: 0.6295, F Adv: 0.3015\n",
      "  Cycle Photo: 0.0695, Cycle Monet: 0.0775\n",
      "  Perceptual Photo: 0.2158, Perceptual Monet: 0.2414\n",
      "  Total G Loss: 4.6867\n",
      "Epoch [15/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2244, D_X Fake: 0.2205, D_X Total: 0.2224\n",
      "  D_Y Real: 0.0440, D_Y Fake: 0.4684, D_Y Total: 0.2562\n",
      "Generator Losses:\n",
      "  G Adv: 0.2486, F Adv: 0.2863\n",
      "  Cycle Photo: 0.0792, Cycle Monet: 0.0605\n",
      "  Perceptual Photo: 0.1809, Perceptual Monet: 0.2235\n",
      "  Total G Loss: 3.9537\n",
      "Epoch [15/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2565, D_X Fake: 0.2801, D_X Total: 0.2683\n",
      "  D_Y Real: 0.3955, D_Y Fake: 0.1315, D_Y Total: 0.2635\n",
      "Generator Losses:\n",
      "  G Adv: 0.8867, F Adv: 0.2312\n",
      "  Cycle Photo: 0.0889, Cycle Monet: 0.0535\n",
      "  Perceptual Photo: 0.2691, Perceptual Monet: 0.1951\n",
      "  Total G Loss: 4.8632\n",
      "Epoch [15/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3436, D_X Fake: 0.2815, D_X Total: 0.3125\n",
      "  D_Y Real: 0.1215, D_Y Fake: 0.1054, D_Y Total: 0.1134\n",
      "Generator Losses:\n",
      "  G Adv: 0.4000, F Adv: 0.2363\n",
      "  Cycle Photo: 0.0774, Cycle Monet: 0.0483\n",
      "  Perceptual Photo: 0.2795, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 4.1627\n",
      "Epoch [15/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2005, D_X Fake: 0.3320, D_X Total: 0.2663\n",
      "  D_Y Real: 0.1138, D_Y Fake: 0.2183, D_Y Total: 0.1661\n",
      "Generator Losses:\n",
      "  G Adv: 0.3469, F Adv: 0.2539\n",
      "  Cycle Photo: 0.0643, Cycle Monet: 0.0709\n",
      "  Perceptual Photo: 0.1900, Perceptual Monet: 0.2028\n",
      "  Total G Loss: 3.9167\n",
      "Epoch [15/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2356, D_X Fake: 0.2637, D_X Total: 0.2496\n",
      "  D_Y Real: 0.2094, D_Y Fake: 0.0591, D_Y Total: 0.1343\n",
      "Generator Losses:\n",
      "  G Adv: 0.7046, F Adv: 0.2307\n",
      "  Cycle Photo: 0.0613, Cycle Monet: 0.0860\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 4.1406\n",
      "Epoch [15/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2475, D_X Fake: 0.2376, D_X Total: 0.2426\n",
      "  D_Y Real: 0.0591, D_Y Fake: 0.2138, D_Y Total: 0.1364\n",
      "Generator Losses:\n",
      "  G Adv: 0.3516, F Adv: 0.2542\n",
      "  Cycle Photo: 0.0761, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 3.5418\n",
      "Epoch [15/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3228, D_X Fake: 0.2391, D_X Total: 0.2810\n",
      "  D_Y Real: 0.1013, D_Y Fake: 0.1046, D_Y Total: 0.1030\n",
      "Generator Losses:\n",
      "  G Adv: 0.4881, F Adv: 0.2849\n",
      "  Cycle Photo: 0.0806, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.2316, Perceptual Monet: 0.1759\n",
      "  Total G Loss: 4.0974\n",
      "Epoch [15/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2131, D_X Fake: 0.2369, D_X Total: 0.2250\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.0720, D_Y Total: 0.0567\n",
      "Generator Losses:\n",
      "  G Adv: 0.5887, F Adv: 0.2819\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0521\n",
      "  Perceptual Photo: 0.1690, Perceptual Monet: 0.1861\n",
      "  Total G Loss: 3.6787\n",
      "Epoch [15/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2784, D_X Fake: 0.2172, D_X Total: 0.2478\n",
      "  D_Y Real: 0.1407, D_Y Fake: 0.1420, D_Y Total: 0.1414\n",
      "Generator Losses:\n",
      "  G Adv: 0.2948, F Adv: 0.3412\n",
      "  Cycle Photo: 0.0661, Cycle Monet: 0.0706\n",
      "  Perceptual Photo: 0.1590, Perceptual Monet: 0.2516\n",
      "  Total G Loss: 4.0550\n",
      "Epoch [15/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2684, D_X Fake: 0.1871, D_X Total: 0.2277\n",
      "  D_Y Real: 0.1386, D_Y Fake: 0.1416, D_Y Total: 0.1401\n",
      "Generator Losses:\n",
      "  G Adv: 0.2357, F Adv: 0.3535\n",
      "  Cycle Photo: 0.0452, Cycle Monet: 0.0674\n",
      "  Perceptual Photo: 0.1373, Perceptual Monet: 0.1847\n",
      "  Total G Loss: 3.3249\n",
      "Epoch [15/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2214, D_X Fake: 0.2968, D_X Total: 0.2591\n",
      "  D_Y Real: 0.1261, D_Y Fake: 0.0796, D_Y Total: 0.1028\n",
      "Generator Losses:\n",
      "  G Adv: 0.3570, F Adv: 0.2143\n",
      "  Cycle Photo: 0.0770, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.2099, Perceptual Monet: 0.1964\n",
      "  Total G Loss: 3.8540\n",
      "Epoch [16/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2850, D_X Fake: 0.2193, D_X Total: 0.2521\n",
      "  D_Y Real: 0.2322, D_Y Fake: 0.0467, D_Y Total: 0.1395\n",
      "Generator Losses:\n",
      "  G Adv: 0.6698, F Adv: 0.4080\n",
      "  Cycle Photo: 0.0723, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1864, Perceptual Monet: 0.1983\n",
      "  Total G Loss: 4.1825\n",
      "Epoch [16/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2045, D_X Fake: 0.2281, D_X Total: 0.2163\n",
      "  D_Y Real: 0.0617, D_Y Fake: 0.1780, D_Y Total: 0.1199\n",
      "Generator Losses:\n",
      "  G Adv: 0.4267, F Adv: 0.2759\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0547\n",
      "  Perceptual Photo: 0.1409, Perceptual Monet: 0.1816\n",
      "  Total G Loss: 3.2742\n",
      "Epoch [16/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1471, D_X Fake: 0.2323, D_X Total: 0.1897\n",
      "  D_Y Real: 0.1320, D_Y Fake: 0.1052, D_Y Total: 0.1186\n",
      "Generator Losses:\n",
      "  G Adv: 0.5622, F Adv: 0.2883\n",
      "  Cycle Photo: 0.0697, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1759, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.7275\n",
      "Epoch [16/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3173, D_X Fake: 0.2893, D_X Total: 0.3033\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.1253, D_Y Total: 0.0783\n",
      "Generator Losses:\n",
      "  G Adv: 0.3729, F Adv: 0.2051\n",
      "  Cycle Photo: 0.0555, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1999, Perceptual Monet: 0.1364\n",
      "  Total G Loss: 3.2925\n",
      "Epoch [16/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1835, D_X Fake: 0.3199, D_X Total: 0.2517\n",
      "  D_Y Real: 0.2529, D_Y Fake: 0.0552, D_Y Total: 0.1540\n",
      "Generator Losses:\n",
      "  G Adv: 0.6478, F Adv: 0.2251\n",
      "  Cycle Photo: 0.0866, Cycle Monet: 0.0515\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1472\n",
      "  Total G Loss: 3.8248\n",
      "Epoch [16/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3080, D_X Fake: 0.1514, D_X Total: 0.2297\n",
      "  D_Y Real: 0.1210, D_Y Fake: 0.0749, D_Y Total: 0.0979\n",
      "Generator Losses:\n",
      "  G Adv: 0.4262, F Adv: 0.2756\n",
      "  Cycle Photo: 0.0786, Cycle Monet: 0.0577\n",
      "  Perceptual Photo: 0.2016, Perceptual Monet: 0.1882\n",
      "  Total G Loss: 4.0135\n",
      "Epoch [16/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.1520, D_X Total: 0.1494\n",
      "  D_Y Real: 0.1585, D_Y Fake: 0.1277, D_Y Total: 0.1431\n",
      "Generator Losses:\n",
      "  G Adv: 0.5611, F Adv: 0.4134\n",
      "  Cycle Photo: 0.0976, Cycle Monet: 0.0507\n",
      "  Perceptual Photo: 0.1843, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 4.2683\n",
      "Epoch [16/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2620, D_X Fake: 0.1730, D_X Total: 0.2175\n",
      "  D_Y Real: 0.1429, D_Y Fake: 0.0989, D_Y Total: 0.1209\n",
      "Generator Losses:\n",
      "  G Adv: 0.6941, F Adv: 0.4500\n",
      "  Cycle Photo: 0.0757, Cycle Monet: 0.0567\n",
      "  Perceptual Photo: 0.2005, Perceptual Monet: 0.2163\n",
      "  Total G Loss: 4.5517\n",
      "Epoch [16/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2483, D_X Fake: 0.1068, D_X Total: 0.1776\n",
      "  D_Y Real: 0.0554, D_Y Fake: 0.2034, D_Y Total: 0.1294\n",
      "Generator Losses:\n",
      "  G Adv: 0.2932, F Adv: 0.5146\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0492\n",
      "  Perceptual Photo: 0.2221, Perceptual Monet: 0.2138\n",
      "  Total G Loss: 4.1083\n",
      "Epoch [16/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2245, D_X Fake: 0.2823, D_X Total: 0.2534\n",
      "  D_Y Real: 0.1304, D_Y Fake: 0.2071, D_Y Total: 0.1687\n",
      "Generator Losses:\n",
      "  G Adv: 0.3731, F Adv: 0.3105\n",
      "  Cycle Photo: 0.0535, Cycle Monet: 0.0549\n",
      "  Perceptual Photo: 0.2285, Perceptual Monet: 0.1942\n",
      "  Total G Loss: 3.8814\n",
      "Epoch [16/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2018, D_X Fake: 0.1342, D_X Total: 0.1680\n",
      "  D_Y Real: 0.1129, D_Y Fake: 0.0797, D_Y Total: 0.0963\n",
      "Generator Losses:\n",
      "  G Adv: 0.3765, F Adv: 0.4695\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1952\n",
      "  Total G Loss: 3.6072\n",
      "Epoch [16/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1005, D_X Fake: 0.1680, D_X Total: 0.1343\n",
      "  D_Y Real: 0.0806, D_Y Fake: 0.1613, D_Y Total: 0.1210\n",
      "Generator Losses:\n",
      "  G Adv: 0.5127, F Adv: 0.3407\n",
      "  Cycle Photo: 0.0785, Cycle Monet: 0.0498\n",
      "  Perceptual Photo: 0.1818, Perceptual Monet: 0.1980\n",
      "  Total G Loss: 4.0348\n",
      "Epoch [16/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1617, D_X Fake: 0.1254, D_X Total: 0.1435\n",
      "  D_Y Real: 0.0911, D_Y Fake: 0.0968, D_Y Total: 0.0940\n",
      "Generator Losses:\n",
      "  G Adv: 0.4757, F Adv: 0.3683\n",
      "  Cycle Photo: 0.0640, Cycle Monet: 0.0633\n",
      "  Perceptual Photo: 0.1962, Perceptual Monet: 0.2128\n",
      "  Total G Loss: 4.1615\n",
      "Epoch [16/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0971, D_X Fake: 0.1520, D_X Total: 0.1245\n",
      "  D_Y Real: 0.0712, D_Y Fake: 0.0951, D_Y Total: 0.0832\n",
      "Generator Losses:\n",
      "  G Adv: 0.5271, F Adv: 0.3034\n",
      "  Cycle Photo: 0.0711, Cycle Monet: 0.0565\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1976\n",
      "  Total G Loss: 3.9767\n",
      "Epoch [16/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0684, D_X Fake: 0.1094, D_X Total: 0.0889\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.1406, D_Y Total: 0.0903\n",
      "Generator Losses:\n",
      "  G Adv: 0.5360, F Adv: 0.6175\n",
      "  Cycle Photo: 0.0987, Cycle Monet: 0.0841\n",
      "  Perceptual Photo: 0.1844, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 4.7400\n",
      "Epoch [16/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1408, D_X Fake: 0.2138, D_X Total: 0.1773\n",
      "  D_Y Real: 0.1729, D_Y Fake: 0.2252, D_Y Total: 0.1990\n",
      "Generator Losses:\n",
      "  G Adv: 0.3293, F Adv: 0.3684\n",
      "  Cycle Photo: 0.0658, Cycle Monet: 0.0622\n",
      "  Perceptual Photo: 0.1852, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.7654\n",
      "Epoch [16/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0931, D_X Fake: 0.3443, D_X Total: 0.2187\n",
      "  D_Y Real: 0.0833, D_Y Fake: 0.3583, D_Y Total: 0.2208\n",
      "Generator Losses:\n",
      "  G Adv: 0.2183, F Adv: 0.2208\n",
      "  Cycle Photo: 0.0595, Cycle Monet: 0.0585\n",
      "  Perceptual Photo: 0.1698, Perceptual Monet: 0.2036\n",
      "  Total G Loss: 3.4853\n",
      "Epoch [16/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0376, D_X Fake: 0.1776, D_X Total: 0.1076\n",
      "  D_Y Real: 0.1568, D_Y Fake: 0.0913, D_Y Total: 0.1241\n",
      "Generator Losses:\n",
      "  G Adv: 0.7576, F Adv: 0.3282\n",
      "  Cycle Photo: 0.0664, Cycle Monet: 0.0612\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.2188\n",
      "  Total G Loss: 4.1857\n",
      "Epoch [16/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0928, D_X Fake: 0.1474, D_X Total: 0.1201\n",
      "  D_Y Real: 0.0951, D_Y Fake: 0.3270, D_Y Total: 0.2110\n",
      "Generator Losses:\n",
      "  G Adv: 0.1932, F Adv: 0.4812\n",
      "  Cycle Photo: 0.0703, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.2085, Perceptual Monet: 0.2023\n",
      "  Total G Loss: 3.8514\n",
      "Epoch [16/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1212, D_X Fake: 0.0695, D_X Total: 0.0953\n",
      "  D_Y Real: 0.2007, D_Y Fake: 0.1866, D_Y Total: 0.1936\n",
      "Generator Losses:\n",
      "  G Adv: 0.4836, F Adv: 0.6484\n",
      "  Cycle Photo: 0.0897, Cycle Monet: 0.0654\n",
      "  Perceptual Photo: 0.1861, Perceptual Monet: 0.2459\n",
      "  Total G Loss: 4.8427\n",
      "Epoch [16/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0445, D_X Fake: 0.2078, D_X Total: 0.1262\n",
      "  D_Y Real: 0.1236, D_Y Fake: 0.0980, D_Y Total: 0.1108\n",
      "Generator Losses:\n",
      "  G Adv: 0.4375, F Adv: 0.3392\n",
      "  Cycle Photo: 0.0841, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.2175\n",
      "  Total G Loss: 3.9121\n",
      "Epoch [16/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0521, D_X Fake: 0.0802, D_X Total: 0.0662\n",
      "  D_Y Real: 0.1301, D_Y Fake: 0.0871, D_Y Total: 0.1086\n",
      "Generator Losses:\n",
      "  G Adv: 0.6647, F Adv: 0.4983\n",
      "  Cycle Photo: 0.0827, Cycle Monet: 0.0527\n",
      "  Perceptual Photo: 0.1848, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 4.3680\n",
      "Epoch [16/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0925, D_X Fake: 0.1520, D_X Total: 0.1222\n",
      "  D_Y Real: 0.2413, D_Y Fake: 0.1028, D_Y Total: 0.1721\n",
      "Generator Losses:\n",
      "  G Adv: 0.6465, F Adv: 0.4495\n",
      "  Cycle Photo: 0.0679, Cycle Monet: 0.0547\n",
      "  Perceptual Photo: 0.1816, Perceptual Monet: 0.2094\n",
      "  Total G Loss: 4.2772\n",
      "Epoch [16/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.1195, D_X Total: 0.1053\n",
      "  D_Y Real: 0.0484, D_Y Fake: 0.3324, D_Y Total: 0.1904\n",
      "Generator Losses:\n",
      "  G Adv: 0.2813, F Adv: 0.5901\n",
      "  Cycle Photo: 0.0851, Cycle Monet: 0.0502\n",
      "  Perceptual Photo: 0.1560, Perceptual Monet: 0.2058\n",
      "  Total G Loss: 4.0336\n",
      "Epoch [17/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3610, D_X Fake: 0.0472, D_X Total: 0.2041\n",
      "  D_Y Real: 0.1362, D_Y Fake: 0.2765, D_Y Total: 0.2063\n",
      "Generator Losses:\n",
      "  G Adv: 0.2538, F Adv: 0.8640\n",
      "  Cycle Photo: 0.0589, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.2202, Perceptual Monet: 0.2087\n",
      "  Total G Loss: 4.3053\n",
      "Epoch [17/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2081, D_X Fake: 0.2310, D_X Total: 0.2196\n",
      "  D_Y Real: 0.1692, D_Y Fake: 0.1150, D_Y Total: 0.1421\n",
      "Generator Losses:\n",
      "  G Adv: 0.3690, F Adv: 0.5227\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.2060, Perceptual Monet: 0.2100\n",
      "  Total G Loss: 4.0862\n",
      "Epoch [17/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2715, D_X Fake: 0.0492, D_X Total: 0.1603\n",
      "  D_Y Real: 0.0887, D_Y Fake: 0.1931, D_Y Total: 0.1409\n",
      "Generator Losses:\n",
      "  G Adv: 0.4225, F Adv: 0.7164\n",
      "  Cycle Photo: 0.0561, Cycle Monet: 0.0663\n",
      "  Perceptual Photo: 0.1977, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 4.3100\n",
      "Epoch [17/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1598, D_X Fake: 0.1614, D_X Total: 0.1606\n",
      "  D_Y Real: 0.0634, D_Y Fake: 0.3321, D_Y Total: 0.1978\n",
      "Generator Losses:\n",
      "  G Adv: 0.1917, F Adv: 0.4416\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0534\n",
      "  Perceptual Photo: 0.1756, Perceptual Monet: 0.2061\n",
      "  Total G Loss: 3.6221\n",
      "Epoch [17/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4516, D_X Fake: 0.0487, D_X Total: 0.2502\n",
      "  D_Y Real: 0.0631, D_Y Fake: 0.1999, D_Y Total: 0.1315\n",
      "Generator Losses:\n",
      "  G Adv: 0.2158, F Adv: 0.7576\n",
      "  Cycle Photo: 0.0602, Cycle Monet: 0.0491\n",
      "  Perceptual Photo: 0.2278, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 4.1244\n",
      "Epoch [17/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0490, D_X Fake: 0.1079, D_X Total: 0.0785\n",
      "  D_Y Real: 0.1885, D_Y Fake: 0.0560, D_Y Total: 0.1222\n",
      "Generator Losses:\n",
      "  G Adv: 0.8592, F Adv: 0.6291\n",
      "  Cycle Photo: 0.0758, Cycle Monet: 0.0625\n",
      "  Perceptual Photo: 0.2361, Perceptual Monet: 0.2479\n",
      "  Total G Loss: 5.2912\n",
      "Epoch [17/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0863, D_X Fake: 0.1171, D_X Total: 0.1017\n",
      "  D_Y Real: 0.3834, D_Y Fake: 0.0665, D_Y Total: 0.2250\n",
      "Generator Losses:\n",
      "  G Adv: 0.7978, F Adv: 0.5288\n",
      "  Cycle Photo: 0.0577, Cycle Monet: 0.0681\n",
      "  Perceptual Photo: 0.1854, Perceptual Monet: 0.2405\n",
      "  Total G Loss: 4.7141\n",
      "Epoch [17/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0462, D_X Fake: 0.1376, D_X Total: 0.0919\n",
      "  D_Y Real: 0.2075, D_Y Fake: 0.0560, D_Y Total: 0.1318\n",
      "Generator Losses:\n",
      "  G Adv: 0.7591, F Adv: 0.3714\n",
      "  Cycle Photo: 0.0636, Cycle Monet: 0.0600\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.2498\n",
      "  Total G Loss: 4.4221\n",
      "Epoch [17/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0407, D_X Fake: 0.2011, D_X Total: 0.1209\n",
      "  D_Y Real: 0.0739, D_Y Fake: 0.1056, D_Y Total: 0.0897\n",
      "Generator Losses:\n",
      "  G Adv: 0.4740, F Adv: 0.2766\n",
      "  Cycle Photo: 0.0837, Cycle Monet: 0.0618\n",
      "  Perceptual Photo: 0.2030, Perceptual Monet: 0.2506\n",
      "  Total G Loss: 4.4734\n",
      "Epoch [17/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0882, D_X Fake: 0.0482, D_X Total: 0.0682\n",
      "  D_Y Real: 0.1331, D_Y Fake: 0.2148, D_Y Total: 0.1740\n",
      "Generator Losses:\n",
      "  G Adv: 0.3049, F Adv: 0.7481\n",
      "  Cycle Photo: 0.0639, Cycle Monet: 0.0537\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.2239\n",
      "  Total G Loss: 4.1951\n",
      "Epoch [17/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0929, D_X Fake: 0.1138, D_X Total: 0.1034\n",
      "  D_Y Real: 0.1234, D_Y Fake: 0.0369, D_Y Total: 0.0802\n",
      "Generator Losses:\n",
      "  G Adv: 0.8582, F Adv: 0.6952\n",
      "  Cycle Photo: 0.0750, Cycle Monet: 0.0485\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.2105\n",
      "  Total G Loss: 4.7559\n",
      "Epoch [17/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2143, D_X Fake: 0.0754, D_X Total: 0.1449\n",
      "  D_Y Real: 0.1693, D_Y Fake: 0.1570, D_Y Total: 0.1632\n",
      "Generator Losses:\n",
      "  G Adv: 0.5775, F Adv: 0.5853\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0545\n",
      "  Perceptual Photo: 0.2094, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 4.2694\n",
      "Epoch [17/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1916, D_X Fake: 0.1467, D_X Total: 0.1692\n",
      "  D_Y Real: 0.0504, D_Y Fake: 0.1654, D_Y Total: 0.1079\n",
      "Generator Losses:\n",
      "  G Adv: 0.4285, F Adv: 0.5280\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.2165, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.9328\n",
      "Epoch [17/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0587, D_X Fake: 0.3213, D_X Total: 0.1900\n",
      "  D_Y Real: 0.0576, D_Y Fake: 0.3463, D_Y Total: 0.2019\n",
      "Generator Losses:\n",
      "  G Adv: 0.2435, F Adv: 0.2199\n",
      "  Cycle Photo: 0.0656, Cycle Monet: 0.0404\n",
      "  Perceptual Photo: 0.1835, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 3.3753\n",
      "Epoch [17/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1148, D_X Fake: 0.0673, D_X Total: 0.0911\n",
      "  D_Y Real: 0.0879, D_Y Fake: 0.1264, D_Y Total: 0.1072\n",
      "Generator Losses:\n",
      "  G Adv: 0.5302, F Adv: 0.7084\n",
      "  Cycle Photo: 0.0742, Cycle Monet: 0.0495\n",
      "  Perceptual Photo: 0.2088, Perceptual Monet: 0.2099\n",
      "  Total G Loss: 4.5689\n",
      "Epoch [17/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2969, D_X Fake: 0.0826, D_X Total: 0.1898\n",
      "  D_Y Real: 0.2573, D_Y Fake: 0.1247, D_Y Total: 0.1910\n",
      "Generator Losses:\n",
      "  G Adv: 0.6584, F Adv: 0.6874\n",
      "  Cycle Photo: 0.1280, Cycle Monet: 0.0451\n",
      "  Perceptual Photo: 0.2812, Perceptual Monet: 0.1939\n",
      "  Total G Loss: 5.4514\n",
      "Epoch [17/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2315, D_X Fake: 0.0717, D_X Total: 0.1516\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.2551, D_Y Total: 0.1615\n",
      "Generator Losses:\n",
      "  G Adv: 0.3662, F Adv: 0.7112\n",
      "  Cycle Photo: 0.0577, Cycle Monet: 0.0611\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.2115\n",
      "  Total G Loss: 4.1842\n",
      "Epoch [17/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0296, D_X Fake: 0.0469, D_X Total: 0.0382\n",
      "  D_Y Real: 0.0760, D_Y Fake: 0.1334, D_Y Total: 0.1047\n",
      "Generator Losses:\n",
      "  G Adv: 0.4874, F Adv: 0.5413\n",
      "  Cycle Photo: 0.0993, Cycle Monet: 0.0614\n",
      "  Perceptual Photo: 0.1949, Perceptual Monet: 0.2109\n",
      "  Total G Loss: 4.6641\n",
      "Epoch [17/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1091, D_X Fake: 0.0355, D_X Total: 0.0723\n",
      "  D_Y Real: 0.0806, D_Y Fake: 0.3217, D_Y Total: 0.2011\n",
      "Generator Losses:\n",
      "  G Adv: 0.3252, F Adv: 0.7941\n",
      "  Cycle Photo: 0.0648, Cycle Monet: 0.0488\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1939\n",
      "  Total G Loss: 4.1280\n",
      "Epoch [17/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3605, D_X Fake: 0.2332, D_X Total: 0.2968\n",
      "  D_Y Real: 0.1302, D_Y Fake: 0.0785, D_Y Total: 0.1043\n",
      "Generator Losses:\n",
      "  G Adv: 0.4906, F Adv: 0.3196\n",
      "  Cycle Photo: 0.0619, Cycle Monet: 0.0520\n",
      "  Perceptual Photo: 0.2215, Perceptual Monet: 0.1911\n",
      "  Total G Loss: 4.0122\n",
      "Epoch [17/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2061, D_X Fake: 0.2541, D_X Total: 0.2301\n",
      "  D_Y Real: 0.0274, D_Y Fake: 0.0812, D_Y Total: 0.0543\n",
      "Generator Losses:\n",
      "  G Adv: 0.5908, F Adv: 0.2954\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0555\n",
      "  Perceptual Photo: 0.1317, Perceptual Monet: 0.2249\n",
      "  Total G Loss: 3.7493\n",
      "Epoch [17/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1989, D_X Fake: 0.2429, D_X Total: 0.2209\n",
      "  D_Y Real: 0.1180, D_Y Fake: 0.0493, D_Y Total: 0.0837\n",
      "Generator Losses:\n",
      "  G Adv: 0.8816, F Adv: 0.2337\n",
      "  Cycle Photo: 0.0859, Cycle Monet: 0.0510\n",
      "  Perceptual Photo: 0.2022, Perceptual Monet: 0.1628\n",
      "  Total G Loss: 4.3102\n",
      "Epoch [17/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2375, D_X Fake: 0.2140, D_X Total: 0.2257\n",
      "  D_Y Real: 0.3892, D_Y Fake: 0.2273, D_Y Total: 0.3083\n",
      "Generator Losses:\n",
      "  G Adv: 0.4314, F Adv: 0.2650\n",
      "  Cycle Photo: 0.0644, Cycle Monet: 0.0511\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.4416\n",
      "Epoch [17/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1654, D_X Fake: 0.2098, D_X Total: 0.1876\n",
      "  D_Y Real: 0.2376, D_Y Fake: 0.2771, D_Y Total: 0.2574\n",
      "Generator Losses:\n",
      "  G Adv: 0.3177, F Adv: 0.2963\n",
      "  Cycle Photo: 0.1339, Cycle Monet: 0.0688\n",
      "  Perceptual Photo: 0.1860, Perceptual Monet: 0.2139\n",
      "  Total G Loss: 4.6405\n",
      "Epoch [18/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2298, D_X Fake: 0.2106, D_X Total: 0.2202\n",
      "  D_Y Real: 0.2853, D_Y Fake: 0.2976, D_Y Total: 0.2915\n",
      "Generator Losses:\n",
      "  G Adv: 0.2932, F Adv: 0.2664\n",
      "  Cycle Photo: 0.0904, Cycle Monet: 0.0647\n",
      "  Perceptual Photo: 0.2072, Perceptual Monet: 0.1932\n",
      "  Total G Loss: 4.1124\n",
      "Epoch [18/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2743, D_X Fake: 0.2350, D_X Total: 0.2547\n",
      "  D_Y Real: 0.2695, D_Y Fake: 0.2881, D_Y Total: 0.2788\n",
      "Generator Losses:\n",
      "  G Adv: 0.2971, F Adv: 0.3011\n",
      "  Cycle Photo: 0.0575, Cycle Monet: 0.0449\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.1726\n",
      "Epoch [18/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2577, D_X Fake: 0.1980, D_X Total: 0.2278\n",
      "  D_Y Real: 0.2339, D_Y Fake: 0.2787, D_Y Total: 0.2563\n",
      "Generator Losses:\n",
      "  G Adv: 0.2107, F Adv: 0.2441\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1410, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 2.8652\n",
      "Epoch [18/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2606, D_X Fake: 0.1905, D_X Total: 0.2256\n",
      "  D_Y Real: 0.2861, D_Y Fake: 0.1568, D_Y Total: 0.2215\n",
      "Generator Losses:\n",
      "  G Adv: 0.3620, F Adv: 0.3556\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1260, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 2.9876\n",
      "Epoch [18/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2725, D_X Fake: 0.2532, D_X Total: 0.2629\n",
      "  D_Y Real: 0.2066, D_Y Fake: 0.1700, D_Y Total: 0.1883\n",
      "Generator Losses:\n",
      "  G Adv: 0.2477, F Adv: 0.2945\n",
      "  Cycle Photo: 0.0679, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.1772, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.4539\n",
      "Epoch [18/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2891, D_X Fake: 0.1827, D_X Total: 0.2359\n",
      "  D_Y Real: 0.1973, D_Y Fake: 0.2509, D_Y Total: 0.2241\n",
      "Generator Losses:\n",
      "  G Adv: 0.2430, F Adv: 0.3111\n",
      "  Cycle Photo: 0.0612, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1478\n",
      "  Total G Loss: 3.0301\n",
      "Epoch [18/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2353, D_X Fake: 0.2477, D_X Total: 0.2415\n",
      "  D_Y Real: 0.2919, D_Y Fake: 0.2187, D_Y Total: 0.2553\n",
      "Generator Losses:\n",
      "  G Adv: 0.2709, F Adv: 0.2457\n",
      "  Cycle Photo: 0.0620, Cycle Monet: 0.0677\n",
      "  Perceptual Photo: 0.1502, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.3901\n",
      "Epoch [18/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1437, D_X Fake: 0.3334, D_X Total: 0.2386\n",
      "  D_Y Real: 0.2952, D_Y Fake: 0.1558, D_Y Total: 0.2255\n",
      "Generator Losses:\n",
      "  G Adv: 0.3250, F Adv: 0.1935\n",
      "  Cycle Photo: 0.0557, Cycle Monet: 0.0522\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.2655\n",
      "Epoch [18/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2738, D_X Fake: 0.2561, D_X Total: 0.2650\n",
      "  D_Y Real: 0.2927, D_Y Fake: 0.1747, D_Y Total: 0.2337\n",
      "Generator Losses:\n",
      "  G Adv: 0.3844, F Adv: 0.3395\n",
      "  Cycle Photo: 0.0583, Cycle Monet: 0.0490\n",
      "  Perceptual Photo: 0.1869, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 3.5838\n",
      "Epoch [18/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2794, D_X Fake: 0.3570, D_X Total: 0.3182\n",
      "  D_Y Real: 0.3287, D_Y Fake: 0.1899, D_Y Total: 0.2593\n",
      "Generator Losses:\n",
      "  G Adv: 0.2852, F Adv: 0.2401\n",
      "  Cycle Photo: 0.0535, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1234, Perceptual Monet: 0.1515\n",
      "  Total G Loss: 2.8968\n",
      "Epoch [18/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1977, D_X Fake: 0.3284, D_X Total: 0.2631\n",
      "  D_Y Real: 0.2243, D_Y Fake: 0.2604, D_Y Total: 0.2423\n",
      "Generator Losses:\n",
      "  G Adv: 0.2717, F Adv: 0.2651\n",
      "  Cycle Photo: 0.0707, Cycle Monet: 0.0599\n",
      "  Perceptual Photo: 0.1809, Perceptual Monet: 0.1920\n",
      "  Total G Loss: 3.7075\n",
      "Epoch [18/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1026, D_X Fake: 0.2696, D_X Total: 0.1861\n",
      "  D_Y Real: 0.2363, D_Y Fake: 0.2645, D_Y Total: 0.2504\n",
      "Generator Losses:\n",
      "  G Adv: 0.3658, F Adv: 0.2632\n",
      "  Cycle Photo: 0.0746, Cycle Monet: 0.0500\n",
      "  Perceptual Photo: 0.1032, Perceptual Monet: 0.1621\n",
      "  Total G Loss: 3.2005\n",
      "Epoch [18/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1827, D_X Fake: 0.3371, D_X Total: 0.2599\n",
      "  D_Y Real: 0.2006, D_Y Fake: 0.2683, D_Y Total: 0.2345\n",
      "Generator Losses:\n",
      "  G Adv: 0.2307, F Adv: 0.2666\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1581, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.1548\n",
      "Epoch [18/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1433, D_X Fake: 0.2761, D_X Total: 0.2097\n",
      "  D_Y Real: 0.1983, D_Y Fake: 0.2480, D_Y Total: 0.2232\n",
      "Generator Losses:\n",
      "  G Adv: 0.2199, F Adv: 0.2277\n",
      "  Cycle Photo: 0.1204, Cycle Monet: 0.0510\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.6519\n",
      "Epoch [18/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2729, D_X Fake: 0.2606, D_X Total: 0.2668\n",
      "  D_Y Real: 0.2303, D_Y Fake: 0.2509, D_Y Total: 0.2406\n",
      "Generator Losses:\n",
      "  G Adv: 0.1804, F Adv: 0.2780\n",
      "  Cycle Photo: 0.0581, Cycle Monet: 0.0581\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.1378\n",
      "Epoch [18/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3270, D_X Fake: 0.1267, D_X Total: 0.2268\n",
      "  D_Y Real: 0.2486, D_Y Fake: 0.3057, D_Y Total: 0.2772\n",
      "Generator Losses:\n",
      "  G Adv: 0.2187, F Adv: 0.3581\n",
      "  Cycle Photo: 0.0616, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1833, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.3876\n",
      "Epoch [18/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1662, D_X Fake: 0.3882, D_X Total: 0.2772\n",
      "  D_Y Real: 0.2418, D_Y Fake: 0.2685, D_Y Total: 0.2552\n",
      "Generator Losses:\n",
      "  G Adv: 0.3515, F Adv: 0.2310\n",
      "  Cycle Photo: 0.0780, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1649, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.5335\n",
      "Epoch [18/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2441, D_X Fake: 0.1111, D_X Total: 0.1776\n",
      "  D_Y Real: 0.1784, D_Y Fake: 0.2782, D_Y Total: 0.2283\n",
      "Generator Losses:\n",
      "  G Adv: 0.1909, F Adv: 0.4796\n",
      "  Cycle Photo: 0.0583, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.1729, Perceptual Monet: 0.1875\n",
      "  Total G Loss: 3.5361\n",
      "Epoch [18/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2874, D_X Fake: 0.1638, D_X Total: 0.2256\n",
      "  D_Y Real: 0.2631, D_Y Fake: 0.2424, D_Y Total: 0.2527\n",
      "Generator Losses:\n",
      "  G Adv: 0.2089, F Adv: 0.3878\n",
      "  Cycle Photo: 0.0774, Cycle Monet: 0.0539\n",
      "  Perceptual Photo: 0.1909, Perceptual Monet: 0.2097\n",
      "  Total G Loss: 3.9125\n",
      "Epoch [18/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1152, D_X Fake: 0.0802, D_X Total: 0.0977\n",
      "  D_Y Real: 0.1336, D_Y Fake: 0.4127, D_Y Total: 0.2731\n",
      "Generator Losses:\n",
      "  G Adv: 0.1415, F Adv: 0.2462\n",
      "  Cycle Photo: 0.0667, Cycle Monet: 0.0539\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.2939\n",
      "Epoch [18/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1236, D_X Fake: 0.1999, D_X Total: 0.1618\n",
      "  D_Y Real: 0.3054, D_Y Fake: 0.1885, D_Y Total: 0.2470\n",
      "Generator Losses:\n",
      "  G Adv: 0.2470, F Adv: 0.2515\n",
      "  Cycle Photo: 0.0948, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1681, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.4410\n",
      "Epoch [18/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1948, D_X Fake: 0.0822, D_X Total: 0.1385\n",
      "  D_Y Real: 0.2658, D_Y Fake: 0.2346, D_Y Total: 0.2502\n",
      "Generator Losses:\n",
      "  G Adv: 0.2952, F Adv: 0.6694\n",
      "  Cycle Photo: 0.0687, Cycle Monet: 0.0470\n",
      "  Perceptual Photo: 0.1544, Perceptual Monet: 0.2037\n",
      "  Total G Loss: 3.9122\n",
      "Epoch [18/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0919, D_X Fake: 0.0732, D_X Total: 0.0825\n",
      "  D_Y Real: 0.2839, D_Y Fake: 0.2222, D_Y Total: 0.2531\n",
      "Generator Losses:\n",
      "  G Adv: 0.2549, F Adv: 0.2742\n",
      "  Cycle Photo: 0.0981, Cycle Monet: 0.0540\n",
      "  Perceptual Photo: 0.1793, Perceptual Monet: 0.2155\n",
      "  Total G Loss: 4.0247\n",
      "Epoch [18/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0488, D_X Fake: 0.1731, D_X Total: 0.1109\n",
      "  D_Y Real: 0.3845, D_Y Fake: 0.1371, D_Y Total: 0.2608\n",
      "Generator Losses:\n",
      "  G Adv: 0.4550, F Adv: 0.3570\n",
      "  Cycle Photo: 0.0607, Cycle Monet: 0.0395\n",
      "  Perceptual Photo: 0.1149, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.1394\n",
      "Epoch [19/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1039, D_X Fake: 0.1403, D_X Total: 0.1221\n",
      "  D_Y Real: 0.2567, D_Y Fake: 0.2433, D_Y Total: 0.2500\n",
      "Generator Losses:\n",
      "  G Adv: 0.2593, F Adv: 0.3578\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0492\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.3579\n",
      "Epoch [19/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1013, D_X Fake: 0.1520, D_X Total: 0.1266\n",
      "  D_Y Real: 0.2249, D_Y Fake: 0.2485, D_Y Total: 0.2367\n",
      "Generator Losses:\n",
      "  G Adv: 0.2670, F Adv: 0.2556\n",
      "  Cycle Photo: 0.0607, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1718\n",
      "  Total G Loss: 3.0749\n",
      "Epoch [19/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1141, D_X Fake: 0.0374, D_X Total: 0.0757\n",
      "  D_Y Real: 0.4268, D_Y Fake: 0.2058, D_Y Total: 0.3163\n",
      "Generator Losses:\n",
      "  G Adv: 0.3742, F Adv: 0.3897\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0496\n",
      "  Perceptual Photo: 0.1891, Perceptual Monet: 0.1787\n",
      "  Total G Loss: 3.6629\n",
      "Epoch [19/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2455, D_X Fake: 0.1121, D_X Total: 0.1788\n",
      "  D_Y Real: 0.1810, D_Y Fake: 0.3621, D_Y Total: 0.2716\n",
      "Generator Losses:\n",
      "  G Adv: 0.1296, F Adv: 0.5555\n",
      "  Cycle Photo: 0.0737, Cycle Monet: 0.0641\n",
      "  Perceptual Photo: 0.2147, Perceptual Monet: 0.2314\n",
      "  Total G Loss: 4.2943\n",
      "Epoch [19/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0696, D_X Fake: 0.1645, D_X Total: 0.1171\n",
      "  D_Y Real: 0.2674, D_Y Fake: 0.2796, D_Y Total: 0.2735\n",
      "Generator Losses:\n",
      "  G Adv: 0.2936, F Adv: 0.3563\n",
      "  Cycle Photo: 0.0724, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1575, Perceptual Monet: 0.1787\n",
      "  Total G Loss: 3.4152\n",
      "Epoch [19/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1590, D_X Fake: 0.0653, D_X Total: 0.1121\n",
      "  D_Y Real: 0.2198, D_Y Fake: 0.2500, D_Y Total: 0.2349\n",
      "Generator Losses:\n",
      "  G Adv: 0.3517, F Adv: 0.7799\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0489\n",
      "  Perceptual Photo: 0.1727, Perceptual Monet: 0.1933\n",
      "  Total G Loss: 3.9823\n",
      "Epoch [19/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1165, D_X Fake: 0.0930, D_X Total: 0.1047\n",
      "  D_Y Real: 0.2685, D_Y Fake: 0.2835, D_Y Total: 0.2760\n",
      "Generator Losses:\n",
      "  G Adv: 0.2103, F Adv: 0.5522\n",
      "  Cycle Photo: 0.0735, Cycle Monet: 0.0488\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.2125\n",
      "  Total G Loss: 3.8425\n",
      "Epoch [19/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0589, D_X Fake: 0.0924, D_X Total: 0.0757\n",
      "  D_Y Real: 0.1881, D_Y Fake: 0.3339, D_Y Total: 0.2610\n",
      "Generator Losses:\n",
      "  G Adv: 0.2814, F Adv: 0.6005\n",
      "  Cycle Photo: 0.0662, Cycle Monet: 0.0709\n",
      "  Perceptual Photo: 0.1924, Perceptual Monet: 0.1938\n",
      "  Total G Loss: 4.1841\n",
      "Epoch [19/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1253, D_X Fake: 0.0894, D_X Total: 0.1074\n",
      "  D_Y Real: 0.2538, D_Y Fake: 0.1523, D_Y Total: 0.2030\n",
      "Generator Losses:\n",
      "  G Adv: 0.3354, F Adv: 0.4004\n",
      "  Cycle Photo: 0.0599, Cycle Monet: 0.0558\n",
      "  Perceptual Photo: 0.2032, Perceptual Monet: 0.2039\n",
      "  Total G Loss: 3.9287\n",
      "Epoch [19/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1086, D_X Fake: 0.1121, D_X Total: 0.1103\n",
      "  D_Y Real: 0.2879, D_Y Fake: 0.2454, D_Y Total: 0.2667\n",
      "Generator Losses:\n",
      "  G Adv: 0.2697, F Adv: 0.4741\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0599\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.2244\n",
      "  Total G Loss: 3.6202\n",
      "Epoch [19/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2247, D_X Fake: 0.0770, D_X Total: 0.1508\n",
      "  D_Y Real: 0.2329, D_Y Fake: 0.2923, D_Y Total: 0.2626\n",
      "Generator Losses:\n",
      "  G Adv: 0.2190, F Adv: 0.5414\n",
      "  Cycle Photo: 0.0577, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1860\n",
      "  Total G Loss: 3.4121\n",
      "Epoch [19/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0654, D_X Fake: 0.1163, D_X Total: 0.0909\n",
      "  D_Y Real: 0.1929, D_Y Fake: 0.2585, D_Y Total: 0.2257\n",
      "Generator Losses:\n",
      "  G Adv: 0.2835, F Adv: 0.4811\n",
      "  Cycle Photo: 0.1059, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1786, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 4.0724\n",
      "Epoch [19/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0447, D_X Fake: 0.1840, D_X Total: 0.1143\n",
      "  D_Y Real: 0.1357, D_Y Fake: 0.4547, D_Y Total: 0.2952\n",
      "Generator Losses:\n",
      "  G Adv: 0.1345, F Adv: 0.4288\n",
      "  Cycle Photo: 0.0523, Cycle Monet: 0.0601\n",
      "  Perceptual Photo: 0.1695, Perceptual Monet: 0.2518\n",
      "  Total G Loss: 3.7943\n",
      "Epoch [19/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0521, D_X Fake: 0.1579, D_X Total: 0.1050\n",
      "  D_Y Real: 0.2017, D_Y Fake: 0.1378, D_Y Total: 0.1697\n",
      "Generator Losses:\n",
      "  G Adv: 0.3305, F Adv: 0.4262\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1954\n",
      "  Total G Loss: 3.3688\n",
      "Epoch [19/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1495, D_X Fake: 0.1121, D_X Total: 0.1308\n",
      "  D_Y Real: 0.2721, D_Y Fake: 0.1711, D_Y Total: 0.2216\n",
      "Generator Losses:\n",
      "  G Adv: 0.3091, F Adv: 0.5639\n",
      "  Cycle Photo: 0.0576, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 3.4774\n",
      "Epoch [19/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2251, D_X Fake: 0.3533, D_X Total: 0.2892\n",
      "  D_Y Real: 0.4086, D_Y Fake: 0.0892, D_Y Total: 0.2489\n",
      "Generator Losses:\n",
      "  G Adv: 0.5876, F Adv: 0.4109\n",
      "  Cycle Photo: 0.0714, Cycle Monet: 0.0761\n",
      "  Perceptual Photo: 0.1973, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 4.3870\n",
      "Epoch [19/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1057, D_X Fake: 0.2270, D_X Total: 0.1664\n",
      "  D_Y Real: 0.0592, D_Y Fake: 0.1632, D_Y Total: 0.1112\n",
      "Generator Losses:\n",
      "  G Adv: 0.5213, F Adv: 0.2718\n",
      "  Cycle Photo: 0.0850, Cycle Monet: 0.0845\n",
      "  Perceptual Photo: 0.2451, Perceptual Monet: 0.2686\n",
      "  Total G Loss: 5.0571\n",
      "Epoch [19/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0646, D_X Fake: 0.0712, D_X Total: 0.0679\n",
      "  D_Y Real: 0.1115, D_Y Fake: 0.1003, D_Y Total: 0.1059\n",
      "Generator Losses:\n",
      "  G Adv: 0.3345, F Adv: 0.7627\n",
      "  Cycle Photo: 0.0646, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.2320\n",
      "  Total G Loss: 4.1187\n",
      "Epoch [19/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1866, D_X Fake: 0.0863, D_X Total: 0.1364\n",
      "  D_Y Real: 0.0647, D_Y Fake: 0.3158, D_Y Total: 0.1903\n",
      "Generator Losses:\n",
      "  G Adv: 0.1457, F Adv: 0.7388\n",
      "  Cycle Photo: 0.0991, Cycle Monet: 0.0669\n",
      "  Perceptual Photo: 0.2469, Perceptual Monet: 0.1935\n",
      "  Total G Loss: 4.7461\n",
      "Epoch [19/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2727, D_X Fake: 0.0666, D_X Total: 0.1696\n",
      "  D_Y Real: 0.0877, D_Y Fake: 0.1250, D_Y Total: 0.1064\n",
      "Generator Losses:\n",
      "  G Adv: 0.4117, F Adv: 0.6544\n",
      "  Cycle Photo: 0.0707, Cycle Monet: 0.0483\n",
      "  Perceptual Photo: 0.2137, Perceptual Monet: 0.1859\n",
      "  Total G Loss: 4.2540\n",
      "Epoch [19/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1397, D_X Fake: 0.0668, D_X Total: 0.1033\n",
      "  D_Y Real: 0.1638, D_Y Fake: 0.1288, D_Y Total: 0.1463\n",
      "Generator Losses:\n",
      "  G Adv: 0.4901, F Adv: 0.5878\n",
      "  Cycle Photo: 0.0626, Cycle Monet: 0.0556\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.1983\n",
      "  Total G Loss: 4.1109\n",
      "Epoch [19/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0760, D_X Fake: 0.1770, D_X Total: 0.1265\n",
      "  D_Y Real: 0.1430, D_Y Fake: 0.0593, D_Y Total: 0.1011\n",
      "Generator Losses:\n",
      "  G Adv: 0.4460, F Adv: 0.3868\n",
      "  Cycle Photo: 0.0575, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.2112, Perceptual Monet: 0.2049\n",
      "  Total G Loss: 3.9347\n",
      "Epoch [19/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1593, D_X Fake: 0.0519, D_X Total: 0.1056\n",
      "  D_Y Real: 0.0692, D_Y Fake: 0.2162, D_Y Total: 0.1427\n",
      "Generator Losses:\n",
      "  G Adv: 0.4456, F Adv: 0.7085\n",
      "  Cycle Photo: 0.0553, Cycle Monet: 0.0559\n",
      "  Perceptual Photo: 0.1856, Perceptual Monet: 0.2213\n",
      "  Total G Loss: 4.3005\n",
      "Epoch [19/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0834, D_X Fake: 0.0617, D_X Total: 0.0726\n",
      "  D_Y Real: 0.3069, D_Y Fake: 0.0785, D_Y Total: 0.1927\n",
      "Generator Losses:\n",
      "  G Adv: 0.7271, F Adv: 0.7105\n",
      "  Cycle Photo: 0.0935, Cycle Monet: 0.0614\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.2227\n",
      "  Total G Loss: 4.9587\n",
      "Epoch [20/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0344, D_X Fake: 0.2702, D_X Total: 0.1523\n",
      "  D_Y Real: 0.2647, D_Y Fake: 0.0271, D_Y Total: 0.1459\n",
      "Generator Losses:\n",
      "  G Adv: 0.8258, F Adv: 0.3323\n",
      "  Cycle Photo: 0.0619, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.2294, Perceptual Monet: 0.2033\n",
      "  Total G Loss: 4.3481\n",
      "Epoch [20/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1867, D_X Fake: 0.0769, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0641, D_Y Fake: 0.3623, D_Y Total: 0.2132\n",
      "Generator Losses:\n",
      "  G Adv: 0.2068, F Adv: 0.6316\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0549\n",
      "  Perceptual Photo: 0.1551, Perceptual Monet: 0.2276\n",
      "  Total G Loss: 3.8305\n",
      "Epoch [20/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1163, D_X Fake: 0.1898, D_X Total: 0.1531\n",
      "  D_Y Real: 0.0830, D_Y Fake: 0.2949, D_Y Total: 0.1889\n",
      "Generator Losses:\n",
      "  G Adv: 0.2019, F Adv: 0.1898\n",
      "  Cycle Photo: 0.0690, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1655, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.1240\n",
      "Epoch [20/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1098, D_X Fake: 0.0611, D_X Total: 0.0855\n",
      "  D_Y Real: 0.1274, D_Y Fake: 0.0673, D_Y Total: 0.0974\n",
      "Generator Losses:\n",
      "  G Adv: 0.7096, F Adv: 0.7363\n",
      "  Cycle Photo: 0.0637, Cycle Monet: 0.0612\n",
      "  Perceptual Photo: 0.1689, Perceptual Monet: 0.2019\n",
      "  Total G Loss: 4.5485\n",
      "Epoch [20/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1479, D_X Fake: 0.1665, D_X Total: 0.1572\n",
      "  D_Y Real: 0.1149, D_Y Fake: 0.0913, D_Y Total: 0.1031\n",
      "Generator Losses:\n",
      "  G Adv: 0.3878, F Adv: 0.3410\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0598\n",
      "  Perceptual Photo: 0.1634, Perceptual Monet: 0.2334\n",
      "  Total G Loss: 3.8630\n",
      "Epoch [20/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1008, D_X Fake: 0.0977, D_X Total: 0.0993\n",
      "  D_Y Real: 0.1490, D_Y Fake: 0.1306, D_Y Total: 0.1398\n",
      "Generator Losses:\n",
      "  G Adv: 0.3665, F Adv: 0.6111\n",
      "  Cycle Photo: 0.0769, Cycle Monet: 0.0605\n",
      "  Perceptual Photo: 0.2012, Perceptual Monet: 0.2096\n",
      "  Total G Loss: 4.4058\n",
      "Epoch [20/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1954, D_X Fake: 0.0434, D_X Total: 0.1194\n",
      "  D_Y Real: 0.2231, D_Y Fake: 0.0753, D_Y Total: 0.1492\n",
      "Generator Losses:\n",
      "  G Adv: 0.6192, F Adv: 0.7421\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0639\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.2253\n",
      "  Total G Loss: 4.4860\n",
      "Epoch [20/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.0647, D_X Total: 0.1706\n",
      "  D_Y Real: 0.1167, D_Y Fake: 0.0492, D_Y Total: 0.0829\n",
      "Generator Losses:\n",
      "  G Adv: 0.4679, F Adv: 0.6876\n",
      "  Cycle Photo: 0.0510, Cycle Monet: 0.0436\n",
      "  Perceptual Photo: 0.1832, Perceptual Monet: 0.2185\n",
      "  Total G Loss: 4.1099\n",
      "Epoch [20/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1742, D_X Fake: 0.0926, D_X Total: 0.1334\n",
      "  D_Y Real: 0.1881, D_Y Fake: 0.1039, D_Y Total: 0.1460\n",
      "Generator Losses:\n",
      "  G Adv: 0.5520, F Adv: 0.4352\n",
      "  Cycle Photo: 0.0680, Cycle Monet: 0.0507\n",
      "  Perceptual Photo: 0.2065, Perceptual Monet: 0.2015\n",
      "  Total G Loss: 4.2144\n",
      "Epoch [20/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1713, D_X Fake: 0.2644, D_X Total: 0.2179\n",
      "  D_Y Real: 0.0664, D_Y Fake: 0.0976, D_Y Total: 0.0820\n",
      "Generator Losses:\n",
      "  G Adv: 0.4923, F Adv: 0.2440\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1946, Perceptual Monet: 0.1993\n",
      "  Total G Loss: 3.6806\n",
      "Epoch [20/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2409, D_X Fake: 0.2531, D_X Total: 0.2470\n",
      "  D_Y Real: 0.1796, D_Y Fake: 0.0488, D_Y Total: 0.1142\n",
      "Generator Losses:\n",
      "  G Adv: 0.4616, F Adv: 0.2905\n",
      "  Cycle Photo: 0.0807, Cycle Monet: 0.0513\n",
      "  Perceptual Photo: 0.1739, Perceptual Monet: 0.1911\n",
      "  Total G Loss: 3.8972\n",
      "Epoch [20/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3340, D_X Fake: 0.2384, D_X Total: 0.2862\n",
      "  D_Y Real: 0.1258, D_Y Fake: 0.1064, D_Y Total: 0.1161\n",
      "Generator Losses:\n",
      "  G Adv: 0.4289, F Adv: 0.3296\n",
      "  Cycle Photo: 0.0671, Cycle Monet: 0.0451\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1862\n",
      "  Total G Loss: 3.5660\n",
      "Epoch [20/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3385, D_X Fake: 0.1647, D_X Total: 0.2516\n",
      "  D_Y Real: 0.0498, D_Y Fake: 0.4637, D_Y Total: 0.2568\n",
      "Generator Losses:\n",
      "  G Adv: 0.2211, F Adv: 0.4169\n",
      "  Cycle Photo: 0.0706, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1981, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.6544\n",
      "Epoch [20/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3214, D_X Fake: 0.2575, D_X Total: 0.2894\n",
      "  D_Y Real: 0.0964, D_Y Fake: 0.1552, D_Y Total: 0.1258\n",
      "Generator Losses:\n",
      "  G Adv: 0.2453, F Adv: 0.2936\n",
      "  Cycle Photo: 0.0587, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1799, Perceptual Monet: 0.1892\n",
      "  Total G Loss: 3.3785\n",
      "Epoch [20/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3169, D_X Fake: 0.2489, D_X Total: 0.2829\n",
      "  D_Y Real: 0.0474, D_Y Fake: 0.3123, D_Y Total: 0.1799\n",
      "Generator Losses:\n",
      "  G Adv: 0.2778, F Adv: 0.2236\n",
      "  Cycle Photo: 0.0645, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.2089, Perceptual Monet: 0.1381\n",
      "  Total G Loss: 3.1953\n",
      "Epoch [20/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2125, D_X Fake: 0.1839, D_X Total: 0.1982\n",
      "  D_Y Real: 0.3485, D_Y Fake: 0.1106, D_Y Total: 0.2295\n",
      "Generator Losses:\n",
      "  G Adv: 0.5599, F Adv: 0.3062\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.3956\n",
      "Epoch [20/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3600, D_X Fake: 0.1819, D_X Total: 0.2709\n",
      "  D_Y Real: 0.1802, D_Y Fake: 0.0491, D_Y Total: 0.1147\n",
      "Generator Losses:\n",
      "  G Adv: 0.5755, F Adv: 0.3619\n",
      "  Cycle Photo: 0.0481, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.2009\n",
      "  Total G Loss: 3.6976\n",
      "Epoch [20/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1941, D_X Fake: 0.1915, D_X Total: 0.1928\n",
      "  D_Y Real: 0.1962, D_Y Fake: 0.1285, D_Y Total: 0.1624\n",
      "Generator Losses:\n",
      "  G Adv: 0.5781, F Adv: 0.3313\n",
      "  Cycle Photo: 0.0795, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.7882\n",
      "Epoch [20/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1757, D_X Fake: 0.2743, D_X Total: 0.2250\n",
      "  D_Y Real: 0.2174, D_Y Fake: 0.0825, D_Y Total: 0.1499\n",
      "Generator Losses:\n",
      "  G Adv: 0.4533, F Adv: 0.2934\n",
      "  Cycle Photo: 0.0563, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1648, Perceptual Monet: 0.1569\n",
      "  Total G Loss: 3.3615\n",
      "Epoch [20/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2297, D_X Fake: 0.2236, D_X Total: 0.2267\n",
      "  D_Y Real: 0.0776, D_Y Fake: 0.1646, D_Y Total: 0.1211\n",
      "Generator Losses:\n",
      "  G Adv: 0.5312, F Adv: 0.2986\n",
      "  Cycle Photo: 0.0459, Cycle Monet: 0.0572\n",
      "  Perceptual Photo: 0.1873, Perceptual Monet: 0.1968\n",
      "  Total G Loss: 3.7814\n",
      "Epoch [20/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2280, D_X Fake: 0.1723, D_X Total: 0.2001\n",
      "  D_Y Real: 0.1732, D_Y Fake: 0.0764, D_Y Total: 0.1248\n",
      "Generator Losses:\n",
      "  G Adv: 0.4981, F Adv: 0.3537\n",
      "  Cycle Photo: 0.0670, Cycle Monet: 0.0451\n",
      "  Perceptual Photo: 0.1833, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.7078\n",
      "Epoch [20/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2713, D_X Fake: 0.2007, D_X Total: 0.2360\n",
      "  D_Y Real: 0.1295, D_Y Fake: 0.1276, D_Y Total: 0.1285\n",
      "Generator Losses:\n",
      "  G Adv: 0.4425, F Adv: 0.3327\n",
      "  Cycle Photo: 0.0649, Cycle Monet: 0.0470\n",
      "  Perceptual Photo: 0.2127, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.8083\n",
      "Epoch [20/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2880, D_X Fake: 0.1795, D_X Total: 0.2337\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.2529, D_Y Total: 0.1434\n",
      "Generator Losses:\n",
      "  G Adv: 0.2854, F Adv: 0.3630\n",
      "  Cycle Photo: 0.0686, Cycle Monet: 0.0522\n",
      "  Perceptual Photo: 0.2343, Perceptual Monet: 0.1930\n",
      "  Total G Loss: 3.9931\n",
      "Epoch [20/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3392, D_X Fake: 0.1982, D_X Total: 0.2687\n",
      "  D_Y Real: 0.1321, D_Y Fake: 0.0937, D_Y Total: 0.1129\n",
      "Generator Losses:\n",
      "  G Adv: 0.6977, F Adv: 0.3135\n",
      "  Cycle Photo: 0.0461, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1796, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.5532\n",
      "Saved checkpoint at epoch 20\n",
      "Epoch [21/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2313, D_X Fake: 0.2731, D_X Total: 0.2522\n",
      "  D_Y Real: 0.2004, D_Y Fake: 0.0512, D_Y Total: 0.1258\n",
      "Generator Losses:\n",
      "  G Adv: 0.7260, F Adv: 0.2297\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1836, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.6645\n",
      "Epoch [21/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1197, D_X Fake: 0.3013, D_X Total: 0.2105\n",
      "  D_Y Real: 0.0974, D_Y Fake: 0.2051, D_Y Total: 0.1513\n",
      "Generator Losses:\n",
      "  G Adv: 0.4855, F Adv: 0.2292\n",
      "  Cycle Photo: 0.0821, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1873, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.7188\n",
      "Epoch [21/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2073, D_X Fake: 0.2134, D_X Total: 0.2104\n",
      "  D_Y Real: 0.0551, D_Y Fake: 0.0568, D_Y Total: 0.0559\n",
      "Generator Losses:\n",
      "  G Adv: 0.7887, F Adv: 0.2945\n",
      "  Cycle Photo: 0.0581, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.7013\n",
      "Epoch [21/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2183, D_X Fake: 0.2508, D_X Total: 0.2345\n",
      "  D_Y Real: 0.1147, D_Y Fake: 0.1017, D_Y Total: 0.1082\n",
      "Generator Losses:\n",
      "  G Adv: 0.5826, F Adv: 0.2942\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1621, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.4952\n",
      "Epoch [21/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1632, D_X Fake: 0.2102, D_X Total: 0.1867\n",
      "  D_Y Real: 0.2116, D_Y Fake: 0.0446, D_Y Total: 0.1281\n",
      "Generator Losses:\n",
      "  G Adv: 0.7674, F Adv: 0.3264\n",
      "  Cycle Photo: 0.0558, Cycle Monet: 0.0573\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.2082\n",
      "  Total G Loss: 3.9966\n",
      "Epoch [21/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3886, D_X Fake: 0.2851, D_X Total: 0.3368\n",
      "  D_Y Real: 0.1380, D_Y Fake: 0.0900, D_Y Total: 0.1140\n",
      "Generator Losses:\n",
      "  G Adv: 0.2914, F Adv: 0.2040\n",
      "  Cycle Photo: 0.0714, Cycle Monet: 0.0615\n",
      "  Perceptual Photo: 0.2465, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.8926\n",
      "Epoch [21/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1843, D_X Fake: 0.1441, D_X Total: 0.1642\n",
      "  D_Y Real: 0.1676, D_Y Fake: 0.0803, D_Y Total: 0.1240\n",
      "Generator Losses:\n",
      "  G Adv: 0.7595, F Adv: 0.3722\n",
      "  Cycle Photo: 0.0448, Cycle Monet: 0.0432\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 3.7260\n",
      "Epoch [21/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2290, D_X Fake: 0.1466, D_X Total: 0.1878\n",
      "  D_Y Real: 0.1445, D_Y Fake: 0.0557, D_Y Total: 0.1001\n",
      "Generator Losses:\n",
      "  G Adv: 0.7385, F Adv: 0.4151\n",
      "  Cycle Photo: 0.0687, Cycle Monet: 0.0518\n",
      "  Perceptual Photo: 0.1923, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 4.2597\n",
      "Epoch [21/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0764, D_X Fake: 0.1291, D_X Total: 0.1027\n",
      "  D_Y Real: 0.1190, D_Y Fake: 0.0552, D_Y Total: 0.0871\n",
      "Generator Losses:\n",
      "  G Adv: 0.8304, F Adv: 0.3381\n",
      "  Cycle Photo: 0.0530, Cycle Monet: 0.0579\n",
      "  Perceptual Photo: 0.2273, Perceptual Monet: 0.1894\n",
      "  Total G Loss: 4.3607\n",
      "Epoch [21/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2441, D_X Fake: 0.0638, D_X Total: 0.1540\n",
      "  D_Y Real: 0.0804, D_Y Fake: 0.1595, D_Y Total: 0.1200\n",
      "Generator Losses:\n",
      "  G Adv: 0.5523, F Adv: 0.7643\n",
      "  Cycle Photo: 0.0709, Cycle Monet: 0.0555\n",
      "  Perceptual Photo: 0.1778, Perceptual Monet: 0.2263\n",
      "  Total G Loss: 4.6016\n",
      "Epoch [21/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0907, D_X Fake: 0.1801, D_X Total: 0.1354\n",
      "  D_Y Real: 0.0983, D_Y Fake: 0.0741, D_Y Total: 0.0862\n",
      "Generator Losses:\n",
      "  G Adv: 0.5377, F Adv: 0.4510\n",
      "  Cycle Photo: 0.0644, Cycle Monet: 0.0620\n",
      "  Perceptual Photo: 0.1870, Perceptual Monet: 0.2191\n",
      "  Total G Loss: 4.2831\n",
      "Epoch [21/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.1817, D_X Total: 0.1274\n",
      "  D_Y Real: 0.0903, D_Y Fake: 0.1419, D_Y Total: 0.1161\n",
      "Generator Losses:\n",
      "  G Adv: 0.6297, F Adv: 0.3286\n",
      "  Cycle Photo: 0.0648, Cycle Monet: 0.0543\n",
      "  Perceptual Photo: 0.1851, Perceptual Monet: 0.1753\n",
      "  Total G Loss: 3.9509\n",
      "Epoch [21/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0802, D_X Fake: 0.1922, D_X Total: 0.1362\n",
      "  D_Y Real: 0.1120, D_Y Fake: 0.0797, D_Y Total: 0.0959\n",
      "Generator Losses:\n",
      "  G Adv: 0.6426, F Adv: 0.3363\n",
      "  Cycle Photo: 0.0556, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1529, Perceptual Monet: 0.1888\n",
      "  Total G Loss: 3.6981\n",
      "Epoch [21/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.1384, D_X Total: 0.1270\n",
      "  D_Y Real: 0.3470, D_Y Fake: 0.0684, D_Y Total: 0.2077\n",
      "Generator Losses:\n",
      "  G Adv: 1.2795, F Adv: 0.3852\n",
      "  Cycle Photo: 0.0845, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1983, Perceptual Monet: 0.1982\n",
      "  Total G Loss: 4.9790\n",
      "Epoch [21/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2055, D_X Fake: 0.1264, D_X Total: 0.1659\n",
      "  D_Y Real: 0.0907, D_Y Fake: 0.1907, D_Y Total: 0.1407\n",
      "Generator Losses:\n",
      "  G Adv: 0.5014, F Adv: 0.5102\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0627\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.2023\n",
      "  Total G Loss: 3.7988\n",
      "Epoch [21/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2138, D_X Fake: 0.1467, D_X Total: 0.1803\n",
      "  D_Y Real: 0.0746, D_Y Fake: 0.2017, D_Y Total: 0.1382\n",
      "Generator Losses:\n",
      "  G Adv: 0.3234, F Adv: 0.4568\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.2624\n",
      "Epoch [21/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0648, D_X Fake: 0.0189, D_X Total: 0.0419\n",
      "  D_Y Real: 0.0505, D_Y Fake: 0.0730, D_Y Total: 0.0617\n",
      "Generator Losses:\n",
      "  G Adv: 0.7416, F Adv: 0.9170\n",
      "  Cycle Photo: 0.0763, Cycle Monet: 0.0574\n",
      "  Perceptual Photo: 0.1609, Perceptual Monet: 0.2159\n",
      "  Total G Loss: 4.8792\n",
      "Epoch [21/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0522, D_X Fake: 0.1856, D_X Total: 0.1189\n",
      "  D_Y Real: 0.2158, D_Y Fake: 0.0796, D_Y Total: 0.1477\n",
      "Generator Losses:\n",
      "  G Adv: 0.6763, F Adv: 0.3838\n",
      "  Cycle Photo: 0.0724, Cycle Monet: 0.0575\n",
      "  Perceptual Photo: 0.1950, Perceptual Monet: 0.2123\n",
      "  Total G Loss: 4.3964\n",
      "Epoch [21/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2248, D_X Fake: 0.0769, D_X Total: 0.1509\n",
      "  D_Y Real: 0.0695, D_Y Fake: 0.1826, D_Y Total: 0.1260\n",
      "Generator Losses:\n",
      "  G Adv: 0.3620, F Adv: 0.5924\n",
      "  Cycle Photo: 0.0498, Cycle Monet: 0.0413\n",
      "  Perceptual Photo: 0.2098, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 3.7996\n",
      "Epoch [21/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1351, D_X Fake: 0.1836, D_X Total: 0.1594\n",
      "  D_Y Real: 0.0709, D_Y Fake: 0.1225, D_Y Total: 0.0967\n",
      "Generator Losses:\n",
      "  G Adv: 0.6431, F Adv: 0.3666\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.1802, Perceptual Monet: 0.1969\n",
      "  Total G Loss: 3.8112\n",
      "Epoch [21/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1328, D_X Fake: 0.0264, D_X Total: 0.0796\n",
      "  D_Y Real: 0.0629, D_Y Fake: 0.1160, D_Y Total: 0.0894\n",
      "Generator Losses:\n",
      "  G Adv: 0.6580, F Adv: 0.8252\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1936, Perceptual Monet: 0.2021\n",
      "  Total G Loss: 4.5552\n",
      "Epoch [21/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1341, D_X Fake: 0.0490, D_X Total: 0.0916\n",
      "  D_Y Real: 0.2111, D_Y Fake: 0.0768, D_Y Total: 0.1439\n",
      "Generator Losses:\n",
      "  G Adv: 0.4575, F Adv: 0.7479\n",
      "  Cycle Photo: 0.0507, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1308, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.6730\n",
      "Epoch [21/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0335, D_X Fake: 0.1336, D_X Total: 0.0836\n",
      "  D_Y Real: 0.1493, D_Y Fake: 0.1065, D_Y Total: 0.1279\n",
      "Generator Losses:\n",
      "  G Adv: 0.9318, F Adv: 0.3095\n",
      "  Cycle Photo: 0.0689, Cycle Monet: 0.0433\n",
      "  Perceptual Photo: 0.1870, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 4.2473\n",
      "Epoch [21/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0404, D_X Fake: 0.3573, D_X Total: 0.1988\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.1757, D_Y Total: 0.0997\n",
      "Generator Losses:\n",
      "  G Adv: 0.3034, F Adv: 0.3145\n",
      "  Cycle Photo: 0.0842, Cycle Monet: 0.0601\n",
      "  Perceptual Photo: 0.1358, Perceptual Monet: 0.2086\n",
      "  Total G Loss: 3.7829\n",
      "Epoch [22/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1131, D_X Fake: 0.0825, D_X Total: 0.0978\n",
      "  D_Y Real: 0.1583, D_Y Fake: 0.1096, D_Y Total: 0.1340\n",
      "Generator Losses:\n",
      "  G Adv: 0.5706, F Adv: 0.6086\n",
      "  Cycle Photo: 0.0667, Cycle Monet: 0.0448\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.7575\n",
      "Epoch [22/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0698, D_X Fake: 0.1318, D_X Total: 0.1008\n",
      "  D_Y Real: 0.1625, D_Y Fake: 0.1636, D_Y Total: 0.1630\n",
      "Generator Losses:\n",
      "  G Adv: 0.3239, F Adv: 0.4555\n",
      "  Cycle Photo: 0.0734, Cycle Monet: 0.0501\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.1872\n",
      "  Total G Loss: 3.7730\n",
      "Epoch [22/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1679, D_X Fake: 0.1805, D_X Total: 0.1742\n",
      "  D_Y Real: 0.2758, D_Y Fake: 0.1837, D_Y Total: 0.2297\n",
      "Generator Losses:\n",
      "  G Adv: 0.4689, F Adv: 0.4194\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1822, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.6082\n",
      "Epoch [22/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1349, D_X Fake: 0.0920, D_X Total: 0.1134\n",
      "  D_Y Real: 0.1362, D_Y Fake: 0.0491, D_Y Total: 0.0927\n",
      "Generator Losses:\n",
      "  G Adv: 0.6102, F Adv: 0.5434\n",
      "  Cycle Photo: 0.0938, Cycle Monet: 0.0550\n",
      "  Perceptual Photo: 0.2460, Perceptual Monet: 0.1896\n",
      "  Total G Loss: 4.8197\n",
      "Epoch [22/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0952, D_X Fake: 0.3081, D_X Total: 0.2017\n",
      "  D_Y Real: 0.3464, D_Y Fake: 0.0248, D_Y Total: 0.1856\n",
      "Generator Losses:\n",
      "  G Adv: 0.9091, F Adv: 0.2133\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1781, Perceptual Monet: 0.1711\n",
      "  Total G Loss: 3.7713\n",
      "Epoch [22/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2366, D_X Fake: 0.0423, D_X Total: 0.1395\n",
      "  D_Y Real: 0.1668, D_Y Fake: 0.0722, D_Y Total: 0.1195\n",
      "Generator Losses:\n",
      "  G Adv: 0.6557, F Adv: 0.8094\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0495\n",
      "  Perceptual Photo: 0.1796, Perceptual Monet: 0.1904\n",
      "  Total G Loss: 4.4029\n",
      "Epoch [22/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1497, D_X Fake: 0.1929, D_X Total: 0.1713\n",
      "  D_Y Real: 0.1132, D_Y Fake: 0.2714, D_Y Total: 0.1923\n",
      "Generator Losses:\n",
      "  G Adv: 0.3670, F Adv: 0.4003\n",
      "  Cycle Photo: 0.0680, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.2012, Perceptual Monet: 0.1918\n",
      "  Total G Loss: 3.8549\n",
      "Epoch [22/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2184, D_X Fake: 0.0774, D_X Total: 0.1479\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.2887, D_Y Total: 0.1588\n",
      "Generator Losses:\n",
      "  G Adv: 0.2928, F Adv: 0.5440\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1795\n",
      "  Total G Loss: 3.5512\n",
      "Epoch [22/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0745, D_X Fake: 0.1638, D_X Total: 0.1191\n",
      "  D_Y Real: 0.2955, D_Y Fake: 0.0861, D_Y Total: 0.1908\n",
      "Generator Losses:\n",
      "  G Adv: 0.6315, F Adv: 0.3732\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0575\n",
      "  Perceptual Photo: 0.1857, Perceptual Monet: 0.2159\n",
      "  Total G Loss: 4.2169\n",
      "Epoch [22/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1908, D_X Fake: 0.0641, D_X Total: 0.1275\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0919, D_Y Total: 0.0659\n",
      "Generator Losses:\n",
      "  G Adv: 0.4731, F Adv: 0.7551\n",
      "  Cycle Photo: 0.0628, Cycle Monet: 0.0501\n",
      "  Perceptual Photo: 0.2098, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 4.2585\n",
      "Epoch [22/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2429, D_X Fake: 0.1214, D_X Total: 0.1822\n",
      "  D_Y Real: 0.1466, D_Y Fake: 0.1220, D_Y Total: 0.1343\n",
      "Generator Losses:\n",
      "  G Adv: 0.3000, F Adv: 0.7481\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0440\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.1910\n",
      "  Total G Loss: 3.7993\n",
      "Epoch [22/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0888, D_X Fake: 0.2012, D_X Total: 0.1450\n",
      "  D_Y Real: 0.0514, D_Y Fake: 0.2695, D_Y Total: 0.1604\n",
      "Generator Losses:\n",
      "  G Adv: 0.4500, F Adv: 0.4590\n",
      "  Cycle Photo: 0.0593, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.2097, Perceptual Monet: 0.1740\n",
      "  Total G Loss: 3.7757\n",
      "Epoch [22/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0771, D_X Fake: 0.1133, D_X Total: 0.0952\n",
      "  D_Y Real: 0.1103, D_Y Fake: 0.1012, D_Y Total: 0.1058\n",
      "Generator Losses:\n",
      "  G Adv: 0.5677, F Adv: 0.5169\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0492\n",
      "  Perceptual Photo: 0.1769, Perceptual Monet: 0.2027\n",
      "  Total G Loss: 4.0029\n",
      "Epoch [22/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1737, D_X Fake: 0.0784, D_X Total: 0.1261\n",
      "  D_Y Real: 0.0666, D_Y Fake: 0.2021, D_Y Total: 0.1344\n",
      "Generator Losses:\n",
      "  G Adv: 0.3711, F Adv: 0.6977\n",
      "  Cycle Photo: 0.1377, Cycle Monet: 0.0544\n",
      "  Perceptual Photo: 0.1710, Perceptual Monet: 0.2119\n",
      "  Total G Loss: 4.9041\n",
      "Epoch [22/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1701, D_X Fake: 0.0831, D_X Total: 0.1266\n",
      "  D_Y Real: 0.1373, D_Y Fake: 0.2167, D_Y Total: 0.1770\n",
      "Generator Losses:\n",
      "  G Adv: 0.6903, F Adv: 0.4696\n",
      "  Cycle Photo: 0.0501, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.6628\n",
      "Epoch [22/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.1005, D_X Total: 0.1885\n",
      "  D_Y Real: 0.1546, D_Y Fake: 0.0402, D_Y Total: 0.0974\n",
      "Generator Losses:\n",
      "  G Adv: 0.3259, F Adv: 0.6220\n",
      "  Cycle Photo: 0.0598, Cycle Monet: 0.0475\n",
      "  Perceptual Photo: 0.2199, Perceptual Monet: 0.2283\n",
      "  Total G Loss: 4.2622\n",
      "Epoch [22/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1279, D_X Fake: 0.0584, D_X Total: 0.0931\n",
      "  D_Y Real: 0.1219, D_Y Fake: 0.1072, D_Y Total: 0.1145\n",
      "Generator Losses:\n",
      "  G Adv: 0.3362, F Adv: 0.4631\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.2038, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.6745\n",
      "Epoch [22/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0711, D_X Fake: 0.0546, D_X Total: 0.0628\n",
      "  D_Y Real: 0.1059, D_Y Fake: 0.2376, D_Y Total: 0.1718\n",
      "Generator Losses:\n",
      "  G Adv: 0.3052, F Adv: 0.7181\n",
      "  Cycle Photo: 0.0659, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 3.8255\n",
      "Epoch [22/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1308, D_X Fake: 0.0474, D_X Total: 0.0891\n",
      "  D_Y Real: 0.1007, D_Y Fake: 0.1510, D_Y Total: 0.1259\n",
      "Generator Losses:\n",
      "  G Adv: 0.5298, F Adv: 0.4891\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1797, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.6809\n",
      "Epoch [22/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1713, D_X Fake: 0.0411, D_X Total: 0.1062\n",
      "  D_Y Real: 0.2669, D_Y Fake: 0.0955, D_Y Total: 0.1812\n",
      "Generator Losses:\n",
      "  G Adv: 0.6226, F Adv: 1.1743\n",
      "  Cycle Photo: 0.0506, Cycle Monet: 0.0492\n",
      "  Perceptual Photo: 0.1615, Perceptual Monet: 0.1948\n",
      "  Total G Loss: 4.5753\n",
      "Epoch [22/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1980, D_X Fake: 0.0629, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0511, D_Y Fake: 0.2490, D_Y Total: 0.1500\n",
      "Generator Losses:\n",
      "  G Adv: 0.2514, F Adv: 0.5667\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1743, Perceptual Monet: 0.2093\n",
      "  Total G Loss: 3.7654\n",
      "Epoch [22/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1513, D_X Fake: 0.0611, D_X Total: 0.1062\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.1693, D_Y Total: 0.1040\n",
      "Generator Losses:\n",
      "  G Adv: 0.5846, F Adv: 0.6173\n",
      "  Cycle Photo: 0.0594, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.2638, Perceptual Monet: 0.1897\n",
      "  Total G Loss: 4.5719\n",
      "Epoch [22/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0641, D_X Fake: 0.1197, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0676, D_Y Fake: 0.0567, D_Y Total: 0.0621\n",
      "Generator Losses:\n",
      "  G Adv: 0.7855, F Adv: 0.4733\n",
      "  Cycle Photo: 0.0837, Cycle Monet: 0.0693\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.2362\n",
      "  Total G Loss: 4.7994\n",
      "Epoch [22/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1420, D_X Fake: 0.0866, D_X Total: 0.1143\n",
      "  D_Y Real: 0.0716, D_Y Fake: 0.1352, D_Y Total: 0.1034\n",
      "Generator Losses:\n",
      "  G Adv: 0.3941, F Adv: 0.6131\n",
      "  Cycle Photo: 0.0618, Cycle Monet: 0.0492\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.2039\n",
      "  Total G Loss: 3.9822\n",
      "Epoch [23/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2395, D_X Fake: 0.0379, D_X Total: 0.1387\n",
      "  D_Y Real: 0.0445, D_Y Fake: 0.1485, D_Y Total: 0.0965\n",
      "Generator Losses:\n",
      "  G Adv: 0.3737, F Adv: 0.7729\n",
      "  Cycle Photo: 0.0577, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.1761, Perceptual Monet: 0.2030\n",
      "  Total G Loss: 4.0618\n",
      "Epoch [23/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1377, D_X Fake: 0.1361, D_X Total: 0.1369\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.1045, D_Y Total: 0.0674\n",
      "Generator Losses:\n",
      "  G Adv: 0.4160, F Adv: 0.4762\n",
      "  Cycle Photo: 0.0666, Cycle Monet: 0.0472\n",
      "  Perceptual Photo: 0.1852, Perceptual Monet: 0.1884\n",
      "  Total G Loss: 3.8987\n",
      "Epoch [23/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1066, D_X Fake: 0.1685, D_X Total: 0.1376\n",
      "  D_Y Real: 0.0747, D_Y Fake: 0.0843, D_Y Total: 0.0795\n",
      "Generator Losses:\n",
      "  G Adv: 0.3625, F Adv: 0.3420\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0541\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.2104\n",
      "  Total G Loss: 3.6348\n",
      "Epoch [23/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0480, D_X Fake: 0.1503, D_X Total: 0.0992\n",
      "  D_Y Real: 0.2355, D_Y Fake: 0.0630, D_Y Total: 0.1493\n",
      "Generator Losses:\n",
      "  G Adv: 0.6992, F Adv: 0.4626\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1557, Perceptual Monet: 0.1950\n",
      "  Total G Loss: 3.7489\n",
      "Epoch [23/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2045, D_X Fake: 0.0432, D_X Total: 0.1239\n",
      "  D_Y Real: 0.1579, D_Y Fake: 0.1465, D_Y Total: 0.1522\n",
      "Generator Losses:\n",
      "  G Adv: 0.6243, F Adv: 0.9105\n",
      "  Cycle Photo: 0.0750, Cycle Monet: 0.0658\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.2096\n",
      "  Total G Loss: 4.7525\n",
      "Epoch [23/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1738, D_X Fake: 0.0810, D_X Total: 0.1274\n",
      "  D_Y Real: 0.1390, D_Y Fake: 0.1574, D_Y Total: 0.1482\n",
      "Generator Losses:\n",
      "  G Adv: 0.3728, F Adv: 0.6027\n",
      "  Cycle Photo: 0.0648, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.1702, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.7926\n",
      "Epoch [23/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1368, D_X Fake: 0.0610, D_X Total: 0.0989\n",
      "  D_Y Real: 0.1023, D_Y Fake: 0.1117, D_Y Total: 0.1070\n",
      "Generator Losses:\n",
      "  G Adv: 0.5511, F Adv: 0.5415\n",
      "  Cycle Photo: 0.0759, Cycle Monet: 0.0596\n",
      "  Perceptual Photo: 0.1932, Perceptual Monet: 0.2082\n",
      "  Total G Loss: 4.4539\n",
      "Epoch [23/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3070, D_X Fake: 0.0701, D_X Total: 0.1885\n",
      "  D_Y Real: 0.0699, D_Y Fake: 0.2333, D_Y Total: 0.1516\n",
      "Generator Losses:\n",
      "  G Adv: 0.6126, F Adv: 0.7583\n",
      "  Cycle Photo: 0.0563, Cycle Monet: 0.0448\n",
      "  Perceptual Photo: 0.2108, Perceptual Monet: 0.1905\n",
      "  Total G Loss: 4.3888\n",
      "Epoch [23/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.0716, D_X Total: 0.0807\n",
      "  D_Y Real: 0.1006, D_Y Fake: 0.1968, D_Y Total: 0.1487\n",
      "Generator Losses:\n",
      "  G Adv: 0.4731, F Adv: 0.6864\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1632, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 3.8936\n",
      "Epoch [23/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0228, D_X Fake: 0.2103, D_X Total: 0.1165\n",
      "  D_Y Real: 0.0918, D_Y Fake: 0.0581, D_Y Total: 0.0750\n",
      "Generator Losses:\n",
      "  G Adv: 0.7183, F Adv: 0.2806\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0559\n",
      "  Perceptual Photo: 0.1254, Perceptual Monet: 0.2104\n",
      "  Total G Loss: 3.6232\n",
      "Epoch [23/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1404, D_X Fake: 0.0314, D_X Total: 0.0859\n",
      "  D_Y Real: 0.2185, D_Y Fake: 0.0963, D_Y Total: 0.1574\n",
      "Generator Losses:\n",
      "  G Adv: 0.8119, F Adv: 0.5603\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0670\n",
      "  Perceptual Photo: 0.1994, Perceptual Monet: 0.2349\n",
      "  Total G Loss: 4.7660\n",
      "Epoch [23/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0786, D_X Fake: 0.0532, D_X Total: 0.0659\n",
      "  D_Y Real: 0.1128, D_Y Fake: 0.0490, D_Y Total: 0.0809\n",
      "Generator Losses:\n",
      "  G Adv: 0.8803, F Adv: 0.8308\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0441\n",
      "  Perceptual Photo: 0.1561, Perceptual Monet: 0.2078\n",
      "  Total G Loss: 4.3850\n",
      "Epoch [23/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1168, D_X Fake: 0.1193, D_X Total: 0.1180\n",
      "  D_Y Real: 0.1633, D_Y Fake: 0.0871, D_Y Total: 0.1252\n",
      "Generator Losses:\n",
      "  G Adv: 0.6124, F Adv: 0.4224\n",
      "  Cycle Photo: 0.0572, Cycle Monet: 0.0464\n",
      "  Perceptual Photo: 0.2329, Perceptual Monet: 0.1913\n",
      "  Total G Loss: 4.1913\n",
      "Epoch [23/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.6443, D_X Fake: 0.0373, D_X Total: 0.3408\n",
      "  D_Y Real: 0.2597, D_Y Fake: 0.1302, D_Y Total: 0.1950\n",
      "Generator Losses:\n",
      "  G Adv: 0.6360, F Adv: 0.7516\n",
      "  Cycle Photo: 0.0680, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.2672, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 4.5844\n",
      "Epoch [23/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1841, D_X Fake: 0.0483, D_X Total: 0.1162\n",
      "  D_Y Real: 0.0788, D_Y Fake: 0.1425, D_Y Total: 0.1107\n",
      "Generator Losses:\n",
      "  G Adv: 0.4456, F Adv: 0.6951\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0476\n",
      "  Perceptual Photo: 0.1705, Perceptual Monet: 0.1988\n",
      "  Total G Loss: 3.9752\n",
      "Epoch [23/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0598, D_X Fake: 0.0693, D_X Total: 0.0646\n",
      "  D_Y Real: 0.0769, D_Y Fake: 0.0656, D_Y Total: 0.0712\n",
      "Generator Losses:\n",
      "  G Adv: 0.6658, F Adv: 0.4474\n",
      "  Cycle Photo: 0.0726, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.1657, Perceptual Monet: 0.1955\n",
      "  Total G Loss: 4.0732\n",
      "Epoch [23/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0324, D_X Fake: 0.1840, D_X Total: 0.1082\n",
      "  D_Y Real: 0.0521, D_Y Fake: 0.1661, D_Y Total: 0.1091\n",
      "Generator Losses:\n",
      "  G Adv: 0.5683, F Adv: 0.3892\n",
      "  Cycle Photo: 0.1251, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 4.3229\n",
      "Epoch [23/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0508, D_X Fake: 0.0803, D_X Total: 0.0655\n",
      "  D_Y Real: 0.1168, D_Y Fake: 0.0502, D_Y Total: 0.0835\n",
      "Generator Losses:\n",
      "  G Adv: 0.8198, F Adv: 0.5815\n",
      "  Cycle Photo: 0.0738, Cycle Monet: 0.0494\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.2172\n",
      "  Total G Loss: 4.4895\n",
      "Epoch [23/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1396, D_X Fake: 0.0442, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0645, D_Y Fake: 0.1212, D_Y Total: 0.0929\n",
      "Generator Losses:\n",
      "  G Adv: 0.5235, F Adv: 0.6794\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0572\n",
      "  Perceptual Photo: 0.1864, Perceptual Monet: 0.2147\n",
      "  Total G Loss: 4.3255\n",
      "Epoch [23/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0607, D_X Fake: 0.1361, D_X Total: 0.0984\n",
      "  D_Y Real: 0.2250, D_Y Fake: 0.0908, D_Y Total: 0.1579\n",
      "Generator Losses:\n",
      "  G Adv: 0.9819, F Adv: 0.3762\n",
      "  Cycle Photo: 0.0713, Cycle Monet: 0.0476\n",
      "  Perceptual Photo: 0.1835, Perceptual Monet: 0.1947\n",
      "  Total G Loss: 4.4376\n",
      "Epoch [23/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0660, D_X Fake: 0.1244, D_X Total: 0.0952\n",
      "  D_Y Real: 0.0940, D_Y Fake: 0.0703, D_Y Total: 0.0821\n",
      "Generator Losses:\n",
      "  G Adv: 0.8341, F Adv: 0.2094\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0621\n",
      "  Perceptual Photo: 0.1810, Perceptual Monet: 0.1916\n",
      "  Total G Loss: 4.0537\n",
      "Epoch [23/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0858, D_X Fake: 0.1389, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0787, D_Y Fake: 0.1636, D_Y Total: 0.1212\n",
      "Generator Losses:\n",
      "  G Adv: 0.4833, F Adv: 0.4696\n",
      "  Cycle Photo: 0.0566, Cycle Monet: 0.0489\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1965\n",
      "  Total G Loss: 3.7866\n",
      "Epoch [23/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2233, D_X Fake: 0.1624, D_X Total: 0.1929\n",
      "  D_Y Real: 0.1194, D_Y Fake: 0.0727, D_Y Total: 0.0961\n",
      "Generator Losses:\n",
      "  G Adv: 0.4287, F Adv: 0.6405\n",
      "  Cycle Photo: 0.0711, Cycle Monet: 0.0457\n",
      "  Perceptual Photo: 0.1707, Perceptual Monet: 0.1847\n",
      "  Total G Loss: 4.0136\n",
      "Epoch [23/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0682, D_X Fake: 0.0858, D_X Total: 0.0770\n",
      "  D_Y Real: 0.0812, D_Y Fake: 0.0774, D_Y Total: 0.0793\n",
      "Generator Losses:\n",
      "  G Adv: 0.4873, F Adv: 0.5887\n",
      "  Cycle Photo: 0.0683, Cycle Monet: 0.0463\n",
      "  Perceptual Photo: 0.1820, Perceptual Monet: 0.1975\n",
      "  Total G Loss: 4.1197\n",
      "Epoch [24/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1456, D_X Fake: 0.1221, D_X Total: 0.1338\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.2692, D_Y Total: 0.1534\n",
      "Generator Losses:\n",
      "  G Adv: 0.4288, F Adv: 0.7597\n",
      "  Cycle Photo: 0.0543, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.2047, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 4.1107\n",
      "Epoch [24/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1105, D_X Fake: 0.0593, D_X Total: 0.0849\n",
      "  D_Y Real: 0.0801, D_Y Fake: 0.1158, D_Y Total: 0.0979\n",
      "Generator Losses:\n",
      "  G Adv: 0.4346, F Adv: 0.6397\n",
      "  Cycle Photo: 0.0749, Cycle Monet: 0.0625\n",
      "  Perceptual Photo: 0.1935, Perceptual Monet: 0.2005\n",
      "  Total G Loss: 4.4184\n",
      "Epoch [24/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2526, D_X Fake: 0.1027, D_X Total: 0.1776\n",
      "  D_Y Real: 0.1321, D_Y Fake: 0.1780, D_Y Total: 0.1551\n",
      "Generator Losses:\n",
      "  G Adv: 0.4424, F Adv: 0.2882\n",
      "  Cycle Photo: 0.0613, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.2306, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 3.8518\n",
      "Epoch [24/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.0414, D_X Total: 0.0686\n",
      "  D_Y Real: 0.1045, D_Y Fake: 0.3135, D_Y Total: 0.2090\n",
      "Generator Losses:\n",
      "  G Adv: 0.2892, F Adv: 0.4145\n",
      "  Cycle Photo: 0.0701, Cycle Monet: 0.0543\n",
      "  Perceptual Photo: 0.2031, Perceptual Monet: 0.1952\n",
      "  Total G Loss: 3.9390\n",
      "Epoch [24/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1519, D_X Fake: 0.0439, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0534, D_Y Fake: 0.1192, D_Y Total: 0.0863\n",
      "Generator Losses:\n",
      "  G Adv: 0.2874, F Adv: 0.7200\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0577\n",
      "  Perceptual Photo: 0.1771, Perceptual Monet: 0.2135\n",
      "  Total G Loss: 4.1437\n",
      "Epoch [24/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1994, D_X Fake: 0.1792, D_X Total: 0.1893\n",
      "  D_Y Real: 0.1591, D_Y Fake: 0.0636, D_Y Total: 0.1114\n",
      "Generator Losses:\n",
      "  G Adv: 0.8307, F Adv: 0.3738\n",
      "  Cycle Photo: 0.0652, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1876, Perceptual Monet: 0.1896\n",
      "  Total G Loss: 4.2565\n",
      "Epoch [24/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0577, D_X Fake: 0.0658, D_X Total: 0.0617\n",
      "  D_Y Real: 0.0637, D_Y Fake: 0.2028, D_Y Total: 0.1333\n",
      "Generator Losses:\n",
      "  G Adv: 0.5409, F Adv: 0.7233\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0476\n",
      "  Perceptual Photo: 0.1837, Perceptual Monet: 0.2027\n",
      "  Total G Loss: 4.1583\n",
      "Epoch [24/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2864, D_X Fake: 0.0191, D_X Total: 0.1527\n",
      "  D_Y Real: 0.0738, D_Y Fake: 0.0804, D_Y Total: 0.0771\n",
      "Generator Losses:\n",
      "  G Adv: 0.3862, F Adv: 1.0368\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0485\n",
      "  Perceptual Photo: 0.1683, Perceptual Monet: 0.2056\n",
      "  Total G Loss: 4.4066\n",
      "Epoch [24/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0923, D_X Fake: 0.0443, D_X Total: 0.0683\n",
      "  D_Y Real: 0.1231, D_Y Fake: 0.0321, D_Y Total: 0.0776\n",
      "Generator Losses:\n",
      "  G Adv: 0.6331, F Adv: 0.5318\n",
      "  Cycle Photo: 0.0550, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1701, Perceptual Monet: 0.1846\n",
      "  Total G Loss: 3.9741\n",
      "Epoch [24/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0733, D_X Fake: 0.0719, D_X Total: 0.0726\n",
      "  D_Y Real: 0.1865, D_Y Fake: 0.1751, D_Y Total: 0.1808\n",
      "Generator Losses:\n",
      "  G Adv: 0.4082, F Adv: 0.6277\n",
      "  Cycle Photo: 0.0993, Cycle Monet: 0.0533\n",
      "  Perceptual Photo: 0.2018, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 4.4844\n",
      "Epoch [24/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1480, D_X Fake: 0.1765, D_X Total: 0.1623\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.0819, D_Y Total: 0.0620\n",
      "Generator Losses:\n",
      "  G Adv: 0.5332, F Adv: 0.5960\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1774, Perceptual Monet: 0.1702\n",
      "  Total G Loss: 3.7707\n",
      "Epoch [24/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1357, D_X Fake: 0.0979, D_X Total: 0.1168\n",
      "  D_Y Real: 0.1782, D_Y Fake: 0.0774, D_Y Total: 0.1278\n",
      "Generator Losses:\n",
      "  G Adv: 0.6982, F Adv: 0.6845\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0447\n",
      "  Perceptual Photo: 0.1890, Perceptual Monet: 0.2013\n",
      "  Total G Loss: 4.2163\n",
      "Epoch [24/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0429, D_X Fake: 0.0448, D_X Total: 0.0438\n",
      "  D_Y Real: 0.1084, D_Y Fake: 0.0787, D_Y Total: 0.0935\n",
      "Generator Losses:\n",
      "  G Adv: 0.8890, F Adv: 0.5434\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0506\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 4.1343\n",
      "Epoch [24/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0262, D_X Fake: 0.2054, D_X Total: 0.1158\n",
      "  D_Y Real: 0.0764, D_Y Fake: 0.2245, D_Y Total: 0.1505\n",
      "Generator Losses:\n",
      "  G Adv: 0.2838, F Adv: 0.3297\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0625\n",
      "  Perceptual Photo: 0.1732, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.5707\n",
      "Epoch [24/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2056, D_X Fake: 0.1003, D_X Total: 0.1529\n",
      "  D_Y Real: 0.2481, D_Y Fake: 0.0671, D_Y Total: 0.1576\n",
      "Generator Losses:\n",
      "  G Adv: 0.6152, F Adv: 0.5467\n",
      "  Cycle Photo: 0.0664, Cycle Monet: 0.0471\n",
      "  Perceptual Photo: 0.1966, Perceptual Monet: 0.1991\n",
      "  Total G Loss: 4.2756\n",
      "Epoch [24/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0344, D_X Fake: 0.2795, D_X Total: 0.1570\n",
      "  D_Y Real: 0.0408, D_Y Fake: 0.0718, D_Y Total: 0.0563\n",
      "Generator Losses:\n",
      "  G Adv: 0.6982, F Adv: 0.3095\n",
      "  Cycle Photo: 0.1190, Cycle Monet: 0.0432\n",
      "  Perceptual Photo: 0.2266, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 4.5888\n",
      "Epoch [24/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0585, D_X Fake: 0.0639, D_X Total: 0.0612\n",
      "  D_Y Real: 0.2259, D_Y Fake: 0.0748, D_Y Total: 0.1504\n",
      "Generator Losses:\n",
      "  G Adv: 0.7058, F Adv: 0.7511\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0585\n",
      "  Perceptual Photo: 0.2126, Perceptual Monet: 0.1922\n",
      "  Total G Loss: 4.5636\n",
      "Epoch [24/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0913, D_X Fake: 0.0464, D_X Total: 0.0689\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.4451, D_Y Total: 0.2433\n",
      "Generator Losses:\n",
      "  G Adv: 0.3091, F Adv: 0.5335\n",
      "  Cycle Photo: 0.0872, Cycle Monet: 0.0746\n",
      "  Perceptual Photo: 0.1637, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 4.1931\n",
      "Epoch [24/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2106, D_X Fake: 0.0836, D_X Total: 0.1471\n",
      "  D_Y Real: 0.1006, D_Y Fake: 0.3383, D_Y Total: 0.2194\n",
      "Generator Losses:\n",
      "  G Adv: 0.2857, F Adv: 0.5561\n",
      "  Cycle Photo: 0.0676, Cycle Monet: 0.0511\n",
      "  Perceptual Photo: 0.2077, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.9815\n",
      "Epoch [24/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1949, D_X Fake: 0.0974, D_X Total: 0.1462\n",
      "  D_Y Real: 0.1383, D_Y Fake: 0.0631, D_Y Total: 0.1007\n",
      "Generator Losses:\n",
      "  G Adv: 0.6580, F Adv: 0.6264\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0495\n",
      "  Perceptual Photo: 0.1791, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 4.0850\n",
      "Epoch [24/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1011, D_X Fake: 0.2052, D_X Total: 0.1532\n",
      "  D_Y Real: 0.1324, D_Y Fake: 0.1839, D_Y Total: 0.1581\n",
      "Generator Losses:\n",
      "  G Adv: 0.4754, F Adv: 0.3856\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.1756, Perceptual Monet: 0.1984\n",
      "  Total G Loss: 3.6737\n",
      "Epoch [24/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1008, D_X Fake: 0.1047, D_X Total: 0.1027\n",
      "  D_Y Real: 0.1072, D_Y Fake: 0.1255, D_Y Total: 0.1164\n",
      "Generator Losses:\n",
      "  G Adv: 0.5657, F Adv: 0.5159\n",
      "  Cycle Photo: 0.0836, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1890, Perceptual Monet: 0.1896\n",
      "  Total G Loss: 4.2176\n",
      "Epoch [24/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1309, D_X Fake: 0.0442, D_X Total: 0.0876\n",
      "  D_Y Real: 0.0534, D_Y Fake: 0.1139, D_Y Total: 0.0836\n",
      "Generator Losses:\n",
      "  G Adv: 0.5023, F Adv: 0.9077\n",
      "  Cycle Photo: 0.0690, Cycle Monet: 0.0490\n",
      "  Perceptual Photo: 0.1923, Perceptual Monet: 0.2029\n",
      "  Total G Loss: 4.5658\n",
      "Epoch [24/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1456, D_X Fake: 0.0477, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0791, D_Y Fake: 0.2112, D_Y Total: 0.1452\n",
      "Generator Losses:\n",
      "  G Adv: 0.3916, F Adv: 0.4443\n",
      "  Cycle Photo: 0.0559, Cycle Monet: 0.0683\n",
      "  Perceptual Photo: 0.1831, Perceptual Monet: 0.2435\n",
      "  Total G Loss: 4.2114\n",
      "Epoch [25/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1810, D_X Fake: 0.1485, D_X Total: 0.1648\n",
      "  D_Y Real: 0.1891, D_Y Fake: 0.1296, D_Y Total: 0.1593\n",
      "Generator Losses:\n",
      "  G Adv: 0.5606, F Adv: 0.4920\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0526\n",
      "  Perceptual Photo: 0.1777, Perceptual Monet: 0.2171\n",
      "  Total G Loss: 3.9737\n",
      "Epoch [25/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2364, D_X Fake: 0.0526, D_X Total: 0.1445\n",
      "  D_Y Real: 0.0653, D_Y Fake: 0.3234, D_Y Total: 0.1944\n",
      "Generator Losses:\n",
      "  G Adv: 0.2527, F Adv: 0.6330\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1891, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 3.6246\n",
      "Epoch [25/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0644, D_X Fake: 0.1131, D_X Total: 0.0888\n",
      "  D_Y Real: 0.0792, D_Y Fake: 0.2355, D_Y Total: 0.1573\n",
      "Generator Losses:\n",
      "  G Adv: 0.3455, F Adv: 0.5219\n",
      "  Cycle Photo: 0.0668, Cycle Monet: 0.0543\n",
      "  Perceptual Photo: 0.2004, Perceptual Monet: 0.2157\n",
      "  Total G Loss: 4.1594\n",
      "Epoch [25/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0540, D_X Fake: 0.1565, D_X Total: 0.1053\n",
      "  D_Y Real: 0.1117, D_Y Fake: 0.1258, D_Y Total: 0.1187\n",
      "Generator Losses:\n",
      "  G Adv: 0.5591, F Adv: 0.6862\n",
      "  Cycle Photo: 0.0925, Cycle Monet: 0.0466\n",
      "  Perceptual Photo: 0.1510, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 4.2898\n",
      "Epoch [25/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1620, D_X Fake: 0.0634, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.0727, D_Y Total: 0.0658\n",
      "Generator Losses:\n",
      "  G Adv: 0.7138, F Adv: 0.7578\n",
      "  Cycle Photo: 0.0845, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.2054, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 4.6437\n",
      "Epoch [25/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4299, D_X Fake: 0.0667, D_X Total: 0.2483\n",
      "  D_Y Real: 0.0387, D_Y Fake: 0.3078, D_Y Total: 0.1732\n",
      "Generator Losses:\n",
      "  G Adv: 0.2493, F Adv: 0.7089\n",
      "  Cycle Photo: 0.0733, Cycle Monet: 0.0444\n",
      "  Perceptual Photo: 0.2298, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 4.1407\n",
      "Epoch [25/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1295, D_X Fake: 0.0522, D_X Total: 0.0908\n",
      "  D_Y Real: 0.1138, D_Y Fake: 0.1025, D_Y Total: 0.1082\n",
      "Generator Losses:\n",
      "  G Adv: 0.4783, F Adv: 0.6142\n",
      "  Cycle Photo: 0.1061, Cycle Monet: 0.0650\n",
      "  Perceptual Photo: 0.2129, Perceptual Monet: 0.2398\n",
      "  Total G Loss: 5.0677\n",
      "Epoch [25/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0509, D_X Fake: 0.0903, D_X Total: 0.0706\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.2387, D_Y Total: 0.1329\n",
      "Generator Losses:\n",
      "  G Adv: 0.3317, F Adv: 0.4418\n",
      "  Cycle Photo: 0.0749, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.2036, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.7638\n",
      "Epoch [25/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1501, D_X Fake: 0.0724, D_X Total: 0.1112\n",
      "  D_Y Real: 0.1349, D_Y Fake: 0.0836, D_Y Total: 0.1093\n",
      "Generator Losses:\n",
      "  G Adv: 0.6627, F Adv: 0.4538\n",
      "  Cycle Photo: 0.0644, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1450, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.6214\n",
      "Epoch [25/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0927, D_X Fake: 0.0347, D_X Total: 0.0637\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.1582, D_Y Total: 0.0953\n",
      "Generator Losses:\n",
      "  G Adv: 0.5937, F Adv: 0.9824\n",
      "  Cycle Photo: 0.0972, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1880, Perceptual Monet: 0.1868\n",
      "  Total G Loss: 4.7969\n",
      "Epoch [25/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2846, D_X Fake: 0.0327, D_X Total: 0.1587\n",
      "  D_Y Real: 0.0498, D_Y Fake: 0.2251, D_Y Total: 0.1375\n",
      "Generator Losses:\n",
      "  G Adv: 0.4303, F Adv: 1.0484\n",
      "  Cycle Photo: 0.0831, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 4.3089\n",
      "Epoch [25/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1176, D_X Fake: 0.0710, D_X Total: 0.0943\n",
      "  D_Y Real: 0.1193, D_Y Fake: 0.0322, D_Y Total: 0.0757\n",
      "Generator Losses:\n",
      "  G Adv: 0.5342, F Adv: 0.6052\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0464\n",
      "  Perceptual Photo: 0.2125, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 4.0560\n",
      "Epoch [25/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0562, D_X Fake: 0.0468, D_X Total: 0.0515\n",
      "  D_Y Real: 0.1324, D_Y Fake: 0.1938, D_Y Total: 0.1631\n",
      "Generator Losses:\n",
      "  G Adv: 0.3203, F Adv: 0.7450\n",
      "  Cycle Photo: 0.0674, Cycle Monet: 0.0563\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.2008\n",
      "  Total G Loss: 4.0596\n",
      "Epoch [25/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1037, D_X Fake: 0.1945, D_X Total: 0.1491\n",
      "  D_Y Real: 0.1334, D_Y Fake: 0.1828, D_Y Total: 0.1581\n",
      "Generator Losses:\n",
      "  G Adv: 0.2843, F Adv: 0.3026\n",
      "  Cycle Photo: 0.0619, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.1991, Perceptual Monet: 0.1961\n",
      "  Total G Loss: 3.6909\n",
      "Epoch [25/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0674, D_X Fake: 0.1411, D_X Total: 0.1043\n",
      "  D_Y Real: 0.1398, D_Y Fake: 0.0839, D_Y Total: 0.1119\n",
      "Generator Losses:\n",
      "  G Adv: 0.6202, F Adv: 0.4879\n",
      "  Cycle Photo: 0.0484, Cycle Monet: 0.0507\n",
      "  Perceptual Photo: 0.1887, Perceptual Monet: 0.2051\n",
      "  Total G Loss: 4.0672\n",
      "Epoch [25/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0271, D_X Fake: 0.1165, D_X Total: 0.0718\n",
      "  D_Y Real: 0.0584, D_Y Fake: 0.1092, D_Y Total: 0.0838\n",
      "Generator Losses:\n",
      "  G Adv: 0.7023, F Adv: 0.4760\n",
      "  Cycle Photo: 0.0950, Cycle Monet: 0.0598\n",
      "  Perceptual Photo: 0.2193, Perceptual Monet: 0.1915\n",
      "  Total G Loss: 4.7800\n",
      "Epoch [25/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2526, D_X Fake: 0.0806, D_X Total: 0.1666\n",
      "  D_Y Real: 0.1592, D_Y Fake: 0.1980, D_Y Total: 0.1786\n",
      "Generator Losses:\n",
      "  G Adv: 0.4958, F Adv: 0.9324\n",
      "  Cycle Photo: 0.0771, Cycle Monet: 0.0470\n",
      "  Perceptual Photo: 0.2016, Perceptual Monet: 0.2069\n",
      "  Total G Loss: 4.7116\n",
      "Epoch [25/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0867, D_X Fake: 0.1943, D_X Total: 0.1405\n",
      "  D_Y Real: 0.1398, D_Y Fake: 0.0508, D_Y Total: 0.0953\n",
      "Generator Losses:\n",
      "  G Adv: 0.4924, F Adv: 0.3829\n",
      "  Cycle Photo: 0.0580, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.5631\n",
      "Epoch [25/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0596, D_X Fake: 0.2142, D_X Total: 0.1369\n",
      "  D_Y Real: 0.2015, D_Y Fake: 0.0639, D_Y Total: 0.1327\n",
      "Generator Losses:\n",
      "  G Adv: 0.5384, F Adv: 0.2320\n",
      "  Cycle Photo: 0.0498, Cycle Monet: 0.0453\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.4230\n",
      "Epoch [25/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0606, D_X Fake: 0.0822, D_X Total: 0.0714\n",
      "  D_Y Real: 0.1332, D_Y Fake: 0.0812, D_Y Total: 0.1072\n",
      "Generator Losses:\n",
      "  G Adv: 0.7340, F Adv: 0.6487\n",
      "  Cycle Photo: 0.1098, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1671\n",
      "  Total G Loss: 4.4178\n",
      "Epoch [25/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0501, D_X Fake: 0.0352, D_X Total: 0.0427\n",
      "  D_Y Real: 0.0753, D_Y Fake: 0.2019, D_Y Total: 0.1386\n",
      "Generator Losses:\n",
      "  G Adv: 0.5905, F Adv: 0.5730\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.2047\n",
      "  Total G Loss: 3.9235\n",
      "Epoch [25/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0402, D_X Fake: 0.3179, D_X Total: 0.1791\n",
      "  D_Y Real: 0.2174, D_Y Fake: 0.0696, D_Y Total: 0.1435\n",
      "Generator Losses:\n",
      "  G Adv: 0.7572, F Adv: 0.2567\n",
      "  Cycle Photo: 0.0608, Cycle Monet: 0.0550\n",
      "  Perceptual Photo: 0.2257, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 4.2619\n",
      "Epoch [25/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0644, D_X Fake: 0.0788, D_X Total: 0.0716\n",
      "  D_Y Real: 0.0946, D_Y Fake: 0.0613, D_Y Total: 0.0779\n",
      "Generator Losses:\n",
      "  G Adv: 0.5583, F Adv: 0.6784\n",
      "  Cycle Photo: 0.0544, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1641, Perceptual Monet: 0.1946\n",
      "  Total G Loss: 4.0026\n",
      "Epoch [25/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2178, D_X Fake: 0.0393, D_X Total: 0.1285\n",
      "  D_Y Real: 0.0733, D_Y Fake: 0.2596, D_Y Total: 0.1665\n",
      "Generator Losses:\n",
      "  G Adv: 0.2875, F Adv: 0.9635\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1814, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 4.0376\n",
      "Epoch [26/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0685, D_X Fake: 0.1103, D_X Total: 0.0894\n",
      "  D_Y Real: 0.1625, D_Y Fake: 0.0689, D_Y Total: 0.1157\n",
      "Generator Losses:\n",
      "  G Adv: 1.0563, F Adv: 0.4432\n",
      "  Cycle Photo: 0.1162, Cycle Monet: 0.0587\n",
      "  Perceptual Photo: 0.1554, Perceptual Monet: 0.2287\n",
      "  Total G Loss: 5.1693\n",
      "Epoch [26/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1476, D_X Fake: 0.1514, D_X Total: 0.1495\n",
      "  D_Y Real: 0.0610, D_Y Fake: 0.1465, D_Y Total: 0.1037\n",
      "Generator Losses:\n",
      "  G Adv: 0.4387, F Adv: 0.4513\n",
      "  Cycle Photo: 0.0726, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.7749\n",
      "Epoch [26/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2440, D_X Fake: 0.1695, D_X Total: 0.2067\n",
      "  D_Y Real: 0.0749, D_Y Fake: 0.1355, D_Y Total: 0.1052\n",
      "Generator Losses:\n",
      "  G Adv: 0.6407, F Adv: 0.2891\n",
      "  Cycle Photo: 0.0865, Cycle Monet: 0.0965\n",
      "  Perceptual Photo: 0.2565, Perceptual Monet: 0.2283\n",
      "  Total G Loss: 5.1836\n",
      "Epoch [26/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2829, D_X Fake: 0.3768, D_X Total: 0.3299\n",
      "  D_Y Real: 0.2088, D_Y Fake: 0.0706, D_Y Total: 0.1397\n",
      "Generator Losses:\n",
      "  G Adv: 0.7476, F Adv: 0.2050\n",
      "  Cycle Photo: 0.0824, Cycle Monet: 0.0491\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.2149\n",
      "  Total G Loss: 4.1906\n",
      "Epoch [26/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2560, D_X Fake: 0.2849, D_X Total: 0.2704\n",
      "  D_Y Real: 0.1214, D_Y Fake: 0.0839, D_Y Total: 0.1027\n",
      "Generator Losses:\n",
      "  G Adv: 0.6687, F Adv: 0.2630\n",
      "  Cycle Photo: 0.0829, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.7254\n",
      "Epoch [26/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2268, D_X Fake: 0.2539, D_X Total: 0.2404\n",
      "  D_Y Real: 0.0622, D_Y Fake: 0.0683, D_Y Total: 0.0653\n",
      "Generator Losses:\n",
      "  G Adv: 0.4643, F Adv: 0.2525\n",
      "  Cycle Photo: 0.0998, Cycle Monet: 0.0493\n",
      "  Perceptual Photo: 0.1959, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 4.1076\n",
      "Epoch [26/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3554, D_X Fake: 0.2511, D_X Total: 0.3032\n",
      "  D_Y Real: 0.1376, D_Y Fake: 0.4512, D_Y Total: 0.2944\n",
      "Generator Losses:\n",
      "  G Adv: 0.2044, F Adv: 0.2856\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.2027, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.2324\n",
      "Epoch [26/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2874, D_X Fake: 0.2171, D_X Total: 0.2523\n",
      "  D_Y Real: 0.2037, D_Y Fake: 0.0706, D_Y Total: 0.1372\n",
      "Generator Losses:\n",
      "  G Adv: 0.4658, F Adv: 0.3425\n",
      "  Cycle Photo: 0.1433, Cycle Monet: 0.0501\n",
      "  Perceptual Photo: 0.2134, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 4.7048\n",
      "Epoch [26/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1824, D_X Fake: 0.3128, D_X Total: 0.2476\n",
      "  D_Y Real: 0.2640, D_Y Fake: 0.0860, D_Y Total: 0.1750\n",
      "Generator Losses:\n",
      "  G Adv: 0.8797, F Adv: 0.2257\n",
      "  Cycle Photo: 0.0701, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1916\n",
      "  Total G Loss: 3.9944\n",
      "Epoch [26/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2184, D_X Fake: 0.3548, D_X Total: 0.2866\n",
      "  D_Y Real: 0.2508, D_Y Fake: 0.0566, D_Y Total: 0.1537\n",
      "Generator Losses:\n",
      "  G Adv: 0.8396, F Adv: 0.1843\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.5931\n",
      "Epoch [26/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2270, D_X Fake: 0.2597, D_X Total: 0.2434\n",
      "  D_Y Real: 0.1794, D_Y Fake: 0.0760, D_Y Total: 0.1277\n",
      "Generator Losses:\n",
      "  G Adv: 0.8272, F Adv: 0.2824\n",
      "  Cycle Photo: 0.0657, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.2000, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.9563\n",
      "Epoch [26/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2022, D_X Fake: 0.2183, D_X Total: 0.2103\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.1088, D_Y Total: 0.0733\n",
      "Generator Losses:\n",
      "  G Adv: 0.5840, F Adv: 0.3717\n",
      "  Cycle Photo: 0.0540, Cycle Monet: 0.0516\n",
      "  Perceptual Photo: 0.1375, Perceptual Monet: 0.1883\n",
      "  Total G Loss: 3.6405\n",
      "Epoch [26/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2527, D_X Fake: 0.2393, D_X Total: 0.2460\n",
      "  D_Y Real: 0.0842, D_Y Fake: 0.1059, D_Y Total: 0.0950\n",
      "Generator Losses:\n",
      "  G Adv: 0.4465, F Adv: 0.2777\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1994, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.5930\n",
      "Epoch [26/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2104, D_X Fake: 0.2367, D_X Total: 0.2235\n",
      "  D_Y Real: 0.2080, D_Y Fake: 0.0618, D_Y Total: 0.1349\n",
      "Generator Losses:\n",
      "  G Adv: 0.7953, F Adv: 0.3091\n",
      "  Cycle Photo: 0.0666, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.1907, Perceptual Monet: 0.1554\n",
      "  Total G Loss: 4.0093\n",
      "Epoch [26/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1762, D_X Fake: 0.2003, D_X Total: 0.1882\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.0960, D_Y Total: 0.0743\n",
      "Generator Losses:\n",
      "  G Adv: 0.5908, F Adv: 0.3616\n",
      "  Cycle Photo: 0.0841, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.7367\n",
      "Epoch [26/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2691, D_X Fake: 0.2277, D_X Total: 0.2484\n",
      "  D_Y Real: 0.0674, D_Y Fake: 0.1161, D_Y Total: 0.0917\n",
      "Generator Losses:\n",
      "  G Adv: 0.3851, F Adv: 0.2791\n",
      "  Cycle Photo: 0.0558, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1615, Perceptual Monet: 0.1329\n",
      "  Total G Loss: 3.1567\n",
      "Epoch [26/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2686, D_X Fake: 0.2827, D_X Total: 0.2757\n",
      "  D_Y Real: 0.1595, D_Y Fake: 0.1311, D_Y Total: 0.1453\n",
      "Generator Losses:\n",
      "  G Adv: 0.6489, F Adv: 0.2583\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 3.5718\n",
      "Epoch [26/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3191, D_X Fake: 0.2114, D_X Total: 0.2652\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.2210, D_Y Total: 0.1304\n",
      "Generator Losses:\n",
      "  G Adv: 0.3865, F Adv: 0.3602\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0511\n",
      "  Perceptual Photo: 0.1866, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.6485\n",
      "Epoch [26/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2272, D_X Fake: 0.1882, D_X Total: 0.2077\n",
      "  D_Y Real: 0.1594, D_Y Fake: 0.0646, D_Y Total: 0.1120\n",
      "Generator Losses:\n",
      "  G Adv: 0.8917, F Adv: 0.3370\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0473\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1411\n",
      "  Total G Loss: 3.5299\n",
      "Epoch [26/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1601, D_X Fake: 0.3059, D_X Total: 0.2330\n",
      "  D_Y Real: 0.1344, D_Y Fake: 0.0504, D_Y Total: 0.0924\n",
      "Generator Losses:\n",
      "  G Adv: 0.4885, F Adv: 0.2294\n",
      "  Cycle Photo: 0.0558, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1452\n",
      "  Total G Loss: 3.1804\n",
      "Epoch [26/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1970, D_X Fake: 0.2365, D_X Total: 0.2167\n",
      "  D_Y Real: 0.0927, D_Y Fake: 0.1042, D_Y Total: 0.0985\n",
      "Generator Losses:\n",
      "  G Adv: 0.5338, F Adv: 0.2959\n",
      "  Cycle Photo: 0.0785, Cycle Monet: 0.0449\n",
      "  Perceptual Photo: 0.1687, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.7318\n",
      "Epoch [26/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2648, D_X Fake: 0.2106, D_X Total: 0.2377\n",
      "  D_Y Real: 0.0928, D_Y Fake: 0.0863, D_Y Total: 0.0896\n",
      "Generator Losses:\n",
      "  G Adv: 0.5506, F Adv: 0.3409\n",
      "  Cycle Photo: 0.0749, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1788, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.8081\n",
      "Epoch [26/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3134, D_X Fake: 0.1888, D_X Total: 0.2511\n",
      "  D_Y Real: 0.1557, D_Y Fake: 0.1002, D_Y Total: 0.1279\n",
      "Generator Losses:\n",
      "  G Adv: 0.6511, F Adv: 0.4002\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1621, Perceptual Monet: 0.1612\n",
      "  Total G Loss: 3.5132\n",
      "Epoch [26/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2955, D_X Fake: 0.2425, D_X Total: 0.2690\n",
      "  D_Y Real: 0.1606, D_Y Fake: 0.0983, D_Y Total: 0.1295\n",
      "Generator Losses:\n",
      "  G Adv: 0.7778, F Adv: 0.3030\n",
      "  Cycle Photo: 0.0550, Cycle Monet: 0.0515\n",
      "  Perceptual Photo: 0.2016, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.9748\n",
      "Epoch [27/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3215, D_X Fake: 0.1846, D_X Total: 0.2530\n",
      "  D_Y Real: 0.1612, D_Y Fake: 0.1463, D_Y Total: 0.1537\n",
      "Generator Losses:\n",
      "  G Adv: 0.7578, F Adv: 0.3643\n",
      "  Cycle Photo: 0.0628, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.8473\n",
      "Epoch [27/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1689, D_X Fake: 0.2781, D_X Total: 0.2235\n",
      "  D_Y Real: 0.0910, D_Y Fake: 0.0564, D_Y Total: 0.0737\n",
      "Generator Losses:\n",
      "  G Adv: 0.5559, F Adv: 0.2156\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0585\n",
      "  Perceptual Photo: 0.1709, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.5602\n",
      "Epoch [27/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2869, D_X Fake: 0.2334, D_X Total: 0.2602\n",
      "  D_Y Real: 0.1826, D_Y Fake: 0.0883, D_Y Total: 0.1355\n",
      "Generator Losses:\n",
      "  G Adv: 0.6824, F Adv: 0.2196\n",
      "  Cycle Photo: 0.0669, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.2308, Perceptual Monet: 0.1684\n",
      "  Total G Loss: 3.9054\n",
      "Epoch [27/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.2870, D_X Total: 0.2000\n",
      "  D_Y Real: 0.1197, D_Y Fake: 0.0855, D_Y Total: 0.1026\n",
      "Generator Losses:\n",
      "  G Adv: 0.7528, F Adv: 0.2419\n",
      "  Cycle Photo: 0.0625, Cycle Monet: 0.0553\n",
      "  Perceptual Photo: 0.1600, Perceptual Monet: 0.1966\n",
      "  Total G Loss: 3.9558\n",
      "Epoch [27/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2980, D_X Fake: 0.1608, D_X Total: 0.2294\n",
      "  D_Y Real: 0.0625, D_Y Fake: 0.1458, D_Y Total: 0.1041\n",
      "Generator Losses:\n",
      "  G Adv: 0.5937, F Adv: 0.3907\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1724, Perceptual Monet: 0.1440\n",
      "  Total G Loss: 3.4406\n",
      "Epoch [27/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1804, D_X Fake: 0.2739, D_X Total: 0.2272\n",
      "  D_Y Real: 0.0956, D_Y Fake: 0.2669, D_Y Total: 0.1812\n",
      "Generator Losses:\n",
      "  G Adv: 0.3678, F Adv: 0.2547\n",
      "  Cycle Photo: 0.0425, Cycle Monet: 0.0542\n",
      "  Perceptual Photo: 0.1809, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.2194\n",
      "Epoch [27/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1997, D_X Fake: 0.2364, D_X Total: 0.2181\n",
      "  D_Y Real: 0.1151, D_Y Fake: 0.1150, D_Y Total: 0.1150\n",
      "Generator Losses:\n",
      "  G Adv: 0.6092, F Adv: 0.2967\n",
      "  Cycle Photo: 0.0490, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1579, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.3817\n",
      "Epoch [27/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1499, D_X Fake: 0.1592, D_X Total: 0.1545\n",
      "  D_Y Real: 0.0976, D_Y Fake: 0.1254, D_Y Total: 0.1115\n",
      "Generator Losses:\n",
      "  G Adv: 0.7184, F Adv: 0.3169\n",
      "  Cycle Photo: 0.0481, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.5355\n",
      "Epoch [27/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1432, D_X Fake: 0.2734, D_X Total: 0.2083\n",
      "  D_Y Real: 0.0469, D_Y Fake: 0.1821, D_Y Total: 0.1145\n",
      "Generator Losses:\n",
      "  G Adv: 0.3034, F Adv: 0.2603\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0472\n",
      "  Perceptual Photo: 0.1668, Perceptual Monet: 0.1755\n",
      "  Total G Loss: 3.2261\n",
      "Epoch [27/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1853, D_X Fake: 0.1755, D_X Total: 0.1804\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.3284, D_Y Total: 0.1852\n",
      "Generator Losses:\n",
      "  G Adv: 0.2401, F Adv: 0.2710\n",
      "  Cycle Photo: 0.0539, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1699, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.2457\n",
      "Epoch [27/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1523, D_X Fake: 0.1874, D_X Total: 0.1699\n",
      "  D_Y Real: 0.0799, D_Y Fake: 0.0634, D_Y Total: 0.0716\n",
      "Generator Losses:\n",
      "  G Adv: 0.4621, F Adv: 0.3957\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0518\n",
      "  Perceptual Photo: 0.1889, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.7333\n",
      "Epoch [27/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1324, D_X Fake: 0.1042, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0479, D_Y Fake: 0.0901, D_Y Total: 0.0690\n",
      "Generator Losses:\n",
      "  G Adv: 0.6846, F Adv: 0.5207\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1799, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.9445\n",
      "Epoch [27/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1752, D_X Fake: 0.1288, D_X Total: 0.1520\n",
      "  D_Y Real: 0.0866, D_Y Fake: 0.1464, D_Y Total: 0.1165\n",
      "Generator Losses:\n",
      "  G Adv: 0.9172, F Adv: 0.3377\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1712\n",
      "  Total G Loss: 3.7970\n",
      "Epoch [27/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0269, D_X Fake: 0.1601, D_X Total: 0.0935\n",
      "  D_Y Real: 0.1815, D_Y Fake: 0.0895, D_Y Total: 0.1355\n",
      "Generator Losses:\n",
      "  G Adv: 0.6880, F Adv: 0.4784\n",
      "  Cycle Photo: 0.0700, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1274, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.7551\n",
      "Epoch [27/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0585, D_X Fake: 0.0868, D_X Total: 0.0727\n",
      "  D_Y Real: 0.0842, D_Y Fake: 0.1029, D_Y Total: 0.0935\n",
      "Generator Losses:\n",
      "  G Adv: 0.9233, F Adv: 0.5649\n",
      "  Cycle Photo: 0.0572, Cycle Monet: 0.0553\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.2070\n",
      "  Total G Loss: 4.4390\n",
      "Epoch [27/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1863, D_X Fake: 0.0429, D_X Total: 0.1146\n",
      "  D_Y Real: 0.1748, D_Y Fake: 0.1034, D_Y Total: 0.1391\n",
      "Generator Losses:\n",
      "  G Adv: 0.8526, F Adv: 0.7991\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1873, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 4.3544\n",
      "Epoch [27/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1023, D_X Fake: 0.1518, D_X Total: 0.1271\n",
      "  D_Y Real: 0.1504, D_Y Fake: 0.0713, D_Y Total: 0.1108\n",
      "Generator Losses:\n",
      "  G Adv: 0.5288, F Adv: 0.4950\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.2052, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.7947\n",
      "Epoch [27/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0512, D_X Fake: 0.1065, D_X Total: 0.0788\n",
      "  D_Y Real: 0.2058, D_Y Fake: 0.0957, D_Y Total: 0.1507\n",
      "Generator Losses:\n",
      "  G Adv: 0.6927, F Adv: 0.5095\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0483\n",
      "  Perceptual Photo: 0.1203, Perceptual Monet: 0.2246\n",
      "  Total G Loss: 3.8450\n",
      "Epoch [27/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2303, D_X Fake: 0.0237, D_X Total: 0.1270\n",
      "  D_Y Real: 0.1045, D_Y Fake: 0.1798, D_Y Total: 0.1421\n",
      "Generator Losses:\n",
      "  G Adv: 0.3985, F Adv: 1.0825\n",
      "  Cycle Photo: 0.0600, Cycle Monet: 0.0490\n",
      "  Perceptual Photo: 0.1785, Perceptual Monet: 0.2105\n",
      "  Total G Loss: 4.5156\n",
      "Epoch [27/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3312, D_X Fake: 0.1261, D_X Total: 0.2287\n",
      "  D_Y Real: 0.0534, D_Y Fake: 0.0829, D_Y Total: 0.0682\n",
      "Generator Losses:\n",
      "  G Adv: 0.2909, F Adv: 0.6344\n",
      "  Cycle Photo: 0.0549, Cycle Monet: 0.0471\n",
      "  Perceptual Photo: 0.1738, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.6592\n",
      "Epoch [27/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1180, D_X Fake: 0.1617, D_X Total: 0.1399\n",
      "  D_Y Real: 0.1114, D_Y Fake: 0.0729, D_Y Total: 0.0922\n",
      "Generator Losses:\n",
      "  G Adv: 0.6799, F Adv: 0.3752\n",
      "  Cycle Photo: 0.0823, Cycle Monet: 0.0513\n",
      "  Perceptual Photo: 0.1995, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 4.2252\n",
      "Epoch [27/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0461, D_X Fake: 0.1379, D_X Total: 0.0920\n",
      "  D_Y Real: 0.0841, D_Y Fake: 0.1717, D_Y Total: 0.1279\n",
      "Generator Losses:\n",
      "  G Adv: 0.3887, F Adv: 0.4432\n",
      "  Cycle Photo: 0.0796, Cycle Monet: 0.0583\n",
      "  Perceptual Photo: 0.1942, Perceptual Monet: 0.1976\n",
      "  Total G Loss: 4.1701\n",
      "Epoch [27/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3070, D_X Fake: 0.0506, D_X Total: 0.1788\n",
      "  D_Y Real: 0.0853, D_Y Fake: 0.1599, D_Y Total: 0.1226\n",
      "Generator Losses:\n",
      "  G Adv: 0.4024, F Adv: 0.5545\n",
      "  Cycle Photo: 0.0684, Cycle Monet: 0.0536\n",
      "  Perceptual Photo: 0.1990, Perceptual Monet: 0.2133\n",
      "  Total G Loss: 4.2387\n",
      "Epoch [27/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0363, D_X Fake: 0.2187, D_X Total: 0.1275\n",
      "  D_Y Real: 0.2568, D_Y Fake: 0.1138, D_Y Total: 0.1853\n",
      "Generator Losses:\n",
      "  G Adv: 0.5458, F Adv: 0.3415\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.4330\n",
      "Epoch [28/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1381, D_X Fake: 0.1007, D_X Total: 0.1194\n",
      "  D_Y Real: 0.0488, D_Y Fake: 0.1416, D_Y Total: 0.0952\n",
      "Generator Losses:\n",
      "  G Adv: 0.5448, F Adv: 0.5575\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1637, Perceptual Monet: 0.1708\n",
      "  Total G Loss: 3.6361\n",
      "Epoch [28/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0798, D_X Fake: 0.0642, D_X Total: 0.0720\n",
      "  D_Y Real: 0.1199, D_Y Fake: 0.0900, D_Y Total: 0.1050\n",
      "Generator Losses:\n",
      "  G Adv: 0.4342, F Adv: 0.5506\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0520\n",
      "  Perceptual Photo: 0.1942, Perceptual Monet: 0.2163\n",
      "  Total G Loss: 4.0893\n",
      "Epoch [28/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2679, D_X Fake: 0.0748, D_X Total: 0.1713\n",
      "  D_Y Real: 0.0751, D_Y Fake: 0.1147, D_Y Total: 0.0949\n",
      "Generator Losses:\n",
      "  G Adv: 0.4608, F Adv: 0.9616\n",
      "  Cycle Photo: 0.0555, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.9787\n",
      "Epoch [28/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1074, D_X Fake: 0.0885, D_X Total: 0.0980\n",
      "  D_Y Real: 0.0629, D_Y Fake: 0.0670, D_Y Total: 0.0649\n",
      "Generator Losses:\n",
      "  G Adv: 0.7399, F Adv: 0.4357\n",
      "  Cycle Photo: 0.0705, Cycle Monet: 0.0819\n",
      "  Perceptual Photo: 0.1982, Perceptual Monet: 0.1698\n",
      "  Total G Loss: 4.5395\n",
      "Epoch [28/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1254, D_X Fake: 0.0646, D_X Total: 0.0950\n",
      "  D_Y Real: 0.0663, D_Y Fake: 0.0476, D_Y Total: 0.0570\n",
      "Generator Losses:\n",
      "  G Adv: 0.5982, F Adv: 0.6291\n",
      "  Cycle Photo: 0.0767, Cycle Monet: 0.0538\n",
      "  Perceptual Photo: 0.2105, Perceptual Monet: 0.1987\n",
      "  Total G Loss: 4.5784\n",
      "Epoch [28/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1241, D_X Fake: 0.1168, D_X Total: 0.1205\n",
      "  D_Y Real: 0.1203, D_Y Fake: 0.0646, D_Y Total: 0.0925\n",
      "Generator Losses:\n",
      "  G Adv: 0.7435, F Adv: 0.5284\n",
      "  Cycle Photo: 0.0767, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.2125, Perceptual Monet: 0.1463\n",
      "  Total G Loss: 4.1732\n",
      "Epoch [28/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.0629, D_X Total: 0.0720\n",
      "  D_Y Real: 0.0668, D_Y Fake: 0.3191, D_Y Total: 0.1929\n",
      "Generator Losses:\n",
      "  G Adv: 0.2831, F Adv: 0.6753\n",
      "  Cycle Photo: 0.0698, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1677, Perceptual Monet: 0.1831\n",
      "  Total G Loss: 3.8166\n",
      "Epoch [28/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2103, D_X Fake: 0.1881, D_X Total: 0.1992\n",
      "  D_Y Real: 0.2080, D_Y Fake: 0.0760, D_Y Total: 0.1420\n",
      "Generator Losses:\n",
      "  G Adv: 0.7721, F Adv: 0.5426\n",
      "  Cycle Photo: 0.0531, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.1776, Perceptual Monet: 0.2259\n",
      "  Total G Loss: 4.3426\n",
      "Epoch [28/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2572, D_X Fake: 0.0521, D_X Total: 0.1547\n",
      "  D_Y Real: 0.0596, D_Y Fake: 0.1095, D_Y Total: 0.0845\n",
      "Generator Losses:\n",
      "  G Adv: 0.5888, F Adv: 0.9805\n",
      "  Cycle Photo: 0.0647, Cycle Monet: 0.0586\n",
      "  Perceptual Photo: 0.2208, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 4.7895\n",
      "Epoch [28/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0547, D_X Fake: 0.1143, D_X Total: 0.0845\n",
      "  D_Y Real: 0.0534, D_Y Fake: 0.2838, D_Y Total: 0.1686\n",
      "Generator Losses:\n",
      "  G Adv: 0.2725, F Adv: 0.6513\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0529\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.7136\n",
      "Epoch [28/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0805, D_X Fake: 0.0843, D_X Total: 0.0824\n",
      "  D_Y Real: 0.0851, D_Y Fake: 0.1072, D_Y Total: 0.0961\n",
      "Generator Losses:\n",
      "  G Adv: 0.5891, F Adv: 0.4234\n",
      "  Cycle Photo: 0.1008, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 4.1604\n",
      "Epoch [28/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2691, D_X Fake: 0.0523, D_X Total: 0.1607\n",
      "  D_Y Real: 0.2284, D_Y Fake: 0.0528, D_Y Total: 0.1406\n",
      "Generator Losses:\n",
      "  G Adv: 0.7645, F Adv: 0.7378\n",
      "  Cycle Photo: 0.0459, Cycle Monet: 0.0481\n",
      "  Perceptual Photo: 0.1666, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 4.1157\n",
      "Epoch [28/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1512, D_X Fake: 0.0965, D_X Total: 0.1238\n",
      "  D_Y Real: 0.0914, D_Y Fake: 0.1466, D_Y Total: 0.1190\n",
      "Generator Losses:\n",
      "  G Adv: 0.4537, F Adv: 0.6005\n",
      "  Cycle Photo: 0.0676, Cycle Monet: 0.0524\n",
      "  Perceptual Photo: 0.1263, Perceptual Monet: 0.1892\n",
      "  Total G Loss: 3.8323\n",
      "Epoch [28/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0966, D_X Fake: 0.2072, D_X Total: 0.1519\n",
      "  D_Y Real: 0.1680, D_Y Fake: 0.1067, D_Y Total: 0.1374\n",
      "Generator Losses:\n",
      "  G Adv: 0.7006, F Adv: 0.3656\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1893\n",
      "  Total G Loss: 3.7109\n",
      "Epoch [28/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0981, D_X Fake: 0.0878, D_X Total: 0.0929\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.2020, D_Y Total: 0.1198\n",
      "Generator Losses:\n",
      "  G Adv: 0.3993, F Adv: 0.5519\n",
      "  Cycle Photo: 0.0497, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1709, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.5643\n",
      "Epoch [28/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2251, D_X Fake: 0.0476, D_X Total: 0.1363\n",
      "  D_Y Real: 0.0910, D_Y Fake: 0.1288, D_Y Total: 0.1099\n",
      "Generator Losses:\n",
      "  G Adv: 0.4566, F Adv: 1.3357\n",
      "  Cycle Photo: 0.0625, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 4.4317\n",
      "Epoch [28/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1359, D_X Fake: 0.0379, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.1933, D_Y Total: 0.1177\n",
      "Generator Losses:\n",
      "  G Adv: 0.5240, F Adv: 0.8169\n",
      "  Cycle Photo: 0.0816, Cycle Monet: 0.0477\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 4.2164\n",
      "Epoch [28/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0789, D_X Fake: 0.0609, D_X Total: 0.0699\n",
      "  D_Y Real: 0.0378, D_Y Fake: 0.1719, D_Y Total: 0.1048\n",
      "Generator Losses:\n",
      "  G Adv: 0.5551, F Adv: 0.7820\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0548\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.2110\n",
      "  Total G Loss: 4.2081\n",
      "Epoch [28/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1685, D_X Fake: 0.0351, D_X Total: 0.1018\n",
      "  D_Y Real: 0.0496, D_Y Fake: 0.0544, D_Y Total: 0.0520\n",
      "Generator Losses:\n",
      "  G Adv: 0.4437, F Adv: 0.8763\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0568\n",
      "  Perceptual Photo: 0.1801, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 4.1474\n",
      "Epoch [28/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0738, D_X Fake: 0.1002, D_X Total: 0.0870\n",
      "  D_Y Real: 0.0952, D_Y Fake: 0.0406, D_Y Total: 0.0679\n",
      "Generator Losses:\n",
      "  G Adv: 0.7610, F Adv: 0.5923\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1757, Perceptual Monet: 0.1903\n",
      "  Total G Loss: 4.0206\n",
      "Epoch [28/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1870, D_X Fake: 0.1091, D_X Total: 0.1481\n",
      "  D_Y Real: 0.2182, D_Y Fake: 0.0538, D_Y Total: 0.1360\n",
      "Generator Losses:\n",
      "  G Adv: 0.9975, F Adv: 0.4805\n",
      "  Cycle Photo: 0.0537, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.2157, Perceptual Monet: 0.1986\n",
      "  Total G Loss: 4.5390\n",
      "Epoch [28/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0645, D_X Fake: 0.1497, D_X Total: 0.1071\n",
      "  D_Y Real: 0.0531, D_Y Fake: 0.1248, D_Y Total: 0.0890\n",
      "Generator Losses:\n",
      "  G Adv: 0.5730, F Adv: 0.3928\n",
      "  Cycle Photo: 0.0533, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1793, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 3.8090\n",
      "Epoch [28/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1195, D_X Fake: 0.1930, D_X Total: 0.1563\n",
      "  D_Y Real: 0.1564, D_Y Fake: 0.1365, D_Y Total: 0.1464\n",
      "Generator Losses:\n",
      "  G Adv: 0.5741, F Adv: 0.4900\n",
      "  Cycle Photo: 0.0480, Cycle Monet: 0.0547\n",
      "  Perceptual Photo: 0.1578, Perceptual Monet: 0.1846\n",
      "  Total G Loss: 3.8033\n",
      "Epoch [28/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1023, D_X Fake: 0.0728, D_X Total: 0.0876\n",
      "  D_Y Real: 0.1034, D_Y Fake: 0.0409, D_Y Total: 0.0722\n",
      "Generator Losses:\n",
      "  G Adv: 0.8819, F Adv: 0.6139\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0426\n",
      "  Perceptual Photo: 0.1741, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 4.2219\n",
      "Epoch [29/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1579, D_X Fake: 0.0606, D_X Total: 0.1092\n",
      "  D_Y Real: 0.1705, D_Y Fake: 0.0974, D_Y Total: 0.1339\n",
      "Generator Losses:\n",
      "  G Adv: 0.5781, F Adv: 0.5818\n",
      "  Cycle Photo: 0.0784, Cycle Monet: 0.0522\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.1851\n",
      "  Total G Loss: 4.2505\n",
      "Epoch [29/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1283, D_X Fake: 0.1244, D_X Total: 0.1263\n",
      "  D_Y Real: 0.1581, D_Y Fake: 0.0525, D_Y Total: 0.1053\n",
      "Generator Losses:\n",
      "  G Adv: 0.6455, F Adv: 0.4983\n",
      "  Cycle Photo: 0.0688, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.2243, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 4.1785\n",
      "Epoch [29/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0437, D_X Fake: 0.1935, D_X Total: 0.1186\n",
      "  D_Y Real: 0.0697, D_Y Fake: 0.1916, D_Y Total: 0.1307\n",
      "Generator Losses:\n",
      "  G Adv: 0.4694, F Adv: 0.3637\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0539\n",
      "  Perceptual Photo: 0.1571, Perceptual Monet: 0.2183\n",
      "  Total G Loss: 3.7873\n",
      "Epoch [29/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1104, D_X Fake: 0.1782, D_X Total: 0.1443\n",
      "  D_Y Real: 0.1589, D_Y Fake: 0.0617, D_Y Total: 0.1103\n",
      "Generator Losses:\n",
      "  G Adv: 0.6486, F Adv: 0.5250\n",
      "  Cycle Photo: 0.0555, Cycle Monet: 0.0449\n",
      "  Perceptual Photo: 0.1797, Perceptual Monet: 0.1862\n",
      "  Total G Loss: 4.0069\n",
      "Epoch [29/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1265, D_X Fake: 0.1605, D_X Total: 0.1435\n",
      "  D_Y Real: 0.0918, D_Y Fake: 0.1918, D_Y Total: 0.1418\n",
      "Generator Losses:\n",
      "  G Adv: 0.4677, F Adv: 0.5401\n",
      "  Cycle Photo: 0.0579, Cycle Monet: 0.0447\n",
      "  Perceptual Photo: 0.1940, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.9225\n",
      "Epoch [29/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0700, D_X Fake: 0.1066, D_X Total: 0.0883\n",
      "  D_Y Real: 0.0516, D_Y Fake: 0.0564, D_Y Total: 0.0540\n",
      "Generator Losses:\n",
      "  G Adv: 0.8209, F Adv: 0.6658\n",
      "  Cycle Photo: 0.0608, Cycle Monet: 0.0535\n",
      "  Perceptual Photo: 0.1614, Perceptual Monet: 0.1913\n",
      "  Total G Loss: 4.3923\n",
      "Epoch [29/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1119, D_X Fake: 0.0725, D_X Total: 0.0922\n",
      "  D_Y Real: 0.0464, D_Y Fake: 0.1490, D_Y Total: 0.0977\n",
      "Generator Losses:\n",
      "  G Adv: 0.5164, F Adv: 0.5415\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1578, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.5691\n",
      "Epoch [29/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0880, D_X Fake: 0.2811, D_X Total: 0.1846\n",
      "  D_Y Real: 0.0813, D_Y Fake: 0.1738, D_Y Total: 0.1276\n",
      "Generator Losses:\n",
      "  G Adv: 0.6759, F Adv: 0.2492\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0464\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.3454\n",
      "Epoch [29/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0929, D_X Fake: 0.1168, D_X Total: 0.1049\n",
      "  D_Y Real: 0.0972, D_Y Fake: 0.0624, D_Y Total: 0.0798\n",
      "Generator Losses:\n",
      "  G Adv: 0.6407, F Adv: 0.5890\n",
      "  Cycle Photo: 0.0502, Cycle Monet: 0.0468\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.2078\n",
      "  Total G Loss: 4.1214\n",
      "Epoch [29/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0598, D_X Fake: 0.0315, D_X Total: 0.0457\n",
      "  D_Y Real: 0.1625, D_Y Fake: 0.1254, D_Y Total: 0.1440\n",
      "Generator Losses:\n",
      "  G Adv: 1.0404, F Adv: 0.6712\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0624\n",
      "  Perceptual Photo: 0.1597, Perceptual Monet: 0.1965\n",
      "  Total G Loss: 4.6438\n",
      "Epoch [29/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1755, D_X Fake: 0.0355, D_X Total: 0.1055\n",
      "  D_Y Real: 0.0701, D_Y Fake: 0.2372, D_Y Total: 0.1537\n",
      "Generator Losses:\n",
      "  G Adv: 0.2238, F Adv: 0.4834\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0484\n",
      "  Perceptual Photo: 0.1774, Perceptual Monet: 0.2047\n",
      "  Total G Loss: 3.6021\n",
      "Epoch [29/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0494, D_X Fake: 0.0770, D_X Total: 0.0632\n",
      "  D_Y Real: 0.0481, D_Y Fake: 0.0669, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.6656, F Adv: 0.4563\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.7815\n",
      "Epoch [29/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0610, D_X Fake: 0.1532, D_X Total: 0.1071\n",
      "  D_Y Real: 0.1203, D_Y Fake: 0.0874, D_Y Total: 0.1039\n",
      "Generator Losses:\n",
      "  G Adv: 0.6457, F Adv: 0.4764\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1257, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 3.5811\n",
      "Epoch [29/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1426, D_X Fake: 0.0769, D_X Total: 0.1097\n",
      "  D_Y Real: 0.1512, D_Y Fake: 0.1577, D_Y Total: 0.1545\n",
      "Generator Losses:\n",
      "  G Adv: 0.5284, F Adv: 0.6199\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0477\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.7336\n",
      "Epoch [29/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1378, D_X Fake: 0.1449, D_X Total: 0.1413\n",
      "  D_Y Real: 0.0764, D_Y Fake: 0.1497, D_Y Total: 0.1130\n",
      "Generator Losses:\n",
      "  G Adv: 0.4258, F Adv: 0.4573\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.6659\n",
      "Epoch [29/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2326, D_X Fake: 0.0619, D_X Total: 0.1473\n",
      "  D_Y Real: 0.2376, D_Y Fake: 0.0915, D_Y Total: 0.1646\n",
      "Generator Losses:\n",
      "  G Adv: 0.6300, F Adv: 0.7453\n",
      "  Cycle Photo: 0.0542, Cycle Monet: 0.0541\n",
      "  Perceptual Photo: 0.1820, Perceptual Monet: 0.1940\n",
      "  Total G Loss: 4.3382\n",
      "Epoch [29/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0858, D_X Fake: 0.0979, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.1060, D_Y Total: 0.0675\n",
      "Generator Losses:\n",
      "  G Adv: 0.2329, F Adv: 0.6157\n",
      "  Cycle Photo: 0.1056, Cycle Monet: 0.0515\n",
      "  Perceptual Photo: 0.2228, Perceptual Monet: 0.2302\n",
      "  Total G Loss: 4.6852\n",
      "Epoch [29/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1186, D_X Fake: 0.0571, D_X Total: 0.0879\n",
      "  D_Y Real: 0.0885, D_Y Fake: 0.1111, D_Y Total: 0.0998\n",
      "Generator Losses:\n",
      "  G Adv: 0.5599, F Adv: 0.7761\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0445\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1985\n",
      "  Total G Loss: 3.8646\n",
      "Epoch [29/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1333, D_X Fake: 0.0849, D_X Total: 0.1091\n",
      "  D_Y Real: 0.1741, D_Y Fake: 0.0595, D_Y Total: 0.1168\n",
      "Generator Losses:\n",
      "  G Adv: 0.9591, F Adv: 0.6916\n",
      "  Cycle Photo: 0.0696, Cycle Monet: 0.0528\n",
      "  Perceptual Photo: 0.1978, Perceptual Monet: 0.2256\n",
      "  Total G Loss: 4.9913\n",
      "Epoch [29/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1699, D_X Fake: 0.1595, D_X Total: 0.1647\n",
      "  D_Y Real: 0.1851, D_Y Fake: 0.0491, D_Y Total: 0.1171\n",
      "Generator Losses:\n",
      "  G Adv: 0.4874, F Adv: 0.4175\n",
      "  Cycle Photo: 0.0580, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1968, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.6743\n",
      "Epoch [29/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2242, D_X Fake: 0.0873, D_X Total: 0.1557\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.1744, D_Y Total: 0.1131\n",
      "Generator Losses:\n",
      "  G Adv: 0.3259, F Adv: 0.4242\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1641, Perceptual Monet: 0.1836\n",
      "  Total G Loss: 3.5095\n",
      "Epoch [29/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0390, D_X Fake: 0.1034, D_X Total: 0.0712\n",
      "  D_Y Real: 0.0837, D_Y Fake: 0.0650, D_Y Total: 0.0744\n",
      "Generator Losses:\n",
      "  G Adv: 0.9177, F Adv: 0.3906\n",
      "  Cycle Photo: 0.0725, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1670, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 4.1584\n",
      "Epoch [29/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0633, D_X Fake: 0.2013, D_X Total: 0.1323\n",
      "  D_Y Real: 0.0360, D_Y Fake: 0.1073, D_Y Total: 0.0717\n",
      "Generator Losses:\n",
      "  G Adv: 0.5673, F Adv: 0.3458\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0542\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 3.9256\n",
      "Epoch [29/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0491, D_X Fake: 0.1588, D_X Total: 0.1039\n",
      "  D_Y Real: 0.2030, D_Y Fake: 0.0546, D_Y Total: 0.1288\n",
      "Generator Losses:\n",
      "  G Adv: 0.8860, F Adv: 0.4852\n",
      "  Cycle Photo: 0.0477, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1754, Perceptual Monet: 0.1931\n",
      "  Total G Loss: 4.1520\n",
      "Epoch [30/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1250, D_X Fake: 0.0508, D_X Total: 0.0879\n",
      "  D_Y Real: 0.0813, D_Y Fake: 0.0930, D_Y Total: 0.0871\n",
      "Generator Losses:\n",
      "  G Adv: 0.9334, F Adv: 0.5433\n",
      "  Cycle Photo: 0.0934, Cycle Monet: 0.0626\n",
      "  Perceptual Photo: 0.1753, Perceptual Monet: 0.1992\n",
      "  Total G Loss: 4.9089\n",
      "Epoch [30/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1090, D_X Fake: 0.1189, D_X Total: 0.1139\n",
      "  D_Y Real: 0.1165, D_Y Fake: 0.1158, D_Y Total: 0.1162\n",
      "Generator Losses:\n",
      "  G Adv: 0.7027, F Adv: 0.6236\n",
      "  Cycle Photo: 0.0791, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1769, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 4.3545\n",
      "Epoch [30/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1771, D_X Fake: 0.1589, D_X Total: 0.1680\n",
      "  D_Y Real: 0.2194, D_Y Fake: 0.1031, D_Y Total: 0.1612\n",
      "Generator Losses:\n",
      "  G Adv: 0.6278, F Adv: 0.3068\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0440\n",
      "  Perceptual Photo: 0.1936, Perceptual Monet: 0.1976\n",
      "  Total G Loss: 3.9224\n",
      "Epoch [30/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0941, D_X Fake: 0.1026, D_X Total: 0.0983\n",
      "  D_Y Real: 0.2675, D_Y Fake: 0.0821, D_Y Total: 0.1748\n",
      "Generator Losses:\n",
      "  G Adv: 0.8901, F Adv: 0.6098\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.1912\n",
      "  Total G Loss: 4.1857\n",
      "Epoch [30/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0681, D_X Fake: 0.2297, D_X Total: 0.1489\n",
      "  D_Y Real: 0.1255, D_Y Fake: 0.0774, D_Y Total: 0.1014\n",
      "Generator Losses:\n",
      "  G Adv: 0.5990, F Adv: 0.3260\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0569\n",
      "  Perceptual Photo: 0.2229, Perceptual Monet: 0.2014\n",
      "  Total G Loss: 4.1449\n",
      "Epoch [30/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2214, D_X Fake: 0.1059, D_X Total: 0.1636\n",
      "  D_Y Real: 0.1627, D_Y Fake: 0.3042, D_Y Total: 0.2334\n",
      "Generator Losses:\n",
      "  G Adv: 0.4482, F Adv: 0.5489\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.1914, Perceptual Monet: 0.1815\n",
      "  Total G Loss: 3.8256\n",
      "Epoch [30/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0935, D_X Fake: 0.0910, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0546, D_Y Fake: 0.0822, D_Y Total: 0.0684\n",
      "Generator Losses:\n",
      "  G Adv: 0.6033, F Adv: 0.3240\n",
      "  Cycle Photo: 0.0570, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1817\n",
      "  Total G Loss: 3.7232\n",
      "Epoch [30/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0859, D_X Fake: 0.0726, D_X Total: 0.0793\n",
      "  D_Y Real: 0.0575, D_Y Fake: 0.0875, D_Y Total: 0.0725\n",
      "Generator Losses:\n",
      "  G Adv: 0.5852, F Adv: 0.4739\n",
      "  Cycle Photo: 0.0559, Cycle Monet: 0.0577\n",
      "  Perceptual Photo: 0.2330, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 4.1505\n",
      "Epoch [30/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0746, D_X Fake: 0.2174, D_X Total: 0.1460\n",
      "  D_Y Real: 0.0469, D_Y Fake: 0.1438, D_Y Total: 0.0954\n",
      "Generator Losses:\n",
      "  G Adv: 0.2569, F Adv: 0.2832\n",
      "  Cycle Photo: 0.0652, Cycle Monet: 0.0489\n",
      "  Perceptual Photo: 0.1798, Perceptual Monet: 0.1960\n",
      "  Total G Loss: 3.5610\n",
      "Epoch [30/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1145, D_X Fake: 0.0422, D_X Total: 0.0783\n",
      "  D_Y Real: 0.0946, D_Y Fake: 0.2222, D_Y Total: 0.1584\n",
      "Generator Losses:\n",
      "  G Adv: 0.5174, F Adv: 0.9266\n",
      "  Cycle Photo: 0.0746, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.2068\n",
      "  Total G Loss: 4.4600\n",
      "Epoch [30/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0516, D_X Fake: 0.2770, D_X Total: 0.1643\n",
      "  D_Y Real: 0.0807, D_Y Fake: 0.1288, D_Y Total: 0.1048\n",
      "Generator Losses:\n",
      "  G Adv: 0.7825, F Adv: 0.1812\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0501\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.2196\n",
      "  Total G Loss: 4.0295\n",
      "Epoch [30/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1381, D_X Fake: 0.0721, D_X Total: 0.1051\n",
      "  D_Y Real: 0.1729, D_Y Fake: 0.0869, D_Y Total: 0.1299\n",
      "Generator Losses:\n",
      "  G Adv: 0.6321, F Adv: 0.5607\n",
      "  Cycle Photo: 0.0549, Cycle Monet: 0.0476\n",
      "  Perceptual Photo: 0.1758, Perceptual Monet: 0.2004\n",
      "  Total G Loss: 4.0982\n",
      "Epoch [30/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1690, D_X Fake: 0.0343, D_X Total: 0.1017\n",
      "  D_Y Real: 0.0719, D_Y Fake: 0.1311, D_Y Total: 0.1015\n",
      "Generator Losses:\n",
      "  G Adv: 0.6459, F Adv: 0.6793\n",
      "  Cycle Photo: 0.0669, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.2667, Perceptual Monet: 0.1932\n",
      "  Total G Loss: 4.7212\n",
      "Epoch [30/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0740, D_X Fake: 0.2373, D_X Total: 0.1556\n",
      "  D_Y Real: 0.2571, D_Y Fake: 0.0894, D_Y Total: 0.1733\n",
      "Generator Losses:\n",
      "  G Adv: 1.1486, F Adv: 0.3879\n",
      "  Cycle Photo: 0.0490, Cycle Monet: 0.0436\n",
      "  Perceptual Photo: 0.1661, Perceptual Monet: 0.1832\n",
      "  Total G Loss: 4.2099\n",
      "Epoch [30/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2045, D_X Fake: 0.1094, D_X Total: 0.1569\n",
      "  D_Y Real: 0.1611, D_Y Fake: 0.0633, D_Y Total: 0.1122\n",
      "Generator Losses:\n",
      "  G Adv: 0.6048, F Adv: 0.5747\n",
      "  Cycle Photo: 0.0536, Cycle Monet: 0.0484\n",
      "  Perceptual Photo: 0.1931, Perceptual Monet: 0.2103\n",
      "  Total G Loss: 4.2165\n",
      "Epoch [30/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1083, D_X Fake: 0.1972, D_X Total: 0.1527\n",
      "  D_Y Real: 0.0787, D_Y Fake: 0.1286, D_Y Total: 0.1036\n",
      "Generator Losses:\n",
      "  G Adv: 0.5272, F Adv: 0.2952\n",
      "  Cycle Photo: 0.0578, Cycle Monet: 0.0494\n",
      "  Perceptual Photo: 0.1903, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.6854\n",
      "Epoch [30/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0965, D_X Fake: 0.0841, D_X Total: 0.0903\n",
      "  D_Y Real: 0.1200, D_Y Fake: 0.1060, D_Y Total: 0.1130\n",
      "Generator Losses:\n",
      "  G Adv: 0.6840, F Adv: 0.6425\n",
      "  Cycle Photo: 0.0647, Cycle Monet: 0.0529\n",
      "  Perceptual Photo: 0.1923, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 4.3521\n",
      "Epoch [30/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 1.0124, D_X Fake: 0.6664, D_X Total: 0.8394\n",
      "  D_Y Real: 0.4129, D_Y Fake: 0.0908, D_Y Total: 0.2518\n",
      "Generator Losses:\n",
      "  G Adv: 0.9620, F Adv: 1.1854\n",
      "  Cycle Photo: 0.2413, Cycle Monet: 0.1461\n",
      "  Perceptual Photo: 0.4708, Perceptual Monet: 0.4180\n",
      "  Total G Loss: 10.4661\n",
      "Epoch [30/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2875, D_X Fake: 0.2134, D_X Total: 0.2505\n",
      "  D_Y Real: 0.0927, D_Y Fake: 0.1019, D_Y Total: 0.0973\n",
      "Generator Losses:\n",
      "  G Adv: 0.7300, F Adv: 0.3701\n",
      "  Cycle Photo: 0.0511, Cycle Monet: 0.0491\n",
      "  Perceptual Photo: 0.1702, Perceptual Monet: 0.1911\n",
      "  Total G Loss: 3.9076\n",
      "Epoch [30/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1891, D_X Fake: 0.3110, D_X Total: 0.2500\n",
      "  D_Y Real: 0.1295, D_Y Fake: 0.0340, D_Y Total: 0.0817\n",
      "Generator Losses:\n",
      "  G Adv: 1.1179, F Adv: 0.2501\n",
      "  Cycle Photo: 0.0732, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 4.1387\n",
      "Epoch [30/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2834, D_X Fake: 0.3207, D_X Total: 0.3020\n",
      "  D_Y Real: 0.0706, D_Y Fake: 0.1781, D_Y Total: 0.1244\n",
      "Generator Losses:\n",
      "  G Adv: 0.4705, F Adv: 0.2147\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1764, Perceptual Monet: 0.1812\n",
      "  Total G Loss: 3.3782\n",
      "Epoch [30/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2495, D_X Fake: 0.2630, D_X Total: 0.2562\n",
      "  D_Y Real: 0.0615, D_Y Fake: 0.0610, D_Y Total: 0.0612\n",
      "Generator Losses:\n",
      "  G Adv: 0.5535, F Adv: 0.2672\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.2093\n",
      "  Total G Loss: 3.6188\n",
      "Epoch [30/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2803, D_X Fake: 0.2240, D_X Total: 0.2521\n",
      "  D_Y Real: 0.2365, D_Y Fake: 0.0519, D_Y Total: 0.1442\n",
      "Generator Losses:\n",
      "  G Adv: 0.7305, F Adv: 0.2942\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0500\n",
      "  Perceptual Photo: 0.1435, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.6073\n",
      "Epoch [30/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2712, D_X Fake: 0.2254, D_X Total: 0.2483\n",
      "  D_Y Real: 0.0721, D_Y Fake: 0.1063, D_Y Total: 0.0892\n",
      "Generator Losses:\n",
      "  G Adv: 0.5398, F Adv: 0.3207\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1774, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.5145\n",
      "Epoch [31/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2107, D_X Fake: 0.2634, D_X Total: 0.2371\n",
      "  D_Y Real: 0.0872, D_Y Fake: 0.1016, D_Y Total: 0.0944\n",
      "Generator Losses:\n",
      "  G Adv: 0.4000, F Adv: 0.2913\n",
      "  Cycle Photo: 0.0610, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1558, Perceptual Monet: 0.1567\n",
      "  Total G Loss: 3.2491\n",
      "Epoch [31/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2488, D_X Fake: 0.1744, D_X Total: 0.2116\n",
      "  D_Y Real: 0.1234, D_Y Fake: 0.0873, D_Y Total: 0.1053\n",
      "Generator Losses:\n",
      "  G Adv: 0.5814, F Adv: 0.3301\n",
      "  Cycle Photo: 0.0599, Cycle Monet: 0.0432\n",
      "  Perceptual Photo: 0.1776, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.7436\n",
      "Epoch [31/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2464, D_X Fake: 0.2808, D_X Total: 0.2636\n",
      "  D_Y Real: 0.0709, D_Y Fake: 0.0669, D_Y Total: 0.0689\n",
      "Generator Losses:\n",
      "  G Adv: 0.8008, F Adv: 0.2893\n",
      "  Cycle Photo: 0.0914, Cycle Monet: 0.0562\n",
      "  Perceptual Photo: 0.1744, Perceptual Monet: 0.2127\n",
      "  Total G Loss: 4.5024\n",
      "Epoch [31/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2858, D_X Fake: 0.2610, D_X Total: 0.2734\n",
      "  D_Y Real: 0.0612, D_Y Fake: 0.1055, D_Y Total: 0.0834\n",
      "Generator Losses:\n",
      "  G Adv: 0.4273, F Adv: 0.2860\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1497, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.2598\n",
      "Epoch [31/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2550, D_X Fake: 0.2782, D_X Total: 0.2666\n",
      "  D_Y Real: 0.0854, D_Y Fake: 0.1624, D_Y Total: 0.1239\n",
      "Generator Losses:\n",
      "  G Adv: 0.6422, F Adv: 0.2423\n",
      "  Cycle Photo: 0.0649, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1848, Perceptual Monet: 0.1367\n",
      "  Total G Loss: 3.5233\n",
      "Epoch [31/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1612, D_X Fake: 0.2087, D_X Total: 0.1849\n",
      "  D_Y Real: 0.0795, D_Y Fake: 0.1004, D_Y Total: 0.0900\n",
      "Generator Losses:\n",
      "  G Adv: 0.6315, F Adv: 0.3028\n",
      "  Cycle Photo: 0.0735, Cycle Monet: 0.0470\n",
      "  Perceptual Photo: 0.1556, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.8097\n",
      "Epoch [31/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2369, D_X Fake: 0.3708, D_X Total: 0.3038\n",
      "  D_Y Real: 0.1454, D_Y Fake: 0.0831, D_Y Total: 0.1142\n",
      "Generator Losses:\n",
      "  G Adv: 0.9315, F Adv: 0.2388\n",
      "  Cycle Photo: 0.0419, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1489, Perceptual Monet: 0.1715\n",
      "  Total G Loss: 3.6166\n",
      "Epoch [31/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2684, D_X Fake: 0.1470, D_X Total: 0.2077\n",
      "  D_Y Real: 0.1134, D_Y Fake: 0.0930, D_Y Total: 0.1032\n",
      "Generator Losses:\n",
      "  G Adv: 0.5841, F Adv: 0.4082\n",
      "  Cycle Photo: 0.0758, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1847, Perceptual Monet: 0.1776\n",
      "  Total G Loss: 4.0233\n",
      "Epoch [31/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1917, D_X Fake: 0.1806, D_X Total: 0.1861\n",
      "  D_Y Real: 0.0935, D_Y Fake: 0.0891, D_Y Total: 0.0913\n",
      "Generator Losses:\n",
      "  G Adv: 0.8817, F Adv: 0.2626\n",
      "  Cycle Photo: 0.0595, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1887, Perceptual Monet: 0.1494\n",
      "  Total G Loss: 3.7735\n",
      "Epoch [31/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2430, D_X Fake: 0.1680, D_X Total: 0.2055\n",
      "  D_Y Real: 0.3511, D_Y Fake: 0.0902, D_Y Total: 0.2207\n",
      "Generator Losses:\n",
      "  G Adv: 0.8639, F Adv: 0.4272\n",
      "  Cycle Photo: 0.0615, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1826, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 4.0597\n",
      "Epoch [31/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2395, D_X Fake: 0.2830, D_X Total: 0.2613\n",
      "  D_Y Real: 0.2068, D_Y Fake: 0.0431, D_Y Total: 0.1250\n",
      "Generator Losses:\n",
      "  G Adv: 0.8043, F Adv: 0.2408\n",
      "  Cycle Photo: 0.0901, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.2025, Perceptual Monet: 0.1225\n",
      "  Total G Loss: 3.8916\n",
      "Epoch [31/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1819, D_X Fake: 0.2091, D_X Total: 0.1955\n",
      "  D_Y Real: 0.0714, D_Y Fake: 0.0461, D_Y Total: 0.0587\n",
      "Generator Losses:\n",
      "  G Adv: 0.8823, F Adv: 0.2704\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1783, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.8000\n",
      "Epoch [31/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1226, D_X Fake: 0.1456, D_X Total: 0.1341\n",
      "  D_Y Real: 0.1400, D_Y Fake: 0.0565, D_Y Total: 0.0983\n",
      "Generator Losses:\n",
      "  G Adv: 0.9320, F Adv: 0.2474\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1773, Perceptual Monet: 0.1207\n",
      "  Total G Loss: 3.5508\n",
      "Epoch [31/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1987, D_X Fake: 0.1943, D_X Total: 0.1965\n",
      "  D_Y Real: 0.0655, D_Y Fake: 0.1960, D_Y Total: 0.1308\n",
      "Generator Losses:\n",
      "  G Adv: 0.3507, F Adv: 0.2745\n",
      "  Cycle Photo: 0.0651, Cycle Monet: 0.0532\n",
      "  Perceptual Photo: 0.1629, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.4144\n",
      "Epoch [31/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1762, D_X Fake: 0.0868, D_X Total: 0.1315\n",
      "  D_Y Real: 0.0414, D_Y Fake: 0.2987, D_Y Total: 0.1701\n",
      "Generator Losses:\n",
      "  G Adv: 0.3774, F Adv: 0.6202\n",
      "  Cycle Photo: 0.0480, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.3876\n",
      "Epoch [31/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1180, D_X Fake: 0.2120, D_X Total: 0.1650\n",
      "  D_Y Real: 0.1075, D_Y Fake: 0.2274, D_Y Total: 0.1674\n",
      "Generator Losses:\n",
      "  G Adv: 0.4111, F Adv: 0.2669\n",
      "  Cycle Photo: 0.0864, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.2248, Perceptual Monet: 0.1321\n",
      "  Total G Loss: 3.6454\n",
      "Epoch [31/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1153, D_X Fake: 0.1745, D_X Total: 0.1449\n",
      "  D_Y Real: 0.0534, D_Y Fake: 0.0679, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.6229, F Adv: 0.4409\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1513, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.3980\n",
      "Epoch [31/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0657, D_X Fake: 0.3046, D_X Total: 0.1851\n",
      "  D_Y Real: 0.2297, D_Y Fake: 0.0489, D_Y Total: 0.1393\n",
      "Generator Losses:\n",
      "  G Adv: 0.8514, F Adv: 0.2978\n",
      "  Cycle Photo: 0.0520, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1541, Perceptual Monet: 0.1886\n",
      "  Total G Loss: 3.7912\n",
      "Epoch [31/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2349, D_X Fake: 0.1232, D_X Total: 0.1791\n",
      "  D_Y Real: 0.0657, D_Y Fake: 0.1003, D_Y Total: 0.0830\n",
      "Generator Losses:\n",
      "  G Adv: 0.3729, F Adv: 0.7160\n",
      "  Cycle Photo: 0.0641, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1681, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.7751\n",
      "Epoch [31/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1038, D_X Fake: 0.0910, D_X Total: 0.0974\n",
      "  D_Y Real: 0.0457, D_Y Fake: 0.1481, D_Y Total: 0.0969\n",
      "Generator Losses:\n",
      "  G Adv: 0.3812, F Adv: 0.6250\n",
      "  Cycle Photo: 0.0555, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1417\n",
      "  Total G Loss: 3.2802\n",
      "Epoch [31/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0831, D_X Fake: 0.0770, D_X Total: 0.0800\n",
      "  D_Y Real: 0.0800, D_Y Fake: 0.2209, D_Y Total: 0.1505\n",
      "Generator Losses:\n",
      "  G Adv: 0.3711, F Adv: 0.5400\n",
      "  Cycle Photo: 0.0836, Cycle Monet: 0.0564\n",
      "  Perceptual Photo: 0.1576, Perceptual Monet: 0.2338\n",
      "  Total G Loss: 4.2686\n",
      "Epoch [31/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1370, D_X Fake: 0.0982, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.2983, D_Y Total: 0.1728\n",
      "Generator Losses:\n",
      "  G Adv: 0.4501, F Adv: 0.5251\n",
      "  Cycle Photo: 0.0587, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1929, Perceptual Monet: 0.1478\n",
      "  Total G Loss: 3.6203\n",
      "Epoch [31/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1252, D_X Fake: 0.1102, D_X Total: 0.1177\n",
      "  D_Y Real: 0.0646, D_Y Fake: 0.1129, D_Y Total: 0.0887\n",
      "Generator Losses:\n",
      "  G Adv: 0.6965, F Adv: 0.4902\n",
      "  Cycle Photo: 0.0558, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1526, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.5455\n",
      "Epoch [31/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1615, D_X Fake: 0.1030, D_X Total: 0.1322\n",
      "  D_Y Real: 0.0543, D_Y Fake: 0.1028, D_Y Total: 0.0786\n",
      "Generator Losses:\n",
      "  G Adv: 0.3605, F Adv: 0.5173\n",
      "  Cycle Photo: 0.0781, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.2263, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.9618\n",
      "Epoch [32/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1523, D_X Fake: 0.1080, D_X Total: 0.1301\n",
      "  D_Y Real: 0.1421, D_Y Fake: 0.1474, D_Y Total: 0.1447\n",
      "Generator Losses:\n",
      "  G Adv: 0.3317, F Adv: 0.5476\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1974, Perceptual Monet: 0.1794\n",
      "  Total G Loss: 3.6950\n",
      "Epoch [32/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1556, D_X Fake: 0.0401, D_X Total: 0.0979\n",
      "  D_Y Real: 0.1565, D_Y Fake: 0.0566, D_Y Total: 0.1066\n",
      "Generator Losses:\n",
      "  G Adv: 0.5743, F Adv: 0.5942\n",
      "  Cycle Photo: 0.0642, Cycle Monet: 0.0531\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.2128\n",
      "  Total G Loss: 4.2391\n",
      "Epoch [32/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1038, D_X Fake: 0.1524, D_X Total: 0.1281\n",
      "  D_Y Real: 0.0478, D_Y Fake: 0.0672, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.6102, F Adv: 0.5298\n",
      "  Cycle Photo: 0.0718, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.2248, Perceptual Monet: 0.1745\n",
      "  Total G Loss: 4.2596\n",
      "Epoch [32/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0328, D_X Fake: 0.1433, D_X Total: 0.0880\n",
      "  D_Y Real: 0.0884, D_Y Fake: 0.1357, D_Y Total: 0.1120\n",
      "Generator Losses:\n",
      "  G Adv: 0.5314, F Adv: 0.2968\n",
      "  Cycle Photo: 0.0703, Cycle Monet: 0.0628\n",
      "  Perceptual Photo: 0.1916, Perceptual Monet: 0.2002\n",
      "  Total G Loss: 4.1175\n",
      "Epoch [32/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0825, D_X Fake: 0.0299, D_X Total: 0.0562\n",
      "  D_Y Real: 0.1227, D_Y Fake: 0.0674, D_Y Total: 0.0950\n",
      "Generator Losses:\n",
      "  G Adv: 0.8332, F Adv: 0.5928\n",
      "  Cycle Photo: 0.0570, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1988, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 4.1917\n",
      "Epoch [32/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1404, D_X Fake: 0.0539, D_X Total: 0.0972\n",
      "  D_Y Real: 0.1421, D_Y Fake: 0.0492, D_Y Total: 0.0956\n",
      "Generator Losses:\n",
      "  G Adv: 0.8464, F Adv: 0.6990\n",
      "  Cycle Photo: 0.0676, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.2028, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 4.5948\n",
      "Epoch [32/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0301, D_X Fake: 0.1597, D_X Total: 0.0949\n",
      "  D_Y Real: 0.1113, D_Y Fake: 0.0407, D_Y Total: 0.0760\n",
      "Generator Losses:\n",
      "  G Adv: 0.7074, F Adv: 0.4249\n",
      "  Cycle Photo: 0.0616, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.2142, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 4.0261\n",
      "Epoch [32/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1031, D_X Fake: 0.0790, D_X Total: 0.0910\n",
      "  D_Y Real: 0.1873, D_Y Fake: 0.0425, D_Y Total: 0.1149\n",
      "Generator Losses:\n",
      "  G Adv: 1.0603, F Adv: 0.7834\n",
      "  Cycle Photo: 0.0594, Cycle Monet: 0.0476\n",
      "  Perceptual Photo: 0.1781, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 4.6673\n",
      "Epoch [32/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0715, D_X Fake: 0.0906, D_X Total: 0.0811\n",
      "  D_Y Real: 0.1013, D_Y Fake: 0.1418, D_Y Total: 0.1215\n",
      "Generator Losses:\n",
      "  G Adv: 0.6511, F Adv: 0.5132\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.1930\n",
      "  Total G Loss: 3.8440\n",
      "Epoch [32/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1537, D_X Fake: 0.0572, D_X Total: 0.1055\n",
      "  D_Y Real: 0.0907, D_Y Fake: 0.0407, D_Y Total: 0.0657\n",
      "Generator Losses:\n",
      "  G Adv: 0.6314, F Adv: 0.6526\n",
      "  Cycle Photo: 0.0513, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1854, Perceptual Monet: 0.1518\n",
      "  Total G Loss: 3.8285\n",
      "Epoch [32/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0402, D_X Fake: 0.2297, D_X Total: 0.1349\n",
      "  D_Y Real: 0.1958, D_Y Fake: 0.0378, D_Y Total: 0.1168\n",
      "Generator Losses:\n",
      "  G Adv: 0.8684, F Adv: 0.2493\n",
      "  Cycle Photo: 0.0649, Cycle Monet: 0.0567\n",
      "  Perceptual Photo: 0.2033, Perceptual Monet: 0.2330\n",
      "  Total G Loss: 4.5152\n",
      "Epoch [32/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0892, D_X Fake: 0.0773, D_X Total: 0.0833\n",
      "  D_Y Real: 0.0721, D_Y Fake: 0.1741, D_Y Total: 0.1231\n",
      "Generator Losses:\n",
      "  G Adv: 0.5063, F Adv: 0.7707\n",
      "  Cycle Photo: 0.0490, Cycle Monet: 0.0563\n",
      "  Perceptual Photo: 0.1578, Perceptual Monet: 0.2006\n",
      "  Total G Loss: 4.1217\n",
      "Epoch [32/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1568, D_X Fake: 0.0643, D_X Total: 0.1106\n",
      "  D_Y Real: 0.0488, D_Y Fake: 0.1273, D_Y Total: 0.0880\n",
      "Generator Losses:\n",
      "  G Adv: 0.5240, F Adv: 0.5280\n",
      "  Cycle Photo: 0.0582, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1773, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.5986\n",
      "Epoch [32/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1939, D_X Fake: 0.0359, D_X Total: 0.1149\n",
      "  D_Y Real: 0.1109, D_Y Fake: 0.0402, D_Y Total: 0.0756\n",
      "Generator Losses:\n",
      "  G Adv: 0.7391, F Adv: 0.7056\n",
      "  Cycle Photo: 0.0678, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1467, Perceptual Monet: 0.2115\n",
      "  Total G Loss: 4.4276\n",
      "Epoch [32/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2003, D_X Fake: 0.0253, D_X Total: 0.1128\n",
      "  D_Y Real: 0.1267, D_Y Fake: 0.1166, D_Y Total: 0.1217\n",
      "Generator Losses:\n",
      "  G Adv: 0.6226, F Adv: 0.8765\n",
      "  Cycle Photo: 0.0566, Cycle Monet: 0.0551\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.2096\n",
      "  Total G Loss: 4.4952\n",
      "Epoch [32/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1696, D_X Fake: 0.0838, D_X Total: 0.1267\n",
      "  D_Y Real: 0.0606, D_Y Fake: 0.2726, D_Y Total: 0.1666\n",
      "Generator Losses:\n",
      "  G Adv: 0.2993, F Adv: 0.6038\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.5111\n",
      "Epoch [32/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0731, D_X Fake: 0.0493, D_X Total: 0.0612\n",
      "  D_Y Real: 0.0733, D_Y Fake: 0.1135, D_Y Total: 0.0934\n",
      "Generator Losses:\n",
      "  G Adv: 0.6913, F Adv: 0.7557\n",
      "  Cycle Photo: 0.0561, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.1229, Perceptual Monet: 0.2292\n",
      "  Total G Loss: 4.2486\n",
      "Epoch [32/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3073, D_X Fake: 0.0748, D_X Total: 0.1911\n",
      "  D_Y Real: 0.2349, D_Y Fake: 0.0708, D_Y Total: 0.1529\n",
      "Generator Losses:\n",
      "  G Adv: 0.5460, F Adv: 0.6585\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.7200\n",
      "Epoch [32/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2502, D_X Fake: 0.1401, D_X Total: 0.1951\n",
      "  D_Y Real: 0.0702, D_Y Fake: 0.1029, D_Y Total: 0.0866\n",
      "Generator Losses:\n",
      "  G Adv: 0.6313, F Adv: 0.4362\n",
      "  Cycle Photo: 0.0571, Cycle Monet: 0.0464\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1957\n",
      "  Total G Loss: 3.8947\n",
      "Epoch [32/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0931, D_X Fake: 0.1276, D_X Total: 0.1103\n",
      "  D_Y Real: 0.0510, D_Y Fake: 0.0746, D_Y Total: 0.0628\n",
      "Generator Losses:\n",
      "  G Adv: 0.6959, F Adv: 0.4275\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.3947\n",
      "Epoch [32/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0702, D_X Fake: 0.0544, D_X Total: 0.0623\n",
      "  D_Y Real: 0.0483, D_Y Fake: 0.0914, D_Y Total: 0.0698\n",
      "Generator Losses:\n",
      "  G Adv: 0.6449, F Adv: 0.7956\n",
      "  Cycle Photo: 0.0448, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.1839, Perceptual Monet: 0.1991\n",
      "  Total G Loss: 4.3114\n",
      "Epoch [32/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1799, D_X Fake: 0.1735, D_X Total: 0.1767\n",
      "  D_Y Real: 0.0702, D_Y Fake: 0.1131, D_Y Total: 0.0916\n",
      "Generator Losses:\n",
      "  G Adv: 0.6327, F Adv: 0.3573\n",
      "  Cycle Photo: 0.0862, Cycle Monet: 0.0794\n",
      "  Perceptual Photo: 0.2904, Perceptual Monet: 0.3392\n",
      "  Total G Loss: 5.7946\n",
      "Epoch [32/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3343, D_X Fake: 0.1991, D_X Total: 0.2667\n",
      "  D_Y Real: 0.0997, D_Y Fake: 0.1617, D_Y Total: 0.1307\n",
      "Generator Losses:\n",
      "  G Adv: 0.3798, F Adv: 0.3064\n",
      "  Cycle Photo: 0.0634, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.1690, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 3.5206\n",
      "Epoch [32/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2883, D_X Fake: 0.2522, D_X Total: 0.2703\n",
      "  D_Y Real: 0.0335, D_Y Fake: 0.1100, D_Y Total: 0.0718\n",
      "Generator Losses:\n",
      "  G Adv: 0.4344, F Adv: 0.2482\n",
      "  Cycle Photo: 0.0650, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1785, Perceptual Monet: 0.1521\n",
      "  Total G Loss: 3.3643\n",
      "Epoch [33/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2952, D_X Fake: 0.3051, D_X Total: 0.3001\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.3230, D_Y Total: 0.1756\n",
      "Generator Losses:\n",
      "  G Adv: 0.2798, F Adv: 0.2206\n",
      "  Cycle Photo: 0.0594, Cycle Monet: 0.0501\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.1741\n",
      "Epoch [33/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3351, D_X Fake: 0.1998, D_X Total: 0.2674\n",
      "  D_Y Real: 0.0962, D_Y Fake: 0.0939, D_Y Total: 0.0951\n",
      "Generator Losses:\n",
      "  G Adv: 0.6310, F Adv: 0.3183\n",
      "  Cycle Photo: 0.0867, Cycle Monet: 0.0426\n",
      "  Perceptual Photo: 0.1575, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.8576\n",
      "Epoch [33/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2832, D_X Fake: 0.2656, D_X Total: 0.2744\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.3070, D_Y Total: 0.1711\n",
      "Generator Losses:\n",
      "  G Adv: 0.2774, F Adv: 0.2680\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1739, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 2.9796\n",
      "Epoch [33/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2969, D_X Fake: 0.2354, D_X Total: 0.2661\n",
      "  D_Y Real: 0.0651, D_Y Fake: 0.1748, D_Y Total: 0.1200\n",
      "Generator Losses:\n",
      "  G Adv: 0.4497, F Adv: 0.3442\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0480\n",
      "  Perceptual Photo: 0.1746, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 3.4889\n",
      "Epoch [33/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2423, D_X Fake: 0.2195, D_X Total: 0.2309\n",
      "  D_Y Real: 0.0449, D_Y Fake: 0.1370, D_Y Total: 0.0909\n",
      "Generator Losses:\n",
      "  G Adv: 0.4343, F Adv: 0.2712\n",
      "  Cycle Photo: 0.0631, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1731, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.5386\n",
      "Epoch [33/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3373, D_X Fake: 0.2345, D_X Total: 0.2859\n",
      "  D_Y Real: 0.0720, D_Y Fake: 0.0675, D_Y Total: 0.0698\n",
      "Generator Losses:\n",
      "  G Adv: 0.5160, F Adv: 0.2937\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1803, Perceptual Monet: 0.1381\n",
      "  Total G Loss: 3.2724\n",
      "Epoch [33/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2478, D_X Fake: 0.1665, D_X Total: 0.2072\n",
      "  D_Y Real: 0.1263, D_Y Fake: 0.0584, D_Y Total: 0.0924\n",
      "Generator Losses:\n",
      "  G Adv: 0.9175, F Adv: 0.3564\n",
      "  Cycle Photo: 0.0487, Cycle Monet: 0.0440\n",
      "  Perceptual Photo: 0.1421, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 3.7908\n",
      "Epoch [33/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1718, D_X Fake: 0.3145, D_X Total: 0.2432\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.0696, D_Y Total: 0.0669\n",
      "Generator Losses:\n",
      "  G Adv: 0.6998, F Adv: 0.2167\n",
      "  Cycle Photo: 0.0670, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1641, Perceptual Monet: 0.1374\n",
      "  Total G Loss: 3.4999\n",
      "Epoch [33/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3668, D_X Fake: 0.1409, D_X Total: 0.2538\n",
      "  D_Y Real: 0.1729, D_Y Fake: 0.1625, D_Y Total: 0.1677\n",
      "Generator Losses:\n",
      "  G Adv: 0.5630, F Adv: 0.4237\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1870\n",
      "  Total G Loss: 3.5858\n",
      "Epoch [33/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2436, D_X Fake: 0.1948, D_X Total: 0.2192\n",
      "  D_Y Real: 0.0925, D_Y Fake: 0.0646, D_Y Total: 0.0785\n",
      "Generator Losses:\n",
      "  G Adv: 0.6268, F Adv: 0.2914\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.3400\n",
      "Epoch [33/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2881, D_X Fake: 0.3253, D_X Total: 0.3067\n",
      "  D_Y Real: 0.0815, D_Y Fake: 0.1305, D_Y Total: 0.1060\n",
      "Generator Losses:\n",
      "  G Adv: 0.5581, F Adv: 0.1978\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1832, Perceptual Monet: 0.1428\n",
      "  Total G Loss: 3.1324\n",
      "Epoch [33/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1659, D_X Fake: 0.2583, D_X Total: 0.2121\n",
      "  D_Y Real: 0.0863, D_Y Fake: 0.1173, D_Y Total: 0.1018\n",
      "Generator Losses:\n",
      "  G Adv: 0.5041, F Adv: 0.2260\n",
      "  Cycle Photo: 0.0670, Cycle Monet: 0.0449\n",
      "  Perceptual Photo: 0.1911, Perceptual Monet: 0.1505\n",
      "  Total G Loss: 3.5572\n",
      "Epoch [33/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2811, D_X Fake: 0.1923, D_X Total: 0.2367\n",
      "  D_Y Real: 0.0488, D_Y Fake: 0.1138, D_Y Total: 0.0813\n",
      "Generator Losses:\n",
      "  G Adv: 0.4728, F Adv: 0.3153\n",
      "  Cycle Photo: 0.0986, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1792, Perceptual Monet: 0.1402\n",
      "  Total G Loss: 3.7480\n",
      "Epoch [33/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2718, D_X Fake: 0.2272, D_X Total: 0.2495\n",
      "  D_Y Real: 0.1493, D_Y Fake: 0.0877, D_Y Total: 0.1185\n",
      "Generator Losses:\n",
      "  G Adv: 0.7317, F Adv: 0.2673\n",
      "  Cycle Photo: 0.0726, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.2256, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.9977\n",
      "Epoch [33/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2374, D_X Fake: 0.2299, D_X Total: 0.2336\n",
      "  D_Y Real: 0.0820, D_Y Fake: 0.1725, D_Y Total: 0.1272\n",
      "Generator Losses:\n",
      "  G Adv: 0.2807, F Adv: 0.3077\n",
      "  Cycle Photo: 0.0556, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1955, Perceptual Monet: 0.1158\n",
      "  Total G Loss: 2.9467\n",
      "Epoch [33/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3638, D_X Fake: 0.1966, D_X Total: 0.2802\n",
      "  D_Y Real: 0.0557, D_Y Fake: 0.1733, D_Y Total: 0.1145\n",
      "Generator Losses:\n",
      "  G Adv: 0.5147, F Adv: 0.3468\n",
      "  Cycle Photo: 0.0704, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.2303, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.7879\n",
      "Epoch [33/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2728, D_X Fake: 0.2700, D_X Total: 0.2714\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.2571, D_Y Total: 0.1458\n",
      "Generator Losses:\n",
      "  G Adv: 0.4541, F Adv: 0.2470\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1535, Perceptual Monet: 0.1521\n",
      "  Total G Loss: 3.2661\n",
      "Epoch [33/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2421, D_X Fake: 0.1942, D_X Total: 0.2182\n",
      "  D_Y Real: 0.0348, D_Y Fake: 0.1895, D_Y Total: 0.1122\n",
      "Generator Losses:\n",
      "  G Adv: 0.4417, F Adv: 0.3827\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1682, Perceptual Monet: 0.1361\n",
      "  Total G Loss: 3.1655\n",
      "Epoch [33/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2232, D_X Fake: 0.3076, D_X Total: 0.2654\n",
      "  D_Y Real: 0.0582, D_Y Fake: 0.1533, D_Y Total: 0.1058\n",
      "Generator Losses:\n",
      "  G Adv: 0.5665, F Adv: 0.2485\n",
      "  Cycle Photo: 0.0781, Cycle Monet: 0.0534\n",
      "  Perceptual Photo: 0.1795, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.7777\n",
      "Epoch [33/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2046, D_X Fake: 0.2609, D_X Total: 0.2327\n",
      "  D_Y Real: 0.1630, D_Y Fake: 0.0522, D_Y Total: 0.1076\n",
      "Generator Losses:\n",
      "  G Adv: 0.7162, F Adv: 0.2515\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1263\n",
      "  Total G Loss: 2.9857\n",
      "Epoch [33/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3233, D_X Fake: 0.2178, D_X Total: 0.2706\n",
      "  D_Y Real: 0.0368, D_Y Fake: 0.1362, D_Y Total: 0.0865\n",
      "Generator Losses:\n",
      "  G Adv: 0.5962, F Adv: 0.3246\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1863, Perceptual Monet: 0.1355\n",
      "  Total G Loss: 3.4403\n",
      "Epoch [33/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1322, D_X Fake: 0.3009, D_X Total: 0.2165\n",
      "  D_Y Real: 0.1439, D_Y Fake: 0.1124, D_Y Total: 0.1281\n",
      "Generator Losses:\n",
      "  G Adv: 0.6959, F Adv: 0.2042\n",
      "  Cycle Photo: 0.0557, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1407\n",
      "  Total G Loss: 3.2726\n",
      "Epoch [33/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3118, D_X Fake: 0.2109, D_X Total: 0.2613\n",
      "  D_Y Real: 0.0393, D_Y Fake: 0.0524, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.4653, F Adv: 0.3782\n",
      "  Cycle Photo: 0.0659, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1844, Perceptual Monet: 0.1424\n",
      "  Total G Loss: 3.4886\n",
      "Epoch [33/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2598, D_X Fake: 0.4596, D_X Total: 0.3597\n",
      "  D_Y Real: 0.1498, D_Y Fake: 0.0941, D_Y Total: 0.1220\n",
      "Generator Losses:\n",
      "  G Adv: 0.6808, F Adv: 0.2114\n",
      "  Cycle Photo: 0.1186, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1968, Perceptual Monet: 0.1373\n",
      "  Total G Loss: 4.1058\n",
      "Epoch [34/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2497, D_X Fake: 0.1881, D_X Total: 0.2189\n",
      "  D_Y Real: 0.1923, D_Y Fake: 0.0481, D_Y Total: 0.1202\n",
      "Generator Losses:\n",
      "  G Adv: 1.1033, F Adv: 0.2677\n",
      "  Cycle Photo: 0.0598, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1666, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 4.0494\n",
      "Epoch [34/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1078, D_X Fake: 0.3095, D_X Total: 0.2087\n",
      "  D_Y Real: 0.1749, D_Y Fake: 0.0516, D_Y Total: 0.1133\n",
      "Generator Losses:\n",
      "  G Adv: 0.8750, F Adv: 0.1916\n",
      "  Cycle Photo: 0.0682, Cycle Monet: 0.0583\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.7618\n",
      "Epoch [34/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2634, D_X Fake: 0.1989, D_X Total: 0.2311\n",
      "  D_Y Real: 0.0335, D_Y Fake: 0.1685, D_Y Total: 0.1010\n",
      "Generator Losses:\n",
      "  G Adv: 0.3861, F Adv: 0.2487\n",
      "  Cycle Photo: 0.0554, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1514, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.1128\n",
      "Epoch [34/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3145, D_X Fake: 0.1289, D_X Total: 0.2217\n",
      "  D_Y Real: 0.0509, D_Y Fake: 0.1433, D_Y Total: 0.0971\n",
      "Generator Losses:\n",
      "  G Adv: 0.6134, F Adv: 0.4722\n",
      "  Cycle Photo: 0.0622, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1857, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.9138\n",
      "Epoch [34/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2894, D_X Fake: 0.1618, D_X Total: 0.2256\n",
      "  D_Y Real: 0.0952, D_Y Fake: 0.0700, D_Y Total: 0.0826\n",
      "Generator Losses:\n",
      "  G Adv: 0.6269, F Adv: 0.4043\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1420\n",
      "  Total G Loss: 3.3317\n",
      "Epoch [34/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2445, D_X Fake: 0.1916, D_X Total: 0.2181\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.1048, D_Y Total: 0.0693\n",
      "Generator Losses:\n",
      "  G Adv: 0.5507, F Adv: 0.3633\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1426, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.1049\n",
      "Epoch [34/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1662, D_X Fake: 0.1009, D_X Total: 0.1336\n",
      "  D_Y Real: 0.1064, D_Y Fake: 0.0872, D_Y Total: 0.0968\n",
      "Generator Losses:\n",
      "  G Adv: 0.9606, F Adv: 0.4118\n",
      "  Cycle Photo: 0.0570, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1867, Perceptual Monet: 0.1487\n",
      "  Total G Loss: 3.9700\n",
      "Epoch [34/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1740, D_X Fake: 0.1987, D_X Total: 0.1864\n",
      "  D_Y Real: 0.1090, D_Y Fake: 0.1388, D_Y Total: 0.1239\n",
      "Generator Losses:\n",
      "  G Adv: 0.3860, F Adv: 0.3789\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.2061, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 3.4814\n",
      "Epoch [34/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1460, D_X Fake: 0.0626, D_X Total: 0.1043\n",
      "  D_Y Real: 0.1768, D_Y Fake: 0.0499, D_Y Total: 0.1133\n",
      "Generator Losses:\n",
      "  G Adv: 1.1491, F Adv: 0.6859\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.2103, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 4.6810\n",
      "Epoch [34/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0525, D_X Fake: 0.1984, D_X Total: 0.1255\n",
      "  D_Y Real: 0.0524, D_Y Fake: 0.1811, D_Y Total: 0.1167\n",
      "Generator Losses:\n",
      "  G Adv: 0.3804, F Adv: 0.3821\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0473\n",
      "  Perceptual Photo: 0.1541, Perceptual Monet: 0.2042\n",
      "  Total G Loss: 3.5415\n",
      "Epoch [34/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0806, D_X Fake: 0.1134, D_X Total: 0.0970\n",
      "  D_Y Real: 0.0974, D_Y Fake: 0.1284, D_Y Total: 0.1129\n",
      "Generator Losses:\n",
      "  G Adv: 0.5626, F Adv: 0.4223\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.1836\n",
      "  Total G Loss: 3.4683\n",
      "Epoch [34/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0684, D_X Fake: 0.1065, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0925, D_Y Fake: 0.1777, D_Y Total: 0.1351\n",
      "Generator Losses:\n",
      "  G Adv: 0.4028, F Adv: 0.4487\n",
      "  Cycle Photo: 0.0694, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1903, Perceptual Monet: 0.1969\n",
      "  Total G Loss: 3.9099\n",
      "Epoch [34/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0518, D_X Fake: 0.1640, D_X Total: 0.1079\n",
      "  D_Y Real: 0.2212, D_Y Fake: 0.0343, D_Y Total: 0.1278\n",
      "Generator Losses:\n",
      "  G Adv: 0.8535, F Adv: 0.3826\n",
      "  Cycle Photo: 0.0626, Cycle Monet: 0.0479\n",
      "  Perceptual Photo: 0.1661, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.9923\n",
      "Epoch [34/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0713, D_X Fake: 0.1682, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0432, D_Y Fake: 0.3962, D_Y Total: 0.2197\n",
      "Generator Losses:\n",
      "  G Adv: 0.2186, F Adv: 0.4068\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1519, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.1771\n",
      "Epoch [34/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0440, D_X Fake: 0.1081, D_X Total: 0.0760\n",
      "  D_Y Real: 0.0452, D_Y Fake: 0.1302, D_Y Total: 0.0877\n",
      "Generator Losses:\n",
      "  G Adv: 0.4348, F Adv: 0.4670\n",
      "  Cycle Photo: 0.0710, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1755, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 3.7688\n",
      "Epoch [34/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0858, D_X Fake: 0.1482, D_X Total: 0.1170\n",
      "  D_Y Real: 0.1492, D_Y Fake: 0.1360, D_Y Total: 0.1426\n",
      "Generator Losses:\n",
      "  G Adv: 0.7088, F Adv: 0.3862\n",
      "  Cycle Photo: 0.1048, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 4.2692\n",
      "Epoch [34/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0848, D_X Fake: 0.0531, D_X Total: 0.0690\n",
      "  D_Y Real: 0.0998, D_Y Fake: 0.1516, D_Y Total: 0.1257\n",
      "Generator Losses:\n",
      "  G Adv: 0.4910, F Adv: 0.4690\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0499\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 3.6344\n",
      "Epoch [34/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1553, D_X Fake: 0.0357, D_X Total: 0.0955\n",
      "  D_Y Real: 0.0630, D_Y Fake: 0.2152, D_Y Total: 0.1391\n",
      "Generator Losses:\n",
      "  G Adv: 0.4817, F Adv: 0.8053\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1532, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.7330\n",
      "Epoch [34/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0632, D_X Fake: 0.1355, D_X Total: 0.0994\n",
      "  D_Y Real: 0.2768, D_Y Fake: 0.0859, D_Y Total: 0.1814\n",
      "Generator Losses:\n",
      "  G Adv: 0.8315, F Adv: 0.5045\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1557, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.9421\n",
      "Epoch [34/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1073, D_X Fake: 0.0539, D_X Total: 0.0806\n",
      "  D_Y Real: 0.1014, D_Y Fake: 0.1282, D_Y Total: 0.1148\n",
      "Generator Losses:\n",
      "  G Adv: 0.4524, F Adv: 0.5683\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0432\n",
      "  Perceptual Photo: 0.1713, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.6669\n",
      "Epoch [34/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0278, D_X Fake: 0.0968, D_X Total: 0.0623\n",
      "  D_Y Real: 0.0514, D_Y Fake: 0.1989, D_Y Total: 0.1252\n",
      "Generator Losses:\n",
      "  G Adv: 0.4741, F Adv: 0.2757\n",
      "  Cycle Photo: 0.0577, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1526, Perceptual Monet: 0.1914\n",
      "  Total G Loss: 3.5013\n",
      "Epoch [34/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0680, D_X Fake: 0.2005, D_X Total: 0.1342\n",
      "  D_Y Real: 0.0722, D_Y Fake: 0.0687, D_Y Total: 0.0705\n",
      "Generator Losses:\n",
      "  G Adv: 0.8909, F Adv: 0.3806\n",
      "  Cycle Photo: 0.1065, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.2744, Perceptual Monet: 0.1472\n",
      "  Total G Loss: 4.9221\n",
      "Epoch [34/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0441, D_X Fake: 0.1683, D_X Total: 0.1062\n",
      "  D_Y Real: 0.1955, D_Y Fake: 0.0601, D_Y Total: 0.1278\n",
      "Generator Losses:\n",
      "  G Adv: 0.6851, F Adv: 0.4385\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.4255\n",
      "Epoch [34/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1300, D_X Fake: 0.2409, D_X Total: 0.1855\n",
      "  D_Y Real: 0.0576, D_Y Fake: 0.1326, D_Y Total: 0.0951\n",
      "Generator Losses:\n",
      "  G Adv: 0.5879, F Adv: 0.3256\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0465\n",
      "  Perceptual Photo: 0.1433, Perceptual Monet: 0.1759\n",
      "  Total G Loss: 3.4799\n",
      "Epoch [35/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1578, D_X Fake: 0.0487, D_X Total: 0.1033\n",
      "  D_Y Real: 0.1152, D_Y Fake: 0.0968, D_Y Total: 0.1060\n",
      "Generator Losses:\n",
      "  G Adv: 0.6494, F Adv: 0.6210\n",
      "  Cycle Photo: 0.0709, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1517\n",
      "  Total G Loss: 3.8280\n",
      "Epoch [35/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1044, D_X Fake: 0.2229, D_X Total: 0.1637\n",
      "  D_Y Real: 0.1236, D_Y Fake: 0.0815, D_Y Total: 0.1026\n",
      "Generator Losses:\n",
      "  G Adv: 0.5869, F Adv: 0.3471\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0593\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1973\n",
      "  Total G Loss: 3.7058\n",
      "Epoch [35/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0350, D_X Fake: 0.1381, D_X Total: 0.0865\n",
      "  D_Y Real: 0.0502, D_Y Fake: 0.2914, D_Y Total: 0.1708\n",
      "Generator Losses:\n",
      "  G Adv: 0.2295, F Adv: 0.4425\n",
      "  Cycle Photo: 0.0645, Cycle Monet: 0.0726\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.2057\n",
      "  Total G Loss: 3.9854\n",
      "Epoch [35/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1783, D_X Fake: 0.0473, D_X Total: 0.1128\n",
      "  D_Y Real: 0.0339, D_Y Fake: 0.0957, D_Y Total: 0.0648\n",
      "Generator Losses:\n",
      "  G Adv: 0.4984, F Adv: 0.6651\n",
      "  Cycle Photo: 0.0644, Cycle Monet: 0.0590\n",
      "  Perceptual Photo: 0.1596, Perceptual Monet: 0.2210\n",
      "  Total G Loss: 4.2996\n",
      "Epoch [35/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0585, D_X Fake: 0.1341, D_X Total: 0.0963\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.2255, D_Y Total: 0.1287\n",
      "Generator Losses:\n",
      "  G Adv: 0.4281, F Adv: 0.3462\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1400\n",
      "  Total G Loss: 3.1774\n",
      "Epoch [35/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1010, D_X Fake: 0.1417, D_X Total: 0.1214\n",
      "  D_Y Real: 0.1100, D_Y Fake: 0.1034, D_Y Total: 0.1067\n",
      "Generator Losses:\n",
      "  G Adv: 0.9611, F Adv: 0.3415\n",
      "  Cycle Photo: 0.0536, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1843, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.9688\n",
      "Epoch [35/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0568, D_X Fake: 0.1567, D_X Total: 0.1068\n",
      "  D_Y Real: 0.1759, D_Y Fake: 0.0604, D_Y Total: 0.1181\n",
      "Generator Losses:\n",
      "  G Adv: 0.7407, F Adv: 0.4509\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.6509\n",
      "Epoch [35/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1043, D_X Fake: 0.0856, D_X Total: 0.0950\n",
      "  D_Y Real: 0.1291, D_Y Fake: 0.2155, D_Y Total: 0.1723\n",
      "Generator Losses:\n",
      "  G Adv: 0.2706, F Adv: 0.5887\n",
      "  Cycle Photo: 0.0548, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1534\n",
      "  Total G Loss: 3.2820\n",
      "Epoch [35/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0500, D_X Fake: 0.3112, D_X Total: 0.1806\n",
      "  D_Y Real: 0.1369, D_Y Fake: 0.0838, D_Y Total: 0.1104\n",
      "Generator Losses:\n",
      "  G Adv: 0.5891, F Adv: 0.2731\n",
      "  Cycle Photo: 0.0670, Cycle Monet: 0.0604\n",
      "  Perceptual Photo: 0.1720, Perceptual Monet: 0.1941\n",
      "  Total G Loss: 3.9661\n",
      "Epoch [35/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0359, D_X Fake: 0.0808, D_X Total: 0.0584\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0788, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.5254, F Adv: 0.4131\n",
      "  Cycle Photo: 0.0550, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1737\n",
      "  Total G Loss: 3.5765\n",
      "Epoch [35/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0967, D_X Fake: 0.0771, D_X Total: 0.0869\n",
      "  D_Y Real: 0.2549, D_Y Fake: 0.0723, D_Y Total: 0.1636\n",
      "Generator Losses:\n",
      "  G Adv: 0.6779, F Adv: 0.6454\n",
      "  Cycle Photo: 0.0665, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1933, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 4.2829\n",
      "Epoch [35/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0743, D_X Fake: 0.1013, D_X Total: 0.0878\n",
      "  D_Y Real: 0.1744, D_Y Fake: 0.0597, D_Y Total: 0.1171\n",
      "Generator Losses:\n",
      "  G Adv: 1.1022, F Adv: 0.4466\n",
      "  Cycle Photo: 0.0615, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1655\n",
      "  Total G Loss: 4.0867\n",
      "Epoch [35/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0720, D_X Fake: 0.0641, D_X Total: 0.0680\n",
      "  D_Y Real: 0.1855, D_Y Fake: 0.1164, D_Y Total: 0.1510\n",
      "Generator Losses:\n",
      "  G Adv: 0.6777, F Adv: 0.7215\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0456\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.1798\n",
      "  Total G Loss: 4.0497\n",
      "Epoch [35/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1829, D_X Fake: 0.0602, D_X Total: 0.1215\n",
      "  D_Y Real: 0.1082, D_Y Fake: 0.0908, D_Y Total: 0.0995\n",
      "Generator Losses:\n",
      "  G Adv: 0.6939, F Adv: 0.5013\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0472\n",
      "  Perceptual Photo: 0.1396, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.6808\n",
      "Epoch [35/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0736, D_X Fake: 0.2438, D_X Total: 0.1587\n",
      "  D_Y Real: 0.1411, D_Y Fake: 0.0916, D_Y Total: 0.1163\n",
      "Generator Losses:\n",
      "  G Adv: 0.7898, F Adv: 0.3147\n",
      "  Cycle Photo: 0.0860, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1805, Perceptual Monet: 0.1926\n",
      "  Total G Loss: 4.2456\n",
      "Epoch [35/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2604, D_X Fake: 0.1156, D_X Total: 0.1880\n",
      "  D_Y Real: 0.1049, D_Y Fake: 0.2890, D_Y Total: 0.1969\n",
      "Generator Losses:\n",
      "  G Adv: 0.1981, F Adv: 0.5633\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1640\n",
      "  Total G Loss: 2.9970\n",
      "Epoch [35/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0783, D_X Fake: 0.0805, D_X Total: 0.0794\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.1837, D_Y Total: 0.1064\n",
      "Generator Losses:\n",
      "  G Adv: 0.4324, F Adv: 0.6185\n",
      "  Cycle Photo: 0.0772, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.1949\n",
      "  Total G Loss: 4.1584\n",
      "Epoch [35/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1023, D_X Fake: 0.1885, D_X Total: 0.1454\n",
      "  D_Y Real: 0.0853, D_Y Fake: 0.0838, D_Y Total: 0.0845\n",
      "Generator Losses:\n",
      "  G Adv: 0.6232, F Adv: 0.3619\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.2096, Perceptual Monet: 0.1535\n",
      "  Total G Loss: 3.6562\n",
      "Epoch [35/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1462, D_X Fake: 0.0715, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0512, D_Y Fake: 0.1670, D_Y Total: 0.1091\n",
      "Generator Losses:\n",
      "  G Adv: 0.4038, F Adv: 0.3412\n",
      "  Cycle Photo: 0.0451, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.2969\n",
      "Epoch [35/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0388, D_X Fake: 0.3772, D_X Total: 0.2080\n",
      "  D_Y Real: 0.1140, D_Y Fake: 0.1331, D_Y Total: 0.1235\n",
      "Generator Losses:\n",
      "  G Adv: 0.5577, F Adv: 0.2174\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0568\n",
      "  Perceptual Photo: 0.1626, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.5427\n",
      "Epoch [35/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0883, D_X Fake: 0.1735, D_X Total: 0.1309\n",
      "  D_Y Real: 0.2373, D_Y Fake: 0.0666, D_Y Total: 0.1520\n",
      "Generator Losses:\n",
      "  G Adv: 0.6074, F Adv: 0.4507\n",
      "  Cycle Photo: 0.0520, Cycle Monet: 0.0474\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 3.7067\n",
      "Epoch [35/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0579, D_X Fake: 0.1008, D_X Total: 0.0793\n",
      "  D_Y Real: 0.0623, D_Y Fake: 0.0968, D_Y Total: 0.0796\n",
      "Generator Losses:\n",
      "  G Adv: 0.7060, F Adv: 0.4957\n",
      "  Cycle Photo: 0.0553, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.1435, Perceptual Monet: 0.1976\n",
      "  Total G Loss: 3.9015\n",
      "Epoch [35/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0469, D_X Fake: 0.0563, D_X Total: 0.0516\n",
      "  D_Y Real: 0.0671, D_Y Fake: 0.2031, D_Y Total: 0.1351\n",
      "Generator Losses:\n",
      "  G Adv: 0.4555, F Adv: 0.7731\n",
      "  Cycle Photo: 0.0422, Cycle Monet: 0.0510\n",
      "  Perceptual Photo: 0.1212, Perceptual Monet: 0.2158\n",
      "  Total G Loss: 3.8449\n",
      "Epoch [35/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1103, D_X Fake: 0.0382, D_X Total: 0.0742\n",
      "  D_Y Real: 0.1150, D_Y Fake: 0.0573, D_Y Total: 0.0862\n",
      "Generator Losses:\n",
      "  G Adv: 0.7704, F Adv: 0.5123\n",
      "  Cycle Photo: 0.0580, Cycle Monet: 0.0531\n",
      "  Perceptual Photo: 0.1550, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 4.0522\n",
      "Epoch [36/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2071, D_X Fake: 0.0654, D_X Total: 0.1363\n",
      "  D_Y Real: 0.0766, D_Y Fake: 0.1986, D_Y Total: 0.1376\n",
      "Generator Losses:\n",
      "  G Adv: 0.3554, F Adv: 0.6396\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0565\n",
      "  Perceptual Photo: 0.1739, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.7610\n",
      "Epoch [36/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0863, D_X Fake: 0.0598, D_X Total: 0.0731\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.2220, D_Y Total: 0.1270\n",
      "Generator Losses:\n",
      "  G Adv: 0.5962, F Adv: 0.5619\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1608\n",
      "  Total G Loss: 3.4443\n",
      "Epoch [36/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1704, D_X Fake: 0.0304, D_X Total: 0.1004\n",
      "  D_Y Real: 0.0693, D_Y Fake: 0.2648, D_Y Total: 0.1670\n",
      "Generator Losses:\n",
      "  G Adv: 0.2998, F Adv: 0.4881\n",
      "  Cycle Photo: 0.0857, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.2023, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.7823\n",
      "Epoch [36/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1484, D_X Fake: 0.0425, D_X Total: 0.0955\n",
      "  D_Y Real: 0.0500, D_Y Fake: 0.0729, D_Y Total: 0.0615\n",
      "Generator Losses:\n",
      "  G Adv: 0.7167, F Adv: 0.8526\n",
      "  Cycle Photo: 0.0658, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1811, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 4.4213\n",
      "Epoch [36/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0659, D_X Fake: 0.0933, D_X Total: 0.0796\n",
      "  D_Y Real: 0.0515, D_Y Fake: 0.0523, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.6612, F Adv: 0.7567\n",
      "  Cycle Photo: 0.0437, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1249, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.7721\n",
      "Epoch [36/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3730, D_X Fake: 0.0490, D_X Total: 0.2110\n",
      "  D_Y Real: 0.0629, D_Y Fake: 0.1024, D_Y Total: 0.0827\n",
      "Generator Losses:\n",
      "  G Adv: 0.5322, F Adv: 1.0789\n",
      "  Cycle Photo: 0.0540, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.2030, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 4.2478\n",
      "Epoch [36/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1174, D_X Fake: 0.0504, D_X Total: 0.0839\n",
      "  D_Y Real: 0.0648, D_Y Fake: 0.1882, D_Y Total: 0.1265\n",
      "Generator Losses:\n",
      "  G Adv: 0.4764, F Adv: 0.5435\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0471\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1971\n",
      "  Total G Loss: 3.7059\n",
      "Epoch [36/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2822, D_X Fake: 0.0462, D_X Total: 0.1642\n",
      "  D_Y Real: 0.1296, D_Y Fake: 0.2193, D_Y Total: 0.1745\n",
      "Generator Losses:\n",
      "  G Adv: 0.3917, F Adv: 0.9146\n",
      "  Cycle Photo: 0.0616, Cycle Monet: 0.0544\n",
      "  Perceptual Photo: 0.1916, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 4.3482\n",
      "Epoch [36/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0623, D_X Fake: 0.1676, D_X Total: 0.1149\n",
      "  D_Y Real: 0.3090, D_Y Fake: 0.0917, D_Y Total: 0.2003\n",
      "Generator Losses:\n",
      "  G Adv: 0.9914, F Adv: 0.3484\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1684, Perceptual Monet: 0.1984\n",
      "  Total G Loss: 4.0370\n",
      "Epoch [36/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1476, D_X Fake: 0.1386, D_X Total: 0.1431\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.1317, D_Y Total: 0.0822\n",
      "Generator Losses:\n",
      "  G Adv: 0.2747, F Adv: 0.3785\n",
      "  Cycle Photo: 0.0646, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1944, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.4835\n",
      "Epoch [36/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0474, D_X Fake: 0.3230, D_X Total: 0.1852\n",
      "  D_Y Real: 0.1791, D_Y Fake: 0.0756, D_Y Total: 0.1273\n",
      "Generator Losses:\n",
      "  G Adv: 0.7046, F Adv: 0.1142\n",
      "  Cycle Photo: 0.0508, Cycle Monet: 0.0548\n",
      "  Perceptual Photo: 0.1475, Perceptual Monet: 0.1932\n",
      "  Total G Loss: 3.5786\n",
      "Epoch [36/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0937, D_X Fake: 0.0988, D_X Total: 0.0962\n",
      "  D_Y Real: 0.1248, D_Y Fake: 0.2192, D_Y Total: 0.1720\n",
      "Generator Losses:\n",
      "  G Adv: 0.4125, F Adv: 0.7419\n",
      "  Cycle Photo: 0.0490, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1220, Perceptual Monet: 0.1811\n",
      "  Total G Loss: 3.5269\n",
      "Epoch [36/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0600, D_X Fake: 0.3022, D_X Total: 0.1811\n",
      "  D_Y Real: 0.1232, D_Y Fake: 0.0807, D_Y Total: 0.1019\n",
      "Generator Losses:\n",
      "  G Adv: 0.5624, F Adv: 0.3518\n",
      "  Cycle Photo: 0.0519, Cycle Monet: 0.0441\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1900\n",
      "  Total G Loss: 3.6196\n",
      "Epoch [36/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0388, D_X Fake: 0.0483, D_X Total: 0.0436\n",
      "  D_Y Real: 0.0707, D_Y Fake: 0.1332, D_Y Total: 0.1019\n",
      "Generator Losses:\n",
      "  G Adv: 0.6928, F Adv: 0.7551\n",
      "  Cycle Photo: 0.0574, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1810, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 4.0839\n",
      "Epoch [36/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2645, D_X Fake: 0.0528, D_X Total: 0.1587\n",
      "  D_Y Real: 0.0539, D_Y Fake: 0.1971, D_Y Total: 0.1255\n",
      "Generator Losses:\n",
      "  G Adv: 0.5834, F Adv: 0.6083\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1971, Perceptual Monet: 0.1897\n",
      "  Total G Loss: 4.0810\n",
      "Epoch [36/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1251, D_X Fake: 0.0474, D_X Total: 0.0862\n",
      "  D_Y Real: 0.1040, D_Y Fake: 0.2641, D_Y Total: 0.1840\n",
      "Generator Losses:\n",
      "  G Adv: 0.6020, F Adv: 0.7448\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0448\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1799\n",
      "  Total G Loss: 3.6978\n",
      "Epoch [36/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0474, D_X Fake: 0.2220, D_X Total: 0.1347\n",
      "  D_Y Real: 0.0417, D_Y Fake: 0.2203, D_Y Total: 0.1310\n",
      "Generator Losses:\n",
      "  G Adv: 0.3998, F Adv: 0.2513\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1873, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.0538\n",
      "Epoch [36/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1106, D_X Fake: 0.1018, D_X Total: 0.1062\n",
      "  D_Y Real: 0.2038, D_Y Fake: 0.0472, D_Y Total: 0.1255\n",
      "Generator Losses:\n",
      "  G Adv: 0.8422, F Adv: 0.5813\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0550\n",
      "  Perceptual Photo: 0.1809, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 4.2567\n",
      "Epoch [36/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0991, D_X Fake: 0.1295, D_X Total: 0.1143\n",
      "  D_Y Real: 0.1387, D_Y Fake: 0.1008, D_Y Total: 0.1198\n",
      "Generator Losses:\n",
      "  G Adv: 0.5301, F Adv: 0.5455\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1843, Perceptual Monet: 0.1575\n",
      "  Total G Loss: 3.5725\n",
      "Epoch [36/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0265, D_X Fake: 0.1665, D_X Total: 0.0965\n",
      "  D_Y Real: 0.0666, D_Y Fake: 0.0927, D_Y Total: 0.0797\n",
      "Generator Losses:\n",
      "  G Adv: 0.9695, F Adv: 0.4355\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.1999\n",
      "  Total G Loss: 4.1855\n",
      "Epoch [36/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0549, D_X Fake: 0.1961, D_X Total: 0.1255\n",
      "  D_Y Real: 0.0831, D_Y Fake: 0.0703, D_Y Total: 0.0767\n",
      "Generator Losses:\n",
      "  G Adv: 0.7658, F Adv: 0.3887\n",
      "  Cycle Photo: 0.0768, Cycle Monet: 0.0548\n",
      "  Perceptual Photo: 0.1820, Perceptual Monet: 0.1946\n",
      "  Total G Loss: 4.3528\n",
      "Epoch [36/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0973, D_X Fake: 0.1030, D_X Total: 0.1001\n",
      "  D_Y Real: 0.1060, D_Y Fake: 0.0687, D_Y Total: 0.0873\n",
      "Generator Losses:\n",
      "  G Adv: 0.6773, F Adv: 0.3637\n",
      "  Cycle Photo: 0.0519, Cycle Monet: 0.0726\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 4.0872\n",
      "Epoch [36/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3344, D_X Fake: 0.0413, D_X Total: 0.1879\n",
      "  D_Y Real: 0.0541, D_Y Fake: 0.2309, D_Y Total: 0.1425\n",
      "Generator Losses:\n",
      "  G Adv: 0.2769, F Adv: 0.8021\n",
      "  Cycle Photo: 0.0591, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1978, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.8050\n",
      "Epoch [36/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3032, D_X Fake: 0.0334, D_X Total: 0.1683\n",
      "  D_Y Real: 0.1197, D_Y Fake: 0.0508, D_Y Total: 0.0853\n",
      "Generator Losses:\n",
      "  G Adv: 0.7745, F Adv: 0.7711\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0570\n",
      "  Perceptual Photo: 0.2127, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 4.5865\n",
      "Epoch [37/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0965, D_X Fake: 0.1508, D_X Total: 0.1236\n",
      "  D_Y Real: 0.1283, D_Y Fake: 0.1538, D_Y Total: 0.1411\n",
      "Generator Losses:\n",
      "  G Adv: 0.4286, F Adv: 0.3972\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1689, Perceptual Monet: 0.1912\n",
      "  Total G Loss: 3.4390\n",
      "Epoch [37/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0841, D_X Fake: 0.1210, D_X Total: 0.1026\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.0756, D_Y Total: 0.0589\n",
      "Generator Losses:\n",
      "  G Adv: 0.3493, F Adv: 0.3461\n",
      "  Cycle Photo: 0.0600, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.1911\n",
      "Epoch [37/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2261, D_X Fake: 0.0602, D_X Total: 0.1432\n",
      "  D_Y Real: 0.2094, D_Y Fake: 0.0655, D_Y Total: 0.1374\n",
      "Generator Losses:\n",
      "  G Adv: 0.7367, F Adv: 0.7719\n",
      "  Cycle Photo: 0.0506, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1835, Perceptual Monet: 0.1930\n",
      "  Total G Loss: 4.4065\n",
      "Epoch [37/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1962, D_X Fake: 0.0294, D_X Total: 0.1128\n",
      "  D_Y Real: 0.1210, D_Y Fake: 0.1359, D_Y Total: 0.1284\n",
      "Generator Losses:\n",
      "  G Adv: 0.5350, F Adv: 0.6300\n",
      "  Cycle Photo: 0.0738, Cycle Monet: 0.0521\n",
      "  Perceptual Photo: 0.1874, Perceptual Monet: 0.1823\n",
      "  Total G Loss: 4.2716\n",
      "Epoch [37/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1515, D_X Fake: 0.0369, D_X Total: 0.0942\n",
      "  D_Y Real: 0.0387, D_Y Fake: 0.1291, D_Y Total: 0.0839\n",
      "Generator Losses:\n",
      "  G Adv: 0.4672, F Adv: 0.6415\n",
      "  Cycle Photo: 0.0515, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1937, Perceptual Monet: 0.1467\n",
      "  Total G Loss: 3.6484\n",
      "Epoch [37/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0801, D_X Fake: 0.1396, D_X Total: 0.1098\n",
      "  D_Y Real: 0.0712, D_Y Fake: 0.1073, D_Y Total: 0.0893\n",
      "Generator Losses:\n",
      "  G Adv: 0.7235, F Adv: 0.4795\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1680, Perceptual Monet: 0.1978\n",
      "  Total G Loss: 3.9449\n",
      "Epoch [37/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1882, D_X Fake: 0.0295, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0771, D_Y Fake: 0.1674, D_Y Total: 0.1222\n",
      "Generator Losses:\n",
      "  G Adv: 0.3971, F Adv: 0.6582\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.1830, Perceptual Monet: 0.1948\n",
      "  Total G Loss: 3.9309\n",
      "Epoch [37/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0946, D_X Fake: 0.0736, D_X Total: 0.0841\n",
      "  D_Y Real: 0.0559, D_Y Fake: 0.1075, D_Y Total: 0.0817\n",
      "Generator Losses:\n",
      "  G Adv: 0.6308, F Adv: 0.8005\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0505\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1728\n",
      "  Total G Loss: 4.1366\n",
      "Epoch [37/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2066, D_X Fake: 0.0507, D_X Total: 0.1286\n",
      "  D_Y Real: 0.1743, D_Y Fake: 0.0860, D_Y Total: 0.1301\n",
      "Generator Losses:\n",
      "  G Adv: 0.7353, F Adv: 0.6259\n",
      "  Cycle Photo: 0.0640, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1653, Perceptual Monet: 0.1974\n",
      "  Total G Loss: 4.2443\n",
      "Epoch [37/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0429, D_X Fake: 0.1153, D_X Total: 0.0791\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0779, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.4093, F Adv: 0.4057\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0511\n",
      "  Perceptual Photo: 0.1720, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.6001\n",
      "Epoch [37/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0786, D_X Fake: 0.1371, D_X Total: 0.1078\n",
      "  D_Y Real: 0.1469, D_Y Fake: 0.1088, D_Y Total: 0.1278\n",
      "Generator Losses:\n",
      "  G Adv: 0.7016, F Adv: 0.5398\n",
      "  Cycle Photo: 0.0571, Cycle Monet: 0.0507\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1946\n",
      "  Total G Loss: 4.0184\n",
      "Epoch [37/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1612, D_X Fake: 0.0416, D_X Total: 0.1014\n",
      "  D_Y Real: 0.0778, D_Y Fake: 0.0717, D_Y Total: 0.0747\n",
      "Generator Losses:\n",
      "  G Adv: 0.7087, F Adv: 0.6644\n",
      "  Cycle Photo: 0.0607, Cycle Monet: 0.0519\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.2050\n",
      "  Total G Loss: 4.2262\n",
      "Epoch [37/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0428, D_X Fake: 0.2176, D_X Total: 0.1302\n",
      "  D_Y Real: 0.1998, D_Y Fake: 0.0676, D_Y Total: 0.1337\n",
      "Generator Losses:\n",
      "  G Adv: 0.9981, F Adv: 0.3579\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.1776, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 4.1004\n",
      "Epoch [37/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1905, D_X Fake: 0.4081, D_X Total: 0.2993\n",
      "  D_Y Real: 0.1167, D_Y Fake: 0.0354, D_Y Total: 0.0761\n",
      "Generator Losses:\n",
      "  G Adv: 0.9761, F Adv: 0.3643\n",
      "  Cycle Photo: 0.1327, Cycle Monet: 0.0850\n",
      "  Perceptual Photo: 0.2009, Perceptual Monet: 0.2398\n",
      "  Total G Loss: 5.7206\n",
      "Epoch [37/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3028, D_X Fake: 0.2519, D_X Total: 0.2774\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.1494, D_Y Total: 0.0935\n",
      "Generator Losses:\n",
      "  G Adv: 0.4932, F Adv: 0.3584\n",
      "  Cycle Photo: 0.0674, Cycle Monet: 0.0413\n",
      "  Perceptual Photo: 0.2000, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.7325\n",
      "Epoch [37/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3382, D_X Fake: 0.3492, D_X Total: 0.3437\n",
      "  D_Y Real: 0.0891, D_Y Fake: 0.0509, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.7369, F Adv: 0.2279\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0553\n",
      "  Perceptual Photo: 0.1926, Perceptual Monet: 0.1647\n",
      "  Total G Loss: 3.7539\n",
      "Epoch [37/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1845, D_X Fake: 0.2982, D_X Total: 0.2414\n",
      "  D_Y Real: 0.0590, D_Y Fake: 0.0695, D_Y Total: 0.0642\n",
      "Generator Losses:\n",
      "  G Adv: 0.4217, F Adv: 0.2547\n",
      "  Cycle Photo: 0.0648, Cycle Monet: 0.0464\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.5490\n",
      "Epoch [37/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2626, D_X Fake: 0.2516, D_X Total: 0.2571\n",
      "  D_Y Real: 0.2206, D_Y Fake: 0.1405, D_Y Total: 0.1805\n",
      "Generator Losses:\n",
      "  G Adv: 0.7237, F Adv: 0.2643\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.2362\n",
      "Epoch [37/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2156, D_X Fake: 0.2905, D_X Total: 0.2530\n",
      "  D_Y Real: 0.0641, D_Y Fake: 0.0752, D_Y Total: 0.0696\n",
      "Generator Losses:\n",
      "  G Adv: 0.7840, F Adv: 0.2313\n",
      "  Cycle Photo: 0.0610, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1838, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.6783\n",
      "Epoch [37/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2242, D_X Fake: 0.2819, D_X Total: 0.2531\n",
      "  D_Y Real: 0.0639, D_Y Fake: 0.1099, D_Y Total: 0.0869\n",
      "Generator Losses:\n",
      "  G Adv: 0.5472, F Adv: 0.2445\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.0508\n",
      "Epoch [37/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2295, D_X Fake: 0.2585, D_X Total: 0.2440\n",
      "  D_Y Real: 0.1979, D_Y Fake: 0.0749, D_Y Total: 0.1364\n",
      "Generator Losses:\n",
      "  G Adv: 0.8759, F Adv: 0.2749\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.1926\n",
      "  Total G Loss: 3.8708\n",
      "Epoch [37/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2219, D_X Fake: 0.3115, D_X Total: 0.2667\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0443, D_Y Total: 0.0450\n",
      "Generator Losses:\n",
      "  G Adv: 0.8074, F Adv: 0.2017\n",
      "  Cycle Photo: 0.0671, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1759, Perceptual Monet: 0.1318\n",
      "  Total G Loss: 3.6203\n",
      "Epoch [37/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2374, D_X Fake: 0.2599, D_X Total: 0.2486\n",
      "  D_Y Real: 0.1237, D_Y Fake: 0.0756, D_Y Total: 0.0996\n",
      "Generator Losses:\n",
      "  G Adv: 0.7093, F Adv: 0.3134\n",
      "  Cycle Photo: 0.0452, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1584, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.3562\n",
      "Epoch [37/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3080, D_X Fake: 0.2848, D_X Total: 0.2964\n",
      "  D_Y Real: 0.1014, D_Y Fake: 0.0844, D_Y Total: 0.0929\n",
      "Generator Losses:\n",
      "  G Adv: 0.5928, F Adv: 0.2218\n",
      "  Cycle Photo: 0.0577, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.2240, Perceptual Monet: 0.1464\n",
      "  Total G Loss: 3.6585\n",
      "Epoch [38/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2603, D_X Fake: 0.2829, D_X Total: 0.2716\n",
      "  D_Y Real: 0.1569, D_Y Fake: 0.0599, D_Y Total: 0.1084\n",
      "Generator Losses:\n",
      "  G Adv: 0.6377, F Adv: 0.2130\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1472, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.2843\n",
      "Epoch [38/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2545, D_X Fake: 0.2449, D_X Total: 0.2497\n",
      "  D_Y Real: 0.0608, D_Y Fake: 0.1281, D_Y Total: 0.0945\n",
      "Generator Losses:\n",
      "  G Adv: 0.4254, F Adv: 0.3637\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1699, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.1423\n",
      "Epoch [38/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1507, D_X Fake: 0.2603, D_X Total: 0.2055\n",
      "  D_Y Real: 0.0617, D_Y Fake: 0.1304, D_Y Total: 0.0961\n",
      "Generator Losses:\n",
      "  G Adv: 0.5264, F Adv: 0.2531\n",
      "  Cycle Photo: 0.1216, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1478\n",
      "  Total G Loss: 3.8358\n",
      "Epoch [38/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2948, D_X Fake: 0.2516, D_X Total: 0.2732\n",
      "  D_Y Real: 0.2324, D_Y Fake: 0.0578, D_Y Total: 0.1451\n",
      "Generator Losses:\n",
      "  G Adv: 0.9304, F Adv: 0.4360\n",
      "  Cycle Photo: 0.0600, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1668, Perceptual Monet: 0.1277\n",
      "  Total G Loss: 3.8612\n",
      "Epoch [38/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2453, D_X Fake: 0.2479, D_X Total: 0.2466\n",
      "  D_Y Real: 0.0720, D_Y Fake: 0.1309, D_Y Total: 0.1014\n",
      "Generator Losses:\n",
      "  G Adv: 0.6102, F Adv: 0.2829\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.4014\n",
      "Epoch [38/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2239, D_X Fake: 0.2667, D_X Total: 0.2453\n",
      "  D_Y Real: 0.1470, D_Y Fake: 0.0475, D_Y Total: 0.0972\n",
      "Generator Losses:\n",
      "  G Adv: 0.8399, F Adv: 0.2526\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1528, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.4833\n",
      "Epoch [38/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1707, D_X Fake: 0.2757, D_X Total: 0.2232\n",
      "  D_Y Real: 0.0907, D_Y Fake: 0.2133, D_Y Total: 0.1520\n",
      "Generator Losses:\n",
      "  G Adv: 0.4228, F Adv: 0.2567\n",
      "  Cycle Photo: 0.0687, Cycle Monet: 0.0479\n",
      "  Perceptual Photo: 0.1813, Perceptual Monet: 0.1543\n",
      "  Total G Loss: 3.5236\n",
      "Epoch [38/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1941, D_X Fake: 0.3192, D_X Total: 0.2567\n",
      "  D_Y Real: 0.0608, D_Y Fake: 0.0726, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.5901, F Adv: 0.2113\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1776, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.3119\n",
      "Epoch [38/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2468, D_X Fake: 0.1323, D_X Total: 0.1896\n",
      "  D_Y Real: 0.0404, D_Y Fake: 0.3314, D_Y Total: 0.1859\n",
      "Generator Losses:\n",
      "  G Adv: 0.3133, F Adv: 0.3987\n",
      "  Cycle Photo: 0.1028, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1375, Perceptual Monet: 0.1363\n",
      "  Total G Loss: 3.5950\n",
      "Epoch [38/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3732, D_X Fake: 0.2041, D_X Total: 0.2887\n",
      "  D_Y Real: 0.0362, D_Y Fake: 0.1492, D_Y Total: 0.0927\n",
      "Generator Losses:\n",
      "  G Adv: 0.4012, F Adv: 0.3571\n",
      "  Cycle Photo: 0.0588, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1999, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.4057\n",
      "Epoch [38/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2611, D_X Fake: 0.2243, D_X Total: 0.2427\n",
      "  D_Y Real: 0.0809, D_Y Fake: 0.1149, D_Y Total: 0.0979\n",
      "Generator Losses:\n",
      "  G Adv: 0.6063, F Adv: 0.2965\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0472\n",
      "  Perceptual Photo: 0.1575, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.3720\n",
      "Epoch [38/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2047, D_X Fake: 0.2717, D_X Total: 0.2382\n",
      "  D_Y Real: 0.0720, D_Y Fake: 0.1862, D_Y Total: 0.1291\n",
      "Generator Losses:\n",
      "  G Adv: 0.5082, F Adv: 0.2495\n",
      "  Cycle Photo: 0.0487, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1576, Perceptual Monet: 0.1415\n",
      "  Total G Loss: 3.0871\n",
      "Epoch [38/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4579, D_X Fake: 0.1528, D_X Total: 0.3054\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.1250, D_Y Total: 0.0823\n",
      "Generator Losses:\n",
      "  G Adv: 0.5348, F Adv: 0.2646\n",
      "  Cycle Photo: 0.0575, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1795, Perceptual Monet: 0.1218\n",
      "  Total G Loss: 3.2535\n",
      "Epoch [38/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2429, D_X Fake: 0.3031, D_X Total: 0.2730\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.1695, D_Y Total: 0.0999\n",
      "Generator Losses:\n",
      "  G Adv: 0.2064, F Adv: 0.2107\n",
      "  Cycle Photo: 0.0585, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1923, Perceptual Monet: 0.1340\n",
      "  Total G Loss: 2.9199\n",
      "Epoch [38/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2460, D_X Fake: 0.1738, D_X Total: 0.2099\n",
      "  D_Y Real: 0.1074, D_Y Fake: 0.0508, D_Y Total: 0.0791\n",
      "Generator Losses:\n",
      "  G Adv: 0.7901, F Adv: 0.3189\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1746, Perceptual Monet: 0.1279\n",
      "  Total G Loss: 3.3978\n",
      "Epoch [38/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2289, D_X Fake: 0.1983, D_X Total: 0.2136\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.2699, D_Y Total: 0.1559\n",
      "Generator Losses:\n",
      "  G Adv: 0.3100, F Adv: 0.3406\n",
      "  Cycle Photo: 0.0788, Cycle Monet: 0.0498\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 3.5713\n",
      "Epoch [38/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1395, D_X Fake: 0.2905, D_X Total: 0.2150\n",
      "  D_Y Real: 0.0638, D_Y Fake: 0.1444, D_Y Total: 0.1041\n",
      "Generator Losses:\n",
      "  G Adv: 0.5105, F Adv: 0.2293\n",
      "  Cycle Photo: 0.0555, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1650, Perceptual Monet: 0.1249\n",
      "  Total G Loss: 3.0322\n",
      "Epoch [38/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3966, D_X Fake: 0.1891, D_X Total: 0.2929\n",
      "  D_Y Real: 0.0663, D_Y Fake: 0.1292, D_Y Total: 0.0977\n",
      "Generator Losses:\n",
      "  G Adv: 0.7278, F Adv: 0.3023\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0472\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.4782\n",
      "Epoch [38/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2709, D_X Fake: 0.1536, D_X Total: 0.2122\n",
      "  D_Y Real: 0.0593, D_Y Fake: 0.0518, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.7294, F Adv: 0.3686\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1782, Perceptual Monet: 0.1478\n",
      "  Total G Loss: 3.7018\n",
      "Epoch [38/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1003, D_X Fake: 0.2647, D_X Total: 0.1825\n",
      "  D_Y Real: 0.0938, D_Y Fake: 0.0670, D_Y Total: 0.0804\n",
      "Generator Losses:\n",
      "  G Adv: 0.8179, F Adv: 0.3498\n",
      "  Cycle Photo: 0.0593, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1559\n",
      "  Total G Loss: 3.7966\n",
      "Epoch [38/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2165, D_X Fake: 0.1907, D_X Total: 0.2036\n",
      "  D_Y Real: 0.0937, D_Y Fake: 0.1133, D_Y Total: 0.1035\n",
      "Generator Losses:\n",
      "  G Adv: 0.5787, F Adv: 0.1911\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1385\n",
      "  Total G Loss: 3.0533\n",
      "Epoch [38/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0892, D_X Fake: 0.1684, D_X Total: 0.1288\n",
      "  D_Y Real: 0.1884, D_Y Fake: 0.0631, D_Y Total: 0.1258\n",
      "Generator Losses:\n",
      "  G Adv: 0.8604, F Adv: 0.3888\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1731, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 4.0804\n",
      "Epoch [38/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0529, D_X Fake: 0.2227, D_X Total: 0.1378\n",
      "  D_Y Real: 0.1164, D_Y Fake: 0.0505, D_Y Total: 0.0834\n",
      "Generator Losses:\n",
      "  G Adv: 0.5973, F Adv: 0.2097\n",
      "  Cycle Photo: 0.0664, Cycle Monet: 0.0525\n",
      "  Perceptual Photo: 0.1733, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.7548\n",
      "Epoch [38/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1190, D_X Fake: 0.0722, D_X Total: 0.0956\n",
      "  D_Y Real: 0.1026, D_Y Fake: 0.1450, D_Y Total: 0.1238\n",
      "Generator Losses:\n",
      "  G Adv: 0.3474, F Adv: 0.6054\n",
      "  Cycle Photo: 0.0573, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1307, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.5421\n",
      "Epoch [39/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2643, D_X Fake: 0.1164, D_X Total: 0.1904\n",
      "  D_Y Real: 0.0861, D_Y Fake: 0.1973, D_Y Total: 0.1417\n",
      "Generator Losses:\n",
      "  G Adv: 0.5580, F Adv: 0.5158\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1853, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.7829\n",
      "Epoch [39/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1056, D_X Fake: 0.0831, D_X Total: 0.0944\n",
      "  D_Y Real: 0.0574, D_Y Fake: 0.4870, D_Y Total: 0.2722\n",
      "Generator Losses:\n",
      "  G Adv: 0.2944, F Adv: 0.4120\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1520\n",
      "  Total G Loss: 2.9406\n",
      "Epoch [39/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1618, D_X Fake: 0.1059, D_X Total: 0.1338\n",
      "  D_Y Real: 0.1211, D_Y Fake: 0.1256, D_Y Total: 0.1233\n",
      "Generator Losses:\n",
      "  G Adv: 0.5299, F Adv: 0.5019\n",
      "  Cycle Photo: 0.0461, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1663\n",
      "  Total G Loss: 3.5617\n",
      "Epoch [39/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1932, D_X Fake: 0.0868, D_X Total: 0.1400\n",
      "  D_Y Real: 0.0755, D_Y Fake: 0.1137, D_Y Total: 0.0946\n",
      "Generator Losses:\n",
      "  G Adv: 0.4928, F Adv: 0.5560\n",
      "  Cycle Photo: 0.0659, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1712, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.7623\n",
      "Epoch [39/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1366, D_X Fake: 0.1514, D_X Total: 0.1440\n",
      "  D_Y Real: 0.1048, D_Y Fake: 0.1270, D_Y Total: 0.1159\n",
      "Generator Losses:\n",
      "  G Adv: 0.4038, F Adv: 0.4359\n",
      "  Cycle Photo: 0.0563, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.2249, Perceptual Monet: 0.1876\n",
      "  Total G Loss: 3.8724\n",
      "Epoch [39/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0478, D_X Fake: 0.2111, D_X Total: 0.1294\n",
      "  D_Y Real: 0.1073, D_Y Fake: 0.0907, D_Y Total: 0.0990\n",
      "Generator Losses:\n",
      "  G Adv: 0.6832, F Adv: 0.3696\n",
      "  Cycle Photo: 0.0785, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1837, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 4.0351\n",
      "Epoch [39/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1765, D_X Fake: 0.0905, D_X Total: 0.1335\n",
      "  D_Y Real: 0.0868, D_Y Fake: 0.0706, D_Y Total: 0.0787\n",
      "Generator Losses:\n",
      "  G Adv: 0.6394, F Adv: 0.5503\n",
      "  Cycle Photo: 0.0536, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.2079, Perceptual Monet: 0.1364\n",
      "  Total G Loss: 3.7874\n",
      "Epoch [39/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0477, D_X Fake: 0.2171, D_X Total: 0.1324\n",
      "  D_Y Real: 0.0801, D_Y Fake: 0.1242, D_Y Total: 0.1022\n",
      "Generator Losses:\n",
      "  G Adv: 0.5960, F Adv: 0.2833\n",
      "  Cycle Photo: 0.0420, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.1556, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.3725\n",
      "Epoch [39/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0564, D_X Fake: 0.1898, D_X Total: 0.1231\n",
      "  D_Y Real: 0.0589, D_Y Fake: 0.1156, D_Y Total: 0.0872\n",
      "Generator Losses:\n",
      "  G Adv: 0.4697, F Adv: 0.4332\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1830, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.7441\n",
      "Epoch [39/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2500, D_X Fake: 0.0286, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0679, D_Y Fake: 0.0609, D_Y Total: 0.0644\n",
      "Generator Losses:\n",
      "  G Adv: 0.6254, F Adv: 1.0535\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0481\n",
      "  Perceptual Photo: 0.1223, Perceptual Monet: 0.2036\n",
      "  Total G Loss: 4.2305\n",
      "Epoch [39/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2461, D_X Fake: 0.0332, D_X Total: 0.1396\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.2843, D_Y Total: 0.1640\n",
      "Generator Losses:\n",
      "  G Adv: 0.3969, F Adv: 0.7363\n",
      "  Cycle Photo: 0.0554, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.2055, Perceptual Monet: 0.1551\n",
      "  Total G Loss: 3.8372\n",
      "Epoch [39/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0341, D_X Fake: 0.0326, D_X Total: 0.0333\n",
      "  D_Y Real: 0.0773, D_Y Fake: 0.0726, D_Y Total: 0.0749\n",
      "Generator Losses:\n",
      "  G Adv: 0.7618, F Adv: 0.6242\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.7995\n",
      "Epoch [39/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3852, D_X Fake: 0.0348, D_X Total: 0.2100\n",
      "  D_Y Real: 0.0813, D_Y Fake: 0.1598, D_Y Total: 0.1206\n",
      "Generator Losses:\n",
      "  G Adv: 0.4261, F Adv: 0.9768\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0653\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.1965\n",
      "  Total G Loss: 4.2347\n",
      "Epoch [39/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2509, D_X Fake: 0.0701, D_X Total: 0.1605\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.0660, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.5862, F Adv: 0.5687\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.2046, Perceptual Monet: 0.1488\n",
      "  Total G Loss: 3.7158\n",
      "Epoch [39/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1279, D_X Fake: 0.0362, D_X Total: 0.0820\n",
      "  D_Y Real: 0.0615, D_Y Fake: 0.1075, D_Y Total: 0.0845\n",
      "Generator Losses:\n",
      "  G Adv: 0.5920, F Adv: 0.9741\n",
      "  Cycle Photo: 0.0658, Cycle Monet: 0.0440\n",
      "  Perceptual Photo: 0.1974, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 4.5614\n",
      "Epoch [39/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1683, D_X Fake: 0.0330, D_X Total: 0.1007\n",
      "  D_Y Real: 0.1116, D_Y Fake: 0.0991, D_Y Total: 0.1053\n",
      "Generator Losses:\n",
      "  G Adv: 0.7477, F Adv: 0.4273\n",
      "  Cycle Photo: 0.0632, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.1890, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 4.0103\n",
      "Epoch [39/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1487, D_X Fake: 0.0815, D_X Total: 0.1151\n",
      "  D_Y Real: 0.0731, D_Y Fake: 0.1111, D_Y Total: 0.0921\n",
      "Generator Losses:\n",
      "  G Adv: 0.4701, F Adv: 0.4506\n",
      "  Cycle Photo: 0.0425, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1637, Perceptual Monet: 0.1342\n",
      "  Total G Loss: 3.1161\n",
      "Epoch [39/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3509, D_X Fake: 0.0351, D_X Total: 0.1930\n",
      "  D_Y Real: 0.0758, D_Y Fake: 0.1638, D_Y Total: 0.1198\n",
      "Generator Losses:\n",
      "  G Adv: 0.5614, F Adv: 1.0790\n",
      "  Cycle Photo: 0.0501, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1785, Perceptual Monet: 0.1985\n",
      "  Total G Loss: 4.4608\n",
      "Epoch [39/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1552, D_X Fake: 0.2245, D_X Total: 0.1899\n",
      "  D_Y Real: 0.0352, D_Y Fake: 0.1342, D_Y Total: 0.0847\n",
      "Generator Losses:\n",
      "  G Adv: 0.5666, F Adv: 0.3923\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1749, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.3694\n",
      "Epoch [39/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0967, D_X Fake: 0.1648, D_X Total: 0.1307\n",
      "  D_Y Real: 0.0928, D_Y Fake: 0.1056, D_Y Total: 0.0992\n",
      "Generator Losses:\n",
      "  G Adv: 0.5207, F Adv: 0.5621\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0438\n",
      "  Perceptual Photo: 0.1556, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.6402\n",
      "Epoch [39/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2269, D_X Fake: 0.0432, D_X Total: 0.1350\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.2154, D_Y Total: 0.1287\n",
      "Generator Losses:\n",
      "  G Adv: 0.4926, F Adv: 0.6643\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1603, Perceptual Monet: 0.1425\n",
      "  Total G Loss: 3.4639\n",
      "Epoch [39/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1169, D_X Fake: 0.1063, D_X Total: 0.1116\n",
      "  D_Y Real: 0.1133, D_Y Fake: 0.1576, D_Y Total: 0.1355\n",
      "Generator Losses:\n",
      "  G Adv: 0.5594, F Adv: 0.5408\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.2062, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.8051\n",
      "Epoch [39/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0822, D_X Fake: 0.0604, D_X Total: 0.0713\n",
      "  D_Y Real: 0.1324, D_Y Fake: 0.0710, D_Y Total: 0.1017\n",
      "Generator Losses:\n",
      "  G Adv: 0.6786, F Adv: 0.8026\n",
      "  Cycle Photo: 0.0628, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1763, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 4.2070\n",
      "Epoch [39/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2078, D_X Fake: 0.0832, D_X Total: 0.1455\n",
      "  D_Y Real: 0.1574, D_Y Fake: 0.0518, D_Y Total: 0.1046\n",
      "Generator Losses:\n",
      "  G Adv: 0.7583, F Adv: 0.4406\n",
      "  Cycle Photo: 0.0719, Cycle Monet: 0.0451\n",
      "  Perceptual Photo: 0.2167, Perceptual Monet: 0.1991\n",
      "  Total G Loss: 4.4478\n",
      "Epoch [40/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0785, D_X Fake: 0.2192, D_X Total: 0.1489\n",
      "  D_Y Real: 0.0966, D_Y Fake: 0.0813, D_Y Total: 0.0889\n",
      "Generator Losses:\n",
      "  G Adv: 0.8993, F Adv: 0.2807\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1468\n",
      "  Total G Loss: 3.6780\n",
      "Epoch [40/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0799, D_X Fake: 0.0918, D_X Total: 0.0859\n",
      "  D_Y Real: 0.0464, D_Y Fake: 0.1232, D_Y Total: 0.0848\n",
      "Generator Losses:\n",
      "  G Adv: 0.5538, F Adv: 0.5406\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0511\n",
      "  Perceptual Photo: 0.1801, Perceptual Monet: 0.1942\n",
      "  Total G Loss: 3.8955\n",
      "Epoch [40/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2433, D_X Fake: 0.1912, D_X Total: 0.2173\n",
      "  D_Y Real: 0.0698, D_Y Fake: 0.0909, D_Y Total: 0.0804\n",
      "Generator Losses:\n",
      "  G Adv: 0.8529, F Adv: 0.3715\n",
      "  Cycle Photo: 0.0729, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1751, Perceptual Monet: 0.1948\n",
      "  Total G Loss: 4.2109\n",
      "Epoch [40/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0291, D_X Fake: 0.2251, D_X Total: 0.1271\n",
      "  D_Y Real: 0.0873, D_Y Fake: 0.1319, D_Y Total: 0.1096\n",
      "Generator Losses:\n",
      "  G Adv: 0.4468, F Adv: 0.4068\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1587, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.3401\n",
      "Epoch [40/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4556, D_X Fake: 0.0766, D_X Total: 0.2661\n",
      "  D_Y Real: 0.0769, D_Y Fake: 0.1980, D_Y Total: 0.1374\n",
      "Generator Losses:\n",
      "  G Adv: 0.3684, F Adv: 0.9800\n",
      "  Cycle Photo: 0.0533, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1270, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.7283\n",
      "Epoch [40/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1039, D_X Fake: 0.1280, D_X Total: 0.1160\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.1139, D_Y Total: 0.0863\n",
      "Generator Losses:\n",
      "  G Adv: 0.6655, F Adv: 0.4735\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.1635, Perceptual Monet: 0.2139\n",
      "  Total G Loss: 4.0108\n",
      "Epoch [40/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1128, D_X Fake: 0.1284, D_X Total: 0.1206\n",
      "  D_Y Real: 0.1185, D_Y Fake: 0.1831, D_Y Total: 0.1508\n",
      "Generator Losses:\n",
      "  G Adv: 0.5363, F Adv: 0.4884\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.5519\n",
      "Epoch [40/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0498, D_X Fake: 0.2291, D_X Total: 0.1395\n",
      "  D_Y Real: 0.0513, D_Y Fake: 0.0851, D_Y Total: 0.0682\n",
      "Generator Losses:\n",
      "  G Adv: 0.6100, F Adv: 0.2847\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1287, Perceptual Monet: 0.1970\n",
      "  Total G Loss: 3.3742\n",
      "Epoch [40/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0413, D_X Fake: 0.1290, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0868, D_Y Fake: 0.0842, D_Y Total: 0.0855\n",
      "Generator Losses:\n",
      "  G Adv: 0.6354, F Adv: 0.4356\n",
      "  Cycle Photo: 0.0582, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1983, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.9149\n",
      "Epoch [40/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2855, D_X Fake: 0.1731, D_X Total: 0.2293\n",
      "  D_Y Real: 0.0919, D_Y Fake: 0.0563, D_Y Total: 0.0741\n",
      "Generator Losses:\n",
      "  G Adv: 0.6220, F Adv: 0.3701\n",
      "  Cycle Photo: 0.0668, Cycle Monet: 0.0578\n",
      "  Perceptual Photo: 0.2190, Perceptual Monet: 0.2006\n",
      "  Total G Loss: 4.3362\n",
      "Epoch [40/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2910, D_X Fake: 0.0450, D_X Total: 0.1680\n",
      "  D_Y Real: 0.1617, D_Y Fake: 0.0484, D_Y Total: 0.1051\n",
      "Generator Losses:\n",
      "  G Adv: 0.9143, F Adv: 0.9857\n",
      "  Cycle Photo: 0.0579, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1903, Perceptual Monet: 0.1999\n",
      "  Total G Loss: 4.8139\n",
      "Epoch [40/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1475, D_X Fake: 0.0586, D_X Total: 0.1031\n",
      "  D_Y Real: 0.0554, D_Y Fake: 0.2298, D_Y Total: 0.1426\n",
      "Generator Losses:\n",
      "  G Adv: 0.3048, F Adv: 0.6918\n",
      "  Cycle Photo: 0.0624, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1828, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 3.8918\n",
      "Epoch [40/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2052, D_X Fake: 0.1474, D_X Total: 0.1763\n",
      "  D_Y Real: 0.1344, D_Y Fake: 0.2792, D_Y Total: 0.2068\n",
      "Generator Losses:\n",
      "  G Adv: 0.3400, F Adv: 0.4783\n",
      "  Cycle Photo: 0.0523, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.2051, Perceptual Monet: 0.1842\n",
      "  Total G Loss: 3.6689\n",
      "Epoch [40/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0631, D_X Fake: 0.0966, D_X Total: 0.0798\n",
      "  D_Y Real: 0.0718, D_Y Fake: 0.0635, D_Y Total: 0.0677\n",
      "Generator Losses:\n",
      "  G Adv: 0.6966, F Adv: 0.3010\n",
      "  Cycle Photo: 0.0498, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1966, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.6480\n",
      "Epoch [40/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0511, D_X Fake: 0.1465, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0502, D_Y Fake: 0.1467, D_Y Total: 0.0985\n",
      "Generator Losses:\n",
      "  G Adv: 0.4749, F Adv: 0.5757\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1829\n",
      "  Total G Loss: 3.4271\n",
      "Epoch [40/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1292, D_X Fake: 0.0846, D_X Total: 0.1069\n",
      "  D_Y Real: 0.0781, D_Y Fake: 0.0738, D_Y Total: 0.0759\n",
      "Generator Losses:\n",
      "  G Adv: 0.5785, F Adv: 0.6250\n",
      "  Cycle Photo: 0.0672, Cycle Monet: 0.0495\n",
      "  Perceptual Photo: 0.2008, Perceptual Monet: 0.1941\n",
      "  Total G Loss: 4.3451\n",
      "Epoch [40/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1249, D_X Fake: 0.0555, D_X Total: 0.0902\n",
      "  D_Y Real: 0.1170, D_Y Fake: 0.0440, D_Y Total: 0.0805\n",
      "Generator Losses:\n",
      "  G Adv: 0.7262, F Adv: 0.6988\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1876, Perceptual Monet: 0.1918\n",
      "  Total G Loss: 4.1050\n",
      "Epoch [40/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2755, D_X Fake: 0.0999, D_X Total: 0.1877\n",
      "  D_Y Real: 0.1607, D_Y Fake: 0.0887, D_Y Total: 0.1247\n",
      "Generator Losses:\n",
      "  G Adv: 0.9071, F Adv: 1.0875\n",
      "  Cycle Photo: 0.0730, Cycle Monet: 0.0453\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.2006\n",
      "  Total G Loss: 4.9085\n",
      "Epoch [40/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1017, D_X Fake: 0.0610, D_X Total: 0.0813\n",
      "  D_Y Real: 0.0529, D_Y Fake: 0.1214, D_Y Total: 0.0871\n",
      "Generator Losses:\n",
      "  G Adv: 0.3887, F Adv: 0.6432\n",
      "  Cycle Photo: 0.0566, Cycle Monet: 0.0527\n",
      "  Perceptual Photo: 0.1940, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.9541\n",
      "Epoch [40/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1440, D_X Fake: 0.1315, D_X Total: 0.1378\n",
      "  D_Y Real: 0.1329, D_Y Fake: 0.0448, D_Y Total: 0.0889\n",
      "Generator Losses:\n",
      "  G Adv: 0.9810, F Adv: 0.4775\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0461\n",
      "  Perceptual Photo: 0.1710, Perceptual Monet: 0.1924\n",
      "  Total G Loss: 4.2095\n",
      "Epoch [40/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0555, D_X Fake: 0.0876, D_X Total: 0.0716\n",
      "  D_Y Real: 0.0423, D_Y Fake: 0.2856, D_Y Total: 0.1639\n",
      "Generator Losses:\n",
      "  G Adv: 0.3193, F Adv: 0.3499\n",
      "  Cycle Photo: 0.0443, Cycle Monet: 0.0492\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.2114\n",
      "  Total G Loss: 3.4313\n",
      "Epoch [40/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0625, D_X Fake: 0.0368, D_X Total: 0.0496\n",
      "  D_Y Real: 0.0529, D_Y Fake: 0.1146, D_Y Total: 0.0837\n",
      "Generator Losses:\n",
      "  G Adv: 0.4411, F Adv: 0.7192\n",
      "  Cycle Photo: 0.0672, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1994, Perceptual Monet: 0.1963\n",
      "  Total G Loss: 4.2482\n",
      "Epoch [40/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1542, D_X Fake: 0.0788, D_X Total: 0.1165\n",
      "  D_Y Real: 0.0843, D_Y Fake: 0.1112, D_Y Total: 0.0978\n",
      "Generator Losses:\n",
      "  G Adv: 0.6349, F Adv: 0.6366\n",
      "  Cycle Photo: 0.0573, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.2082, Perceptual Monet: 0.1847\n",
      "  Total G Loss: 4.2212\n",
      "Epoch [40/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0790, D_X Fake: 0.3754, D_X Total: 0.2272\n",
      "  D_Y Real: 0.0520, D_Y Fake: 0.1233, D_Y Total: 0.0877\n",
      "Generator Losses:\n",
      "  G Adv: 0.2221, F Adv: 0.1330\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 2.9362\n",
      "Saved checkpoint at epoch 40\n",
      "Epoch [41/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0847, D_X Fake: 0.1197, D_X Total: 0.1022\n",
      "  D_Y Real: 0.1215, D_Y Fake: 0.1673, D_Y Total: 0.1444\n",
      "Generator Losses:\n",
      "  G Adv: 0.5279, F Adv: 0.4921\n",
      "  Cycle Photo: 0.0619, Cycle Monet: 0.0575\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.8592\n",
      "Epoch [41/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1651, D_X Fake: 0.1791, D_X Total: 0.1721\n",
      "  D_Y Real: 0.1707, D_Y Fake: 0.0468, D_Y Total: 0.1088\n",
      "Generator Losses:\n",
      "  G Adv: 0.5148, F Adv: 0.4231\n",
      "  Cycle Photo: 0.0518, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1907, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.6643\n",
      "Epoch [41/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1412, D_X Fake: 0.0673, D_X Total: 0.1043\n",
      "  D_Y Real: 0.1657, D_Y Fake: 0.0545, D_Y Total: 0.1101\n",
      "Generator Losses:\n",
      "  G Adv: 0.7595, F Adv: 0.6647\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0532\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.2108\n",
      "  Total G Loss: 4.2530\n",
      "Epoch [41/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1012, D_X Fake: 0.1405, D_X Total: 0.1208\n",
      "  D_Y Real: 0.0891, D_Y Fake: 0.0654, D_Y Total: 0.0772\n",
      "Generator Losses:\n",
      "  G Adv: 0.5732, F Adv: 0.5597\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0479\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.2072\n",
      "  Total G Loss: 4.0762\n",
      "Epoch [41/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3259, D_X Fake: 0.0403, D_X Total: 0.1831\n",
      "  D_Y Real: 0.2254, D_Y Fake: 0.1169, D_Y Total: 0.1711\n",
      "Generator Losses:\n",
      "  G Adv: 0.8501, F Adv: 0.6395\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1735, Perceptual Monet: 0.1989\n",
      "  Total G Loss: 4.2157\n",
      "Epoch [41/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0885, D_X Fake: 0.0666, D_X Total: 0.0775\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.2586, D_Y Total: 0.1522\n",
      "Generator Losses:\n",
      "  G Adv: 0.3793, F Adv: 0.6057\n",
      "  Cycle Photo: 0.0825, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1633, Perceptual Monet: 0.1909\n",
      "  Total G Loss: 3.9685\n",
      "Epoch [41/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1617, D_X Fake: 0.0850, D_X Total: 0.1234\n",
      "  D_Y Real: 0.1313, D_Y Fake: 0.0385, D_Y Total: 0.0849\n",
      "Generator Losses:\n",
      "  G Adv: 0.7707, F Adv: 0.5753\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1648, Perceptual Monet: 0.1979\n",
      "  Total G Loss: 4.0432\n",
      "Epoch [41/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2359, D_X Fake: 0.0397, D_X Total: 0.1378\n",
      "  D_Y Real: 0.1049, D_Y Fake: 0.0478, D_Y Total: 0.0763\n",
      "Generator Losses:\n",
      "  G Adv: 0.7299, F Adv: 0.8868\n",
      "  Cycle Photo: 0.0596, Cycle Monet: 0.0474\n",
      "  Perceptual Photo: 0.1701, Perceptual Monet: 0.2144\n",
      "  Total G Loss: 4.6085\n",
      "Epoch [41/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1189, D_X Fake: 0.0624, D_X Total: 0.0907\n",
      "  D_Y Real: 0.0474, D_Y Fake: 0.1951, D_Y Total: 0.1213\n",
      "Generator Losses:\n",
      "  G Adv: 0.6414, F Adv: 0.6213\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0433\n",
      "  Perceptual Photo: 0.1933, Perceptual Monet: 0.2154\n",
      "  Total G Loss: 4.1819\n",
      "Epoch [41/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1307, D_X Fake: 0.0816, D_X Total: 0.1062\n",
      "  D_Y Real: 0.0597, D_Y Fake: 0.0913, D_Y Total: 0.0755\n",
      "Generator Losses:\n",
      "  G Adv: 0.6275, F Adv: 0.4265\n",
      "  Cycle Photo: 0.0557, Cycle Monet: 0.0445\n",
      "  Perceptual Photo: 0.1726, Perceptual Monet: 0.1909\n",
      "  Total G Loss: 3.8736\n",
      "Epoch [41/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2105, D_X Fake: 0.1002, D_X Total: 0.1553\n",
      "  D_Y Real: 0.0914, D_Y Fake: 0.0427, D_Y Total: 0.0671\n",
      "Generator Losses:\n",
      "  G Adv: 0.8135, F Adv: 0.5828\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.2341, Perceptual Monet: 0.1856\n",
      "  Total G Loss: 4.5552\n",
      "Epoch [41/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3965, D_X Fake: 0.0530, D_X Total: 0.2247\n",
      "  D_Y Real: 0.0627, D_Y Fake: 0.1865, D_Y Total: 0.1246\n",
      "Generator Losses:\n",
      "  G Adv: 0.3861, F Adv: 0.8559\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.2005, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 4.0697\n",
      "Epoch [41/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.0730, D_X Total: 0.1747\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.2214, D_Y Total: 0.1342\n",
      "Generator Losses:\n",
      "  G Adv: 0.3439, F Adv: 0.9613\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1254, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.6474\n",
      "Epoch [41/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1680, D_X Fake: 0.0836, D_X Total: 0.1258\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.2275, D_Y Total: 0.1295\n",
      "Generator Losses:\n",
      "  G Adv: 0.4489, F Adv: 0.7143\n",
      "  Cycle Photo: 0.0474, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1754, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.8752\n",
      "Epoch [41/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0679, D_X Fake: 0.4591, D_X Total: 0.2635\n",
      "  D_Y Real: 0.2300, D_Y Fake: 0.0470, D_Y Total: 0.1385\n",
      "Generator Losses:\n",
      "  G Adv: 1.0150, F Adv: 0.1157\n",
      "  Cycle Photo: 0.0526, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1890, Perceptual Monet: 0.1819\n",
      "  Total G Loss: 3.9984\n",
      "Epoch [41/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3251, D_X Fake: 0.0989, D_X Total: 0.2120\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0927, D_Y Total: 0.0609\n",
      "Generator Losses:\n",
      "  G Adv: 0.5778, F Adv: 0.6141\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1866, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.9132\n",
      "Epoch [41/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0374, D_X Fake: 0.1261, D_X Total: 0.0817\n",
      "  D_Y Real: 0.0982, D_Y Fake: 0.0380, D_Y Total: 0.0681\n",
      "Generator Losses:\n",
      "  G Adv: 1.0346, F Adv: 0.5141\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0474\n",
      "  Perceptual Photo: 0.1979, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 4.4479\n",
      "Epoch [41/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0930, D_X Fake: 0.0566, D_X Total: 0.0748\n",
      "  D_Y Real: 0.0734, D_Y Fake: 0.1310, D_Y Total: 0.1022\n",
      "Generator Losses:\n",
      "  G Adv: 0.4029, F Adv: 0.5671\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.1941\n",
      "  Total G Loss: 3.6044\n",
      "Epoch [41/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2852, D_X Fake: 0.0316, D_X Total: 0.1584\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.2073, D_Y Total: 0.1172\n",
      "Generator Losses:\n",
      "  G Adv: 0.3202, F Adv: 0.6650\n",
      "  Cycle Photo: 0.0503, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1453, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.3984\n",
      "Epoch [41/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1072, D_X Fake: 0.3140, D_X Total: 0.2106\n",
      "  D_Y Real: 0.0841, D_Y Fake: 0.1506, D_Y Total: 0.1173\n",
      "Generator Losses:\n",
      "  G Adv: 0.5254, F Adv: 0.2693\n",
      "  Cycle Photo: 0.0878, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1518\n",
      "  Total G Loss: 3.6368\n",
      "Epoch [41/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0661, D_X Fake: 0.3345, D_X Total: 0.2003\n",
      "  D_Y Real: 0.0709, D_Y Fake: 0.1012, D_Y Total: 0.0861\n",
      "Generator Losses:\n",
      "  G Adv: 0.5288, F Adv: 0.3696\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0436\n",
      "  Perceptual Photo: 0.1631, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 3.5667\n",
      "Epoch [41/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0856, D_X Fake: 0.2175, D_X Total: 0.1516\n",
      "  D_Y Real: 0.0474, D_Y Fake: 0.2610, D_Y Total: 0.1542\n",
      "Generator Losses:\n",
      "  G Adv: 0.4403, F Adv: 0.4329\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1762, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.3812\n",
      "Epoch [41/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0569, D_X Fake: 0.2829, D_X Total: 0.1699\n",
      "  D_Y Real: 0.0567, D_Y Fake: 0.0493, D_Y Total: 0.0530\n",
      "Generator Losses:\n",
      "  G Adv: 0.5059, F Adv: 0.2827\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1823\n",
      "  Total G Loss: 3.3565\n",
      "Epoch [41/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1150, D_X Fake: 0.0859, D_X Total: 0.1005\n",
      "  D_Y Real: 0.1109, D_Y Fake: 0.2171, D_Y Total: 0.1640\n",
      "Generator Losses:\n",
      "  G Adv: 0.4463, F Adv: 0.6104\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.5969\n",
      "Epoch [42/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1859, D_X Fake: 0.0652, D_X Total: 0.1256\n",
      "  D_Y Real: 0.0598, D_Y Fake: 0.1132, D_Y Total: 0.0865\n",
      "Generator Losses:\n",
      "  G Adv: 0.4913, F Adv: 0.6187\n",
      "  Cycle Photo: 0.0493, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1753, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.8599\n",
      "Epoch [42/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.0559, D_X Total: 0.0622\n",
      "  D_Y Real: 0.0720, D_Y Fake: 0.3791, D_Y Total: 0.2256\n",
      "Generator Losses:\n",
      "  G Adv: 0.4556, F Adv: 0.3881\n",
      "  Cycle Photo: 0.0753, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.1690, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.6599\n",
      "Epoch [42/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1194, D_X Fake: 0.1975, D_X Total: 0.1585\n",
      "  D_Y Real: 0.0688, D_Y Fake: 0.0600, D_Y Total: 0.0644\n",
      "Generator Losses:\n",
      "  G Adv: 0.7000, F Adv: 0.2883\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1715, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.6312\n",
      "Epoch [42/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0325, D_X Fake: 0.2055, D_X Total: 0.1190\n",
      "  D_Y Real: 0.0586, D_Y Fake: 0.0557, D_Y Total: 0.0572\n",
      "Generator Losses:\n",
      "  G Adv: 0.7558, F Adv: 0.4783\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1998\n",
      "  Total G Loss: 3.8969\n",
      "Epoch [42/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0562, D_X Fake: 0.1061, D_X Total: 0.0812\n",
      "  D_Y Real: 0.1479, D_Y Fake: 0.0832, D_Y Total: 0.1156\n",
      "Generator Losses:\n",
      "  G Adv: 0.8124, F Adv: 0.3858\n",
      "  Cycle Photo: 0.0576, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1655, Perceptual Monet: 0.1512\n",
      "  Total G Loss: 3.6341\n",
      "Epoch [42/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1801, D_X Fake: 0.0404, D_X Total: 0.1102\n",
      "  D_Y Real: 0.1095, D_Y Fake: 0.0738, D_Y Total: 0.0916\n",
      "Generator Losses:\n",
      "  G Adv: 0.7231, F Adv: 0.8318\n",
      "  Cycle Photo: 0.0556, Cycle Monet: 0.0391\n",
      "  Perceptual Photo: 0.1937, Perceptual Monet: 0.1838\n",
      "  Total G Loss: 4.3888\n",
      "Epoch [42/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0953, D_X Fake: 0.3326, D_X Total: 0.2140\n",
      "  D_Y Real: 0.1009, D_Y Fake: 0.1202, D_Y Total: 0.1105\n",
      "Generator Losses:\n",
      "  G Adv: 0.7041, F Adv: 0.2165\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1215, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.2501\n",
      "Epoch [42/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0527, D_X Fake: 0.0835, D_X Total: 0.0681\n",
      "  D_Y Real: 0.1899, D_Y Fake: 0.0513, D_Y Total: 0.1206\n",
      "Generator Losses:\n",
      "  G Adv: 0.9970, F Adv: 0.4733\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1382\n",
      "  Total G Loss: 3.6922\n",
      "Epoch [42/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0601, D_X Fake: 0.1519, D_X Total: 0.1060\n",
      "  D_Y Real: 0.0924, D_Y Fake: 0.1569, D_Y Total: 0.1246\n",
      "Generator Losses:\n",
      "  G Adv: 0.2675, F Adv: 0.2483\n",
      "  Cycle Photo: 0.0550, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.2127, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.3871\n",
      "Epoch [42/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0587, D_X Fake: 0.0900, D_X Total: 0.0744\n",
      "  D_Y Real: 0.0893, D_Y Fake: 0.0703, D_Y Total: 0.0798\n",
      "Generator Losses:\n",
      "  G Adv: 0.4893, F Adv: 0.5296\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1618, Perceptual Monet: 0.1415\n",
      "  Total G Loss: 3.3072\n",
      "Epoch [42/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1262, D_X Fake: 0.1014, D_X Total: 0.1138\n",
      "  D_Y Real: 0.1616, D_Y Fake: 0.1085, D_Y Total: 0.1351\n",
      "Generator Losses:\n",
      "  G Adv: 0.5469, F Adv: 0.4274\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1882, Perceptual Monet: 0.2002\n",
      "  Total G Loss: 3.8130\n",
      "Epoch [42/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.1530, D_X Total: 0.1182\n",
      "  D_Y Real: 0.0760, D_Y Fake: 0.2276, D_Y Total: 0.1518\n",
      "Generator Losses:\n",
      "  G Adv: 0.3658, F Adv: 0.4015\n",
      "  Cycle Photo: 0.0461, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1807, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.4222\n",
      "Epoch [42/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1454, D_X Fake: 0.1197, D_X Total: 0.1326\n",
      "  D_Y Real: 0.1222, D_Y Fake: 0.0520, D_Y Total: 0.0871\n",
      "Generator Losses:\n",
      "  G Adv: 0.5767, F Adv: 0.5487\n",
      "  Cycle Photo: 0.0557, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1859, Perceptual Monet: 0.1958\n",
      "  Total G Loss: 3.9658\n",
      "Epoch [42/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2651, D_X Fake: 0.0643, D_X Total: 0.1647\n",
      "  D_Y Real: 0.0942, D_Y Fake: 0.0437, D_Y Total: 0.0689\n",
      "Generator Losses:\n",
      "  G Adv: 0.9050, F Adv: 0.7773\n",
      "  Cycle Photo: 0.0707, Cycle Monet: 0.0618\n",
      "  Perceptual Photo: 0.2782, Perceptual Monet: 0.1989\n",
      "  Total G Loss: 5.3932\n",
      "Epoch [42/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0281, D_X Fake: 0.1337, D_X Total: 0.0809\n",
      "  D_Y Real: 0.1570, D_Y Fake: 0.1490, D_Y Total: 0.1530\n",
      "Generator Losses:\n",
      "  G Adv: 0.8856, F Adv: 0.5259\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0554\n",
      "  Perceptual Photo: 0.1522, Perceptual Monet: 0.2076\n",
      "  Total G Loss: 4.2687\n",
      "Epoch [42/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2111, D_X Fake: 0.0361, D_X Total: 0.1236\n",
      "  D_Y Real: 0.0997, D_Y Fake: 0.1599, D_Y Total: 0.1298\n",
      "Generator Losses:\n",
      "  G Adv: 0.3512, F Adv: 0.9177\n",
      "  Cycle Photo: 0.0572, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1890, Perceptual Monet: 0.2046\n",
      "  Total G Loss: 4.2685\n",
      "Epoch [42/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2561, D_X Fake: 0.0788, D_X Total: 0.1675\n",
      "  D_Y Real: 0.0765, D_Y Fake: 0.0855, D_Y Total: 0.0810\n",
      "Generator Losses:\n",
      "  G Adv: 0.5092, F Adv: 0.7015\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.2005\n",
      "  Total G Loss: 3.9601\n",
      "Epoch [42/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0581, D_X Fake: 0.1079, D_X Total: 0.0830\n",
      "  D_Y Real: 0.0706, D_Y Fake: 0.0727, D_Y Total: 0.0716\n",
      "Generator Losses:\n",
      "  G Adv: 0.7522, F Adv: 0.4783\n",
      "  Cycle Photo: 0.0543, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.8464\n",
      "Epoch [42/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0596, D_X Fake: 0.3892, D_X Total: 0.2244\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0769, D_Y Total: 0.0562\n",
      "Generator Losses:\n",
      "  G Adv: 0.7025, F Adv: 0.3743\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.5661\n",
      "Epoch [42/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0568, D_X Fake: 0.0504, D_X Total: 0.0536\n",
      "  D_Y Real: 0.1757, D_Y Fake: 0.1923, D_Y Total: 0.1840\n",
      "Generator Losses:\n",
      "  G Adv: 0.4022, F Adv: 0.5911\n",
      "  Cycle Photo: 0.0451, Cycle Monet: 0.0496\n",
      "  Perceptual Photo: 0.1685, Perceptual Monet: 0.1754\n",
      "  Total G Loss: 3.6596\n",
      "Epoch [42/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0585, D_X Fake: 0.1023, D_X Total: 0.0804\n",
      "  D_Y Real: 0.0975, D_Y Fake: 0.1152, D_Y Total: 0.1064\n",
      "Generator Losses:\n",
      "  G Adv: 0.6771, F Adv: 0.6321\n",
      "  Cycle Photo: 0.0685, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1622, Perceptual Monet: 0.1852\n",
      "  Total G Loss: 4.1399\n",
      "Epoch [42/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1166, D_X Fake: 0.1411, D_X Total: 0.1289\n",
      "  D_Y Real: 0.0990, D_Y Fake: 0.1086, D_Y Total: 0.1038\n",
      "Generator Losses:\n",
      "  G Adv: 0.8070, F Adv: 0.4331\n",
      "  Cycle Photo: 0.0590, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1745, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.9897\n",
      "Epoch [42/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1126, D_X Fake: 0.2220, D_X Total: 0.1673\n",
      "  D_Y Real: 0.0568, D_Y Fake: 0.1454, D_Y Total: 0.1011\n",
      "Generator Losses:\n",
      "  G Adv: 0.5718, F Adv: 0.3403\n",
      "  Cycle Photo: 0.0737, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1631, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.5691\n",
      "Epoch [42/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4393, D_X Fake: 0.0896, D_X Total: 0.2645\n",
      "  D_Y Real: 0.0887, D_Y Fake: 0.3315, D_Y Total: 0.2101\n",
      "Generator Losses:\n",
      "  G Adv: 0.2887, F Adv: 0.6947\n",
      "  Cycle Photo: 0.0536, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1959, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.8598\n",
      "Epoch [43/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0765, D_X Fake: 0.0729, D_X Total: 0.0747\n",
      "  D_Y Real: 0.0823, D_Y Fake: 0.1052, D_Y Total: 0.0937\n",
      "Generator Losses:\n",
      "  G Adv: 0.5727, F Adv: 0.5311\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.2131\n",
      "  Total G Loss: 3.8463\n",
      "Epoch [43/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0361, D_X Fake: 0.1639, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0762, D_Y Total: 0.0589\n",
      "Generator Losses:\n",
      "  G Adv: 0.3957, F Adv: 0.4946\n",
      "  Cycle Photo: 0.0641, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.4941\n",
      "Epoch [43/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0335, D_X Fake: 0.0761, D_X Total: 0.0548\n",
      "  D_Y Real: 0.0894, D_Y Fake: 0.0609, D_Y Total: 0.0751\n",
      "Generator Losses:\n",
      "  G Adv: 0.8185, F Adv: 0.3650\n",
      "  Cycle Photo: 0.0612, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.8473\n",
      "Epoch [43/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3224, D_X Fake: 0.0406, D_X Total: 0.1815\n",
      "  D_Y Real: 0.0558, D_Y Fake: 0.0757, D_Y Total: 0.0658\n",
      "Generator Losses:\n",
      "  G Adv: 0.7024, F Adv: 0.8623\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0451\n",
      "  Perceptual Photo: 0.1790, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 4.2095\n",
      "Epoch [43/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0374, D_X Fake: 0.1306, D_X Total: 0.0840\n",
      "  D_Y Real: 0.0882, D_Y Fake: 0.0621, D_Y Total: 0.0752\n",
      "Generator Losses:\n",
      "  G Adv: 0.9569, F Adv: 0.3671\n",
      "  Cycle Photo: 0.0658, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1935, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 4.1287\n",
      "Epoch [43/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0612, D_X Fake: 0.0500, D_X Total: 0.0556\n",
      "  D_Y Real: 0.2065, D_Y Fake: 0.0491, D_Y Total: 0.1278\n",
      "Generator Losses:\n",
      "  G Adv: 1.0746, F Adv: 0.2686\n",
      "  Cycle Photo: 0.0865, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1575\n",
      "  Total G Loss: 4.1062\n",
      "Epoch [43/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0829, D_X Fake: 0.1598, D_X Total: 0.1213\n",
      "  D_Y Real: 0.1812, D_Y Fake: 0.0447, D_Y Total: 0.1129\n",
      "Generator Losses:\n",
      "  G Adv: 0.7363, F Adv: 0.4535\n",
      "  Cycle Photo: 0.0732, Cycle Monet: 0.0574\n",
      "  Perceptual Photo: 0.2143, Perceptual Monet: 0.2112\n",
      "  Total G Loss: 4.6241\n",
      "Epoch [43/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0577, D_X Fake: 0.1014, D_X Total: 0.0796\n",
      "  D_Y Real: 0.1605, D_Y Fake: 0.0714, D_Y Total: 0.1159\n",
      "Generator Losses:\n",
      "  G Adv: 0.8010, F Adv: 0.5054\n",
      "  Cycle Photo: 0.0518, Cycle Monet: 0.0426\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.6583\n",
      "Epoch [43/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2992, D_X Fake: 0.0563, D_X Total: 0.1777\n",
      "  D_Y Real: 0.0797, D_Y Fake: 0.2627, D_Y Total: 0.1712\n",
      "Generator Losses:\n",
      "  G Adv: 0.3184, F Adv: 1.2117\n",
      "  Cycle Photo: 0.0657, Cycle Monet: 0.0603\n",
      "  Perceptual Photo: 0.1865, Perceptual Monet: 0.1851\n",
      "  Total G Loss: 4.6483\n",
      "Epoch [43/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3880, D_X Fake: 0.1354, D_X Total: 0.2617\n",
      "  D_Y Real: 0.0646, D_Y Fake: 0.0647, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.4582, F Adv: 0.5166\n",
      "  Cycle Photo: 0.0428, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1630, Perceptual Monet: 0.2057\n",
      "  Total G Loss: 3.7022\n",
      "Epoch [43/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0486, D_X Fake: 0.1397, D_X Total: 0.0942\n",
      "  D_Y Real: 0.0455, D_Y Fake: 0.1131, D_Y Total: 0.0793\n",
      "Generator Losses:\n",
      "  G Adv: 0.4266, F Adv: 0.6267\n",
      "  Cycle Photo: 0.0593, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.5987\n",
      "Epoch [43/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0456, D_X Fake: 0.1333, D_X Total: 0.0895\n",
      "  D_Y Real: 0.2084, D_Y Fake: 0.0615, D_Y Total: 0.1349\n",
      "Generator Losses:\n",
      "  G Adv: 0.9660, F Adv: 0.2484\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1753\n",
      "  Total G Loss: 3.5119\n",
      "Epoch [43/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2112, D_X Fake: 0.0239, D_X Total: 0.1175\n",
      "  D_Y Real: 0.0805, D_Y Fake: 0.1121, D_Y Total: 0.0963\n",
      "Generator Losses:\n",
      "  G Adv: 0.6601, F Adv: 0.7663\n",
      "  Cycle Photo: 0.0526, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.8249\n",
      "Epoch [43/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0699, D_X Fake: 0.1614, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0970, D_Y Fake: 0.1425, D_Y Total: 0.1198\n",
      "Generator Losses:\n",
      "  G Adv: 0.5643, F Adv: 0.3636\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.3347\n",
      "Epoch [43/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0562, D_X Fake: 0.1915, D_X Total: 0.1239\n",
      "  D_Y Real: 0.1086, D_Y Fake: 0.1583, D_Y Total: 0.1335\n",
      "Generator Losses:\n",
      "  G Adv: 0.5427, F Adv: 0.4011\n",
      "  Cycle Photo: 0.0480, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1665, Perceptual Monet: 0.1871\n",
      "  Total G Loss: 3.6783\n",
      "Epoch [43/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1052, D_X Fake: 0.0826, D_X Total: 0.0939\n",
      "  D_Y Real: 0.2515, D_Y Fake: 0.0581, D_Y Total: 0.1548\n",
      "Generator Losses:\n",
      "  G Adv: 1.2346, F Adv: 0.9071\n",
      "  Cycle Photo: 0.0595, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1869, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 4.9093\n",
      "Epoch [43/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1648, D_X Fake: 0.0774, D_X Total: 0.1211\n",
      "  D_Y Real: 0.0554, D_Y Fake: 0.0901, D_Y Total: 0.0728\n",
      "Generator Losses:\n",
      "  G Adv: 0.5512, F Adv: 0.5448\n",
      "  Cycle Photo: 0.0459, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1688, Perceptual Monet: 0.1864\n",
      "  Total G Loss: 3.7096\n",
      "Epoch [43/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1025, D_X Fake: 0.1731, D_X Total: 0.1378\n",
      "  D_Y Real: 0.0642, D_Y Fake: 0.3093, D_Y Total: 0.1867\n",
      "Generator Losses:\n",
      "  G Adv: 0.3747, F Adv: 0.4757\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.3703\n",
      "Epoch [43/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1151, D_X Fake: 0.2267, D_X Total: 0.1709\n",
      "  D_Y Real: 0.0791, D_Y Fake: 0.1276, D_Y Total: 0.1034\n",
      "Generator Losses:\n",
      "  G Adv: 0.4586, F Adv: 0.3408\n",
      "  Cycle Photo: 0.0556, Cycle Monet: 0.0542\n",
      "  Perceptual Photo: 0.2115, Perceptual Monet: 0.1960\n",
      "  Total G Loss: 3.9350\n",
      "Epoch [43/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1273, D_X Fake: 0.1520, D_X Total: 0.1397\n",
      "  D_Y Real: 0.1071, D_Y Fake: 0.1386, D_Y Total: 0.1228\n",
      "Generator Losses:\n",
      "  G Adv: 0.5328, F Adv: 0.5381\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1620\n",
      "  Total G Loss: 3.5462\n",
      "Epoch [43/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0702, D_X Fake: 0.1060, D_X Total: 0.0881\n",
      "  D_Y Real: 0.1655, D_Y Fake: 0.1373, D_Y Total: 0.1514\n",
      "Generator Losses:\n",
      "  G Adv: 0.5958, F Adv: 0.4988\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1521, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.3719\n",
      "Epoch [43/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1463, D_X Fake: 0.1071, D_X Total: 0.1267\n",
      "  D_Y Real: 0.0441, D_Y Fake: 0.1024, D_Y Total: 0.0732\n",
      "Generator Losses:\n",
      "  G Adv: 0.6327, F Adv: 0.5937\n",
      "  Cycle Photo: 0.0533, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1755\n",
      "  Total G Loss: 3.7670\n",
      "Epoch [43/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0323, D_X Fake: 0.0864, D_X Total: 0.0593\n",
      "  D_Y Real: 0.1242, D_Y Fake: 0.0425, D_Y Total: 0.0834\n",
      "Generator Losses:\n",
      "  G Adv: 0.8498, F Adv: 0.6050\n",
      "  Cycle Photo: 0.1055, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.2009\n",
      "  Total G Loss: 4.7038\n",
      "Epoch [43/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1313, D_X Fake: 0.0367, D_X Total: 0.0840\n",
      "  D_Y Real: 0.0695, D_Y Fake: 0.0796, D_Y Total: 0.0745\n",
      "Generator Losses:\n",
      "  G Adv: 0.6303, F Adv: 0.6419\n",
      "  Cycle Photo: 0.0554, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.9371\n",
      "Epoch [44/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0354, D_X Fake: 0.0631, D_X Total: 0.0493\n",
      "  D_Y Real: 0.0892, D_Y Fake: 0.0640, D_Y Total: 0.0766\n",
      "Generator Losses:\n",
      "  G Adv: 0.7766, F Adv: 0.4976\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1364\n",
      "  Total G Loss: 3.4788\n",
      "Epoch [44/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0674, D_X Fake: 0.3758, D_X Total: 0.2216\n",
      "  D_Y Real: 0.1040, D_Y Fake: 0.1421, D_Y Total: 0.1231\n",
      "Generator Losses:\n",
      "  G Adv: 0.6161, F Adv: 0.2091\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0428\n",
      "  Perceptual Photo: 0.1600, Perceptual Monet: 0.1892\n",
      "  Total G Loss: 3.3740\n",
      "Epoch [44/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0654, D_X Fake: 0.2441, D_X Total: 0.1548\n",
      "  D_Y Real: 0.0756, D_Y Fake: 0.2206, D_Y Total: 0.1481\n",
      "Generator Losses:\n",
      "  G Adv: 0.3822, F Adv: 0.3669\n",
      "  Cycle Photo: 0.0568, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.3733\n",
      "Epoch [44/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0633, D_X Fake: 0.1458, D_X Total: 0.1046\n",
      "  D_Y Real: 0.0887, D_Y Fake: 0.0540, D_Y Total: 0.0713\n",
      "Generator Losses:\n",
      "  G Adv: 0.7027, F Adv: 0.5258\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1220, Perceptual Monet: 0.1808\n",
      "  Total G Loss: 3.5470\n",
      "Epoch [44/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1581, D_X Fake: 0.1227, D_X Total: 0.1404\n",
      "  D_Y Real: 0.0869, D_Y Fake: 0.1272, D_Y Total: 0.1070\n",
      "Generator Losses:\n",
      "  G Adv: 0.5022, F Adv: 0.4588\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1721, Perceptual Monet: 0.2229\n",
      "  Total G Loss: 3.9677\n",
      "Epoch [44/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0653, D_X Fake: 0.1781, D_X Total: 0.1217\n",
      "  D_Y Real: 0.3268, D_Y Fake: 0.0541, D_Y Total: 0.1905\n",
      "Generator Losses:\n",
      "  G Adv: 1.0468, F Adv: 0.4211\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1713, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.9515\n",
      "Epoch [44/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0381, D_X Fake: 0.1215, D_X Total: 0.0798\n",
      "  D_Y Real: 0.0802, D_Y Fake: 0.0827, D_Y Total: 0.0815\n",
      "Generator Losses:\n",
      "  G Adv: 0.5802, F Adv: 0.5062\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0484\n",
      "  Perceptual Photo: 0.1886, Perceptual Monet: 0.2057\n",
      "  Total G Loss: 3.9650\n",
      "Epoch [44/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2889, D_X Fake: 0.0817, D_X Total: 0.1853\n",
      "  D_Y Real: 0.0858, D_Y Fake: 0.0952, D_Y Total: 0.0905\n",
      "Generator Losses:\n",
      "  G Adv: 0.6258, F Adv: 0.7216\n",
      "  Cycle Photo: 0.0554, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1787, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 4.0224\n",
      "Epoch [44/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1512, D_X Fake: 0.0812, D_X Total: 0.1162\n",
      "  D_Y Real: 0.1818, D_Y Fake: 0.1275, D_Y Total: 0.1546\n",
      "Generator Losses:\n",
      "  G Adv: 0.5562, F Adv: 0.9738\n",
      "  Cycle Photo: 0.0588, Cycle Monet: 0.0474\n",
      "  Perceptual Photo: 0.1622, Perceptual Monet: 0.2000\n",
      "  Total G Loss: 4.4026\n",
      "Epoch [44/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1703, D_X Fake: 0.0635, D_X Total: 0.1169\n",
      "  D_Y Real: 0.2114, D_Y Fake: 0.0582, D_Y Total: 0.1348\n",
      "Generator Losses:\n",
      "  G Adv: 0.6512, F Adv: 0.5047\n",
      "  Cycle Photo: 0.0561, Cycle Monet: 0.0444\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1874\n",
      "  Total G Loss: 3.9341\n",
      "Epoch [44/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0497, D_X Fake: 0.1537, D_X Total: 0.1017\n",
      "  D_Y Real: 0.1061, D_Y Fake: 0.1043, D_Y Total: 0.1052\n",
      "Generator Losses:\n",
      "  G Adv: 0.5814, F Adv: 0.5761\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.6010\n",
      "Epoch [44/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0569, D_X Fake: 0.2004, D_X Total: 0.1286\n",
      "  D_Y Real: 0.0930, D_Y Fake: 0.1532, D_Y Total: 0.1231\n",
      "Generator Losses:\n",
      "  G Adv: 0.4900, F Adv: 0.5632\n",
      "  Cycle Photo: 0.0576, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.2009, Perceptual Monet: 0.1702\n",
      "  Total G Loss: 3.8868\n",
      "Epoch [44/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2772, D_X Fake: 0.0601, D_X Total: 0.1686\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.1451, D_Y Total: 0.0989\n",
      "Generator Losses:\n",
      "  G Adv: 0.5960, F Adv: 0.7190\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 3.7869\n",
      "Epoch [44/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0665, D_X Fake: 0.1037, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0507, D_Y Fake: 0.0616, D_Y Total: 0.0562\n",
      "Generator Losses:\n",
      "  G Adv: 0.6079, F Adv: 0.4922\n",
      "  Cycle Photo: 0.0471, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1846, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.7367\n",
      "Epoch [44/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1361, D_X Fake: 0.1206, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.1018, D_Y Total: 0.0803\n",
      "Generator Losses:\n",
      "  G Adv: 0.5250, F Adv: 0.5597\n",
      "  Cycle Photo: 0.0728, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1947, Perceptual Monet: 0.1887\n",
      "  Total G Loss: 4.1888\n",
      "Epoch [44/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1890, D_X Fake: 0.0467, D_X Total: 0.1179\n",
      "  D_Y Real: 0.1703, D_Y Fake: 0.1243, D_Y Total: 0.1473\n",
      "Generator Losses:\n",
      "  G Adv: 0.5417, F Adv: 0.6990\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1721, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.7266\n",
      "Epoch [44/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2379, D_X Fake: 0.0302, D_X Total: 0.1340\n",
      "  D_Y Real: 0.0741, D_Y Fake: 0.1089, D_Y Total: 0.0915\n",
      "Generator Losses:\n",
      "  G Adv: 0.7175, F Adv: 0.9691\n",
      "  Cycle Photo: 0.0502, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1536, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 4.2872\n",
      "Epoch [44/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0663, D_X Fake: 0.1402, D_X Total: 0.1032\n",
      "  D_Y Real: 0.0851, D_Y Fake: 0.1394, D_Y Total: 0.1122\n",
      "Generator Losses:\n",
      "  G Adv: 0.5059, F Adv: 0.4451\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0441\n",
      "  Perceptual Photo: 0.1744, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5291\n",
      "Epoch [44/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0379, D_X Fake: 0.0537, D_X Total: 0.0458\n",
      "  D_Y Real: 0.0367, D_Y Fake: 0.0825, D_Y Total: 0.0596\n",
      "Generator Losses:\n",
      "  G Adv: 0.7500, F Adv: 0.6651\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.8447\n",
      "Epoch [44/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1107, D_X Fake: 0.1619, D_X Total: 0.1363\n",
      "  D_Y Real: 0.1271, D_Y Fake: 0.1070, D_Y Total: 0.1170\n",
      "Generator Losses:\n",
      "  G Adv: 0.6357, F Adv: 0.4252\n",
      "  Cycle Photo: 0.0571, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1771, Perceptual Monet: 0.1329\n",
      "  Total G Loss: 3.5174\n",
      "Epoch [44/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1792, D_X Fake: 0.1649, D_X Total: 0.1721\n",
      "  D_Y Real: 0.0870, D_Y Fake: 0.0781, D_Y Total: 0.0825\n",
      "Generator Losses:\n",
      "  G Adv: 0.4738, F Adv: 0.5713\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1659, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.4607\n",
      "Epoch [44/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1643, D_X Fake: 0.0553, D_X Total: 0.1098\n",
      "  D_Y Real: 0.1293, D_Y Fake: 0.0584, D_Y Total: 0.0939\n",
      "Generator Losses:\n",
      "  G Adv: 0.7889, F Adv: 0.7804\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.9657\n",
      "Epoch [44/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1047, D_X Fake: 0.0501, D_X Total: 0.0774\n",
      "  D_Y Real: 0.0245, D_Y Fake: 0.1644, D_Y Total: 0.0944\n",
      "Generator Losses:\n",
      "  G Adv: 0.4504, F Adv: 0.8482\n",
      "  Cycle Photo: 0.0749, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1661, Perceptual Monet: 0.2025\n",
      "  Total G Loss: 4.3432\n",
      "Epoch [44/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1761, D_X Fake: 0.0485, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0500, D_Y Fake: 0.1522, D_Y Total: 0.1011\n",
      "Generator Losses:\n",
      "  G Adv: 0.4827, F Adv: 0.6589\n",
      "  Cycle Photo: 0.0792, Cycle Monet: 0.0471\n",
      "  Perceptual Photo: 0.2187, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 4.3841\n",
      "Epoch [45/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1095, D_X Fake: 0.0750, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0696, D_Y Fake: 0.0736, D_Y Total: 0.0716\n",
      "Generator Losses:\n",
      "  G Adv: 0.6438, F Adv: 0.5844\n",
      "  Cycle Photo: 0.0706, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.2036, Perceptual Monet: 0.1460\n",
      "  Total G Loss: 4.0077\n",
      "Epoch [45/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1960, D_X Fake: 0.0726, D_X Total: 0.1343\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.1012, D_Y Total: 0.0628\n",
      "Generator Losses:\n",
      "  G Adv: 0.6115, F Adv: 0.5848\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1761, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.7176\n",
      "Epoch [45/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1470, D_X Fake: 0.1831, D_X Total: 0.1651\n",
      "  D_Y Real: 0.1691, D_Y Fake: 0.0959, D_Y Total: 0.1325\n",
      "Generator Losses:\n",
      "  G Adv: 0.7830, F Adv: 0.5208\n",
      "  Cycle Photo: 0.0668, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1849, Perceptual Monet: 0.1938\n",
      "  Total G Loss: 4.3437\n",
      "Epoch [45/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1145, D_X Fake: 0.1163, D_X Total: 0.1154\n",
      "  D_Y Real: 0.1070, D_Y Fake: 0.0922, D_Y Total: 0.0996\n",
      "Generator Losses:\n",
      "  G Adv: 0.6462, F Adv: 0.5080\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1486, Perceptual Monet: 0.1663\n",
      "  Total G Loss: 3.5585\n",
      "Epoch [45/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0491, D_X Fake: 0.1188, D_X Total: 0.0839\n",
      "  D_Y Real: 0.0846, D_Y Fake: 0.0946, D_Y Total: 0.0896\n",
      "Generator Losses:\n",
      "  G Adv: 0.6365, F Adv: 0.5859\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.3965\n",
      "Epoch [45/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0662, D_X Fake: 0.1648, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0741, D_Y Fake: 0.2198, D_Y Total: 0.1469\n",
      "Generator Losses:\n",
      "  G Adv: 0.3160, F Adv: 0.4885\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.1560\n",
      "  Total G Loss: 3.1159\n",
      "Epoch [45/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1647, D_X Fake: 0.0938, D_X Total: 0.1293\n",
      "  D_Y Real: 0.1364, D_Y Fake: 0.0804, D_Y Total: 0.1084\n",
      "Generator Losses:\n",
      "  G Adv: 0.6968, F Adv: 0.5437\n",
      "  Cycle Photo: 0.0437, Cycle Monet: 0.0448\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.7231\n",
      "Epoch [45/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1248, D_X Fake: 0.0859, D_X Total: 0.1054\n",
      "  D_Y Real: 0.1037, D_Y Fake: 0.1309, D_Y Total: 0.1173\n",
      "Generator Losses:\n",
      "  G Adv: 0.6226, F Adv: 0.6296\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.8517\n",
      "Epoch [45/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0950, D_X Fake: 0.1015, D_X Total: 0.0983\n",
      "  D_Y Real: 0.0553, D_Y Fake: 0.0575, D_Y Total: 0.0564\n",
      "Generator Losses:\n",
      "  G Adv: 0.6788, F Adv: 0.4360\n",
      "  Cycle Photo: 0.0582, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.6020\n",
      "Epoch [45/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0578, D_X Fake: 0.1696, D_X Total: 0.1137\n",
      "  D_Y Real: 0.0661, D_Y Fake: 0.0935, D_Y Total: 0.0798\n",
      "Generator Losses:\n",
      "  G Adv: 0.4756, F Adv: 0.3676\n",
      "  Cycle Photo: 0.0836, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1918, Perceptual Monet: 0.1851\n",
      "  Total G Loss: 3.9473\n",
      "Epoch [45/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0650, D_X Fake: 0.1865, D_X Total: 0.1258\n",
      "  D_Y Real: 0.0648, D_Y Fake: 0.0983, D_Y Total: 0.0815\n",
      "Generator Losses:\n",
      "  G Adv: 0.6348, F Adv: 0.1978\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1633, Perceptual Monet: 0.2084\n",
      "  Total G Loss: 3.5464\n",
      "Epoch [45/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2652, D_X Fake: 0.0375, D_X Total: 0.1513\n",
      "  D_Y Real: 0.1441, D_Y Fake: 0.0941, D_Y Total: 0.1191\n",
      "Generator Losses:\n",
      "  G Adv: 0.5894, F Adv: 0.9060\n",
      "  Cycle Photo: 0.0436, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.9667\n",
      "Epoch [45/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0953, D_X Fake: 0.0237, D_X Total: 0.0595\n",
      "  D_Y Real: 0.0492, D_Y Fake: 0.0482, D_Y Total: 0.0487\n",
      "Generator Losses:\n",
      "  G Adv: 1.0081, F Adv: 0.7477\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1721, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 4.4729\n",
      "Epoch [45/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1464, D_X Fake: 0.0696, D_X Total: 0.1080\n",
      "  D_Y Real: 0.0732, D_Y Fake: 0.0981, D_Y Total: 0.0857\n",
      "Generator Losses:\n",
      "  G Adv: 0.5953, F Adv: 0.5351\n",
      "  Cycle Photo: 0.0484, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1610, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.6414\n",
      "Epoch [45/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1635, D_X Fake: 0.1153, D_X Total: 0.1394\n",
      "  D_Y Real: 0.0711, D_Y Fake: 0.1370, D_Y Total: 0.1040\n",
      "Generator Losses:\n",
      "  G Adv: 0.7506, F Adv: 0.5183\n",
      "  Cycle Photo: 0.0813, Cycle Monet: 0.0529\n",
      "  Perceptual Photo: 0.1759, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 4.3834\n",
      "Epoch [45/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1522, D_X Fake: 0.1144, D_X Total: 0.1333\n",
      "  D_Y Real: 0.0498, D_Y Fake: 0.2246, D_Y Total: 0.1372\n",
      "Generator Losses:\n",
      "  G Adv: 0.4530, F Adv: 0.3087\n",
      "  Cycle Photo: 0.0508, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.1233\n",
      "Epoch [45/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0515, D_X Fake: 0.0571, D_X Total: 0.0543\n",
      "  D_Y Real: 0.0916, D_Y Fake: 0.0591, D_Y Total: 0.0754\n",
      "Generator Losses:\n",
      "  G Adv: 0.6886, F Adv: 0.6247\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1865, Perceptual Monet: 0.1785\n",
      "  Total G Loss: 4.0782\n",
      "Epoch [45/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2042, D_X Fake: 0.0461, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0736, D_Y Fake: 0.1200, D_Y Total: 0.0968\n",
      "Generator Losses:\n",
      "  G Adv: 0.7179, F Adv: 0.5198\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1798, Perceptual Monet: 0.1988\n",
      "  Total G Loss: 4.1586\n",
      "Epoch [45/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2434, D_X Fake: 0.0718, D_X Total: 0.1576\n",
      "  D_Y Real: 0.0664, D_Y Fake: 0.2830, D_Y Total: 0.1747\n",
      "Generator Losses:\n",
      "  G Adv: 0.2791, F Adv: 0.9459\n",
      "  Cycle Photo: 0.0537, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1743, Perceptual Monet: 0.1626\n",
      "  Total G Loss: 3.8156\n",
      "Epoch [45/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1448, D_X Fake: 0.1266, D_X Total: 0.1357\n",
      "  D_Y Real: 0.0801, D_Y Fake: 0.1714, D_Y Total: 0.1257\n",
      "Generator Losses:\n",
      "  G Adv: 0.4486, F Adv: 0.5424\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1994, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.5783\n",
      "Epoch [45/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1253, D_X Fake: 0.0729, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0656, D_Y Fake: 0.0672, D_Y Total: 0.0664\n",
      "Generator Losses:\n",
      "  G Adv: 0.6720, F Adv: 0.5685\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1683, Perceptual Monet: 0.1872\n",
      "  Total G Loss: 3.7663\n",
      "Epoch [45/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0708, D_X Fake: 0.0960, D_X Total: 0.0834\n",
      "  D_Y Real: 0.0834, D_Y Fake: 0.0615, D_Y Total: 0.0724\n",
      "Generator Losses:\n",
      "  G Adv: 0.5997, F Adv: 0.4894\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.6236\n",
      "Epoch [45/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1077, D_X Fake: 0.1186, D_X Total: 0.1131\n",
      "  D_Y Real: 0.0926, D_Y Fake: 0.0895, D_Y Total: 0.0910\n",
      "Generator Losses:\n",
      "  G Adv: 0.7654, F Adv: 0.4058\n",
      "  Cycle Photo: 0.0690, Cycle Monet: 0.0500\n",
      "  Perceptual Photo: 0.1742, Perceptual Monet: 0.1888\n",
      "  Total G Loss: 4.1766\n",
      "Epoch [45/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1509, D_X Fake: 0.0883, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0452, D_Y Fake: 0.0553, D_Y Total: 0.0502\n",
      "Generator Losses:\n",
      "  G Adv: 0.7758, F Adv: 0.5469\n",
      "  Cycle Photo: 0.0578, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.2443, Perceptual Monet: 0.1510\n",
      "  Total G Loss: 4.2655\n",
      "Epoch [46/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1311, D_X Fake: 0.0246, D_X Total: 0.0779\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.1468, D_Y Total: 0.0897\n",
      "Generator Losses:\n",
      "  G Adv: 0.5484, F Adv: 0.7929\n",
      "  Cycle Photo: 0.0513, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1650, Perceptual Monet: 0.1648\n",
      "  Total G Loss: 3.8736\n",
      "Epoch [46/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0484, D_X Fake: 0.2386, D_X Total: 0.1435\n",
      "  D_Y Real: 0.0742, D_Y Fake: 0.1191, D_Y Total: 0.0966\n",
      "Generator Losses:\n",
      "  G Adv: 0.5523, F Adv: 0.2903\n",
      "  Cycle Photo: 0.0851, Cycle Monet: 0.0497\n",
      "  Perceptual Photo: 0.2125, Perceptual Monet: 0.2060\n",
      "  Total G Loss: 4.2830\n",
      "Epoch [46/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0910, D_X Fake: 0.0497, D_X Total: 0.0703\n",
      "  D_Y Real: 0.1481, D_Y Fake: 0.1195, D_Y Total: 0.1338\n",
      "Generator Losses:\n",
      "  G Adv: 0.5479, F Adv: 0.6688\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0524\n",
      "  Perceptual Photo: 0.1642, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.9687\n",
      "Epoch [46/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1346, D_X Fake: 0.0687, D_X Total: 0.1017\n",
      "  D_Y Real: 0.2899, D_Y Fake: 0.0531, D_Y Total: 0.1715\n",
      "Generator Losses:\n",
      "  G Adv: 0.9027, F Adv: 0.6061\n",
      "  Cycle Photo: 0.0474, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1745, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.9522\n",
      "Epoch [46/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1183, D_X Fake: 0.0853, D_X Total: 0.1018\n",
      "  D_Y Real: 0.2454, D_Y Fake: 0.0651, D_Y Total: 0.1553\n",
      "Generator Losses:\n",
      "  G Adv: 0.6750, F Adv: 0.5100\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1532, Perceptual Monet: 0.1910\n",
      "  Total G Loss: 3.7100\n",
      "Epoch [46/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1067, D_X Fake: 0.1139, D_X Total: 0.1103\n",
      "  D_Y Real: 0.0533, D_Y Fake: 0.0973, D_Y Total: 0.0753\n",
      "Generator Losses:\n",
      "  G Adv: 0.6914, F Adv: 0.5248\n",
      "  Cycle Photo: 0.0420, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1483, Perceptual Monet: 0.1847\n",
      "  Total G Loss: 3.7259\n",
      "Epoch [46/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0938, D_X Fake: 0.1685, D_X Total: 0.1312\n",
      "  D_Y Real: 0.1816, D_Y Fake: 0.0668, D_Y Total: 0.1242\n",
      "Generator Losses:\n",
      "  G Adv: 0.9715, F Adv: 0.4174\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1302, Perceptual Monet: 0.1697\n",
      "  Total G Loss: 3.7313\n",
      "Epoch [46/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0950, D_X Fake: 0.1509, D_X Total: 0.1230\n",
      "  D_Y Real: 0.1676, D_Y Fake: 0.0326, D_Y Total: 0.1001\n",
      "Generator Losses:\n",
      "  G Adv: 1.0378, F Adv: 0.3308\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.1552, Perceptual Monet: 0.1960\n",
      "  Total G Loss: 3.9701\n",
      "Epoch [46/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0690, D_X Fake: 0.0598, D_X Total: 0.0644\n",
      "  D_Y Real: 0.0823, D_Y Fake: 0.1495, D_Y Total: 0.1159\n",
      "Generator Losses:\n",
      "  G Adv: 0.5738, F Adv: 0.5973\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1781, Perceptual Monet: 0.1521\n",
      "  Total G Loss: 3.6874\n",
      "Epoch [46/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2129, D_X Fake: 0.0675, D_X Total: 0.1402\n",
      "  D_Y Real: 0.0725, D_Y Fake: 0.2032, D_Y Total: 0.1379\n",
      "Generator Losses:\n",
      "  G Adv: 0.4558, F Adv: 0.6552\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 3.7931\n",
      "Epoch [46/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0963, D_X Fake: 0.2093, D_X Total: 0.1528\n",
      "  D_Y Real: 0.0641, D_Y Fake: 0.1310, D_Y Total: 0.0975\n",
      "Generator Losses:\n",
      "  G Adv: 0.5239, F Adv: 0.3269\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1769, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.3787\n",
      "Epoch [46/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0740, D_X Fake: 0.2782, D_X Total: 0.1761\n",
      "  D_Y Real: 0.1806, D_Y Fake: 0.0510, D_Y Total: 0.1158\n",
      "Generator Losses:\n",
      "  G Adv: 0.9111, F Adv: 0.3250\n",
      "  Cycle Photo: 0.0443, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.8817\n",
      "Epoch [46/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1297, D_X Fake: 0.0979, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0855, D_Y Total: 0.0616\n",
      "Generator Losses:\n",
      "  G Adv: 0.6322, F Adv: 0.6423\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1891, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.8714\n",
      "Epoch [46/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1129, D_X Fake: 0.0786, D_X Total: 0.0958\n",
      "  D_Y Real: 0.0945, D_Y Fake: 0.0842, D_Y Total: 0.0893\n",
      "Generator Losses:\n",
      "  G Adv: 0.5136, F Adv: 0.5779\n",
      "  Cycle Photo: 0.0614, Cycle Monet: 0.0478\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.9170\n",
      "Epoch [46/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0270, D_X Fake: 0.0844, D_X Total: 0.0557\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.1522, D_Y Total: 0.0917\n",
      "Generator Losses:\n",
      "  G Adv: 0.5078, F Adv: 0.6954\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1782, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.7558\n",
      "Epoch [46/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1069, D_X Fake: 0.0907, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0523, D_Y Fake: 0.1129, D_Y Total: 0.0826\n",
      "Generator Losses:\n",
      "  G Adv: 0.5410, F Adv: 0.6390\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1402, Perceptual Monet: 0.1932\n",
      "  Total G Loss: 3.7290\n",
      "Epoch [46/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3005, D_X Fake: 0.3106, D_X Total: 0.3055\n",
      "  D_Y Real: 0.1044, D_Y Fake: 0.0630, D_Y Total: 0.0837\n",
      "Generator Losses:\n",
      "  G Adv: 0.9855, F Adv: 0.4033\n",
      "  Cycle Photo: 0.0696, Cycle Monet: 0.0601\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.2346\n",
      "  Total G Loss: 4.7511\n",
      "Epoch [46/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2654, D_X Fake: 0.2537, D_X Total: 0.2595\n",
      "  D_Y Real: 0.1274, D_Y Fake: 0.0756, D_Y Total: 0.1015\n",
      "Generator Losses:\n",
      "  G Adv: 1.1821, F Adv: 0.2857\n",
      "  Cycle Photo: 0.0544, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 3.9277\n",
      "Epoch [46/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2729, D_X Fake: 0.3293, D_X Total: 0.3011\n",
      "  D_Y Real: 0.0736, D_Y Fake: 0.0814, D_Y Total: 0.0775\n",
      "Generator Losses:\n",
      "  G Adv: 0.5762, F Adv: 0.2529\n",
      "  Cycle Photo: 0.0603, Cycle Monet: 0.0628\n",
      "  Perceptual Photo: 0.1939, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.8633\n",
      "Epoch [46/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2086, D_X Fake: 0.3309, D_X Total: 0.2698\n",
      "  D_Y Real: 0.1459, D_Y Fake: 0.0663, D_Y Total: 0.1061\n",
      "Generator Losses:\n",
      "  G Adv: 1.2666, F Adv: 0.2188\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1520, Perceptual Monet: 0.1372\n",
      "  Total G Loss: 3.7126\n",
      "Epoch [46/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1533, D_X Fake: 0.2516, D_X Total: 0.2024\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0862, D_Y Total: 0.0586\n",
      "Generator Losses:\n",
      "  G Adv: 0.4512, F Adv: 0.2840\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1869, Perceptual Monet: 0.1455\n",
      "  Total G Loss: 3.2719\n",
      "Epoch [46/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3136, D_X Fake: 0.1653, D_X Total: 0.2394\n",
      "  D_Y Real: 0.0851, D_Y Fake: 0.1867, D_Y Total: 0.1359\n",
      "Generator Losses:\n",
      "  G Adv: 0.4590, F Adv: 0.3433\n",
      "  Cycle Photo: 0.0846, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.5149\n",
      "Epoch [46/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2412, D_X Fake: 0.2195, D_X Total: 0.2303\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.1951, D_Y Total: 0.1180\n",
      "Generator Losses:\n",
      "  G Adv: 0.4736, F Adv: 0.2636\n",
      "  Cycle Photo: 0.0587, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.2861\n",
      "Epoch [46/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4233, D_X Fake: 0.2126, D_X Total: 0.3179\n",
      "  D_Y Real: 0.1003, D_Y Fake: 0.0863, D_Y Total: 0.0933\n",
      "Generator Losses:\n",
      "  G Adv: 0.5872, F Adv: 0.2688\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0466\n",
      "  Perceptual Photo: 0.2042, Perceptual Monet: 0.1495\n",
      "  Total G Loss: 3.5989\n",
      "Epoch [47/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2565, D_X Fake: 0.3316, D_X Total: 0.2941\n",
      "  D_Y Real: 0.0933, D_Y Fake: 0.0820, D_Y Total: 0.0876\n",
      "Generator Losses:\n",
      "  G Adv: 0.6140, F Adv: 0.3113\n",
      "  Cycle Photo: 0.0584, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1760, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.6027\n",
      "Epoch [47/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3251, D_X Fake: 0.1868, D_X Total: 0.2560\n",
      "  D_Y Real: 0.1222, D_Y Fake: 0.0478, D_Y Total: 0.0850\n",
      "Generator Losses:\n",
      "  G Adv: 0.8109, F Adv: 0.2853\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1584, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.3537\n",
      "Epoch [47/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3828, D_X Fake: 0.2477, D_X Total: 0.3153\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.2611, D_Y Total: 0.1462\n",
      "Generator Losses:\n",
      "  G Adv: 0.3148, F Adv: 0.2889\n",
      "  Cycle Photo: 0.0725, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1824, Perceptual Monet: 0.1229\n",
      "  Total G Loss: 3.1928\n",
      "Epoch [47/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2174, D_X Fake: 0.2684, D_X Total: 0.2429\n",
      "  D_Y Real: 0.1175, D_Y Fake: 0.0742, D_Y Total: 0.0959\n",
      "Generator Losses:\n",
      "  G Adv: 0.5606, F Adv: 0.2119\n",
      "  Cycle Photo: 0.0493, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1379, Perceptual Monet: 0.1269\n",
      "  Total G Loss: 2.9436\n",
      "Epoch [47/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2238, D_X Fake: 0.2847, D_X Total: 0.2542\n",
      "  D_Y Real: 0.1220, D_Y Fake: 0.0597, D_Y Total: 0.0909\n",
      "Generator Losses:\n",
      "  G Adv: 0.7919, F Adv: 0.2410\n",
      "  Cycle Photo: 0.1149, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.2378, Perceptual Monet: 0.1172\n",
      "  Total G Loss: 4.2984\n",
      "Epoch [47/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3338, D_X Fake: 0.2085, D_X Total: 0.2712\n",
      "  D_Y Real: 0.2150, D_Y Fake: 0.0391, D_Y Total: 0.1271\n",
      "Generator Losses:\n",
      "  G Adv: 0.9569, F Adv: 0.3427\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0503\n",
      "  Perceptual Photo: 0.1643, Perceptual Monet: 0.1835\n",
      "  Total G Loss: 3.9044\n",
      "Epoch [47/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3398, D_X Fake: 0.1752, D_X Total: 0.2575\n",
      "  D_Y Real: 0.0620, D_Y Fake: 0.1465, D_Y Total: 0.1042\n",
      "Generator Losses:\n",
      "  G Adv: 0.6382, F Adv: 0.3296\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1637, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.4697\n",
      "Epoch [47/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2195, D_X Fake: 0.1918, D_X Total: 0.2057\n",
      "  D_Y Real: 0.0580, D_Y Fake: 0.2018, D_Y Total: 0.1299\n",
      "Generator Losses:\n",
      "  G Adv: 0.3508, F Adv: 0.2742\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1443\n",
      "  Total G Loss: 2.8670\n",
      "Epoch [47/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3096, D_X Fake: 0.1867, D_X Total: 0.2482\n",
      "  D_Y Real: 0.0707, D_Y Fake: 0.0768, D_Y Total: 0.0737\n",
      "Generator Losses:\n",
      "  G Adv: 0.6139, F Adv: 0.3779\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1736, Perceptual Monet: 0.1421\n",
      "  Total G Loss: 3.4105\n",
      "Epoch [47/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3216, D_X Fake: 0.3261, D_X Total: 0.3239\n",
      "  D_Y Real: 0.0440, D_Y Fake: 0.0559, D_Y Total: 0.0500\n",
      "Generator Losses:\n",
      "  G Adv: 0.6306, F Adv: 0.2144\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1814, Perceptual Monet: 0.1396\n",
      "  Total G Loss: 3.2735\n",
      "Epoch [47/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2599, D_X Fake: 0.2229, D_X Total: 0.2414\n",
      "  D_Y Real: 0.0838, D_Y Fake: 0.0778, D_Y Total: 0.0808\n",
      "Generator Losses:\n",
      "  G Adv: 0.7637, F Adv: 0.2838\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1803, Perceptual Monet: 0.1437\n",
      "  Total G Loss: 3.5326\n",
      "Epoch [47/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1440, D_X Fake: 0.3542, D_X Total: 0.2491\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.0984, D_Y Total: 0.0711\n",
      "Generator Losses:\n",
      "  G Adv: 0.6520, F Adv: 0.1865\n",
      "  Cycle Photo: 0.0743, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1807, Perceptual Monet: 0.1244\n",
      "  Total G Loss: 3.4121\n",
      "Epoch [47/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1508, D_X Fake: 0.2919, D_X Total: 0.2214\n",
      "  D_Y Real: 0.1091, D_Y Fake: 0.0515, D_Y Total: 0.0803\n",
      "Generator Losses:\n",
      "  G Adv: 0.5035, F Adv: 0.2876\n",
      "  Cycle Photo: 0.0860, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1453, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.5248\n",
      "Epoch [47/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2455, D_X Fake: 0.2856, D_X Total: 0.2656\n",
      "  D_Y Real: 0.1034, D_Y Fake: 0.0490, D_Y Total: 0.0762\n",
      "Generator Losses:\n",
      "  G Adv: 0.8385, F Adv: 0.2266\n",
      "  Cycle Photo: 0.0595, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1916, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.8393\n",
      "Epoch [47/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3241, D_X Fake: 0.2084, D_X Total: 0.2662\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.1629, D_Y Total: 0.1038\n",
      "Generator Losses:\n",
      "  G Adv: 0.5843, F Adv: 0.3558\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1885, Perceptual Monet: 0.1435\n",
      "  Total G Loss: 3.5161\n",
      "Epoch [47/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2160, D_X Fake: 0.2078, D_X Total: 0.2119\n",
      "  D_Y Real: 0.0506, D_Y Fake: 0.0530, D_Y Total: 0.0518\n",
      "Generator Losses:\n",
      "  G Adv: 0.9581, F Adv: 0.3252\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1205\n",
      "  Total G Loss: 3.4113\n",
      "Epoch [47/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2913, D_X Fake: 0.3263, D_X Total: 0.3088\n",
      "  D_Y Real: 0.0762, D_Y Fake: 0.0685, D_Y Total: 0.0723\n",
      "Generator Losses:\n",
      "  G Adv: 0.7149, F Adv: 0.2095\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1887, Perceptual Monet: 0.1488\n",
      "  Total G Loss: 3.4909\n",
      "Epoch [47/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2190, D_X Fake: 0.2849, D_X Total: 0.2519\n",
      "  D_Y Real: 0.0530, D_Y Fake: 0.1498, D_Y Total: 0.1014\n",
      "Generator Losses:\n",
      "  G Adv: 0.4524, F Adv: 0.3146\n",
      "  Cycle Photo: 0.0775, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.1247\n",
      "  Total G Loss: 3.3092\n",
      "Epoch [47/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1215, D_X Fake: 0.3373, D_X Total: 0.2294\n",
      "  D_Y Real: 0.0626, D_Y Fake: 0.0566, D_Y Total: 0.0596\n",
      "Generator Losses:\n",
      "  G Adv: 0.8950, F Adv: 0.2435\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1332\n",
      "  Total G Loss: 3.2813\n",
      "Epoch [47/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1861, D_X Fake: 0.3546, D_X Total: 0.2704\n",
      "  D_Y Real: 0.0864, D_Y Fake: 0.0424, D_Y Total: 0.0644\n",
      "Generator Losses:\n",
      "  G Adv: 1.0493, F Adv: 0.2006\n",
      "  Cycle Photo: 0.0535, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1984, Perceptual Monet: 0.1342\n",
      "  Total G Loss: 3.7460\n",
      "Epoch [47/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2591, D_X Fake: 0.1974, D_X Total: 0.2282\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.1015, D_Y Total: 0.0634\n",
      "Generator Losses:\n",
      "  G Adv: 0.5833, F Adv: 0.2915\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1412, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.3618\n",
      "Epoch [47/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2836, D_X Fake: 0.1724, D_X Total: 0.2280\n",
      "  D_Y Real: 0.1178, D_Y Fake: 0.0315, D_Y Total: 0.0747\n",
      "Generator Losses:\n",
      "  G Adv: 0.8686, F Adv: 0.3432\n",
      "  Cycle Photo: 0.0657, Cycle Monet: 0.0449\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1437\n",
      "  Total G Loss: 3.8508\n",
      "Epoch [47/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2496, D_X Fake: 0.2642, D_X Total: 0.2569\n",
      "  D_Y Real: 0.0885, D_Y Fake: 0.0610, D_Y Total: 0.0747\n",
      "Generator Losses:\n",
      "  G Adv: 0.8421, F Adv: 0.2637\n",
      "  Cycle Photo: 0.0537, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.3968\n",
      "Epoch [47/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2206, D_X Fake: 0.4154, D_X Total: 0.3180\n",
      "  D_Y Real: 0.1241, D_Y Fake: 0.0806, D_Y Total: 0.1024\n",
      "Generator Losses:\n",
      "  G Adv: 0.6162, F Adv: 0.2196\n",
      "  Cycle Photo: 0.0581, Cycle Monet: 0.0461\n",
      "  Perceptual Photo: 0.1475, Perceptual Monet: 0.1469\n",
      "  Total G Loss: 3.3499\n",
      "Epoch [48/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2043, D_X Fake: 0.2382, D_X Total: 0.2213\n",
      "  D_Y Real: 0.1649, D_Y Fake: 0.1295, D_Y Total: 0.1472\n",
      "Generator Losses:\n",
      "  G Adv: 0.8723, F Adv: 0.2982\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1443\n",
      "  Total G Loss: 3.4430\n",
      "Epoch [48/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1339, D_X Fake: 0.3019, D_X Total: 0.2179\n",
      "  D_Y Real: 0.0414, D_Y Fake: 0.2208, D_Y Total: 0.1311\n",
      "Generator Losses:\n",
      "  G Adv: 0.3588, F Adv: 0.2512\n",
      "  Cycle Photo: 0.0607, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1255\n",
      "  Total G Loss: 2.9872\n",
      "Epoch [48/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2824, D_X Fake: 0.0676, D_X Total: 0.1750\n",
      "  D_Y Real: 0.0485, D_Y Fake: 0.1034, D_Y Total: 0.0759\n",
      "Generator Losses:\n",
      "  G Adv: 0.4678, F Adv: 0.4314\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1460, Perceptual Monet: 0.1449\n",
      "  Total G Loss: 3.2288\n",
      "Epoch [48/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1271, D_X Fake: 0.2447, D_X Total: 0.1859\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.1643, D_Y Total: 0.0959\n",
      "Generator Losses:\n",
      "  G Adv: 0.5671, F Adv: 0.3096\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1787, Perceptual Monet: 0.1386\n",
      "  Total G Loss: 3.2390\n",
      "Epoch [48/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0269, D_X Fake: 0.1705, D_X Total: 0.0987\n",
      "  D_Y Real: 0.1266, D_Y Fake: 0.0690, D_Y Total: 0.0978\n",
      "Generator Losses:\n",
      "  G Adv: 0.7520, F Adv: 0.3343\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1322, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.3057\n",
      "Epoch [48/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0275, D_X Fake: 0.1527, D_X Total: 0.0901\n",
      "  D_Y Real: 0.1182, D_Y Fake: 0.0432, D_Y Total: 0.0807\n",
      "Generator Losses:\n",
      "  G Adv: 0.8054, F Adv: 0.3683\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1620, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.6520\n",
      "Epoch [48/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0564, D_X Fake: 0.0693, D_X Total: 0.0629\n",
      "  D_Y Real: 0.0468, D_Y Fake: 0.1017, D_Y Total: 0.0743\n",
      "Generator Losses:\n",
      "  G Adv: 0.6996, F Adv: 0.5548\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0466\n",
      "  Perceptual Photo: 0.1612, Perceptual Monet: 0.1804\n",
      "  Total G Loss: 3.9511\n",
      "Epoch [48/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0266, D_X Fake: 0.0971, D_X Total: 0.0618\n",
      "  D_Y Real: 0.0817, D_Y Fake: 0.0702, D_Y Total: 0.0759\n",
      "Generator Losses:\n",
      "  G Adv: 1.0012, F Adv: 0.4325\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 4.0249\n",
      "Epoch [48/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.0907, D_X Total: 0.0829\n",
      "  D_Y Real: 0.0945, D_Y Fake: 0.1098, D_Y Total: 0.1021\n",
      "Generator Losses:\n",
      "  G Adv: 0.7366, F Adv: 0.6865\n",
      "  Cycle Photo: 0.0454, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.7189\n",
      "Epoch [48/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0960, D_X Fake: 0.1087, D_X Total: 0.1023\n",
      "  D_Y Real: 0.1314, D_Y Fake: 0.0742, D_Y Total: 0.1028\n",
      "Generator Losses:\n",
      "  G Adv: 1.2001, F Adv: 0.6200\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1395, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 4.0819\n",
      "Epoch [48/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1178, D_X Fake: 0.0598, D_X Total: 0.0888\n",
      "  D_Y Real: 0.0524, D_Y Fake: 0.0759, D_Y Total: 0.0641\n",
      "Generator Losses:\n",
      "  G Adv: 0.5508, F Adv: 0.5774\n",
      "  Cycle Photo: 0.0678, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1906, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.8849\n",
      "Epoch [48/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0918, D_X Fake: 0.3000, D_X Total: 0.1959\n",
      "  D_Y Real: 0.0760, D_Y Fake: 0.1481, D_Y Total: 0.1121\n",
      "Generator Losses:\n",
      "  G Adv: 0.4463, F Adv: 0.2493\n",
      "  Cycle Photo: 0.0502, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.1031\n",
      "Epoch [48/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1397, D_X Fake: 0.1140, D_X Total: 0.1269\n",
      "  D_Y Real: 0.0503, D_Y Fake: 0.1631, D_Y Total: 0.1067\n",
      "Generator Losses:\n",
      "  G Adv: 0.4469, F Adv: 0.4196\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1620, Perceptual Monet: 0.1543\n",
      "  Total G Loss: 3.2474\n",
      "Epoch [48/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0767, D_X Fake: 0.1274, D_X Total: 0.1021\n",
      "  D_Y Real: 0.0958, D_Y Fake: 0.1430, D_Y Total: 0.1194\n",
      "Generator Losses:\n",
      "  G Adv: 0.3910, F Adv: 0.4255\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1733, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.3200\n",
      "Epoch [48/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1088, D_X Fake: 0.0581, D_X Total: 0.0835\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.1450, D_Y Total: 0.0963\n",
      "Generator Losses:\n",
      "  G Adv: 0.4111, F Adv: 0.7770\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1372\n",
      "  Total G Loss: 3.4083\n",
      "Epoch [48/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0406, D_X Fake: 0.1513, D_X Total: 0.0959\n",
      "  D_Y Real: 0.1541, D_Y Fake: 0.0747, D_Y Total: 0.1144\n",
      "Generator Losses:\n",
      "  G Adv: 0.7121, F Adv: 0.3231\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0570\n",
      "  Perceptual Photo: 0.1944, Perceptual Monet: 0.2347\n",
      "  Total G Loss: 4.2764\n",
      "Epoch [48/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0337, D_X Fake: 0.2549, D_X Total: 0.1443\n",
      "  D_Y Real: 0.2302, D_Y Fake: 0.0518, D_Y Total: 0.1410\n",
      "Generator Losses:\n",
      "  G Adv: 0.7477, F Adv: 0.2647\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0493\n",
      "  Perceptual Photo: 0.1469, Perceptual Monet: 0.2100\n",
      "  Total G Loss: 3.6504\n",
      "Epoch [48/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2581, D_X Fake: 0.0453, D_X Total: 0.1517\n",
      "  D_Y Real: 0.1549, D_Y Fake: 0.0837, D_Y Total: 0.1193\n",
      "Generator Losses:\n",
      "  G Adv: 0.6105, F Adv: 0.9416\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1648, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 4.0855\n",
      "Epoch [48/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0666, D_X Fake: 0.1581, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0837, D_Y Fake: 0.0763, D_Y Total: 0.0800\n",
      "Generator Losses:\n",
      "  G Adv: 0.7618, F Adv: 0.3637\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.2008, Perceptual Monet: 0.2062\n",
      "  Total G Loss: 4.0810\n",
      "Epoch [48/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0721, D_X Fake: 0.0950, D_X Total: 0.0835\n",
      "  D_Y Real: 0.0425, D_Y Fake: 0.1090, D_Y Total: 0.0757\n",
      "Generator Losses:\n",
      "  G Adv: 0.6788, F Adv: 0.4690\n",
      "  Cycle Photo: 0.0551, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.5736\n",
      "Epoch [48/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0514, D_X Fake: 0.1027, D_X Total: 0.0771\n",
      "  D_Y Real: 0.0714, D_Y Fake: 0.0371, D_Y Total: 0.0543\n",
      "Generator Losses:\n",
      "  G Adv: 0.8862, F Adv: 0.5348\n",
      "  Cycle Photo: 0.0848, Cycle Monet: 0.0438\n",
      "  Perceptual Photo: 0.1612, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 4.3531\n",
      "Epoch [48/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1595, D_X Fake: 0.0613, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0730, D_Y Fake: 0.1548, D_Y Total: 0.1139\n",
      "Generator Losses:\n",
      "  G Adv: 0.5365, F Adv: 0.6401\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.2114, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 4.1311\n",
      "Epoch [48/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0293, D_X Fake: 0.1843, D_X Total: 0.1068\n",
      "  D_Y Real: 0.0800, D_Y Fake: 0.0748, D_Y Total: 0.0774\n",
      "Generator Losses:\n",
      "  G Adv: 0.5870, F Adv: 0.4148\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1330\n",
      "  Total G Loss: 3.1288\n",
      "Epoch [48/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1427, D_X Fake: 0.0822, D_X Total: 0.1124\n",
      "  D_Y Real: 0.1191, D_Y Fake: 0.0330, D_Y Total: 0.0760\n",
      "Generator Losses:\n",
      "  G Adv: 0.7638, F Adv: 0.3709\n",
      "  Cycle Photo: 0.0705, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.2672, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 4.4186\n",
      "Epoch [49/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1261, D_X Fake: 0.0414, D_X Total: 0.0837\n",
      "  D_Y Real: 0.0565, D_Y Fake: 0.1819, D_Y Total: 0.1192\n",
      "Generator Losses:\n",
      "  G Adv: 0.4553, F Adv: 0.7351\n",
      "  Cycle Photo: 0.0694, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.2115, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 4.0908\n",
      "Epoch [49/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0410, D_X Fake: 0.0722, D_X Total: 0.0566\n",
      "  D_Y Real: 0.0502, D_Y Fake: 0.2749, D_Y Total: 0.1625\n",
      "Generator Losses:\n",
      "  G Adv: 0.3391, F Adv: 0.4526\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1696, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.2701\n",
      "Epoch [49/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2821, D_X Fake: 0.0667, D_X Total: 0.1744\n",
      "  D_Y Real: 0.0721, D_Y Fake: 0.0493, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.6256, F Adv: 0.7064\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1513, Perceptual Monet: 0.1495\n",
      "  Total G Loss: 3.6156\n",
      "Epoch [49/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2703, D_X Fake: 0.0395, D_X Total: 0.1549\n",
      "  D_Y Real: 0.1567, D_Y Fake: 0.1725, D_Y Total: 0.1646\n",
      "Generator Losses:\n",
      "  G Adv: 0.5528, F Adv: 1.1329\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1757, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 4.4418\n",
      "Epoch [49/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0449, D_X Fake: 0.2757, D_X Total: 0.1603\n",
      "  D_Y Real: 0.1535, D_Y Fake: 0.0555, D_Y Total: 0.1045\n",
      "Generator Losses:\n",
      "  G Adv: 0.8504, F Adv: 0.1560\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1787, Perceptual Monet: 0.1836\n",
      "  Total G Loss: 3.7212\n",
      "Epoch [49/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0635, D_X Fake: 0.0463, D_X Total: 0.0549\n",
      "  D_Y Real: 0.0599, D_Y Fake: 0.0577, D_Y Total: 0.0588\n",
      "Generator Losses:\n",
      "  G Adv: 0.7733, F Adv: 0.5165\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1679, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.8023\n",
      "Epoch [49/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1605, D_X Fake: 0.1345, D_X Total: 0.1475\n",
      "  D_Y Real: 0.0704, D_Y Fake: 0.1871, D_Y Total: 0.1287\n",
      "Generator Losses:\n",
      "  G Adv: 0.3157, F Adv: 0.5591\n",
      "  Cycle Photo: 0.0548, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.5104\n",
      "Epoch [49/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1120, D_X Fake: 0.0660, D_X Total: 0.0890\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.1552, D_Y Total: 0.0978\n",
      "Generator Losses:\n",
      "  G Adv: 0.4868, F Adv: 0.6818\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1855, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.9594\n",
      "Epoch [49/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0684, D_X Fake: 0.2899, D_X Total: 0.1791\n",
      "  D_Y Real: 0.0460, D_Y Fake: 0.1155, D_Y Total: 0.0808\n",
      "Generator Losses:\n",
      "  G Adv: 0.5000, F Adv: 0.3822\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.0797\n",
      "Epoch [49/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0384, D_X Fake: 0.0965, D_X Total: 0.0675\n",
      "  D_Y Real: 0.0788, D_Y Fake: 0.0480, D_Y Total: 0.0634\n",
      "Generator Losses:\n",
      "  G Adv: 0.8406, F Adv: 0.5441\n",
      "  Cycle Photo: 0.0626, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1916, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 4.1386\n",
      "Epoch [49/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0836, D_X Fake: 0.1144, D_X Total: 0.0990\n",
      "  D_Y Real: 0.0616, D_Y Fake: 0.1274, D_Y Total: 0.0945\n",
      "Generator Losses:\n",
      "  G Adv: 0.3256, F Adv: 0.4365\n",
      "  Cycle Photo: 0.0628, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1655\n",
      "  Total G Loss: 3.3691\n",
      "Epoch [49/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2698, D_X Fake: 0.0208, D_X Total: 0.1453\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.2673, D_Y Total: 0.1556\n",
      "Generator Losses:\n",
      "  G Adv: 0.3561, F Adv: 0.8755\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.6619\n",
      "Epoch [49/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1505, D_X Fake: 0.1466, D_X Total: 0.1485\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0457, D_Y Total: 0.0474\n",
      "Generator Losses:\n",
      "  G Adv: 0.6106, F Adv: 0.3734\n",
      "  Cycle Photo: 0.0566, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.2135, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.8204\n",
      "Epoch [49/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2264, D_X Fake: 0.0491, D_X Total: 0.1377\n",
      "  D_Y Real: 0.1233, D_Y Fake: 0.1384, D_Y Total: 0.1309\n",
      "Generator Losses:\n",
      "  G Adv: 0.5670, F Adv: 0.8559\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0625\n",
      "  Perceptual Photo: 0.2034, Perceptual Monet: 0.1799\n",
      "  Total G Loss: 4.4522\n",
      "Epoch [49/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0475, D_X Fake: 0.0487, D_X Total: 0.0481\n",
      "  D_Y Real: 0.0625, D_Y Fake: 0.1942, D_Y Total: 0.1283\n",
      "Generator Losses:\n",
      "  G Adv: 0.2785, F Adv: 0.7980\n",
      "  Cycle Photo: 0.0548, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.5939\n",
      "Epoch [49/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0826, D_X Fake: 0.1698, D_X Total: 0.1262\n",
      "  D_Y Real: 0.0712, D_Y Fake: 0.1054, D_Y Total: 0.0883\n",
      "Generator Losses:\n",
      "  G Adv: 0.6949, F Adv: 0.2740\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1733, Perceptual Monet: 0.1292\n",
      "  Total G Loss: 3.2453\n",
      "Epoch [49/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2492, D_X Fake: 0.0749, D_X Total: 0.1621\n",
      "  D_Y Real: 0.0930, D_Y Fake: 0.0906, D_Y Total: 0.0918\n",
      "Generator Losses:\n",
      "  G Adv: 0.6388, F Adv: 0.7244\n",
      "  Cycle Photo: 0.0611, Cycle Monet: 0.0540\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 4.1638\n",
      "Epoch [49/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1899, D_X Fake: 0.0467, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0759, D_Y Fake: 0.1675, D_Y Total: 0.1217\n",
      "Generator Losses:\n",
      "  G Adv: 0.4082, F Adv: 0.6560\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1693, Perceptual Monet: 0.1898\n",
      "  Total G Loss: 3.8177\n",
      "Epoch [49/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0978, D_X Fake: 0.0433, D_X Total: 0.0706\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.1454, D_Y Total: 0.0922\n",
      "Generator Losses:\n",
      "  G Adv: 0.5918, F Adv: 0.5494\n",
      "  Cycle Photo: 0.0701, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1908, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 4.0241\n",
      "Epoch [49/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0735, D_X Fake: 0.0437, D_X Total: 0.0586\n",
      "  D_Y Real: 0.1170, D_Y Fake: 0.1081, D_Y Total: 0.1125\n",
      "Generator Losses:\n",
      "  G Adv: 0.5978, F Adv: 0.4210\n",
      "  Cycle Photo: 0.0590, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1713, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.5106\n",
      "Epoch [49/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1149, D_X Fake: 0.0801, D_X Total: 0.0975\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.0757, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.5687, F Adv: 0.5497\n",
      "  Cycle Photo: 0.0727, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.2197, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 4.2093\n",
      "Epoch [49/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2201, D_X Fake: 0.1311, D_X Total: 0.1756\n",
      "  D_Y Real: 0.0593, D_Y Fake: 0.0602, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.5561, F Adv: 0.5162\n",
      "  Cycle Photo: 0.0443, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.6361\n",
      "Epoch [49/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1176, D_X Fake: 0.0722, D_X Total: 0.0949\n",
      "  D_Y Real: 0.0781, D_Y Fake: 0.1867, D_Y Total: 0.1324\n",
      "Generator Losses:\n",
      "  G Adv: 0.3216, F Adv: 0.7055\n",
      "  Cycle Photo: 0.0573, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1791, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.7210\n",
      "Epoch [49/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0416, D_X Fake: 0.0710, D_X Total: 0.0563\n",
      "  D_Y Real: 0.0673, D_Y Fake: 0.0745, D_Y Total: 0.0709\n",
      "Generator Losses:\n",
      "  G Adv: 0.8702, F Adv: 0.7021\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1941, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 4.3357\n",
      "Epoch [50/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1221, D_X Fake: 0.0502, D_X Total: 0.0861\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.1016, D_Y Total: 0.0771\n",
      "Generator Losses:\n",
      "  G Adv: 0.6142, F Adv: 0.7130\n",
      "  Cycle Photo: 0.0625, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1728, Perceptual Monet: 0.1835\n",
      "  Total G Loss: 4.1508\n",
      "Epoch [50/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2386, D_X Fake: 0.0743, D_X Total: 0.1564\n",
      "  D_Y Real: 0.1053, D_Y Fake: 0.1597, D_Y Total: 0.1325\n",
      "Generator Losses:\n",
      "  G Adv: 0.4718, F Adv: 0.5108\n",
      "  Cycle Photo: 0.0454, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.5322\n",
      "Epoch [50/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0454, D_X Fake: 0.1652, D_X Total: 0.1053\n",
      "  D_Y Real: 0.1187, D_Y Fake: 0.0578, D_Y Total: 0.0882\n",
      "Generator Losses:\n",
      "  G Adv: 0.6977, F Adv: 0.3670\n",
      "  Cycle Photo: 0.0593, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1747, Perceptual Monet: 0.1527\n",
      "  Total G Loss: 3.6534\n",
      "Epoch [50/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1067, D_X Fake: 0.0775, D_X Total: 0.0921\n",
      "  D_Y Real: 0.0623, D_Y Fake: 0.0710, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.6515, F Adv: 0.8491\n",
      "  Cycle Photo: 0.0618, Cycle Monet: 0.0570\n",
      "  Perceptual Photo: 0.1812, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 4.3727\n",
      "Epoch [50/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0849, D_X Fake: 0.1221, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0814, D_Y Fake: 0.1146, D_Y Total: 0.0980\n",
      "Generator Losses:\n",
      "  G Adv: 0.5151, F Adv: 0.5813\n",
      "  Cycle Photo: 0.0706, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.8670\n",
      "Epoch [50/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0769, D_X Fake: 0.0384, D_X Total: 0.0576\n",
      "  D_Y Real: 0.1423, D_Y Fake: 0.0776, D_Y Total: 0.1100\n",
      "Generator Losses:\n",
      "  G Adv: 0.7923, F Adv: 0.6360\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.1737\n",
      "  Total G Loss: 3.7416\n",
      "Epoch [50/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1258, D_X Fake: 0.0487, D_X Total: 0.0873\n",
      "  D_Y Real: 0.0902, D_Y Fake: 0.1700, D_Y Total: 0.1301\n",
      "Generator Losses:\n",
      "  G Adv: 0.5708, F Adv: 0.9367\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1237, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.8325\n",
      "Epoch [50/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3570, D_X Fake: 0.0747, D_X Total: 0.2159\n",
      "  D_Y Real: 0.0530, D_Y Fake: 0.1379, D_Y Total: 0.0954\n",
      "Generator Losses:\n",
      "  G Adv: 0.4844, F Adv: 0.8988\n",
      "  Cycle Photo: 0.0559, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1965, Perceptual Monet: 0.1577\n",
      "  Total G Loss: 4.0355\n",
      "Epoch [50/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1092, D_X Fake: 0.0821, D_X Total: 0.0957\n",
      "  D_Y Real: 0.0602, D_Y Fake: 0.0392, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.5041, F Adv: 0.6005\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1408\n",
      "  Total G Loss: 3.1482\n",
      "Epoch [50/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.2438, D_X Total: 0.1466\n",
      "  D_Y Real: 0.0699, D_Y Fake: 0.1086, D_Y Total: 0.0892\n",
      "Generator Losses:\n",
      "  G Adv: 0.6354, F Adv: 0.3692\n",
      "  Cycle Photo: 0.0769, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1750, Perceptual Monet: 0.1772\n",
      "  Total G Loss: 3.9645\n",
      "Epoch [50/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2025, D_X Fake: 0.1045, D_X Total: 0.1535\n",
      "  D_Y Real: 0.0665, D_Y Fake: 0.1013, D_Y Total: 0.0839\n",
      "Generator Losses:\n",
      "  G Adv: 0.5220, F Adv: 0.6358\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.2105, Perceptual Monet: 0.1962\n",
      "  Total G Loss: 4.0874\n",
      "Epoch [50/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0941, D_X Fake: 0.1984, D_X Total: 0.1462\n",
      "  D_Y Real: 0.0498, D_Y Fake: 0.0698, D_Y Total: 0.0598\n",
      "Generator Losses:\n",
      "  G Adv: 0.7712, F Adv: 0.4146\n",
      "  Cycle Photo: 0.0507, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.1332\n",
      "  Total G Loss: 3.3673\n",
      "Epoch [50/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1512, D_X Fake: 0.0745, D_X Total: 0.1129\n",
      "  D_Y Real: 0.0519, D_Y Fake: 0.0669, D_Y Total: 0.0594\n",
      "Generator Losses:\n",
      "  G Adv: 0.6947, F Adv: 0.7460\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 4.0170\n",
      "Epoch [50/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0639, D_X Fake: 0.1338, D_X Total: 0.0989\n",
      "  D_Y Real: 0.0576, D_Y Fake: 0.0945, D_Y Total: 0.0761\n",
      "Generator Losses:\n",
      "  G Adv: 0.7897, F Adv: 0.4981\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0456\n",
      "  Perceptual Photo: 0.1557, Perceptual Monet: 0.1804\n",
      "  Total G Loss: 3.7534\n",
      "Epoch [50/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0738, D_X Fake: 0.0507, D_X Total: 0.0622\n",
      "  D_Y Real: 0.2546, D_Y Fake: 0.0488, D_Y Total: 0.1517\n",
      "Generator Losses:\n",
      "  G Adv: 1.0757, F Adv: 0.5509\n",
      "  Cycle Photo: 0.0646, Cycle Monet: 0.0451\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1870\n",
      "  Total G Loss: 4.3399\n",
      "Epoch [50/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0640, D_X Fake: 0.0749, D_X Total: 0.0694\n",
      "  D_Y Real: 0.2408, D_Y Fake: 0.1020, D_Y Total: 0.1714\n",
      "Generator Losses:\n",
      "  G Adv: 1.4515, F Adv: 0.3017\n",
      "  Cycle Photo: 0.0713, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 4.3431\n",
      "Epoch [50/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0557, D_X Fake: 0.1783, D_X Total: 0.1170\n",
      "  D_Y Real: 0.1911, D_Y Fake: 0.0872, D_Y Total: 0.1392\n",
      "Generator Losses:\n",
      "  G Adv: 1.1199, F Adv: 0.4470\n",
      "  Cycle Photo: 0.0557, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1144, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.8155\n",
      "Epoch [50/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1451, D_X Fake: 0.0559, D_X Total: 0.1005\n",
      "  D_Y Real: 0.0874, D_Y Fake: 0.1742, D_Y Total: 0.1308\n",
      "Generator Losses:\n",
      "  G Adv: 0.4903, F Adv: 0.5771\n",
      "  Cycle Photo: 0.0535, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.2169, Perceptual Monet: 0.1534\n",
      "  Total G Loss: 3.7735\n",
      "Epoch [50/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1020, D_X Fake: 0.0857, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0586, D_Y Fake: 0.0942, D_Y Total: 0.0764\n",
      "Generator Losses:\n",
      "  G Adv: 0.5948, F Adv: 0.5046\n",
      "  Cycle Photo: 0.0521, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1777, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.7377\n",
      "Epoch [50/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0929, D_X Fake: 0.0249, D_X Total: 0.0589\n",
      "  D_Y Real: 0.0915, D_Y Fake: 0.0802, D_Y Total: 0.0858\n",
      "Generator Losses:\n",
      "  G Adv: 0.5987, F Adv: 0.6616\n",
      "  Cycle Photo: 0.0706, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1696, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 4.0505\n",
      "Epoch [50/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1448, D_X Fake: 0.0788, D_X Total: 0.1118\n",
      "  D_Y Real: 0.0802, D_Y Fake: 0.0624, D_Y Total: 0.0713\n",
      "Generator Losses:\n",
      "  G Adv: 0.7279, F Adv: 0.4813\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.7973\n",
      "Epoch [50/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0538, D_X Fake: 0.2820, D_X Total: 0.1679\n",
      "  D_Y Real: 0.0873, D_Y Fake: 0.0678, D_Y Total: 0.0776\n",
      "Generator Losses:\n",
      "  G Adv: 0.9561, F Adv: 0.2968\n",
      "  Cycle Photo: 0.0570, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1969, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.9969\n",
      "Epoch [50/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1138, D_X Fake: 0.0991, D_X Total: 0.1064\n",
      "  D_Y Real: 0.0985, D_Y Fake: 0.0416, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.8677, F Adv: 0.7263\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 4.0620\n",
      "Epoch [50/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1502, D_X Fake: 0.1113, D_X Total: 0.1308\n",
      "  D_Y Real: 0.0895, D_Y Fake: 0.2111, D_Y Total: 0.1503\n",
      "Generator Losses:\n",
      "  G Adv: 0.4653, F Adv: 0.6339\n",
      "  Cycle Photo: 0.0540, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 3.6192\n",
      "Epoch [51/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2981, D_X Fake: 0.0539, D_X Total: 0.1760\n",
      "  D_Y Real: 0.0639, D_Y Fake: 0.1239, D_Y Total: 0.0939\n",
      "Generator Losses:\n",
      "  G Adv: 0.5686, F Adv: 0.6974\n",
      "  Cycle Photo: 0.0710, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.2010, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 4.2395\n",
      "Epoch [51/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1874, D_X Fake: 0.0568, D_X Total: 0.1221\n",
      "  D_Y Real: 0.2246, D_Y Fake: 0.0532, D_Y Total: 0.1389\n",
      "Generator Losses:\n",
      "  G Adv: 0.8422, F Adv: 0.7377\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1677, Perceptual Monet: 0.1457\n",
      "  Total G Loss: 3.9112\n",
      "Epoch [51/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1297, D_X Fake: 0.1034, D_X Total: 0.1166\n",
      "  D_Y Real: 0.1398, D_Y Fake: 0.1163, D_Y Total: 0.1281\n",
      "Generator Losses:\n",
      "  G Adv: 0.6275, F Adv: 0.6481\n",
      "  Cycle Photo: 0.0560, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1779, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.9021\n",
      "Epoch [51/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 2.3175, D_X Fake: 1.3634, D_X Total: 1.8405\n",
      "  D_Y Real: 0.0731, D_Y Fake: 0.0651, D_Y Total: 0.0691\n",
      "Generator Losses:\n",
      "  G Adv: 0.7186, F Adv: 2.2337\n",
      "  Cycle Photo: 0.1894, Cycle Monet: 0.3278\n",
      "  Perceptual Photo: 0.3528, Perceptual Monet: 0.3837\n",
      "  Total G Loss: 11.8073\n",
      "Epoch [51/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2466, D_X Fake: 0.4070, D_X Total: 0.3268\n",
      "  D_Y Real: 0.0907, D_Y Fake: 0.0671, D_Y Total: 0.0789\n",
      "Generator Losses:\n",
      "  G Adv: 0.7305, F Adv: 0.2162\n",
      "  Cycle Photo: 0.0455, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1466, Perceptual Monet: 0.1261\n",
      "  Total G Loss: 3.1519\n",
      "Epoch [51/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2873, D_X Fake: 0.3591, D_X Total: 0.3232\n",
      "  D_Y Real: 0.0527, D_Y Fake: 0.0483, D_Y Total: 0.0505\n",
      "Generator Losses:\n",
      "  G Adv: 0.7821, F Adv: 0.1895\n",
      "  Cycle Photo: 0.0450, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.4997\n",
      "Epoch [51/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2885, D_X Fake: 0.2693, D_X Total: 0.2789\n",
      "  D_Y Real: 0.0795, D_Y Fake: 0.0968, D_Y Total: 0.0882\n",
      "Generator Losses:\n",
      "  G Adv: 0.7252, F Adv: 0.2608\n",
      "  Cycle Photo: 0.0438, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.3946\n",
      "Epoch [51/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2256, D_X Fake: 0.2656, D_X Total: 0.2456\n",
      "  D_Y Real: 0.0711, D_Y Fake: 0.1644, D_Y Total: 0.1177\n",
      "Generator Losses:\n",
      "  G Adv: 0.4638, F Adv: 0.2911\n",
      "  Cycle Photo: 0.0531, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1353\n",
      "  Total G Loss: 2.9900\n",
      "Epoch [51/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2938, D_X Fake: 0.2598, D_X Total: 0.2768\n",
      "  D_Y Real: 0.0972, D_Y Fake: 0.0858, D_Y Total: 0.0915\n",
      "Generator Losses:\n",
      "  G Adv: 1.1063, F Adv: 0.2956\n",
      "  Cycle Photo: 0.0947, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1609, Perceptual Monet: 0.1451\n",
      "  Total G Loss: 4.2529\n",
      "Epoch [51/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3340, D_X Fake: 0.2222, D_X Total: 0.2781\n",
      "  D_Y Real: 0.0599, D_Y Fake: 0.0586, D_Y Total: 0.0592\n",
      "Generator Losses:\n",
      "  G Adv: 0.5686, F Adv: 0.2804\n",
      "  Cycle Photo: 0.0774, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1310\n",
      "  Total G Loss: 3.4475\n",
      "Epoch [51/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3260, D_X Fake: 0.2870, D_X Total: 0.3065\n",
      "  D_Y Real: 0.0620, D_Y Fake: 0.0564, D_Y Total: 0.0592\n",
      "Generator Losses:\n",
      "  G Adv: 0.5620, F Adv: 0.3289\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1724, Perceptual Monet: 0.1338\n",
      "  Total G Loss: 3.3731\n",
      "Epoch [51/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2618, D_X Fake: 0.2819, D_X Total: 0.2719\n",
      "  D_Y Real: 0.1057, D_Y Fake: 0.0444, D_Y Total: 0.0751\n",
      "Generator Losses:\n",
      "  G Adv: 0.6941, F Adv: 0.2257\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0541\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.3435\n",
      "Epoch [51/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3058, D_X Fake: 0.2188, D_X Total: 0.2623\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.0564, D_Y Total: 0.0508\n",
      "Generator Losses:\n",
      "  G Adv: 0.9982, F Adv: 0.3067\n",
      "  Cycle Photo: 0.0539, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 3.8039\n",
      "Epoch [51/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2377, D_X Fake: 0.2043, D_X Total: 0.2210\n",
      "  D_Y Real: 0.1091, D_Y Fake: 0.0803, D_Y Total: 0.0947\n",
      "Generator Losses:\n",
      "  G Adv: 0.6937, F Adv: 0.3347\n",
      "  Cycle Photo: 0.0365, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1113\n",
      "  Total G Loss: 2.8805\n",
      "Epoch [51/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2635, D_X Fake: 0.2903, D_X Total: 0.2769\n",
      "  D_Y Real: 0.0659, D_Y Fake: 0.1628, D_Y Total: 0.1143\n",
      "Generator Losses:\n",
      "  G Adv: 0.3789, F Adv: 0.2302\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1458, Perceptual Monet: 0.1409\n",
      "  Total G Loss: 2.8922\n",
      "Epoch [51/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1809, D_X Fake: 0.2588, D_X Total: 0.2199\n",
      "  D_Y Real: 0.0363, D_Y Fake: 0.1324, D_Y Total: 0.0843\n",
      "Generator Losses:\n",
      "  G Adv: 0.4197, F Adv: 0.2220\n",
      "  Cycle Photo: 0.0820, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1357\n",
      "  Total G Loss: 3.2865\n",
      "Epoch [51/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2560, D_X Fake: 0.3028, D_X Total: 0.2794\n",
      "  D_Y Real: 0.0549, D_Y Fake: 0.0528, D_Y Total: 0.0539\n",
      "Generator Losses:\n",
      "  G Adv: 0.8054, F Adv: 0.1775\n",
      "  Cycle Photo: 0.0829, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.2069, Perceptual Monet: 0.1202\n",
      "  Total G Loss: 3.6843\n",
      "Epoch [51/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3481, D_X Fake: 0.2454, D_X Total: 0.2967\n",
      "  D_Y Real: 0.1095, D_Y Fake: 0.1655, D_Y Total: 0.1375\n",
      "Generator Losses:\n",
      "  G Adv: 0.8459, F Adv: 0.2379\n",
      "  Cycle Photo: 0.0526, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1159\n",
      "  Total G Loss: 3.2093\n",
      "Epoch [51/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2277, D_X Fake: 0.3081, D_X Total: 0.2679\n",
      "  D_Y Real: 0.2513, D_Y Fake: 0.0566, D_Y Total: 0.1540\n",
      "Generator Losses:\n",
      "  G Adv: 1.1012, F Adv: 0.2248\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1513, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.5009\n",
      "Epoch [51/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2649, D_X Fake: 0.2551, D_X Total: 0.2600\n",
      "  D_Y Real: 0.3106, D_Y Fake: 0.0554, D_Y Total: 0.1830\n",
      "Generator Losses:\n",
      "  G Adv: 0.9520, F Adv: 0.2673\n",
      "  Cycle Photo: 0.0744, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1913, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 4.1392\n",
      "Epoch [51/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2565, D_X Fake: 0.2577, D_X Total: 0.2571\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.1557, D_Y Total: 0.1001\n",
      "Generator Losses:\n",
      "  G Adv: 0.3793, F Adv: 0.2331\n",
      "  Cycle Photo: 0.0691, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1783, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.3366\n",
      "Epoch [51/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3294, D_X Fake: 0.2129, D_X Total: 0.2711\n",
      "  D_Y Real: 0.0655, D_Y Fake: 0.1116, D_Y Total: 0.0886\n",
      "Generator Losses:\n",
      "  G Adv: 0.6598, F Adv: 0.3168\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1649, Perceptual Monet: 0.1395\n",
      "  Total G Loss: 3.1972\n",
      "Epoch [51/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2215, D_X Fake: 0.2606, D_X Total: 0.2410\n",
      "  D_Y Real: 0.1135, D_Y Fake: 0.0576, D_Y Total: 0.0855\n",
      "Generator Losses:\n",
      "  G Adv: 0.7433, F Adv: 0.2518\n",
      "  Cycle Photo: 0.0596, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1101, Perceptual Monet: 0.1409\n",
      "  Total G Loss: 3.2005\n",
      "Epoch [51/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2875, D_X Fake: 0.2360, D_X Total: 0.2617\n",
      "  D_Y Real: 0.0712, D_Y Fake: 0.0695, D_Y Total: 0.0704\n",
      "Generator Losses:\n",
      "  G Adv: 0.6337, F Adv: 0.2600\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0457\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.1852\n",
      "Epoch [52/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3085, D_X Fake: 0.1852, D_X Total: 0.2468\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.1503, D_Y Total: 0.0986\n",
      "Generator Losses:\n",
      "  G Adv: 0.4472, F Adv: 0.3443\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.2031, Perceptual Monet: 0.1379\n",
      "  Total G Loss: 3.3148\n",
      "Epoch [52/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2832, D_X Fake: 0.2487, D_X Total: 0.2659\n",
      "  D_Y Real: 0.0533, D_Y Fake: 0.2685, D_Y Total: 0.1609\n",
      "Generator Losses:\n",
      "  G Adv: 0.3523, F Adv: 0.2253\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1372\n",
      "  Total G Loss: 2.8701\n",
      "Epoch [52/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3393, D_X Fake: 0.1988, D_X Total: 0.2690\n",
      "  D_Y Real: 0.1271, D_Y Fake: 0.0545, D_Y Total: 0.0908\n",
      "Generator Losses:\n",
      "  G Adv: 0.7178, F Adv: 0.3554\n",
      "  Cycle Photo: 0.0585, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1854, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.6871\n",
      "Epoch [52/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2541, D_X Fake: 0.2569, D_X Total: 0.2555\n",
      "  D_Y Real: 0.1113, D_Y Fake: 0.0825, D_Y Total: 0.0969\n",
      "Generator Losses:\n",
      "  G Adv: 0.6900, F Adv: 0.2558\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1793, Perceptual Monet: 0.1440\n",
      "  Total G Loss: 3.4231\n",
      "Epoch [52/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3388, D_X Fake: 0.2518, D_X Total: 0.2953\n",
      "  D_Y Real: 0.0676, D_Y Fake: 0.1927, D_Y Total: 0.1302\n",
      "Generator Losses:\n",
      "  G Adv: 0.4519, F Adv: 0.3009\n",
      "  Cycle Photo: 0.0706, Cycle Monet: 0.0438\n",
      "  Perceptual Photo: 0.1739, Perceptual Monet: 0.1578\n",
      "  Total G Loss: 3.5553\n",
      "Epoch [52/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2317, D_X Fake: 0.2775, D_X Total: 0.2546\n",
      "  D_Y Real: 0.1370, D_Y Fake: 0.0477, D_Y Total: 0.0923\n",
      "Generator Losses:\n",
      "  G Adv: 0.7719, F Adv: 0.2698\n",
      "  Cycle Photo: 0.0607, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1634, Perceptual Monet: 0.1378\n",
      "  Total G Loss: 3.5883\n",
      "Epoch [52/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2661, D_X Fake: 0.2493, D_X Total: 0.2577\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.4236, D_Y Total: 0.2317\n",
      "Generator Losses:\n",
      "  G Adv: 0.1748, F Adv: 0.2292\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1324\n",
      "  Total G Loss: 2.6071\n",
      "Epoch [52/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3772, D_X Fake: 0.2138, D_X Total: 0.2955\n",
      "  D_Y Real: 0.0885, D_Y Fake: 0.0426, D_Y Total: 0.0655\n",
      "Generator Losses:\n",
      "  G Adv: 0.6565, F Adv: 0.3256\n",
      "  Cycle Photo: 0.0701, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1899, Perceptual Monet: 0.1126\n",
      "  Total G Loss: 3.5300\n",
      "Epoch [52/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2516, D_X Fake: 0.2129, D_X Total: 0.2322\n",
      "  D_Y Real: 0.0357, D_Y Fake: 0.1372, D_Y Total: 0.0865\n",
      "Generator Losses:\n",
      "  G Adv: 0.5274, F Adv: 0.3819\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1318\n",
      "  Total G Loss: 3.0327\n",
      "Epoch [52/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3442, D_X Fake: 0.1650, D_X Total: 0.2546\n",
      "  D_Y Real: 0.1755, D_Y Fake: 0.0396, D_Y Total: 0.1076\n",
      "Generator Losses:\n",
      "  G Adv: 0.7297, F Adv: 0.3850\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1210\n",
      "  Total G Loss: 3.3844\n",
      "Epoch [52/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2823, D_X Fake: 0.1597, D_X Total: 0.2210\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.3501, D_Y Total: 0.1951\n",
      "Generator Losses:\n",
      "  G Adv: 0.4428, F Adv: 0.3707\n",
      "  Cycle Photo: 0.0875, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.1226\n",
      "  Total G Loss: 3.4365\n",
      "Epoch [52/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1629, D_X Fake: 0.2787, D_X Total: 0.2208\n",
      "  D_Y Real: 0.1517, D_Y Fake: 0.0685, D_Y Total: 0.1101\n",
      "Generator Losses:\n",
      "  G Adv: 0.8184, F Adv: 0.2410\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1631, Perceptual Monet: 0.1423\n",
      "  Total G Loss: 3.4634\n",
      "Epoch [52/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1068, D_X Fake: 0.1854, D_X Total: 0.1461\n",
      "  D_Y Real: 0.1730, D_Y Fake: 0.1197, D_Y Total: 0.1463\n",
      "Generator Losses:\n",
      "  G Adv: 0.7139, F Adv: 0.3579\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1127, Perceptual Monet: 0.1426\n",
      "  Total G Loss: 3.1971\n",
      "Epoch [52/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1322, D_X Fake: 0.4477, D_X Total: 0.2900\n",
      "  D_Y Real: 0.0596, D_Y Fake: 0.0514, D_Y Total: 0.0555\n",
      "Generator Losses:\n",
      "  G Adv: 0.6853, F Adv: 0.1617\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1444, Perceptual Monet: 0.1553\n",
      "  Total G Loss: 3.1181\n",
      "Epoch [52/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2444, D_X Fake: 0.2228, D_X Total: 0.2336\n",
      "  D_Y Real: 0.0829, D_Y Fake: 0.0513, D_Y Total: 0.0671\n",
      "Generator Losses:\n",
      "  G Adv: 0.6658, F Adv: 0.3195\n",
      "  Cycle Photo: 0.0563, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1595, Perceptual Monet: 0.1215\n",
      "  Total G Loss: 3.3358\n",
      "Epoch [52/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2656, D_X Fake: 0.1359, D_X Total: 0.2007\n",
      "  D_Y Real: 0.3447, D_Y Fake: 0.0541, D_Y Total: 0.1994\n",
      "Generator Losses:\n",
      "  G Adv: 1.2784, F Adv: 0.3779\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1453, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.9604\n",
      "Epoch [52/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2165, D_X Fake: 0.2298, D_X Total: 0.2231\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.0948, D_Y Total: 0.0697\n",
      "Generator Losses:\n",
      "  G Adv: 0.6218, F Adv: 0.4276\n",
      "  Cycle Photo: 0.0614, Cycle Monet: 0.0476\n",
      "  Perceptual Photo: 0.1851, Perceptual Monet: 0.1571\n",
      "  Total G Loss: 3.8503\n",
      "Epoch [52/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1577, D_X Fake: 0.0283, D_X Total: 0.0930\n",
      "  D_Y Real: 0.0906, D_Y Fake: 0.0965, D_Y Total: 0.0936\n",
      "Generator Losses:\n",
      "  G Adv: 0.7378, F Adv: 0.6323\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1892\n",
      "  Total G Loss: 4.0563\n",
      "Epoch [52/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1436, D_X Fake: 0.0764, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0479, D_Y Fake: 0.1286, D_Y Total: 0.0883\n",
      "Generator Losses:\n",
      "  G Adv: 0.6338, F Adv: 0.5782\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1410, Perceptual Monet: 0.1316\n",
      "  Total G Loss: 3.2357\n",
      "Epoch [52/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0646, D_X Fake: 0.1633, D_X Total: 0.1139\n",
      "  D_Y Real: 0.0897, D_Y Fake: 0.1214, D_Y Total: 0.1055\n",
      "Generator Losses:\n",
      "  G Adv: 0.9762, F Adv: 0.2970\n",
      "  Cycle Photo: 0.0568, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.7648\n",
      "Epoch [52/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1068, D_X Fake: 0.1113, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0768, D_Y Fake: 0.0905, D_Y Total: 0.0837\n",
      "Generator Losses:\n",
      "  G Adv: 0.5850, F Adv: 0.5115\n",
      "  Cycle Photo: 0.0539, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1860, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.8384\n",
      "Epoch [52/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1075, D_X Fake: 0.0642, D_X Total: 0.0859\n",
      "  D_Y Real: 0.1099, D_Y Fake: 0.1214, D_Y Total: 0.1157\n",
      "Generator Losses:\n",
      "  G Adv: 0.5743, F Adv: 0.5861\n",
      "  Cycle Photo: 0.0712, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1607, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.8958\n",
      "Epoch [52/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1443, D_X Fake: 0.0485, D_X Total: 0.0964\n",
      "  D_Y Real: 0.0375, D_Y Fake: 0.0996, D_Y Total: 0.0685\n",
      "Generator Losses:\n",
      "  G Adv: 0.4787, F Adv: 0.6556\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1819, Perceptual Monet: 0.1443\n",
      "  Total G Loss: 3.5941\n",
      "Epoch [52/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0804, D_X Fake: 0.0688, D_X Total: 0.0746\n",
      "  D_Y Real: 0.1768, D_Y Fake: 0.0783, D_Y Total: 0.1276\n",
      "Generator Losses:\n",
      "  G Adv: 0.7091, F Adv: 0.6435\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0216\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1223\n",
      "  Total G Loss: 3.1904\n",
      "Epoch [53/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0426, D_X Fake: 0.0771, D_X Total: 0.0598\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.0763, D_Y Total: 0.0675\n",
      "Generator Losses:\n",
      "  G Adv: 0.6419, F Adv: 0.4515\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1813, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.6749\n",
      "Epoch [53/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0713, D_X Fake: 0.1008, D_X Total: 0.0860\n",
      "  D_Y Real: 0.0776, D_Y Fake: 0.1418, D_Y Total: 0.1097\n",
      "Generator Losses:\n",
      "  G Adv: 0.5457, F Adv: 0.5361\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1640, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.5669\n",
      "Epoch [53/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1807, D_X Fake: 0.0383, D_X Total: 0.1095\n",
      "  D_Y Real: 0.0513, D_Y Fake: 0.2098, D_Y Total: 0.1306\n",
      "Generator Losses:\n",
      "  G Adv: 0.4409, F Adv: 0.8452\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1480\n",
      "  Total G Loss: 3.6561\n",
      "Epoch [53/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1286, D_X Fake: 0.0708, D_X Total: 0.0997\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.0756, D_Y Total: 0.0615\n",
      "Generator Losses:\n",
      "  G Adv: 0.6156, F Adv: 0.5496\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.7019\n",
      "Epoch [53/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1537, D_X Fake: 0.0998, D_X Total: 0.1268\n",
      "  D_Y Real: 0.1721, D_Y Fake: 0.0750, D_Y Total: 0.1236\n",
      "Generator Losses:\n",
      "  G Adv: 0.7121, F Adv: 0.3785\n",
      "  Cycle Photo: 0.0515, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.5360\n",
      "Epoch [53/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0295, D_X Fake: 0.1735, D_X Total: 0.1015\n",
      "  D_Y Real: 0.0601, D_Y Fake: 0.0461, D_Y Total: 0.0531\n",
      "Generator Losses:\n",
      "  G Adv: 0.9253, F Adv: 0.4004\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1396\n",
      "  Total G Loss: 3.4560\n",
      "Epoch [53/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0356, D_X Fake: 0.1310, D_X Total: 0.0833\n",
      "  D_Y Real: 0.0816, D_Y Fake: 0.0679, D_Y Total: 0.0748\n",
      "Generator Losses:\n",
      "  G Adv: 0.7517, F Adv: 0.3437\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.0961, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 3.0670\n",
      "Epoch [53/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1004, D_X Fake: 0.0611, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0741, D_Y Fake: 0.1403, D_Y Total: 0.1072\n",
      "Generator Losses:\n",
      "  G Adv: 0.7501, F Adv: 0.5361\n",
      "  Cycle Photo: 0.0588, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1884\n",
      "  Total G Loss: 4.0400\n",
      "Epoch [53/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2072, D_X Fake: 0.0350, D_X Total: 0.1211\n",
      "  D_Y Real: 0.0614, D_Y Fake: 0.0462, D_Y Total: 0.0538\n",
      "Generator Losses:\n",
      "  G Adv: 0.7763, F Adv: 0.5387\n",
      "  Cycle Photo: 0.0515, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1475, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.8079\n",
      "Epoch [53/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0803, D_X Fake: 0.0637, D_X Total: 0.0720\n",
      "  D_Y Real: 0.1620, D_Y Fake: 0.0664, D_Y Total: 0.1142\n",
      "Generator Losses:\n",
      "  G Adv: 0.8018, F Adv: 0.4789\n",
      "  Cycle Photo: 0.0585, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.9819\n",
      "Epoch [53/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0893, D_X Fake: 0.0693, D_X Total: 0.0793\n",
      "  D_Y Real: 0.0551, D_Y Fake: 0.0467, D_Y Total: 0.0509\n",
      "Generator Losses:\n",
      "  G Adv: 0.6640, F Adv: 0.6324\n",
      "  Cycle Photo: 0.0569, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.7938\n",
      "Epoch [53/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2016, D_X Fake: 0.0444, D_X Total: 0.1230\n",
      "  D_Y Real: 0.0731, D_Y Fake: 0.1030, D_Y Total: 0.0881\n",
      "Generator Losses:\n",
      "  G Adv: 0.5674, F Adv: 0.6607\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1810, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.8892\n",
      "Epoch [53/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0266, D_X Fake: 0.0458, D_X Total: 0.0362\n",
      "  D_Y Real: 0.0872, D_Y Fake: 0.0455, D_Y Total: 0.0663\n",
      "Generator Losses:\n",
      "  G Adv: 0.8242, F Adv: 0.6661\n",
      "  Cycle Photo: 0.0477, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1764, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 4.0090\n",
      "Epoch [53/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0800, D_X Fake: 0.1217, D_X Total: 0.1008\n",
      "  D_Y Real: 0.1351, D_Y Fake: 0.0514, D_Y Total: 0.0932\n",
      "Generator Losses:\n",
      "  G Adv: 0.9565, F Adv: 0.6453\n",
      "  Cycle Photo: 0.0501, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 3.8989\n",
      "Epoch [53/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1382, D_X Fake: 0.0434, D_X Total: 0.0908\n",
      "  D_Y Real: 0.0589, D_Y Fake: 0.0417, D_Y Total: 0.0503\n",
      "Generator Losses:\n",
      "  G Adv: 0.6417, F Adv: 0.7071\n",
      "  Cycle Photo: 0.0502, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.8577\n",
      "Epoch [53/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2821, D_X Fake: 0.0301, D_X Total: 0.1561\n",
      "  D_Y Real: 0.1400, D_Y Fake: 0.0451, D_Y Total: 0.0926\n",
      "Generator Losses:\n",
      "  G Adv: 0.8585, F Adv: 0.8856\n",
      "  Cycle Photo: 0.0523, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1951, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 4.5147\n",
      "Epoch [53/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2820, D_X Fake: 0.0307, D_X Total: 0.1563\n",
      "  D_Y Real: 0.1323, D_Y Fake: 0.0530, D_Y Total: 0.0926\n",
      "Generator Losses:\n",
      "  G Adv: 1.0494, F Adv: 1.0159\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1571, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 4.6182\n",
      "Epoch [53/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0545, D_X Fake: 0.1980, D_X Total: 0.1262\n",
      "  D_Y Real: 0.0528, D_Y Fake: 0.1998, D_Y Total: 0.1263\n",
      "Generator Losses:\n",
      "  G Adv: 0.4902, F Adv: 0.3516\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1766, Perceptual Monet: 0.1378\n",
      "  Total G Loss: 3.2354\n",
      "Epoch [53/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0873, D_X Fake: 0.0875, D_X Total: 0.0874\n",
      "  D_Y Real: 0.1009, D_Y Fake: 0.1127, D_Y Total: 0.1068\n",
      "Generator Losses:\n",
      "  G Adv: 0.5687, F Adv: 0.5430\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1745, Perceptual Monet: 0.1099\n",
      "  Total G Loss: 3.2300\n",
      "Epoch [53/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0632, D_X Fake: 0.0681, D_X Total: 0.0656\n",
      "  D_Y Real: 0.0505, D_Y Fake: 0.0484, D_Y Total: 0.0495\n",
      "Generator Losses:\n",
      "  G Adv: 0.9459, F Adv: 0.5060\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0570\n",
      "  Perceptual Photo: 0.1170, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.9275\n",
      "Epoch [53/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0323, D_X Fake: 0.0464, D_X Total: 0.0394\n",
      "  D_Y Real: 0.0349, D_Y Fake: 0.0510, D_Y Total: 0.0430\n",
      "Generator Losses:\n",
      "  G Adv: 0.8570, F Adv: 0.7282\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1640, Perceptual Monet: 0.1459\n",
      "  Total G Loss: 3.8860\n",
      "Epoch [53/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0749, D_X Fake: 0.1740, D_X Total: 0.1244\n",
      "  D_Y Real: 0.0927, D_Y Fake: 0.0687, D_Y Total: 0.0807\n",
      "Generator Losses:\n",
      "  G Adv: 0.8144, F Adv: 0.2794\n",
      "  Cycle Photo: 0.0576, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.1922\n",
      "  Total G Loss: 3.9685\n",
      "Epoch [53/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1905, D_X Fake: 0.0720, D_X Total: 0.1313\n",
      "  D_Y Real: 0.0912, D_Y Fake: 0.1288, D_Y Total: 0.1100\n",
      "Generator Losses:\n",
      "  G Adv: 0.6578, F Adv: 0.5637\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.1852, Perceptual Monet: 0.1728\n",
      "  Total G Loss: 3.9977\n",
      "Epoch [53/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1154, D_X Fake: 0.0836, D_X Total: 0.0995\n",
      "  D_Y Real: 0.1298, D_Y Fake: 0.0988, D_Y Total: 0.1143\n",
      "Generator Losses:\n",
      "  G Adv: 0.7209, F Adv: 0.4944\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0550\n",
      "  Perceptual Photo: 0.1578, Perceptual Monet: 0.2256\n",
      "  Total G Loss: 4.1492\n",
      "Epoch [54/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1571, D_X Fake: 0.0741, D_X Total: 0.1156\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.1549, D_Y Total: 0.0938\n",
      "Generator Losses:\n",
      "  G Adv: 0.4613, F Adv: 0.6368\n",
      "  Cycle Photo: 0.0477, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.5941\n",
      "Epoch [54/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0855, D_X Fake: 0.0894, D_X Total: 0.0875\n",
      "  D_Y Real: 0.1468, D_Y Fake: 0.0643, D_Y Total: 0.1056\n",
      "Generator Losses:\n",
      "  G Adv: 0.9271, F Adv: 0.7483\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.8838\n",
      "Epoch [54/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0464, D_X Fake: 0.1679, D_X Total: 0.1072\n",
      "  D_Y Real: 0.0912, D_Y Fake: 0.0677, D_Y Total: 0.0794\n",
      "Generator Losses:\n",
      "  G Adv: 1.0349, F Adv: 0.3546\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0395\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1574\n",
      "  Total G Loss: 3.6652\n",
      "Epoch [54/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0593, D_X Fake: 0.1080, D_X Total: 0.0837\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.2698, D_Y Total: 0.1491\n",
      "Generator Losses:\n",
      "  G Adv: 0.4409, F Adv: 0.5696\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0440\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1964\n",
      "  Total G Loss: 3.8255\n",
      "Epoch [54/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1781, D_X Fake: 0.0255, D_X Total: 0.1018\n",
      "  D_Y Real: 0.0709, D_Y Fake: 0.1999, D_Y Total: 0.1354\n",
      "Generator Losses:\n",
      "  G Adv: 0.6723, F Adv: 0.8625\n",
      "  Cycle Photo: 0.0530, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.9721\n",
      "Epoch [54/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1515, D_X Fake: 0.0406, D_X Total: 0.0960\n",
      "  D_Y Real: 0.0431, D_Y Fake: 0.0625, D_Y Total: 0.0528\n",
      "Generator Losses:\n",
      "  G Adv: 0.5848, F Adv: 0.8290\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1558\n",
      "  Total G Loss: 3.8500\n",
      "Epoch [54/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1722, D_X Fake: 0.1735, D_X Total: 0.1728\n",
      "  D_Y Real: 0.0551, D_Y Fake: 0.1948, D_Y Total: 0.1250\n",
      "Generator Losses:\n",
      "  G Adv: 0.4514, F Adv: 0.6161\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1458, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.5367\n",
      "Epoch [54/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1113, D_X Fake: 0.1870, D_X Total: 0.1491\n",
      "  D_Y Real: 0.1338, D_Y Fake: 0.1187, D_Y Total: 0.1263\n",
      "Generator Losses:\n",
      "  G Adv: 0.6938, F Adv: 0.4171\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.2802\n",
      "Epoch [54/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1167, D_X Fake: 0.1069, D_X Total: 0.1118\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.0992, D_Y Total: 0.0790\n",
      "Generator Losses:\n",
      "  G Adv: 0.5390, F Adv: 0.5408\n",
      "  Cycle Photo: 0.0771, Cycle Monet: 0.0626\n",
      "  Perceptual Photo: 0.1603, Perceptual Monet: 0.2113\n",
      "  Total G Loss: 4.3343\n",
      "Epoch [54/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1380, D_X Fake: 0.0563, D_X Total: 0.0972\n",
      "  D_Y Real: 0.0614, D_Y Fake: 0.0675, D_Y Total: 0.0645\n",
      "Generator Losses:\n",
      "  G Adv: 0.5314, F Adv: 0.6182\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1860, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.7885\n",
      "Epoch [54/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1089, D_X Fake: 0.1427, D_X Total: 0.1258\n",
      "  D_Y Real: 0.0789, D_Y Fake: 0.0735, D_Y Total: 0.0762\n",
      "Generator Losses:\n",
      "  G Adv: 0.7565, F Adv: 0.5708\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.7269\n",
      "Epoch [54/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1951, D_X Fake: 0.0779, D_X Total: 0.1365\n",
      "  D_Y Real: 0.0703, D_Y Fake: 0.0624, D_Y Total: 0.0664\n",
      "Generator Losses:\n",
      "  G Adv: 0.6472, F Adv: 0.7110\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1997, Perceptual Monet: 0.1934\n",
      "  Total G Loss: 4.2817\n",
      "Epoch [54/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1571, D_X Fake: 0.0362, D_X Total: 0.0966\n",
      "  D_Y Real: 0.1549, D_Y Fake: 0.0736, D_Y Total: 0.1143\n",
      "Generator Losses:\n",
      "  G Adv: 0.6016, F Adv: 0.6459\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1560, Perceptual Monet: 0.2241\n",
      "  Total G Loss: 4.0346\n",
      "Epoch [54/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1819, D_X Fake: 0.0381, D_X Total: 0.1100\n",
      "  D_Y Real: 0.1337, D_Y Fake: 0.0581, D_Y Total: 0.0959\n",
      "Generator Losses:\n",
      "  G Adv: 0.6790, F Adv: 0.6949\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1823\n",
      "  Total G Loss: 3.9635\n",
      "Epoch [54/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1140, D_X Fake: 0.0289, D_X Total: 0.0715\n",
      "  D_Y Real: 0.1016, D_Y Fake: 0.0796, D_Y Total: 0.0906\n",
      "Generator Losses:\n",
      "  G Adv: 0.6264, F Adv: 0.7194\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0469\n",
      "  Perceptual Photo: 0.1856, Perceptual Monet: 0.1894\n",
      "  Total G Loss: 4.1125\n",
      "Epoch [54/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2587, D_X Fake: 0.0651, D_X Total: 0.1619\n",
      "  D_Y Real: 0.2413, D_Y Fake: 0.0416, D_Y Total: 0.1414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8989, F Adv: 0.7034\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1112, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.7506\n",
      "Epoch [54/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1299, D_X Fake: 0.1554, D_X Total: 0.1427\n",
      "  D_Y Real: 0.0455, D_Y Fake: 0.0780, D_Y Total: 0.0618\n",
      "Generator Losses:\n",
      "  G Adv: 0.4963, F Adv: 0.4730\n",
      "  Cycle Photo: 0.0535, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.1716, Perceptual Monet: 0.1984\n",
      "  Total G Loss: 3.8147\n",
      "Epoch [54/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0819, D_X Fake: 0.0906, D_X Total: 0.0863\n",
      "  D_Y Real: 0.1046, D_Y Fake: 0.0389, D_Y Total: 0.0717\n",
      "Generator Losses:\n",
      "  G Adv: 1.0604, F Adv: 0.4557\n",
      "  Cycle Photo: 0.0609, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1444\n",
      "  Total G Loss: 4.0185\n",
      "Epoch [54/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1192, D_X Fake: 0.1840, D_X Total: 0.1516\n",
      "  D_Y Real: 0.1090, D_Y Fake: 0.0438, D_Y Total: 0.0764\n",
      "Generator Losses:\n",
      "  G Adv: 0.6835, F Adv: 0.3906\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1948, Perceptual Monet: 0.1558\n",
      "  Total G Loss: 3.5429\n",
      "Epoch [54/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1016, D_X Fake: 0.1699, D_X Total: 0.1357\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.1305, D_Y Total: 0.0878\n",
      "Generator Losses:\n",
      "  G Adv: 0.4196, F Adv: 0.3383\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1923, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.4049\n",
      "Epoch [54/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1216, D_X Fake: 0.0303, D_X Total: 0.0760\n",
      "  D_Y Real: 0.0984, D_Y Fake: 0.0875, D_Y Total: 0.0930\n",
      "Generator Losses:\n",
      "  G Adv: 0.6426, F Adv: 0.7879\n",
      "  Cycle Photo: 0.0520, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1856, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 4.0491\n",
      "Epoch [54/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1658, D_X Fake: 0.0659, D_X Total: 0.1159\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.1381, D_Y Total: 0.0861\n",
      "Generator Losses:\n",
      "  G Adv: 0.7016, F Adv: 0.5684\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1597, Perceptual Monet: 0.1906\n",
      "  Total G Loss: 3.8587\n",
      "Epoch [54/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0999, D_X Fake: 0.1555, D_X Total: 0.1277\n",
      "  D_Y Real: 0.1739, D_Y Fake: 0.0418, D_Y Total: 0.1078\n",
      "Generator Losses:\n",
      "  G Adv: 0.8314, F Adv: 0.4203\n",
      "  Cycle Photo: 0.0621, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.2344, Perceptual Monet: 0.1405\n",
      "  Total G Loss: 4.1168\n",
      "Epoch [54/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2300, D_X Fake: 0.0460, D_X Total: 0.1380\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0790, D_Y Total: 0.0593\n",
      "Generator Losses:\n",
      "  G Adv: 0.5457, F Adv: 0.7424\n",
      "  Cycle Photo: 0.0459, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1780\n",
      "  Total G Loss: 3.7710\n",
      "Epoch [55/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1493, D_X Fake: 0.0501, D_X Total: 0.0997\n",
      "  D_Y Real: 0.0510, D_Y Fake: 0.0833, D_Y Total: 0.0672\n",
      "Generator Losses:\n",
      "  G Adv: 0.7864, F Adv: 0.5851\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.6451\n",
      "Epoch [55/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1349, D_X Fake: 0.0415, D_X Total: 0.0882\n",
      "  D_Y Real: 0.0573, D_Y Fake: 0.0759, D_Y Total: 0.0666\n",
      "Generator Losses:\n",
      "  G Adv: 0.7044, F Adv: 0.6531\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1652, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.6289\n",
      "Epoch [55/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0794, D_X Fake: 0.0701, D_X Total: 0.0747\n",
      "  D_Y Real: 0.1472, D_Y Fake: 0.0528, D_Y Total: 0.1000\n",
      "Generator Losses:\n",
      "  G Adv: 0.9269, F Adv: 0.6442\n",
      "  Cycle Photo: 0.0450, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1428, Perceptual Monet: 0.1845\n",
      "  Total G Loss: 4.0310\n",
      "Epoch [55/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0457, D_X Fake: 0.0647, D_X Total: 0.0552\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.0901, D_Y Total: 0.0644\n",
      "Generator Losses:\n",
      "  G Adv: 0.5810, F Adv: 0.4603\n",
      "  Cycle Photo: 0.0625, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.3459\n",
      "Epoch [55/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1475, D_X Fake: 0.0476, D_X Total: 0.0976\n",
      "  D_Y Real: 0.1028, D_Y Fake: 0.0685, D_Y Total: 0.0856\n",
      "Generator Losses:\n",
      "  G Adv: 0.7893, F Adv: 0.4949\n",
      "  Cycle Photo: 0.0803, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1913, Perceptual Monet: 0.1894\n",
      "  Total G Loss: 4.3709\n",
      "Epoch [55/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2412, D_X Fake: 0.0308, D_X Total: 0.1360\n",
      "  D_Y Real: 0.1387, D_Y Fake: 0.0693, D_Y Total: 0.1040\n",
      "Generator Losses:\n",
      "  G Adv: 0.7618, F Adv: 0.9618\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 4.4177\n",
      "Epoch [55/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.2099, D_X Total: 0.1455\n",
      "  D_Y Real: 0.0538, D_Y Fake: 0.1005, D_Y Total: 0.0771\n",
      "Generator Losses:\n",
      "  G Adv: 0.6637, F Adv: 0.4800\n",
      "  Cycle Photo: 0.1059, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.2091, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 4.5002\n",
      "Epoch [55/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0424, D_X Fake: 0.1951, D_X Total: 0.1187\n",
      "  D_Y Real: 0.1505, D_Y Fake: 0.1360, D_Y Total: 0.1432\n",
      "Generator Losses:\n",
      "  G Adv: 1.0095, F Adv: 0.4595\n",
      "  Cycle Photo: 0.0636, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1931, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 4.2909\n",
      "Epoch [55/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1255, D_X Fake: 0.0754, D_X Total: 0.1005\n",
      "  D_Y Real: 0.1948, D_Y Fake: 0.0422, D_Y Total: 0.1185\n",
      "Generator Losses:\n",
      "  G Adv: 0.7818, F Adv: 0.7597\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1168, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.6940\n",
      "Epoch [55/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1651, D_X Fake: 0.0634, D_X Total: 0.1142\n",
      "  D_Y Real: 0.0640, D_Y Fake: 0.0516, D_Y Total: 0.0578\n",
      "Generator Losses:\n",
      "  G Adv: 0.7052, F Adv: 0.5449\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.6304\n",
      "Epoch [55/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0500, D_X Fake: 0.2331, D_X Total: 0.1415\n",
      "  D_Y Real: 0.0368, D_Y Fake: 0.4536, D_Y Total: 0.2452\n",
      "Generator Losses:\n",
      "  G Adv: 0.2556, F Adv: 0.4072\n",
      "  Cycle Photo: 0.0549, Cycle Monet: 0.0468\n",
      "  Perceptual Photo: 0.1134, Perceptual Monet: 0.1841\n",
      "  Total G Loss: 3.1669\n",
      "Epoch [55/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0348, D_X Fake: 0.0442, D_X Total: 0.0395\n",
      "  D_Y Real: 0.0349, D_Y Fake: 0.0799, D_Y Total: 0.0574\n",
      "Generator Losses:\n",
      "  G Adv: 0.4471, F Adv: 0.6694\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1704, Perceptual Monet: 0.1937\n",
      "  Total G Loss: 3.9499\n",
      "Epoch [55/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0927, D_X Fake: 0.1722, D_X Total: 0.1325\n",
      "  D_Y Real: 0.1409, D_Y Fake: 0.0671, D_Y Total: 0.1040\n",
      "Generator Losses:\n",
      "  G Adv: 0.5753, F Adv: 0.3900\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1531, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.2090\n",
      "Epoch [55/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1365, D_X Fake: 0.0275, D_X Total: 0.0820\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.2075, D_Y Total: 0.1359\n",
      "Generator Losses:\n",
      "  G Adv: 0.3921, F Adv: 0.8477\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.7253\n",
      "Epoch [55/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.1470, D_X Total: 0.1101\n",
      "  D_Y Real: 0.1061, D_Y Fake: 0.0638, D_Y Total: 0.0850\n",
      "Generator Losses:\n",
      "  G Adv: 1.0470, F Adv: 0.3477\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.5866\n",
      "Epoch [55/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1366, D_X Fake: 0.0622, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0691, D_Y Fake: 0.0340, D_Y Total: 0.0516\n",
      "Generator Losses:\n",
      "  G Adv: 0.7383, F Adv: 0.6210\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1648\n",
      "  Total G Loss: 3.7512\n",
      "Epoch [55/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0964, D_X Fake: 0.1396, D_X Total: 0.1180\n",
      "  D_Y Real: 0.0903, D_Y Fake: 0.0485, D_Y Total: 0.0694\n",
      "Generator Losses:\n",
      "  G Adv: 0.7992, F Adv: 0.5457\n",
      "  Cycle Photo: 0.0599, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1590, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.9382\n",
      "Epoch [55/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1444, D_X Fake: 0.2238, D_X Total: 0.1841\n",
      "  D_Y Real: 0.0621, D_Y Fake: 0.0937, D_Y Total: 0.0779\n",
      "Generator Losses:\n",
      "  G Adv: 0.6567, F Adv: 0.3709\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0503\n",
      "  Perceptual Photo: 0.1842, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.8611\n",
      "Epoch [55/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1588, D_X Fake: 0.0690, D_X Total: 0.1139\n",
      "  D_Y Real: 0.0820, D_Y Fake: 0.0686, D_Y Total: 0.0753\n",
      "Generator Losses:\n",
      "  G Adv: 0.4354, F Adv: 0.7104\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.4298\n",
      "Epoch [55/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0772, D_X Fake: 0.0958, D_X Total: 0.0865\n",
      "  D_Y Real: 0.1024, D_Y Fake: 0.0590, D_Y Total: 0.0807\n",
      "Generator Losses:\n",
      "  G Adv: 0.5005, F Adv: 0.5621\n",
      "  Cycle Photo: 0.0574, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.1686, Perceptual Monet: 0.1574\n",
      "  Total G Loss: 3.6614\n",
      "Epoch [55/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0536, D_X Fake: 0.1490, D_X Total: 0.1013\n",
      "  D_Y Real: 0.0974, D_Y Fake: 0.0751, D_Y Total: 0.0863\n",
      "Generator Losses:\n",
      "  G Adv: 0.7337, F Adv: 0.4558\n",
      "  Cycle Photo: 0.0518, Cycle Monet: 0.0436\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.1955\n",
      "  Total G Loss: 4.0107\n",
      "Epoch [55/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1398, D_X Fake: 0.0693, D_X Total: 0.1046\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0754, D_Y Total: 0.0612\n",
      "Generator Losses:\n",
      "  G Adv: 0.4530, F Adv: 0.8180\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1681, Perceptual Monet: 0.1782\n",
      "  Total G Loss: 3.7752\n",
      "Epoch [55/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4350, D_X Fake: 0.0435, D_X Total: 0.2392\n",
      "  D_Y Real: 0.0633, D_Y Fake: 0.2879, D_Y Total: 0.1756\n",
      "Generator Losses:\n",
      "  G Adv: 0.3750, F Adv: 1.0534\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0522\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 4.1874\n",
      "Epoch [55/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0963, D_X Fake: 0.0915, D_X Total: 0.0939\n",
      "  D_Y Real: 0.0906, D_Y Fake: 0.1734, D_Y Total: 0.1320\n",
      "Generator Losses:\n",
      "  G Adv: 0.4758, F Adv: 0.4832\n",
      "  Cycle Photo: 0.0593, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1543\n",
      "  Total G Loss: 3.5684\n",
      "Epoch [56/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1183, D_X Fake: 0.0880, D_X Total: 0.1032\n",
      "  D_Y Real: 0.0630, D_Y Fake: 0.2313, D_Y Total: 0.1471\n",
      "Generator Losses:\n",
      "  G Adv: 0.3494, F Adv: 0.5580\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 3.5768\n",
      "Epoch [56/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0468, D_X Fake: 0.0485, D_X Total: 0.0476\n",
      "  D_Y Real: 0.1029, D_Y Fake: 0.0480, D_Y Total: 0.0755\n",
      "Generator Losses:\n",
      "  G Adv: 0.7507, F Adv: 0.6471\n",
      "  Cycle Photo: 0.0608, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1317, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.9095\n",
      "Epoch [56/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2426, D_X Fake: 0.2325, D_X Total: 0.2376\n",
      "  D_Y Real: 0.0779, D_Y Fake: 0.2423, D_Y Total: 0.1601\n",
      "Generator Losses:\n",
      "  G Adv: 0.5308, F Adv: 0.4534\n",
      "  Cycle Photo: 0.0590, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1672, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.5453\n",
      "Epoch [56/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2605, D_X Fake: 0.3384, D_X Total: 0.2995\n",
      "  D_Y Real: 0.1061, D_Y Fake: 0.0859, D_Y Total: 0.0960\n",
      "Generator Losses:\n",
      "  G Adv: 0.5400, F Adv: 0.2346\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1693, Perceptual Monet: 0.1574\n",
      "  Total G Loss: 3.1480\n",
      "Epoch [56/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2952, D_X Fake: 0.3068, D_X Total: 0.3010\n",
      "  D_Y Real: 0.1856, D_Y Fake: 0.0414, D_Y Total: 0.1135\n",
      "Generator Losses:\n",
      "  G Adv: 0.5021, F Adv: 0.2538\n",
      "  Cycle Photo: 0.0498, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1763, Perceptual Monet: 0.1300\n",
      "  Total G Loss: 3.0454\n",
      "Epoch [56/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2909, D_X Fake: 0.2838, D_X Total: 0.2873\n",
      "  D_Y Real: 0.1152, D_Y Fake: 0.0641, D_Y Total: 0.0896\n",
      "Generator Losses:\n",
      "  G Adv: 0.7956, F Adv: 0.2861\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1340\n",
      "  Total G Loss: 3.2989\n",
      "Epoch [56/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2760, D_X Fake: 0.1497, D_X Total: 0.2128\n",
      "  D_Y Real: 0.0818, D_Y Fake: 0.1336, D_Y Total: 0.1077\n",
      "Generator Losses:\n",
      "  G Adv: 0.8258, F Adv: 0.3857\n",
      "  Cycle Photo: 0.0510, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1483, Perceptual Monet: 0.1383\n",
      "  Total G Loss: 3.5159\n",
      "Epoch [56/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2724, D_X Fake: 0.3121, D_X Total: 0.2923\n",
      "  D_Y Real: 0.1618, D_Y Fake: 0.0430, D_Y Total: 0.1024\n",
      "Generator Losses:\n",
      "  G Adv: 0.7260, F Adv: 0.2101\n",
      "  Cycle Photo: 0.0691, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1822, Perceptual Monet: 0.1423\n",
      "  Total G Loss: 3.5783\n",
      "Epoch [56/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2441, D_X Fake: 0.3123, D_X Total: 0.2782\n",
      "  D_Y Real: 0.0645, D_Y Fake: 0.0683, D_Y Total: 0.0664\n",
      "Generator Losses:\n",
      "  G Adv: 0.7244, F Adv: 0.2987\n",
      "  Cycle Photo: 0.0605, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1402\n",
      "  Total G Loss: 3.3822\n",
      "Epoch [56/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2418, D_X Fake: 0.2235, D_X Total: 0.2327\n",
      "  D_Y Real: 0.0916, D_Y Fake: 0.0642, D_Y Total: 0.0779\n",
      "Generator Losses:\n",
      "  G Adv: 0.7389, F Adv: 0.3260\n",
      "  Cycle Photo: 0.0544, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1355\n",
      "  Total G Loss: 3.3834\n",
      "Epoch [56/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3410, D_X Fake: 0.1846, D_X Total: 0.2628\n",
      "  D_Y Real: 0.1558, D_Y Fake: 0.0495, D_Y Total: 0.1027\n",
      "Generator Losses:\n",
      "  G Adv: 0.7796, F Adv: 0.4042\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.1212\n",
      "  Total G Loss: 3.5861\n",
      "Epoch [56/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3881, D_X Fake: 0.2176, D_X Total: 0.3028\n",
      "  D_Y Real: 0.0916, D_Y Fake: 0.0929, D_Y Total: 0.0922\n",
      "Generator Losses:\n",
      "  G Adv: 0.5997, F Adv: 0.3393\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1554\n",
      "  Total G Loss: 3.1413\n",
      "Epoch [56/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2856, D_X Fake: 0.2347, D_X Total: 0.2601\n",
      "  D_Y Real: 0.1045, D_Y Fake: 0.0479, D_Y Total: 0.0762\n",
      "Generator Losses:\n",
      "  G Adv: 0.6711, F Adv: 0.3393\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.3150\n",
      "Epoch [56/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2733, D_X Fake: 0.3144, D_X Total: 0.2938\n",
      "  D_Y Real: 0.0545, D_Y Fake: 0.1985, D_Y Total: 0.1265\n",
      "Generator Losses:\n",
      "  G Adv: 0.2395, F Adv: 0.2407\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1326\n",
      "  Total G Loss: 2.5671\n",
      "Epoch [56/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2661, D_X Fake: 0.2879, D_X Total: 0.2770\n",
      "  D_Y Real: 0.0669, D_Y Fake: 0.1890, D_Y Total: 0.1280\n",
      "Generator Losses:\n",
      "  G Adv: 0.5030, F Adv: 0.2455\n",
      "  Cycle Photo: 0.0448, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1771, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.1535\n",
      "Epoch [56/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3337, D_X Fake: 0.1367, D_X Total: 0.2352\n",
      "  D_Y Real: 0.0740, D_Y Fake: 0.0917, D_Y Total: 0.0828\n",
      "Generator Losses:\n",
      "  G Adv: 0.5768, F Adv: 0.3799\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.0889\n",
      "Epoch [56/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1981, D_X Fake: 0.2255, D_X Total: 0.2118\n",
      "  D_Y Real: 0.1987, D_Y Fake: 0.0555, D_Y Total: 0.1271\n",
      "Generator Losses:\n",
      "  G Adv: 0.5853, F Adv: 0.2886\n",
      "  Cycle Photo: 0.0531, Cycle Monet: 0.0433\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 3.3966\n",
      "Epoch [56/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2920, D_X Fake: 0.1442, D_X Total: 0.2181\n",
      "  D_Y Real: 0.0334, D_Y Fake: 0.0463, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.8986, F Adv: 0.3527\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1633, Perceptual Monet: 0.1428\n",
      "  Total G Loss: 3.4876\n",
      "Epoch [56/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1068, D_X Fake: 0.1304, D_X Total: 0.1186\n",
      "  D_Y Real: 0.1679, D_Y Fake: 0.0561, D_Y Total: 0.1120\n",
      "Generator Losses:\n",
      "  G Adv: 0.8964, F Adv: 0.4703\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1505\n",
      "  Total G Loss: 3.7116\n",
      "Epoch [56/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0808, D_X Fake: 0.1192, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0587, D_Y Fake: 0.0619, D_Y Total: 0.0603\n",
      "Generator Losses:\n",
      "  G Adv: 0.6820, F Adv: 0.5766\n",
      "  Cycle Photo: 0.0594, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1313\n",
      "  Total G Loss: 3.6631\n",
      "Epoch [56/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1041, D_X Fake: 0.0897, D_X Total: 0.0969\n",
      "  D_Y Real: 0.1278, D_Y Fake: 0.0366, D_Y Total: 0.0822\n",
      "Generator Losses:\n",
      "  G Adv: 0.9493, F Adv: 0.4659\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0456\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.8982\n",
      "Epoch [56/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0344, D_X Fake: 0.1449, D_X Total: 0.0896\n",
      "  D_Y Real: 0.0776, D_Y Fake: 0.0851, D_Y Total: 0.0813\n",
      "Generator Losses:\n",
      "  G Adv: 0.6667, F Adv: 0.3976\n",
      "  Cycle Photo: 0.0573, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1234, Perceptual Monet: 0.1342\n",
      "  Total G Loss: 3.2429\n",
      "Epoch [56/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0452, D_X Fake: 0.2109, D_X Total: 0.1281\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0663, D_Y Total: 0.0530\n",
      "Generator Losses:\n",
      "  G Adv: 0.5578, F Adv: 0.3989\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1731, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.5053\n",
      "Epoch [56/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0824, D_X Fake: 0.0276, D_X Total: 0.0550\n",
      "  D_Y Real: 0.0848, D_Y Fake: 0.0867, D_Y Total: 0.0857\n",
      "Generator Losses:\n",
      "  G Adv: 0.8764, F Adv: 0.6051\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1232, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.6404\n",
      "Epoch [57/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1059, D_X Fake: 0.2312, D_X Total: 0.1685\n",
      "  D_Y Real: 0.0900, D_Y Fake: 0.1491, D_Y Total: 0.1196\n",
      "Generator Losses:\n",
      "  G Adv: 0.5819, F Adv: 0.4575\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1156, Perceptual Monet: 0.1256\n",
      "  Total G Loss: 2.9696\n",
      "Epoch [57/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0766, D_X Fake: 0.0660, D_X Total: 0.0713\n",
      "  D_Y Real: 0.0520, D_Y Fake: 0.0805, D_Y Total: 0.0663\n",
      "Generator Losses:\n",
      "  G Adv: 0.4486, F Adv: 0.5396\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 3.1550\n",
      "Epoch [57/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0781, D_X Fake: 0.0901, D_X Total: 0.0841\n",
      "  D_Y Real: 0.1162, D_Y Fake: 0.0509, D_Y Total: 0.0835\n",
      "Generator Losses:\n",
      "  G Adv: 0.6659, F Adv: 0.4245\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0454\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.3927\n",
      "Epoch [57/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0976, D_X Fake: 0.0847, D_X Total: 0.0912\n",
      "  D_Y Real: 0.0536, D_Y Fake: 0.1092, D_Y Total: 0.0814\n",
      "Generator Losses:\n",
      "  G Adv: 0.7631, F Adv: 0.4443\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1543, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.8684\n",
      "Epoch [57/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0566, D_X Fake: 0.1269, D_X Total: 0.0918\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.1053, D_Y Total: 0.0702\n",
      "Generator Losses:\n",
      "  G Adv: 0.5397, F Adv: 0.4259\n",
      "  Cycle Photo: 0.0747, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1607, Perceptual Monet: 0.1420\n",
      "  Total G Loss: 3.6067\n",
      "Epoch [57/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0433, D_X Fake: 0.0658, D_X Total: 0.0545\n",
      "  D_Y Real: 0.1004, D_Y Fake: 0.0627, D_Y Total: 0.0816\n",
      "Generator Losses:\n",
      "  G Adv: 0.9001, F Adv: 0.5825\n",
      "  Cycle Photo: 0.0650, Cycle Monet: 0.0534\n",
      "  Perceptual Photo: 0.1720, Perceptual Monet: 0.1911\n",
      "  Total G Loss: 4.4831\n",
      "Epoch [57/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2020, D_X Fake: 0.0705, D_X Total: 0.1362\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0683, D_Y Total: 0.0541\n",
      "Generator Losses:\n",
      "  G Adv: 0.6529, F Adv: 0.6806\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.1554, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.8845\n",
      "Epoch [57/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1171, D_X Fake: 0.0479, D_X Total: 0.0825\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.1686, D_Y Total: 0.1048\n",
      "Generator Losses:\n",
      "  G Adv: 0.3748, F Adv: 0.7784\n",
      "  Cycle Photo: 0.0632, Cycle Monet: 0.0453\n",
      "  Perceptual Photo: 0.2002, Perceptual Monet: 0.2082\n",
      "  Total G Loss: 4.2800\n",
      "Epoch [57/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0865, D_X Fake: 0.0596, D_X Total: 0.0730\n",
      "  D_Y Real: 0.0395, D_Y Fake: 0.1876, D_Y Total: 0.1135\n",
      "Generator Losses:\n",
      "  G Adv: 0.5387, F Adv: 0.6627\n",
      "  Cycle Photo: 0.0551, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.2244, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 4.1332\n",
      "Epoch [57/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1890, D_X Fake: 0.0696, D_X Total: 0.1293\n",
      "  D_Y Real: 0.0785, D_Y Fake: 0.0644, D_Y Total: 0.0715\n",
      "Generator Losses:\n",
      "  G Adv: 0.7041, F Adv: 0.5729\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1465\n",
      "  Total G Loss: 3.6519\n",
      "Epoch [57/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1074, D_X Fake: 0.1128, D_X Total: 0.1101\n",
      "  D_Y Real: 0.1227, D_Y Fake: 0.1146, D_Y Total: 0.1186\n",
      "Generator Losses:\n",
      "  G Adv: 0.7168, F Adv: 0.5735\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1663, Perceptual Monet: 0.1890\n",
      "  Total G Loss: 3.8363\n",
      "Epoch [57/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1020, D_X Fake: 0.0494, D_X Total: 0.0757\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.1528, D_Y Total: 0.0919\n",
      "Generator Losses:\n",
      "  G Adv: 0.5177, F Adv: 0.6153\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.4250\n",
      "Epoch [57/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2363, D_X Fake: 0.0705, D_X Total: 0.1534\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0709, D_Y Total: 0.0539\n",
      "Generator Losses:\n",
      "  G Adv: 0.6227, F Adv: 0.5857\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.1537\n",
      "  Total G Loss: 3.5318\n",
      "Epoch [57/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1350, D_X Fake: 0.0725, D_X Total: 0.1038\n",
      "  D_Y Real: 0.0381, D_Y Fake: 0.1336, D_Y Total: 0.0858\n",
      "Generator Losses:\n",
      "  G Adv: 0.5800, F Adv: 0.8362\n",
      "  Cycle Photo: 0.0690, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1726, Perceptual Monet: 0.1401\n",
      "  Total G Loss: 4.0986\n",
      "Epoch [57/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2305, D_X Fake: 0.0400, D_X Total: 0.1352\n",
      "  D_Y Real: 0.0513, D_Y Fake: 0.1211, D_Y Total: 0.0862\n",
      "Generator Losses:\n",
      "  G Adv: 0.4479, F Adv: 0.8056\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1400, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 3.6499\n",
      "Epoch [57/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2172, D_X Fake: 0.2810, D_X Total: 0.2491\n",
      "  D_Y Real: 0.0584, D_Y Fake: 0.1307, D_Y Total: 0.0946\n",
      "Generator Losses:\n",
      "  G Adv: 0.6151, F Adv: 0.3448\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.3397\n",
      "Epoch [57/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0367, D_X Fake: 0.1152, D_X Total: 0.0760\n",
      "  D_Y Real: 0.1217, D_Y Fake: 0.0592, D_Y Total: 0.0905\n",
      "Generator Losses:\n",
      "  G Adv: 0.7689, F Adv: 0.3752\n",
      "  Cycle Photo: 0.0531, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1543, Perceptual Monet: 0.1429\n",
      "  Total G Loss: 3.4871\n",
      "Epoch [57/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2056, D_X Fake: 0.0363, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0537, D_Y Fake: 0.0764, D_Y Total: 0.0650\n",
      "Generator Losses:\n",
      "  G Adv: 0.8567, F Adv: 0.7907\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1587, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 4.1115\n",
      "Epoch [57/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1945, D_X Fake: 0.0234, D_X Total: 0.1089\n",
      "  D_Y Real: 0.1433, D_Y Fake: 0.0400, D_Y Total: 0.0917\n",
      "Generator Losses:\n",
      "  G Adv: 0.9590, F Adv: 0.6662\n",
      "  Cycle Photo: 0.0663, Cycle Monet: 0.0578\n",
      "  Perceptual Photo: 0.1951, Perceptual Monet: 0.1912\n",
      "  Total G Loss: 4.7975\n",
      "Epoch [57/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1158, D_X Fake: 0.0641, D_X Total: 0.0900\n",
      "  D_Y Real: 0.0585, D_Y Fake: 0.0424, D_Y Total: 0.0504\n",
      "Generator Losses:\n",
      "  G Adv: 0.9916, F Adv: 0.5416\n",
      "  Cycle Photo: 0.0596, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1620, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 4.0698\n",
      "Epoch [57/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1072, D_X Fake: 0.0422, D_X Total: 0.0747\n",
      "  D_Y Real: 0.0726, D_Y Fake: 0.0929, D_Y Total: 0.0828\n",
      "Generator Losses:\n",
      "  G Adv: 0.8128, F Adv: 0.7956\n",
      "  Cycle Photo: 0.0610, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1506\n",
      "  Total G Loss: 4.0175\n",
      "Epoch [57/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1091, D_X Fake: 0.1195, D_X Total: 0.1143\n",
      "  D_Y Real: 0.0478, D_Y Fake: 0.0473, D_Y Total: 0.0475\n",
      "Generator Losses:\n",
      "  G Adv: 0.8146, F Adv: 0.5159\n",
      "  Cycle Photo: 0.0553, Cycle Monet: 0.0508\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.1999\n",
      "  Total G Loss: 4.2148\n",
      "Epoch [57/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0600, D_X Fake: 0.1104, D_X Total: 0.0852\n",
      "  D_Y Real: 0.0422, D_Y Fake: 0.1053, D_Y Total: 0.0737\n",
      "Generator Losses:\n",
      "  G Adv: 0.8665, F Adv: 0.5826\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 3.8880\n",
      "Epoch [58/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.1720, D_X Total: 0.1309\n",
      "  D_Y Real: 0.0606, D_Y Fake: 0.0669, D_Y Total: 0.0637\n",
      "Generator Losses:\n",
      "  G Adv: 0.6207, F Adv: 0.4786\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.5479\n",
      "Epoch [58/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1241, D_X Fake: 0.1311, D_X Total: 0.1276\n",
      "  D_Y Real: 0.1052, D_Y Fake: 0.0464, D_Y Total: 0.0758\n",
      "Generator Losses:\n",
      "  G Adv: 0.6775, F Adv: 0.2108\n",
      "  Cycle Photo: 0.0461, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.4593\n",
      "Epoch [58/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0594, D_X Fake: 0.1192, D_X Total: 0.0893\n",
      "  D_Y Real: 0.0733, D_Y Fake: 0.0736, D_Y Total: 0.0734\n",
      "Generator Losses:\n",
      "  G Adv: 0.6376, F Adv: 0.1767\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.0909\n",
      "Epoch [58/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2308, D_X Fake: 0.0700, D_X Total: 0.1504\n",
      "  D_Y Real: 0.0484, D_Y Fake: 0.1115, D_Y Total: 0.0799\n",
      "Generator Losses:\n",
      "  G Adv: 0.6028, F Adv: 0.6616\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1597, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 3.5828\n",
      "Epoch [58/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2021, D_X Fake: 0.0348, D_X Total: 0.1185\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.1524, D_Y Total: 0.0937\n",
      "Generator Losses:\n",
      "  G Adv: 0.4426, F Adv: 0.6209\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.6054\n",
      "Epoch [58/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1004, D_X Fake: 0.1358, D_X Total: 0.1181\n",
      "  D_Y Real: 0.0512, D_Y Fake: 0.1636, D_Y Total: 0.1074\n",
      "Generator Losses:\n",
      "  G Adv: 0.5585, F Adv: 0.5908\n",
      "  Cycle Photo: 0.0503, Cycle Monet: 0.0500\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.6570\n",
      "Epoch [58/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0585, D_X Fake: 0.1192, D_X Total: 0.0888\n",
      "  D_Y Real: 0.0592, D_Y Fake: 0.0551, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.6113, F Adv: 0.3704\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0491\n",
      "  Perceptual Photo: 0.1597, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.5835\n",
      "Epoch [58/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1902, D_X Fake: 0.0787, D_X Total: 0.1345\n",
      "  D_Y Real: 0.1180, D_Y Fake: 0.0386, D_Y Total: 0.0783\n",
      "Generator Losses:\n",
      "  G Adv: 0.6511, F Adv: 0.7120\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.2004, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 4.1186\n",
      "Epoch [58/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0370, D_X Fake: 0.3324, D_X Total: 0.1847\n",
      "  D_Y Real: 0.0868, D_Y Fake: 0.0529, D_Y Total: 0.0699\n",
      "Generator Losses:\n",
      "  G Adv: 0.7716, F Adv: 0.2477\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.2176\n",
      "Epoch [58/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1548, D_X Fake: 0.0440, D_X Total: 0.0994\n",
      "  D_Y Real: 0.1237, D_Y Fake: 0.0662, D_Y Total: 0.0950\n",
      "Generator Losses:\n",
      "  G Adv: 1.0000, F Adv: 0.7892\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.9145\n",
      "Epoch [58/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0726, D_X Fake: 0.1214, D_X Total: 0.0970\n",
      "  D_Y Real: 0.0746, D_Y Fake: 0.0890, D_Y Total: 0.0818\n",
      "Generator Losses:\n",
      "  G Adv: 0.6539, F Adv: 0.3389\n",
      "  Cycle Photo: 0.0633, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.5773\n",
      "Epoch [58/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1321, D_X Fake: 0.0668, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0652, D_Y Fake: 0.0722, D_Y Total: 0.0687\n",
      "Generator Losses:\n",
      "  G Adv: 0.9095, F Adv: 0.4804\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.6357\n",
      "Epoch [58/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0884, D_X Fake: 0.1887, D_X Total: 0.1385\n",
      "  D_Y Real: 0.1257, D_Y Fake: 0.0898, D_Y Total: 0.1077\n",
      "Generator Losses:\n",
      "  G Adv: 0.6411, F Adv: 0.3430\n",
      "  Cycle Photo: 0.0428, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.4371\n",
      "Epoch [58/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0362, D_X Fake: 0.1503, D_X Total: 0.0933\n",
      "  D_Y Real: 0.1035, D_Y Fake: 0.0456, D_Y Total: 0.0746\n",
      "Generator Losses:\n",
      "  G Adv: 0.7785, F Adv: 0.3932\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0529\n",
      "  Perceptual Photo: 0.1714, Perceptual Monet: 0.1901\n",
      "  Total G Loss: 3.9861\n",
      "Epoch [58/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0874, D_X Fake: 0.1085, D_X Total: 0.0979\n",
      "  D_Y Real: 0.1537, D_Y Fake: 0.0770, D_Y Total: 0.1153\n",
      "Generator Losses:\n",
      "  G Adv: 1.0114, F Adv: 0.4044\n",
      "  Cycle Photo: 0.0420, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1871\n",
      "  Total G Loss: 3.8472\n",
      "Epoch [58/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0278, D_X Fake: 0.0717, D_X Total: 0.0498\n",
      "  D_Y Real: 0.0872, D_Y Fake: 0.1665, D_Y Total: 0.1269\n",
      "Generator Losses:\n",
      "  G Adv: 0.6724, F Adv: 0.5723\n",
      "  Cycle Photo: 0.0518, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1705, Perceptual Monet: 0.1754\n",
      "  Total G Loss: 3.8695\n",
      "Epoch [58/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1102, D_X Fake: 0.0958, D_X Total: 0.1030\n",
      "  D_Y Real: 0.1107, D_Y Fake: 0.1294, D_Y Total: 0.1200\n",
      "Generator Losses:\n",
      "  G Adv: 0.6229, F Adv: 0.5116\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1608, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.5953\n",
      "Epoch [58/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0618, D_X Fake: 0.2850, D_X Total: 0.1734\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.1062, D_Y Total: 0.0684\n",
      "Generator Losses:\n",
      "  G Adv: 0.5134, F Adv: 0.3220\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.3593\n",
      "Epoch [58/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1475, D_X Fake: 0.0460, D_X Total: 0.0968\n",
      "  D_Y Real: 0.1476, D_Y Fake: 0.0764, D_Y Total: 0.1120\n",
      "Generator Losses:\n",
      "  G Adv: 0.9325, F Adv: 0.5728\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1834\n",
      "  Total G Loss: 4.2026\n",
      "Epoch [58/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1856, D_X Fake: 0.0504, D_X Total: 0.1180\n",
      "  D_Y Real: 0.0784, D_Y Fake: 0.0633, D_Y Total: 0.0709\n",
      "Generator Losses:\n",
      "  G Adv: 0.7309, F Adv: 0.6608\n",
      "  Cycle Photo: 0.0876, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.2469, Perceptual Monet: 0.1368\n",
      "  Total G Loss: 4.5195\n",
      "Epoch [58/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2500, D_X Fake: 0.1261, D_X Total: 0.1881\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.0776, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.6712, F Adv: 0.5290\n",
      "  Cycle Photo: 0.1005, Cycle Monet: 0.0457\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 4.3604\n",
      "Epoch [58/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0715, D_X Fake: 0.1594, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0799, D_Y Fake: 0.2266, D_Y Total: 0.1532\n",
      "Generator Losses:\n",
      "  G Adv: 0.3592, F Adv: 0.4428\n",
      "  Cycle Photo: 0.0553, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1591, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.3569\n",
      "Epoch [58/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0663, D_X Fake: 0.2042, D_X Total: 0.1352\n",
      "  D_Y Real: 0.0434, D_Y Fake: 0.1564, D_Y Total: 0.0999\n",
      "Generator Losses:\n",
      "  G Adv: 0.5585, F Adv: 0.3769\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0433\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1954\n",
      "  Total G Loss: 3.4448\n",
      "Epoch [58/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0353, D_X Fake: 0.0548, D_X Total: 0.0451\n",
      "  D_Y Real: 0.0775, D_Y Fake: 0.0439, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.9366, F Adv: 0.6182\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.7743\n",
      "Epoch [59/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0907, D_X Fake: 0.1072, D_X Total: 0.0990\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.1849, D_Y Total: 0.1124\n",
      "Generator Losses:\n",
      "  G Adv: 0.4698, F Adv: 0.5089\n",
      "  Cycle Photo: 0.0639, Cycle Monet: 0.0404\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.6381\n",
      "Epoch [59/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0910, D_X Fake: 0.1439, D_X Total: 0.1175\n",
      "  D_Y Real: 0.1170, D_Y Fake: 0.0558, D_Y Total: 0.0864\n",
      "Generator Losses:\n",
      "  G Adv: 0.8999, F Adv: 0.4638\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1953, Perceptual Monet: 0.1816\n",
      "  Total G Loss: 4.1026\n",
      "Epoch [59/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0358, D_X Fake: 0.1034, D_X Total: 0.0696\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0814, D_Y Total: 0.0561\n",
      "Generator Losses:\n",
      "  G Adv: 0.6715, F Adv: 0.3752\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.4426\n",
      "Epoch [59/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.1985, D_X Total: 0.1470\n",
      "  D_Y Real: 0.0567, D_Y Fake: 0.1190, D_Y Total: 0.0878\n",
      "Generator Losses:\n",
      "  G Adv: 0.5714, F Adv: 0.4304\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1459\n",
      "  Total G Loss: 3.4074\n",
      "Epoch [59/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1622, D_X Fake: 0.0416, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0685, D_Y Fake: 0.3162, D_Y Total: 0.1924\n",
      "Generator Losses:\n",
      "  G Adv: 0.4312, F Adv: 0.8813\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.6649\n",
      "Epoch [59/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1582, D_X Fake: 0.1102, D_X Total: 0.1342\n",
      "  D_Y Real: 0.0598, D_Y Fake: 0.0924, D_Y Total: 0.0761\n",
      "Generator Losses:\n",
      "  G Adv: 0.6170, F Adv: 0.3987\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1867\n",
      "  Total G Loss: 3.4583\n",
      "Epoch [59/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0786, D_X Fake: 0.2518, D_X Total: 0.1652\n",
      "  D_Y Real: 0.0357, D_Y Fake: 0.1443, D_Y Total: 0.0900\n",
      "Generator Losses:\n",
      "  G Adv: 0.6101, F Adv: 0.3020\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1681, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.4983\n",
      "Epoch [59/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0849, D_X Fake: 0.1647, D_X Total: 0.1248\n",
      "  D_Y Real: 0.1679, D_Y Fake: 0.0758, D_Y Total: 0.1218\n",
      "Generator Losses:\n",
      "  G Adv: 0.9523, F Adv: 0.2381\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.4741\n",
      "Epoch [59/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1532, D_X Fake: 0.1456, D_X Total: 0.1494\n",
      "  D_Y Real: 0.0646, D_Y Fake: 0.3352, D_Y Total: 0.1999\n",
      "Generator Losses:\n",
      "  G Adv: 0.3242, F Adv: 0.4889\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1535, Perceptual Monet: 0.1504\n",
      "  Total G Loss: 2.9930\n",
      "Epoch [59/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1723, D_X Fake: 0.0992, D_X Total: 0.1358\n",
      "  D_Y Real: 0.1800, D_Y Fake: 0.0679, D_Y Total: 0.1240\n",
      "Generator Losses:\n",
      "  G Adv: 0.7539, F Adv: 0.5489\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1967, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 4.0883\n",
      "Epoch [59/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0564, D_X Fake: 0.1396, D_X Total: 0.0980\n",
      "  D_Y Real: 0.0677, D_Y Fake: 0.2574, D_Y Total: 0.1625\n",
      "Generator Losses:\n",
      "  G Adv: 0.4302, F Adv: 0.4743\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0499\n",
      "  Perceptual Photo: 0.1032, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.2536\n",
      "Epoch [59/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1813, D_X Fake: 0.1648, D_X Total: 0.1731\n",
      "  D_Y Real: 0.0850, D_Y Fake: 0.0685, D_Y Total: 0.0768\n",
      "Generator Losses:\n",
      "  G Adv: 0.7078, F Adv: 0.6441\n",
      "  Cycle Photo: 0.0454, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.8294\n",
      "Epoch [59/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1020, D_X Fake: 0.1808, D_X Total: 0.1414\n",
      "  D_Y Real: 0.0878, D_Y Fake: 0.0555, D_Y Total: 0.0717\n",
      "Generator Losses:\n",
      "  G Adv: 0.9471, F Adv: 0.3710\n",
      "  Cycle Photo: 0.0461, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.6535\n",
      "Epoch [59/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1207, D_X Fake: 0.0409, D_X Total: 0.0808\n",
      "  D_Y Real: 0.1568, D_Y Fake: 0.0618, D_Y Total: 0.1093\n",
      "Generator Losses:\n",
      "  G Adv: 0.8495, F Adv: 0.7582\n",
      "  Cycle Photo: 0.0863, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.2214, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 4.7790\n",
      "Epoch [59/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0266, D_X Fake: 0.5263, D_X Total: 0.2765\n",
      "  D_Y Real: 0.0854, D_Y Fake: 0.0465, D_Y Total: 0.0660\n",
      "Generator Losses:\n",
      "  G Adv: 0.8889, F Adv: 0.1658\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1839\n",
      "  Total G Loss: 3.5834\n",
      "Epoch [59/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1436, D_X Fake: 0.1733, D_X Total: 0.1585\n",
      "  D_Y Real: 0.0529, D_Y Fake: 0.1404, D_Y Total: 0.0966\n",
      "Generator Losses:\n",
      "  G Adv: 0.5748, F Adv: 0.3693\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1953, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 3.6649\n",
      "Epoch [59/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0589, D_X Fake: 0.1768, D_X Total: 0.1178\n",
      "  D_Y Real: 0.0375, D_Y Fake: 0.1908, D_Y Total: 0.1141\n",
      "Generator Losses:\n",
      "  G Adv: 0.3332, F Adv: 0.3740\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1581, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.2077\n",
      "Epoch [59/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0394, D_X Fake: 0.0726, D_X Total: 0.0560\n",
      "  D_Y Real: 0.0578, D_Y Fake: 0.0661, D_Y Total: 0.0619\n",
      "Generator Losses:\n",
      "  G Adv: 0.6760, F Adv: 0.6959\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1278, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 3.6354\n",
      "Epoch [59/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1710, D_X Fake: 0.0374, D_X Total: 0.1042\n",
      "  D_Y Real: 0.0406, D_Y Fake: 0.1623, D_Y Total: 0.1014\n",
      "Generator Losses:\n",
      "  G Adv: 0.4839, F Adv: 0.9311\n",
      "  Cycle Photo: 0.0711, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.9358\n",
      "Epoch [59/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2814, D_X Fake: 0.0547, D_X Total: 0.1681\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.0611, D_Y Total: 0.0498\n",
      "Generator Losses:\n",
      "  G Adv: 0.4545, F Adv: 0.8325\n",
      "  Cycle Photo: 0.0582, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.9524\n",
      "Epoch [59/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2142, D_X Fake: 0.0583, D_X Total: 0.1362\n",
      "  D_Y Real: 0.0790, D_Y Fake: 0.0537, D_Y Total: 0.0664\n",
      "Generator Losses:\n",
      "  G Adv: 0.9851, F Adv: 0.8367\n",
      "  Cycle Photo: 0.0590, Cycle Monet: 0.0426\n",
      "  Perceptual Photo: 0.1813, Perceptual Monet: 0.1987\n",
      "  Total G Loss: 4.7384\n",
      "Epoch [59/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1092, D_X Fake: 0.3604, D_X Total: 0.2348\n",
      "  D_Y Real: 0.0424, D_Y Fake: 0.1531, D_Y Total: 0.0978\n",
      "Generator Losses:\n",
      "  G Adv: 0.4418, F Adv: 0.3561\n",
      "  Cycle Photo: 0.0665, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.3262\n",
      "Epoch [59/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1214, D_X Fake: 0.1750, D_X Total: 0.1482\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0956, D_Y Total: 0.0600\n",
      "Generator Losses:\n",
      "  G Adv: 0.4644, F Adv: 0.5583\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1618, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.3053\n",
      "Epoch [59/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2558, D_X Fake: 0.0478, D_X Total: 0.1518\n",
      "  D_Y Real: 0.1515, D_Y Fake: 0.1129, D_Y Total: 0.1322\n",
      "Generator Losses:\n",
      "  G Adv: 0.5417, F Adv: 1.0636\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1777, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 4.3029\n",
      "Epoch [60/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0938, D_X Fake: 0.1754, D_X Total: 0.1346\n",
      "  D_Y Real: 0.1499, D_Y Fake: 0.0503, D_Y Total: 0.1001\n",
      "Generator Losses:\n",
      "  G Adv: 0.8013, F Adv: 0.4159\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1862, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.6694\n",
      "Epoch [60/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0951, D_X Fake: 0.1414, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0873, D_Y Fake: 0.0679, D_Y Total: 0.0776\n",
      "Generator Losses:\n",
      "  G Adv: 0.4888, F Adv: 0.5295\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1158, Perceptual Monet: 0.1881\n",
      "  Total G Loss: 3.5074\n",
      "Epoch [60/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.1446, D_X Total: 0.1066\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.1002, D_Y Total: 0.0719\n",
      "Generator Losses:\n",
      "  G Adv: 0.5462, F Adv: 0.2834\n",
      "  Cycle Photo: 0.0507, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1854, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.4683\n",
      "Epoch [60/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1974, D_X Fake: 0.0737, D_X Total: 0.1356\n",
      "  D_Y Real: 0.1619, D_Y Fake: 0.0709, D_Y Total: 0.1164\n",
      "Generator Losses:\n",
      "  G Adv: 0.7012, F Adv: 0.5871\n",
      "  Cycle Photo: 0.0455, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.5753\n",
      "Epoch [60/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1316, D_X Fake: 0.3264, D_X Total: 0.2290\n",
      "  D_Y Real: 0.0611, D_Y Fake: 0.0681, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.8341, F Adv: 0.3291\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1694\n",
      "  Total G Loss: 3.6105\n",
      "Epoch [60/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0324, D_X Fake: 0.0812, D_X Total: 0.0568\n",
      "  D_Y Real: 0.0347, D_Y Fake: 0.2680, D_Y Total: 0.1513\n",
      "Generator Losses:\n",
      "  G Adv: 0.3166, F Adv: 0.4994\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0477\n",
      "  Perceptual Photo: 0.1254, Perceptual Monet: 0.1984\n",
      "  Total G Loss: 3.3325\n",
      "Epoch [60/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1419, D_X Fake: 0.0767, D_X Total: 0.1093\n",
      "  D_Y Real: 0.1086, D_Y Fake: 0.0841, D_Y Total: 0.0964\n",
      "Generator Losses:\n",
      "  G Adv: 0.9877, F Adv: 0.7650\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 4.1915\n",
      "Epoch [60/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1289, D_X Fake: 0.0838, D_X Total: 0.1064\n",
      "  D_Y Real: 0.1154, D_Y Fake: 0.0705, D_Y Total: 0.0929\n",
      "Generator Losses:\n",
      "  G Adv: 0.7729, F Adv: 0.6033\n",
      "  Cycle Photo: 0.0477, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1357, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.8666\n",
      "Epoch [60/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0842, D_X Fake: 0.1322, D_X Total: 0.1082\n",
      "  D_Y Real: 0.0951, D_Y Fake: 0.1051, D_Y Total: 0.1001\n",
      "Generator Losses:\n",
      "  G Adv: 0.7113, F Adv: 0.5814\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1121, Perceptual Monet: 0.1898\n",
      "  Total G Loss: 3.5883\n",
      "Epoch [60/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2891, D_X Fake: 0.0636, D_X Total: 0.1763\n",
      "  D_Y Real: 0.0639, D_Y Fake: 0.0536, D_Y Total: 0.0588\n",
      "Generator Losses:\n",
      "  G Adv: 0.7571, F Adv: 0.4596\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1798, Perceptual Monet: 0.2030\n",
      "  Total G Loss: 3.9803\n",
      "Epoch [60/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1102, D_X Fake: 0.0714, D_X Total: 0.0908\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0659, D_Y Total: 0.0491\n",
      "Generator Losses:\n",
      "  G Adv: 0.7025, F Adv: 0.5925\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 3.3955\n",
      "Epoch [60/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1167, D_X Fake: 0.1155, D_X Total: 0.1161\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.0528, D_Y Total: 0.0558\n",
      "Generator Losses:\n",
      "  G Adv: 0.6556, F Adv: 0.5283\n",
      "  Cycle Photo: 0.0521, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1128, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.4386\n",
      "Epoch [60/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0863, D_X Fake: 0.1712, D_X Total: 0.1287\n",
      "  D_Y Real: 0.1231, D_Y Fake: 0.0953, D_Y Total: 0.1092\n",
      "Generator Losses:\n",
      "  G Adv: 0.7300, F Adv: 0.3922\n",
      "  Cycle Photo: 0.0528, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1739, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.7375\n",
      "Epoch [60/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1218, D_X Fake: 0.0780, D_X Total: 0.0999\n",
      "  D_Y Real: 0.0548, D_Y Fake: 0.0785, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.6352, F Adv: 0.5628\n",
      "  Cycle Photo: 0.0419, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1504\n",
      "  Total G Loss: 3.4530\n",
      "Epoch [60/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3086, D_X Fake: 0.0369, D_X Total: 0.1727\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0896, D_Y Total: 0.0614\n",
      "Generator Losses:\n",
      "  G Adv: 0.6272, F Adv: 0.8814\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1626, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.9610\n",
      "Epoch [60/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1849, D_X Fake: 0.0338, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0659, D_Y Fake: 0.1885, D_Y Total: 0.1272\n",
      "Generator Losses:\n",
      "  G Adv: 0.5103, F Adv: 0.8453\n",
      "  Cycle Photo: 0.0519, Cycle Monet: 0.0453\n",
      "  Perceptual Photo: 0.1181, Perceptual Monet: 0.1940\n",
      "  Total G Loss: 3.8883\n",
      "Epoch [60/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2481, D_X Fake: 0.0294, D_X Total: 0.1388\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.1014, D_Y Total: 0.0702\n",
      "Generator Losses:\n",
      "  G Adv: 0.5343, F Adv: 0.8264\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1714, Perceptual Monet: 0.1233\n",
      "  Total G Loss: 3.6254\n",
      "Epoch [60/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1523, D_X Fake: 0.1504, D_X Total: 0.1514\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0886, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.6669, F Adv: 0.5083\n",
      "  Cycle Photo: 0.0540, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.6879\n",
      "Epoch [60/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0951, D_X Fake: 0.1217, D_X Total: 0.1084\n",
      "  D_Y Real: 0.1187, D_Y Fake: 0.0735, D_Y Total: 0.0961\n",
      "Generator Losses:\n",
      "  G Adv: 0.7085, F Adv: 0.3916\n",
      "  Cycle Photo: 0.0635, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.1847, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.9684\n",
      "Epoch [60/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0368, D_X Fake: 0.0707, D_X Total: 0.0537\n",
      "  D_Y Real: 0.0890, D_Y Fake: 0.0868, D_Y Total: 0.0879\n",
      "Generator Losses:\n",
      "  G Adv: 0.7858, F Adv: 0.3657\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0622\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1957\n",
      "  Total G Loss: 3.9747\n",
      "Epoch [60/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1571, D_X Fake: 0.1240, D_X Total: 0.1406\n",
      "  D_Y Real: 0.0832, D_Y Fake: 0.0484, D_Y Total: 0.0658\n",
      "Generator Losses:\n",
      "  G Adv: 1.0420, F Adv: 0.7660\n",
      "  Cycle Photo: 0.0447, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 4.2458\n",
      "Epoch [60/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0684, D_X Fake: 0.1477, D_X Total: 0.1081\n",
      "  D_Y Real: 0.0596, D_Y Fake: 0.0478, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.9033, F Adv: 0.5498\n",
      "  Cycle Photo: 0.1209, Cycle Monet: 0.0437\n",
      "  Perceptual Photo: 0.2213, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 5.1369\n",
      "Epoch [60/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1058, D_X Fake: 0.1262, D_X Total: 0.1160\n",
      "  D_Y Real: 0.0462, D_Y Fake: 0.0647, D_Y Total: 0.0555\n",
      "Generator Losses:\n",
      "  G Adv: 0.8180, F Adv: 0.6962\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1760, Perceptual Monet: 0.1836\n",
      "  Total G Loss: 4.2277\n",
      "Epoch [60/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0823, D_X Fake: 0.0453, D_X Total: 0.0638\n",
      "  D_Y Real: 0.0857, D_Y Fake: 0.0610, D_Y Total: 0.0733\n",
      "Generator Losses:\n",
      "  G Adv: 0.6728, F Adv: 0.6788\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1518, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.7294\n",
      "Saved checkpoint at epoch 60\n",
      "Epoch [61/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0644, D_X Fake: 0.2247, D_X Total: 0.1445\n",
      "  D_Y Real: 0.0571, D_Y Fake: 0.0607, D_Y Total: 0.0589\n",
      "Generator Losses:\n",
      "  G Adv: 0.7165, F Adv: 0.3936\n",
      "  Cycle Photo: 0.0568, Cycle Monet: 0.0490\n",
      "  Perceptual Photo: 0.1152, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.6350\n",
      "Epoch [61/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1000, D_X Fake: 0.0750, D_X Total: 0.0875\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.3211, D_Y Total: 0.1774\n",
      "Generator Losses:\n",
      "  G Adv: 0.3590, F Adv: 0.5660\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0413\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.3886\n",
      "Epoch [61/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0708, D_X Fake: 0.1543, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0878, D_Y Total: 0.0591\n",
      "Generator Losses:\n",
      "  G Adv: 0.6517, F Adv: 0.2999\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.2025, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.6519\n",
      "Epoch [61/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0657, D_X Fake: 0.0988, D_X Total: 0.0823\n",
      "  D_Y Real: 0.1109, D_Y Fake: 0.0657, D_Y Total: 0.0883\n",
      "Generator Losses:\n",
      "  G Adv: 0.6910, F Adv: 0.3437\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1706, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.6589\n",
      "Epoch [61/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0690, D_X Fake: 0.1414, D_X Total: 0.1052\n",
      "  D_Y Real: 0.0577, D_Y Fake: 0.1013, D_Y Total: 0.0795\n",
      "Generator Losses:\n",
      "  G Adv: 0.6729, F Adv: 0.3470\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1610, Perceptual Monet: 0.1255\n",
      "  Total G Loss: 3.2466\n",
      "Epoch [61/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4629, D_X Fake: 0.0446, D_X Total: 0.2538\n",
      "  D_Y Real: 0.0727, D_Y Fake: 0.4029, D_Y Total: 0.2378\n",
      "Generator Losses:\n",
      "  G Adv: 0.2227, F Adv: 0.7901\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 3.6917\n",
      "Epoch [61/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1691, D_X Fake: 0.0965, D_X Total: 0.1328\n",
      "  D_Y Real: 0.1524, D_Y Fake: 0.0841, D_Y Total: 0.1182\n",
      "Generator Losses:\n",
      "  G Adv: 0.7488, F Adv: 0.4291\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0444\n",
      "  Perceptual Photo: 0.1908, Perceptual Monet: 0.1859\n",
      "  Total G Loss: 4.0045\n",
      "Epoch [61/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0804, D_X Fake: 0.0421, D_X Total: 0.0612\n",
      "  D_Y Real: 0.0573, D_Y Fake: 0.0587, D_Y Total: 0.0580\n",
      "Generator Losses:\n",
      "  G Adv: 0.6308, F Adv: 0.8342\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1756, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 4.0493\n",
      "Epoch [61/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0845, D_X Fake: 0.1193, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0424, D_Y Fake: 0.0534, D_Y Total: 0.0479\n",
      "Generator Losses:\n",
      "  G Adv: 0.5626, F Adv: 0.5698\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1301, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.2441\n",
      "Epoch [61/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1084, D_X Fake: 0.1197, D_X Total: 0.1140\n",
      "  D_Y Real: 0.1215, D_Y Fake: 0.3768, D_Y Total: 0.2492\n",
      "Generator Losses:\n",
      "  G Adv: 0.3672, F Adv: 0.4834\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1682, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.2999\n",
      "Epoch [61/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0768, D_X Fake: 0.1301, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0731, D_Y Fake: 0.1149, D_Y Total: 0.0940\n",
      "Generator Losses:\n",
      "  G Adv: 0.6997, F Adv: 0.4918\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.2198, Perceptual Monet: 0.1975\n",
      "  Total G Loss: 4.2417\n",
      "Epoch [61/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0492, D_X Fake: 0.1695, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0578, D_Y Fake: 0.0774, D_Y Total: 0.0676\n",
      "Generator Losses:\n",
      "  G Adv: 0.8758, F Adv: 0.4463\n",
      "  Cycle Photo: 0.0384, Cycle Monet: 0.0477\n",
      "  Perceptual Photo: 0.1732, Perceptual Monet: 0.1908\n",
      "  Total G Loss: 4.0034\n",
      "Epoch [61/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2478, D_X Fake: 0.0821, D_X Total: 0.1649\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.0660, D_Y Total: 0.0670\n",
      "Generator Losses:\n",
      "  G Adv: 0.6701, F Adv: 0.4891\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1565\n",
      "  Total G Loss: 3.4015\n",
      "Epoch [61/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1058, D_X Fake: 0.1289, D_X Total: 0.1173\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.0952, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.3525, F Adv: 0.4816\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1805, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 3.4029\n",
      "Epoch [61/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2211, D_X Fake: 0.0678, D_X Total: 0.1444\n",
      "  D_Y Real: 0.0380, D_Y Fake: 0.0960, D_Y Total: 0.0670\n",
      "Generator Losses:\n",
      "  G Adv: 0.5163, F Adv: 0.8359\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1811, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.8284\n",
      "Epoch [61/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0804, D_X Fake: 0.1419, D_X Total: 0.1112\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.1797, D_Y Total: 0.1117\n",
      "Generator Losses:\n",
      "  G Adv: 0.4370, F Adv: 0.4966\n",
      "  Cycle Photo: 0.0447, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1345\n",
      "  Total G Loss: 3.0123\n",
      "Epoch [61/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0611, D_X Fake: 0.1606, D_X Total: 0.1109\n",
      "  D_Y Real: 0.0698, D_Y Fake: 0.1371, D_Y Total: 0.1034\n",
      "Generator Losses:\n",
      "  G Adv: 0.6161, F Adv: 0.3206\n",
      "  Cycle Photo: 0.0506, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1828, Perceptual Monet: 0.1663\n",
      "  Total G Loss: 3.5585\n",
      "Epoch [61/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.1120, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0553, D_Y Fake: 0.0983, D_Y Total: 0.0768\n",
      "Generator Losses:\n",
      "  G Adv: 0.5065, F Adv: 0.3012\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1717, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.2250\n",
      "Epoch [61/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5925, D_X Fake: 0.1344, D_X Total: 0.3634\n",
      "  D_Y Real: 0.1372, D_Y Fake: 0.0769, D_Y Total: 0.1071\n",
      "Generator Losses:\n",
      "  G Adv: 0.7099, F Adv: 1.7206\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0391\n",
      "  Perceptual Photo: 0.1614, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 5.0232\n",
      "Epoch [61/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2383, D_X Fake: 0.0388, D_X Total: 0.1386\n",
      "  D_Y Real: 0.0520, D_Y Fake: 0.0524, D_Y Total: 0.0522\n",
      "Generator Losses:\n",
      "  G Adv: 0.7409, F Adv: 0.8838\n",
      "  Cycle Photo: 0.0755, Cycle Monet: 0.0510\n",
      "  Perceptual Photo: 0.2175, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 4.8783\n",
      "Epoch [61/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0553, D_X Fake: 0.0955, D_X Total: 0.0754\n",
      "  D_Y Real: 0.0432, D_Y Fake: 0.0931, D_Y Total: 0.0681\n",
      "Generator Losses:\n",
      "  G Adv: 0.5456, F Adv: 0.6500\n",
      "  Cycle Photo: 0.0602, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1865\n",
      "  Total G Loss: 3.9103\n",
      "Epoch [61/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2777, D_X Fake: 0.0433, D_X Total: 0.1605\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.2035, D_Y Total: 0.1188\n",
      "Generator Losses:\n",
      "  G Adv: 0.3438, F Adv: 0.6793\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1856, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.8883\n",
      "Epoch [61/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0481, D_X Fake: 0.1455, D_X Total: 0.0968\n",
      "  D_Y Real: 0.0582, D_Y Fake: 0.0512, D_Y Total: 0.0547\n",
      "Generator Losses:\n",
      "  G Adv: 1.0351, F Adv: 0.4132\n",
      "  Cycle Photo: 0.0498, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1202, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.7008\n",
      "Epoch [61/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1321, D_X Fake: 0.1075, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0545, D_Y Fake: 0.0396, D_Y Total: 0.0470\n",
      "Generator Losses:\n",
      "  G Adv: 0.9255, F Adv: 0.5031\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1895\n",
      "  Total G Loss: 3.9732\n",
      "Epoch [62/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0516, D_X Fake: 0.1078, D_X Total: 0.0797\n",
      "  D_Y Real: 0.0695, D_Y Fake: 0.0765, D_Y Total: 0.0730\n",
      "Generator Losses:\n",
      "  G Adv: 0.7635, F Adv: 0.6561\n",
      "  Cycle Photo: 0.0455, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.9856\n",
      "Epoch [62/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2824, D_X Fake: 0.1099, D_X Total: 0.1961\n",
      "  D_Y Real: 0.0445, D_Y Fake: 0.0694, D_Y Total: 0.0570\n",
      "Generator Losses:\n",
      "  G Adv: 0.7114, F Adv: 0.5141\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.4880\n",
      "Epoch [62/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2662, D_X Fake: 0.0614, D_X Total: 0.1638\n",
      "  D_Y Real: 0.0525, D_Y Fake: 0.0925, D_Y Total: 0.0725\n",
      "Generator Losses:\n",
      "  G Adv: 0.5197, F Adv: 0.8281\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1956\n",
      "  Total G Loss: 3.9135\n",
      "Epoch [62/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1203, D_X Fake: 0.1089, D_X Total: 0.1146\n",
      "  D_Y Real: 0.0910, D_Y Fake: 0.0750, D_Y Total: 0.0830\n",
      "Generator Losses:\n",
      "  G Adv: 0.7031, F Adv: 0.5968\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0432\n",
      "  Perceptual Photo: 0.1337, Perceptual Monet: 0.1936\n",
      "  Total G Loss: 3.7944\n",
      "Epoch [62/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1966, D_X Fake: 0.1085, D_X Total: 0.1526\n",
      "  D_Y Real: 0.0749, D_Y Fake: 0.1145, D_Y Total: 0.0947\n",
      "Generator Losses:\n",
      "  G Adv: 0.6241, F Adv: 0.4447\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1955, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.6126\n",
      "Epoch [62/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1014, D_X Fake: 0.0445, D_X Total: 0.0730\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.1478, D_Y Total: 0.0921\n",
      "Generator Losses:\n",
      "  G Adv: 0.5561, F Adv: 0.4424\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1810, Perceptual Monet: 0.1874\n",
      "  Total G Loss: 3.6133\n",
      "Epoch [62/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2501, D_X Fake: 0.0362, D_X Total: 0.1431\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.0917, D_Y Total: 0.0691\n",
      "Generator Losses:\n",
      "  G Adv: 0.8551, F Adv: 0.7507\n",
      "  Cycle Photo: 0.0561, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.9822\n",
      "Epoch [62/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0675, D_X Fake: 0.1584, D_X Total: 0.1130\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.1396, D_Y Total: 0.0843\n",
      "Generator Losses:\n",
      "  G Adv: 0.6320, F Adv: 0.2350\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0391\n",
      "  Perceptual Photo: 0.1717, Perceptual Monet: 0.1608\n",
      "  Total G Loss: 3.4053\n",
      "Epoch [62/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0866, D_X Fake: 0.1782, D_X Total: 0.1324\n",
      "  D_Y Real: 0.0428, D_Y Fake: 0.1598, D_Y Total: 0.1013\n",
      "Generator Losses:\n",
      "  G Adv: 0.3106, F Adv: 0.3812\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.0042\n",
      "Epoch [62/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3046, D_X Fake: 0.0317, D_X Total: 0.1682\n",
      "  D_Y Real: 0.3271, D_Y Fake: 0.0474, D_Y Total: 0.1872\n",
      "Generator Losses:\n",
      "  G Adv: 0.9662, F Adv: 0.7566\n",
      "  Cycle Photo: 0.0487, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.2150, Perceptual Monet: 0.1455\n",
      "  Total G Loss: 4.2842\n",
      "Epoch [62/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0407, D_X Fake: 0.0428, D_X Total: 0.0417\n",
      "  D_Y Real: 0.0846, D_Y Fake: 0.0548, D_Y Total: 0.0697\n",
      "Generator Losses:\n",
      "  G Adv: 1.0047, F Adv: 0.6425\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1166, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.8556\n",
      "Epoch [62/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1065, D_X Fake: 0.0789, D_X Total: 0.0927\n",
      "  D_Y Real: 0.0895, D_Y Fake: 0.0534, D_Y Total: 0.0714\n",
      "Generator Losses:\n",
      "  G Adv: 0.9896, F Adv: 0.6789\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1686, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 4.1424\n",
      "Epoch [62/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0570, D_X Fake: 0.1387, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0988, D_Y Total: 0.0659\n",
      "Generator Losses:\n",
      "  G Adv: 0.5413, F Adv: 0.4777\n",
      "  Cycle Photo: 0.0547, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.6333\n",
      "Epoch [62/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0346, D_X Fake: 0.1472, D_X Total: 0.0909\n",
      "  D_Y Real: 0.0602, D_Y Fake: 0.0982, D_Y Total: 0.0792\n",
      "Generator Losses:\n",
      "  G Adv: 0.5811, F Adv: 0.5393\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.1944\n",
      "  Total G Loss: 3.6270\n",
      "Epoch [62/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0344, D_X Fake: 0.1281, D_X Total: 0.0813\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0710, D_Y Total: 0.0584\n",
      "Generator Losses:\n",
      "  G Adv: 0.7315, F Adv: 0.3153\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1766, Perceptual Monet: 0.1468\n",
      "  Total G Loss: 3.4284\n",
      "Epoch [62/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.0809, D_X Total: 0.0883\n",
      "  D_Y Real: 0.0471, D_Y Fake: 0.1214, D_Y Total: 0.0843\n",
      "Generator Losses:\n",
      "  G Adv: 0.4401, F Adv: 0.6157\n",
      "  Cycle Photo: 0.0610, Cycle Monet: 0.0445\n",
      "  Perceptual Photo: 0.1851, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.8090\n",
      "Epoch [62/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0866, D_X Fake: 0.1600, D_X Total: 0.1233\n",
      "  D_Y Real: 0.1002, D_Y Fake: 0.0646, D_Y Total: 0.0824\n",
      "Generator Losses:\n",
      "  G Adv: 0.6231, F Adv: 0.4379\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1402\n",
      "  Total G Loss: 3.1895\n",
      "Epoch [62/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1846, D_X Fake: 0.0393, D_X Total: 0.1120\n",
      "  D_Y Real: 0.0637, D_Y Fake: 0.0614, D_Y Total: 0.0626\n",
      "Generator Losses:\n",
      "  G Adv: 0.7128, F Adv: 0.8747\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 3.9692\n",
      "Epoch [62/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0583, D_X Fake: 0.1071, D_X Total: 0.0827\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.0502, D_Y Total: 0.0456\n",
      "Generator Losses:\n",
      "  G Adv: 0.8466, F Adv: 0.2391\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1666, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.3836\n",
      "Epoch [62/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0788, D_X Fake: 0.0831, D_X Total: 0.0810\n",
      "  D_Y Real: 0.0660, D_Y Fake: 0.0590, D_Y Total: 0.0625\n",
      "Generator Losses:\n",
      "  G Adv: 0.7519, F Adv: 0.7254\n",
      "  Cycle Photo: 0.0548, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1334, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.7556\n",
      "Epoch [62/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1409, D_X Fake: 0.0604, D_X Total: 0.1006\n",
      "  D_Y Real: 0.1024, D_Y Fake: 0.0351, D_Y Total: 0.0687\n",
      "Generator Losses:\n",
      "  G Adv: 1.0667, F Adv: 0.7047\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0459\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 4.5472\n",
      "Epoch [62/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0576, D_X Fake: 0.2377, D_X Total: 0.1477\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0707, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.6550, F Adv: 0.4256\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0465\n",
      "  Perceptual Photo: 0.1489, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.6561\n",
      "Epoch [62/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0738, D_X Fake: 0.0804, D_X Total: 0.0771\n",
      "  D_Y Real: 0.0732, D_Y Fake: 0.0699, D_Y Total: 0.0716\n",
      "Generator Losses:\n",
      "  G Adv: 0.6810, F Adv: 0.4930\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1185, Perceptual Monet: 0.1437\n",
      "  Total G Loss: 3.0946\n",
      "Epoch [62/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1836, D_X Fake: 0.0350, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0598, D_Y Fake: 0.0601, D_Y Total: 0.0599\n",
      "Generator Losses:\n",
      "  G Adv: 0.6516, F Adv: 0.9184\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0468\n",
      "  Perceptual Photo: 0.1357, Perceptual Monet: 0.2153\n",
      "  Total G Loss: 4.2558\n",
      "Epoch [63/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1238, D_X Fake: 0.0441, D_X Total: 0.0839\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.1685, D_Y Total: 0.1023\n",
      "Generator Losses:\n",
      "  G Adv: 0.6077, F Adv: 0.8568\n",
      "  Cycle Photo: 0.0767, Cycle Monet: 0.0463\n",
      "  Perceptual Photo: 0.2420, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 4.7687\n",
      "Epoch [63/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0641, D_X Fake: 0.1509, D_X Total: 0.1075\n",
      "  D_Y Real: 0.0506, D_Y Fake: 0.1059, D_Y Total: 0.0783\n",
      "Generator Losses:\n",
      "  G Adv: 0.5166, F Adv: 0.4466\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 3.5090\n",
      "Epoch [63/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1391, D_X Fake: 0.2766, D_X Total: 0.2079\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.2251, D_Y Total: 0.1336\n",
      "Generator Losses:\n",
      "  G Adv: 0.3348, F Adv: 0.2921\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1385, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.0202\n",
      "Epoch [63/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0632, D_X Fake: 0.1620, D_X Total: 0.1126\n",
      "  D_Y Real: 0.1598, D_Y Fake: 0.0526, D_Y Total: 0.1062\n",
      "Generator Losses:\n",
      "  G Adv: 0.9920, F Adv: 0.3053\n",
      "  Cycle Photo: 0.0471, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1715, Perceptual Monet: 0.1808\n",
      "  Total G Loss: 3.9504\n",
      "Epoch [63/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1044, D_X Fake: 0.1673, D_X Total: 0.1359\n",
      "  D_Y Real: 0.0788, D_Y Fake: 0.0463, D_Y Total: 0.0625\n",
      "Generator Losses:\n",
      "  G Adv: 0.8363, F Adv: 0.5297\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1807, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.8377\n",
      "Epoch [63/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0325, D_X Fake: 0.1940, D_X Total: 0.1132\n",
      "  D_Y Real: 0.1132, D_Y Fake: 0.0492, D_Y Total: 0.0812\n",
      "Generator Losses:\n",
      "  G Adv: 1.0066, F Adv: 0.3904\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.4830\n",
      "Epoch [63/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1663, D_X Fake: 0.0417, D_X Total: 0.1040\n",
      "  D_Y Real: 0.1103, D_Y Fake: 0.0441, D_Y Total: 0.0772\n",
      "Generator Losses:\n",
      "  G Adv: 0.8799, F Adv: 0.4176\n",
      "  Cycle Photo: 0.0547, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 3.8451\n",
      "Epoch [63/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1545, D_X Fake: 0.0509, D_X Total: 0.1027\n",
      "  D_Y Real: 0.0501, D_Y Fake: 0.0360, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.9584, F Adv: 0.8365\n",
      "  Cycle Photo: 0.0538, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 4.3094\n",
      "Epoch [63/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1099, D_X Fake: 0.1100, D_X Total: 0.1099\n",
      "  D_Y Real: 0.1263, D_Y Fake: 0.0882, D_Y Total: 0.1072\n",
      "Generator Losses:\n",
      "  G Adv: 0.6864, F Adv: 0.3460\n",
      "  Cycle Photo: 0.0621, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1747, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.8342\n",
      "Epoch [63/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0614, D_X Fake: 0.1694, D_X Total: 0.1154\n",
      "  D_Y Real: 0.0755, D_Y Fake: 0.0597, D_Y Total: 0.0676\n",
      "Generator Losses:\n",
      "  G Adv: 0.8104, F Adv: 0.3069\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1518, Perceptual Monet: 0.1566\n",
      "  Total G Loss: 3.5045\n",
      "Epoch [63/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0945, D_X Fake: 0.1109, D_X Total: 0.1027\n",
      "  D_Y Real: 0.0939, D_Y Fake: 0.0671, D_Y Total: 0.0805\n",
      "Generator Losses:\n",
      "  G Adv: 0.9972, F Adv: 0.5835\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 4.1172\n",
      "Epoch [63/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.1356, D_X Total: 0.1053\n",
      "  D_Y Real: 0.0530, D_Y Fake: 0.1037, D_Y Total: 0.0783\n",
      "Generator Losses:\n",
      "  G Adv: 0.5040, F Adv: 0.3240\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1399\n",
      "  Total G Loss: 2.8670\n",
      "Epoch [63/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0933, D_X Fake: 0.0464, D_X Total: 0.0698\n",
      "  D_Y Real: 0.0599, D_Y Fake: 0.0736, D_Y Total: 0.0668\n",
      "Generator Losses:\n",
      "  G Adv: 0.5275, F Adv: 0.7304\n",
      "  Cycle Photo: 0.0425, Cycle Monet: 0.0514\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.2142\n",
      "  Total G Loss: 4.0032\n",
      "Epoch [63/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1910, D_X Fake: 0.0378, D_X Total: 0.1144\n",
      "  D_Y Real: 0.0709, D_Y Fake: 0.1129, D_Y Total: 0.0919\n",
      "Generator Losses:\n",
      "  G Adv: 0.5329, F Adv: 0.5667\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1712, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.6047\n",
      "Epoch [63/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0615, D_X Fake: 0.1585, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0724, D_Y Fake: 0.1010, D_Y Total: 0.0867\n",
      "Generator Losses:\n",
      "  G Adv: 0.6699, F Adv: 0.5444\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0453\n",
      "  Perceptual Photo: 0.1912, Perceptual Monet: 0.2117\n",
      "  Total G Loss: 4.2469\n",
      "Epoch [63/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0672, D_X Fake: 0.0974, D_X Total: 0.0823\n",
      "  D_Y Real: 0.2040, D_Y Fake: 0.0741, D_Y Total: 0.1391\n",
      "Generator Losses:\n",
      "  G Adv: 1.0282, F Adv: 0.4266\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1188, Perceptual Monet: 0.1928\n",
      "  Total G Loss: 3.9189\n",
      "Epoch [63/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0674, D_X Fake: 0.2145, D_X Total: 0.1409\n",
      "  D_Y Real: 0.0949, D_Y Fake: 0.0661, D_Y Total: 0.0805\n",
      "Generator Losses:\n",
      "  G Adv: 1.0548, F Adv: 0.4015\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.9664\n",
      "Epoch [63/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1839, D_X Fake: 0.1024, D_X Total: 0.1432\n",
      "  D_Y Real: 0.0613, D_Y Fake: 0.0580, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.7454, F Adv: 0.5613\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1569, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.7833\n",
      "Epoch [63/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1280, D_X Fake: 0.0419, D_X Total: 0.0849\n",
      "  D_Y Real: 0.0516, D_Y Fake: 0.1759, D_Y Total: 0.1138\n",
      "Generator Losses:\n",
      "  G Adv: 0.4669, F Adv: 0.5990\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 3.5533\n",
      "Epoch [63/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.1127, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0621, D_Y Fake: 0.1243, D_Y Total: 0.0932\n",
      "Generator Losses:\n",
      "  G Adv: 0.9677, F Adv: 0.5078\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1736, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.8625\n",
      "Epoch [63/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1410, D_X Fake: 0.1036, D_X Total: 0.1223\n",
      "  D_Y Real: 0.2366, D_Y Fake: 0.0893, D_Y Total: 0.1629\n",
      "Generator Losses:\n",
      "  G Adv: 1.1444, F Adv: 0.5461\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1082, Perceptual Monet: 0.1945\n",
      "  Total G Loss: 4.0205\n",
      "Epoch [63/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2031, D_X Fake: 0.0852, D_X Total: 0.1442\n",
      "  D_Y Real: 0.1472, D_Y Fake: 0.0503, D_Y Total: 0.0988\n",
      "Generator Losses:\n",
      "  G Adv: 0.7347, F Adv: 0.5291\n",
      "  Cycle Photo: 0.0511, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1725, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.6795\n",
      "Epoch [63/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.0691, D_X Total: 0.0742\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.1598, D_Y Total: 0.1032\n",
      "Generator Losses:\n",
      "  G Adv: 0.4376, F Adv: 0.5822\n",
      "  Cycle Photo: 0.0428, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1532, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.2962\n",
      "Epoch [63/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1083, D_X Fake: 0.2547, D_X Total: 0.1815\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0425, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.7853, F Adv: 0.3616\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1387\n",
      "  Total G Loss: 3.2295\n",
      "Epoch [64/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3867, D_X Fake: 0.0945, D_X Total: 0.2406\n",
      "  D_Y Real: 0.1643, D_Y Fake: 0.0653, D_Y Total: 0.1148\n",
      "Generator Losses:\n",
      "  G Adv: 0.8813, F Adv: 0.6069\n",
      "  Cycle Photo: 0.0522, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1883, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 4.1618\n",
      "Epoch [64/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2945, D_X Fake: 0.0372, D_X Total: 0.1658\n",
      "  D_Y Real: 0.0573, D_Y Fake: 0.1040, D_Y Total: 0.0807\n",
      "Generator Losses:\n",
      "  G Adv: 0.4691, F Adv: 0.9320\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.6062\n",
      "Epoch [64/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0760, D_X Fake: 0.0758, D_X Total: 0.0759\n",
      "  D_Y Real: 0.1000, D_Y Fake: 0.0621, D_Y Total: 0.0810\n",
      "Generator Losses:\n",
      "  G Adv: 0.8703, F Adv: 0.6178\n",
      "  Cycle Photo: 0.0531, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1957\n",
      "  Total G Loss: 4.2267\n",
      "Epoch [64/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2682, D_X Fake: 0.0473, D_X Total: 0.1577\n",
      "  D_Y Real: 0.1268, D_Y Fake: 0.0690, D_Y Total: 0.0979\n",
      "Generator Losses:\n",
      "  G Adv: 0.8432, F Adv: 0.7510\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1237, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.8650\n",
      "Epoch [64/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0965, D_X Fake: 0.0681, D_X Total: 0.0823\n",
      "  D_Y Real: 0.0786, D_Y Fake: 0.0965, D_Y Total: 0.0876\n",
      "Generator Losses:\n",
      "  G Adv: 0.5889, F Adv: 0.9913\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0468\n",
      "  Perceptual Photo: 0.1716, Perceptual Monet: 0.1949\n",
      "  Total G Loss: 4.3697\n",
      "Epoch [64/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1695, D_X Fake: 0.0589, D_X Total: 0.1142\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.1107, D_Y Total: 0.0743\n",
      "Generator Losses:\n",
      "  G Adv: 0.5640, F Adv: 0.7460\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.5748\n",
      "Epoch [64/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0989, D_X Fake: 0.1513, D_X Total: 0.1251\n",
      "  D_Y Real: 0.1110, D_Y Fake: 0.0643, D_Y Total: 0.0876\n",
      "Generator Losses:\n",
      "  G Adv: 0.9316, F Adv: 0.5207\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1232, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.5578\n",
      "Epoch [64/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2018, D_X Fake: 0.0894, D_X Total: 0.1456\n",
      "  D_Y Real: 0.0703, D_Y Fake: 0.1768, D_Y Total: 0.1236\n",
      "Generator Losses:\n",
      "  G Adv: 0.4866, F Adv: 0.6063\n",
      "  Cycle Photo: 0.0578, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1834, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.7734\n",
      "Epoch [64/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1775, D_X Fake: 0.1280, D_X Total: 0.1528\n",
      "  D_Y Real: 0.0824, D_Y Fake: 0.0435, D_Y Total: 0.0630\n",
      "Generator Losses:\n",
      "  G Adv: 1.0701, F Adv: 0.5396\n",
      "  Cycle Photo: 0.0628, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.2315, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 4.7064\n",
      "Epoch [64/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1426, D_X Fake: 0.1122, D_X Total: 0.1274\n",
      "  D_Y Real: 0.1895, D_Y Fake: 0.0896, D_Y Total: 0.1395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8871, F Adv: 0.3352\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1258, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.3289\n",
      "Epoch [64/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0968, D_X Fake: 0.0399, D_X Total: 0.0683\n",
      "  D_Y Real: 0.0456, D_Y Fake: 0.0862, D_Y Total: 0.0659\n",
      "Generator Losses:\n",
      "  G Adv: 0.6005, F Adv: 0.6622\n",
      "  Cycle Photo: 0.0389, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1055, Perceptual Monet: 0.1531\n",
      "  Total G Loss: 3.2429\n",
      "Epoch [64/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0662, D_X Fake: 0.0979, D_X Total: 0.0820\n",
      "  D_Y Real: 0.0903, D_Y Fake: 0.0867, D_Y Total: 0.0885\n",
      "Generator Losses:\n",
      "  G Adv: 0.6089, F Adv: 0.5027\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1752, Perceptual Monet: 0.1708\n",
      "  Total G Loss: 3.5984\n",
      "Epoch [64/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0484, D_X Fake: 0.0564, D_X Total: 0.0524\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.1246, D_Y Total: 0.0809\n",
      "Generator Losses:\n",
      "  G Adv: 0.5325, F Adv: 0.5225\n",
      "  Cycle Photo: 0.0507, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1457, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.4786\n",
      "Epoch [64/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0948, D_X Fake: 0.2600, D_X Total: 0.1774\n",
      "  D_Y Real: 0.2091, D_Y Fake: 0.0316, D_Y Total: 0.1204\n",
      "Generator Losses:\n",
      "  G Adv: 0.9921, F Adv: 0.3041\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1712, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.8813\n",
      "Epoch [64/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1574, D_X Fake: 0.0626, D_X Total: 0.1100\n",
      "  D_Y Real: 0.1407, D_Y Fake: 0.0335, D_Y Total: 0.0871\n",
      "Generator Losses:\n",
      "  G Adv: 0.8706, F Adv: 0.7437\n",
      "  Cycle Photo: 0.0752, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1790, Perceptual Monet: 0.1707\n",
      "  Total G Loss: 4.4454\n",
      "Epoch [64/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1903, D_X Fake: 0.1330, D_X Total: 0.1616\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.1034, D_Y Total: 0.0733\n",
      "Generator Losses:\n",
      "  G Adv: 0.5672, F Adv: 0.4754\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1699, Perceptual Monet: 0.1388\n",
      "  Total G Loss: 3.2402\n",
      "Epoch [64/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2332, D_X Fake: 0.0422, D_X Total: 0.1377\n",
      "  D_Y Real: 0.1690, D_Y Fake: 0.0673, D_Y Total: 0.1182\n",
      "Generator Losses:\n",
      "  G Adv: 0.6889, F Adv: 1.0084\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 4.1671\n",
      "Epoch [64/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0615, D_X Fake: 0.1358, D_X Total: 0.0987\n",
      "  D_Y Real: 0.1176, D_Y Fake: 0.0689, D_Y Total: 0.0932\n",
      "Generator Losses:\n",
      "  G Adv: 1.0239, F Adv: 0.5273\n",
      "  Cycle Photo: 0.0451, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.9010\n",
      "Epoch [64/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3048, D_X Fake: 0.0789, D_X Total: 0.1919\n",
      "  D_Y Real: 0.0705, D_Y Fake: 0.0767, D_Y Total: 0.0736\n",
      "Generator Losses:\n",
      "  G Adv: 0.6644, F Adv: 0.6958\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.7977\n",
      "Epoch [64/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2162, D_X Fake: 0.0788, D_X Total: 0.1475\n",
      "  D_Y Real: 0.1124, D_Y Fake: 0.0832, D_Y Total: 0.0978\n",
      "Generator Losses:\n",
      "  G Adv: 0.8317, F Adv: 0.6313\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1541, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.7551\n",
      "Epoch [64/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3688, D_X Fake: 0.4715, D_X Total: 0.4202\n",
      "  D_Y Real: 0.0668, D_Y Fake: 0.0686, D_Y Total: 0.0677\n",
      "Generator Losses:\n",
      "  G Adv: 0.8817, F Adv: 0.2943\n",
      "  Cycle Photo: 0.0726, Cycle Monet: 0.0919\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.2131\n",
      "  Total G Loss: 4.7329\n",
      "Epoch [64/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4233, D_X Fake: 0.2313, D_X Total: 0.3273\n",
      "  D_Y Real: 0.0831, D_Y Fake: 0.0821, D_Y Total: 0.0826\n",
      "Generator Losses:\n",
      "  G Adv: 0.7705, F Adv: 0.3088\n",
      "  Cycle Photo: 0.0590, Cycle Monet: 0.0579\n",
      "  Perceptual Photo: 0.2232, Perceptual Monet: 0.1926\n",
      "  Total G Loss: 4.3281\n",
      "Epoch [64/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2129, D_X Fake: 0.3120, D_X Total: 0.2625\n",
      "  D_Y Real: 0.1405, D_Y Fake: 0.0834, D_Y Total: 0.1120\n",
      "Generator Losses:\n",
      "  G Adv: 0.7270, F Adv: 0.2213\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0496\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1571\n",
      "  Total G Loss: 3.3475\n",
      "Epoch [64/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2843, D_X Fake: 0.2922, D_X Total: 0.2882\n",
      "  D_Y Real: 0.0477, D_Y Fake: 0.1609, D_Y Total: 0.1043\n",
      "Generator Losses:\n",
      "  G Adv: 0.4138, F Adv: 0.2668\n",
      "  Cycle Photo: 0.0506, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1247\n",
      "  Total G Loss: 2.9386\n",
      "Epoch [65/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2617, D_X Fake: 0.1941, D_X Total: 0.2279\n",
      "  D_Y Real: 0.1379, D_Y Fake: 0.0541, D_Y Total: 0.0960\n",
      "Generator Losses:\n",
      "  G Adv: 0.9481, F Adv: 0.3712\n",
      "  Cycle Photo: 0.0623, Cycle Monet: 0.0577\n",
      "  Perceptual Photo: 0.2096, Perceptual Monet: 0.1895\n",
      "  Total G Loss: 4.5138\n",
      "Epoch [65/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2701, D_X Fake: 0.2869, D_X Total: 0.2785\n",
      "  D_Y Real: 0.0380, D_Y Fake: 0.1601, D_Y Total: 0.0991\n",
      "Generator Losses:\n",
      "  G Adv: 0.4344, F Adv: 0.2661\n",
      "  Cycle Photo: 0.0533, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.0807\n",
      "Epoch [65/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2668, D_X Fake: 0.2871, D_X Total: 0.2769\n",
      "  D_Y Real: 0.0671, D_Y Fake: 0.1639, D_Y Total: 0.1155\n",
      "Generator Losses:\n",
      "  G Adv: 0.7982, F Adv: 0.2148\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1779, Perceptual Monet: 0.1318\n",
      "  Total G Loss: 3.4936\n",
      "Epoch [65/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2077, D_X Fake: 0.3132, D_X Total: 0.2604\n",
      "  D_Y Real: 0.0633, D_Y Fake: 0.3053, D_Y Total: 0.1843\n",
      "Generator Losses:\n",
      "  G Adv: 0.3488, F Adv: 0.2263\n",
      "  Cycle Photo: 0.0471, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1277\n",
      "  Total G Loss: 2.8255\n",
      "Epoch [65/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3472, D_X Fake: 0.2703, D_X Total: 0.3088\n",
      "  D_Y Real: 0.0617, D_Y Fake: 0.0643, D_Y Total: 0.0630\n",
      "Generator Losses:\n",
      "  G Adv: 0.6612, F Adv: 0.2810\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1572, Perceptual Monet: 0.1390\n",
      "  Total G Loss: 3.2812\n",
      "Epoch [65/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3011, D_X Fake: 0.2166, D_X Total: 0.2588\n",
      "  D_Y Real: 0.0510, D_Y Fake: 0.1183, D_Y Total: 0.0847\n",
      "Generator Losses:\n",
      "  G Adv: 0.6567, F Adv: 0.3816\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1366\n",
      "  Total G Loss: 3.3076\n",
      "Epoch [65/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3262, D_X Fake: 0.2486, D_X Total: 0.2874\n",
      "  D_Y Real: 0.0684, D_Y Fake: 0.0321, D_Y Total: 0.0503\n",
      "Generator Losses:\n",
      "  G Adv: 0.8916, F Adv: 0.3000\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1260\n",
      "  Total G Loss: 3.2548\n",
      "Epoch [65/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1916, D_X Fake: 0.1703, D_X Total: 0.1809\n",
      "  D_Y Real: 0.0427, D_Y Fake: 0.2411, D_Y Total: 0.1419\n",
      "Generator Losses:\n",
      "  G Adv: 0.4154, F Adv: 0.3493\n",
      "  Cycle Photo: 0.0846, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1647, Perceptual Monet: 0.1405\n",
      "  Total G Loss: 3.4884\n",
      "Epoch [65/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2706, D_X Fake: 0.2612, D_X Total: 0.2659\n",
      "  D_Y Real: 0.0973, D_Y Fake: 0.1611, D_Y Total: 0.1292\n",
      "Generator Losses:\n",
      "  G Adv: 0.7658, F Adv: 0.2556\n",
      "  Cycle Photo: 0.0666, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1429, Perceptual Monet: 0.1435\n",
      "  Total G Loss: 3.4588\n",
      "Epoch [65/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2599, D_X Fake: 0.2291, D_X Total: 0.2445\n",
      "  D_Y Real: 0.0772, D_Y Fake: 0.0503, D_Y Total: 0.0637\n",
      "Generator Losses:\n",
      "  G Adv: 0.8387, F Adv: 0.2293\n",
      "  Cycle Photo: 0.0474, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1175, Perceptual Monet: 0.1498\n",
      "  Total G Loss: 3.2591\n",
      "Epoch [65/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2344, D_X Fake: 0.2701, D_X Total: 0.2522\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.1874, D_Y Total: 0.1109\n",
      "Generator Losses:\n",
      "  G Adv: 0.3962, F Adv: 0.1597\n",
      "  Cycle Photo: 0.0663, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1951, Perceptual Monet: 0.1372\n",
      "  Total G Loss: 3.2386\n",
      "Epoch [65/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2972, D_X Fake: 0.2194, D_X Total: 0.2583\n",
      "  D_Y Real: 0.0621, D_Y Fake: 0.2345, D_Y Total: 0.1483\n",
      "Generator Losses:\n",
      "  G Adv: 0.4891, F Adv: 0.3358\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1259, Perceptual Monet: 0.1464\n",
      "  Total G Loss: 3.1037\n",
      "Epoch [65/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1885, D_X Fake: 0.2754, D_X Total: 0.2320\n",
      "  D_Y Real: 0.1319, D_Y Fake: 0.0384, D_Y Total: 0.0852\n",
      "Generator Losses:\n",
      "  G Adv: 0.9359, F Adv: 0.2708\n",
      "  Cycle Photo: 0.0599, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1386\n",
      "  Total G Loss: 3.5383\n",
      "Epoch [65/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2901, D_X Fake: 0.2270, D_X Total: 0.2586\n",
      "  D_Y Real: 0.0565, D_Y Fake: 0.0626, D_Y Total: 0.0596\n",
      "Generator Losses:\n",
      "  G Adv: 0.6178, F Adv: 0.3778\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1211\n",
      "  Total G Loss: 3.2554\n",
      "Epoch [65/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1558, D_X Fake: 0.2350, D_X Total: 0.1954\n",
      "  D_Y Real: 0.0683, D_Y Fake: 0.0695, D_Y Total: 0.0689\n",
      "Generator Losses:\n",
      "  G Adv: 0.6469, F Adv: 0.3012\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1807, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.5577\n",
      "Epoch [65/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2355, D_X Fake: 0.1930, D_X Total: 0.2142\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.1585, D_Y Total: 0.1038\n",
      "Generator Losses:\n",
      "  G Adv: 0.4037, F Adv: 0.3160\n",
      "  Cycle Photo: 0.0621, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1710, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.3599\n",
      "Epoch [65/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3459, D_X Fake: 0.2055, D_X Total: 0.2757\n",
      "  D_Y Real: 0.0798, D_Y Fake: 0.0422, D_Y Total: 0.0610\n",
      "Generator Losses:\n",
      "  G Adv: 0.9494, F Adv: 0.3362\n",
      "  Cycle Photo: 0.0508, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.9126\n",
      "Epoch [65/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3326, D_X Fake: 0.1872, D_X Total: 0.2599\n",
      "  D_Y Real: 0.0490, D_Y Fake: 0.0945, D_Y Total: 0.0718\n",
      "Generator Losses:\n",
      "  G Adv: 0.5504, F Adv: 0.3492\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1824, Perceptual Monet: 0.1232\n",
      "  Total G Loss: 3.1801\n",
      "Epoch [65/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1355, D_X Fake: 0.1672, D_X Total: 0.1513\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0398, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.6198, F Adv: 0.3337\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.0848\n",
      "Epoch [65/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1119, D_X Fake: 0.1062, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.1617, D_Y Total: 0.0972\n",
      "Generator Losses:\n",
      "  G Adv: 0.5366, F Adv: 0.3783\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1337, Perceptual Monet: 0.1525\n",
      "  Total G Loss: 2.9329\n",
      "Epoch [65/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1654, D_X Fake: 0.1323, D_X Total: 0.1488\n",
      "  D_Y Real: 0.0700, D_Y Fake: 0.1134, D_Y Total: 0.0917\n",
      "Generator Losses:\n",
      "  G Adv: 0.4640, F Adv: 0.4125\n",
      "  Cycle Photo: 0.0578, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1240, Perceptual Monet: 0.1365\n",
      "  Total G Loss: 3.0513\n",
      "Epoch [65/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2060, D_X Fake: 0.0939, D_X Total: 0.1500\n",
      "  D_Y Real: 0.0380, D_Y Fake: 0.1294, D_Y Total: 0.0837\n",
      "Generator Losses:\n",
      "  G Adv: 0.5540, F Adv: 0.5174\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1393\n",
      "  Total G Loss: 3.3417\n",
      "Epoch [65/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0270, D_X Fake: 0.0615, D_X Total: 0.0442\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0891, D_Y Total: 0.0611\n",
      "Generator Losses:\n",
      "  G Adv: 0.7531, F Adv: 0.4924\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1414\n",
      "  Total G Loss: 3.5210\n",
      "Epoch [65/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1591, D_X Fake: 0.1077, D_X Total: 0.1334\n",
      "  D_Y Real: 0.0790, D_Y Fake: 0.0736, D_Y Total: 0.0763\n",
      "Generator Losses:\n",
      "  G Adv: 0.5936, F Adv: 0.5106\n",
      "  Cycle Photo: 0.0677, Cycle Monet: 0.0456\n",
      "  Perceptual Photo: 0.1637, Perceptual Monet: 0.1852\n",
      "  Total G Loss: 3.9821\n",
      "Epoch [66/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2081, D_X Fake: 0.1538, D_X Total: 0.1809\n",
      "  D_Y Real: 0.1049, D_Y Fake: 0.1084, D_Y Total: 0.1066\n",
      "Generator Losses:\n",
      "  G Adv: 0.5875, F Adv: 0.4287\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1619, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.2887\n",
      "Epoch [66/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1336, D_X Fake: 0.0935, D_X Total: 0.1136\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0783, D_Y Total: 0.0626\n",
      "Generator Losses:\n",
      "  G Adv: 0.5986, F Adv: 0.4626\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1477, Perceptual Monet: 0.1410\n",
      "  Total G Loss: 3.2670\n",
      "Epoch [66/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0890, D_X Fake: 0.1651, D_X Total: 0.1270\n",
      "  D_Y Real: 0.1718, D_Y Fake: 0.0389, D_Y Total: 0.1053\n",
      "Generator Losses:\n",
      "  G Adv: 0.8996, F Adv: 0.4900\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.7745\n",
      "Epoch [66/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2490, D_X Fake: 0.0545, D_X Total: 0.1518\n",
      "  D_Y Real: 0.0582, D_Y Fake: 0.1589, D_Y Total: 0.1085\n",
      "Generator Losses:\n",
      "  G Adv: 0.6197, F Adv: 0.6439\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.1855, Perceptual Monet: 0.1946\n",
      "  Total G Loss: 4.0407\n",
      "Epoch [66/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0531, D_X Fake: 0.0644, D_X Total: 0.0588\n",
      "  D_Y Real: 0.0608, D_Y Fake: 0.0641, D_Y Total: 0.0624\n",
      "Generator Losses:\n",
      "  G Adv: 0.7863, F Adv: 0.4929\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.1706, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.8317\n",
      "Epoch [66/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0983, D_X Fake: 0.1997, D_X Total: 0.1490\n",
      "  D_Y Real: 0.2055, D_Y Fake: 0.0724, D_Y Total: 0.1389\n",
      "Generator Losses:\n",
      "  G Adv: 1.0163, F Adv: 0.3317\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0475\n",
      "  Perceptual Photo: 0.1819, Perceptual Monet: 0.1833\n",
      "  Total G Loss: 4.2109\n",
      "Epoch [66/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0719, D_X Fake: 0.1833, D_X Total: 0.1276\n",
      "  D_Y Real: 0.0552, D_Y Fake: 0.0642, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.9118, F Adv: 0.3830\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.1626, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 3.8212\n",
      "Epoch [66/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1344, D_X Fake: 0.0644, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0537, D_Y Fake: 0.0982, D_Y Total: 0.0760\n",
      "Generator Losses:\n",
      "  G Adv: 0.4993, F Adv: 0.7252\n",
      "  Cycle Photo: 0.0568, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 3.4698\n",
      "Epoch [66/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0885, D_X Fake: 0.0514, D_X Total: 0.0699\n",
      "  D_Y Real: 0.0585, D_Y Fake: 0.0696, D_Y Total: 0.0640\n",
      "Generator Losses:\n",
      "  G Adv: 0.8539, F Adv: 0.4746\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1554\n",
      "  Total G Loss: 3.8177\n",
      "Epoch [66/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1052, D_X Fake: 0.0437, D_X Total: 0.0744\n",
      "  D_Y Real: 0.1009, D_Y Fake: 0.0707, D_Y Total: 0.0858\n",
      "Generator Losses:\n",
      "  G Adv: 0.8276, F Adv: 0.7662\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1450, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 4.1080\n",
      "Epoch [66/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0218, D_X Fake: 0.1714, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0411, D_Y Fake: 0.0797, D_Y Total: 0.0604\n",
      "Generator Losses:\n",
      "  G Adv: 0.7334, F Adv: 0.3591\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1510\n",
      "  Total G Loss: 3.2322\n",
      "Epoch [66/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4983, D_X Fake: 0.0402, D_X Total: 0.2693\n",
      "  D_Y Real: 0.0516, D_Y Fake: 0.1322, D_Y Total: 0.0919\n",
      "Generator Losses:\n",
      "  G Adv: 0.6899, F Adv: 1.1679\n",
      "  Cycle Photo: 0.0474, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 4.3028\n",
      "Epoch [66/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2119, D_X Fake: 0.0384, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0501, D_Y Fake: 0.1303, D_Y Total: 0.0902\n",
      "Generator Losses:\n",
      "  G Adv: 0.4741, F Adv: 0.8651\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0557\n",
      "  Perceptual Photo: 0.1285, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.7682\n",
      "Epoch [66/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0802, D_X Fake: 0.1916, D_X Total: 0.1359\n",
      "  D_Y Real: 0.0965, D_Y Fake: 0.0435, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.8562, F Adv: 0.2857\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.2320\n",
      "Epoch [66/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0465, D_X Fake: 0.0871, D_X Total: 0.0668\n",
      "  D_Y Real: 0.1262, D_Y Fake: 0.0315, D_Y Total: 0.0789\n",
      "Generator Losses:\n",
      "  G Adv: 0.8299, F Adv: 0.5110\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1163, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.3541\n",
      "Epoch [66/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1374, D_X Fake: 0.1529, D_X Total: 0.1452\n",
      "  D_Y Real: 0.0508, D_Y Fake: 0.1090, D_Y Total: 0.0799\n",
      "Generator Losses:\n",
      "  G Adv: 0.8594, F Adv: 0.5024\n",
      "  Cycle Photo: 0.0583, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1535\n",
      "  Total G Loss: 3.8326\n",
      "Epoch [66/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2234, D_X Fake: 0.0384, D_X Total: 0.1309\n",
      "  D_Y Real: 0.0740, D_Y Fake: 0.0418, D_Y Total: 0.0579\n",
      "Generator Losses:\n",
      "  G Adv: 0.7625, F Adv: 0.7392\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.9097\n",
      "Epoch [66/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1154, D_X Fake: 0.0876, D_X Total: 0.1015\n",
      "  D_Y Real: 0.0641, D_Y Fake: 0.0914, D_Y Total: 0.0778\n",
      "Generator Losses:\n",
      "  G Adv: 0.5545, F Adv: 0.5905\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1199, Perceptual Monet: 0.1333\n",
      "  Total G Loss: 3.1615\n",
      "Epoch [66/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1672, D_X Fake: 0.0528, D_X Total: 0.1100\n",
      "  D_Y Real: 0.1234, D_Y Fake: 0.0603, D_Y Total: 0.0918\n",
      "Generator Losses:\n",
      "  G Adv: 0.6746, F Adv: 0.6166\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1537\n",
      "  Total G Loss: 3.4200\n",
      "Epoch [66/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0932, D_X Fake: 0.2201, D_X Total: 0.1566\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0911, D_Y Total: 0.0658\n",
      "Generator Losses:\n",
      "  G Adv: 0.6119, F Adv: 0.4057\n",
      "  Cycle Photo: 0.0640, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.8261\n",
      "Epoch [66/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1004, D_X Fake: 0.0904, D_X Total: 0.0954\n",
      "  D_Y Real: 0.1243, D_Y Fake: 0.0919, D_Y Total: 0.1081\n",
      "Generator Losses:\n",
      "  G Adv: 0.6694, F Adv: 0.5804\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1306\n",
      "  Total G Loss: 3.2553\n",
      "Epoch [66/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1791, D_X Fake: 0.0275, D_X Total: 0.1033\n",
      "  D_Y Real: 0.0431, D_Y Fake: 0.0823, D_Y Total: 0.0627\n",
      "Generator Losses:\n",
      "  G Adv: 0.8532, F Adv: 0.8159\n",
      "  Cycle Photo: 0.0558, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.2079, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 4.5769\n",
      "Epoch [66/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1112, D_X Fake: 0.3272, D_X Total: 0.2192\n",
      "  D_Y Real: 0.0789, D_Y Fake: 0.1243, D_Y Total: 0.1016\n",
      "Generator Losses:\n",
      "  G Adv: 0.5892, F Adv: 0.3345\n",
      "  Cycle Photo: 0.0414, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1955\n",
      "  Total G Loss: 3.4570\n",
      "Epoch [66/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1962, D_X Fake: 0.0466, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0714, D_Y Fake: 0.0641, D_Y Total: 0.0678\n",
      "Generator Losses:\n",
      "  G Adv: 0.7350, F Adv: 0.7665\n",
      "  Cycle Photo: 0.0554, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.9550\n",
      "Epoch [67/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0380, D_X Fake: 0.2016, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.1103, D_Y Total: 0.0788\n",
      "Generator Losses:\n",
      "  G Adv: 0.5550, F Adv: 0.4121\n",
      "  Cycle Photo: 0.0641, Cycle Monet: 0.0545\n",
      "  Perceptual Photo: 0.2088, Perceptual Monet: 0.1319\n",
      "  Total G Loss: 3.8572\n",
      "Epoch [67/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0905, D_X Fake: 0.1124, D_X Total: 0.1015\n",
      "  D_Y Real: 0.1210, D_Y Fake: 0.0665, D_Y Total: 0.0937\n",
      "Generator Losses:\n",
      "  G Adv: 0.6629, F Adv: 0.5866\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1727, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.7370\n",
      "Epoch [67/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2936, D_X Fake: 0.0317, D_X Total: 0.1627\n",
      "  D_Y Real: 0.1695, D_Y Fake: 0.0573, D_Y Total: 0.1134\n",
      "Generator Losses:\n",
      "  G Adv: 1.0178, F Adv: 1.0675\n",
      "  Cycle Photo: 0.0520, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 4.5809\n",
      "Epoch [67/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2155, D_X Fake: 0.0303, D_X Total: 0.1229\n",
      "  D_Y Real: 0.1197, D_Y Fake: 0.0620, D_Y Total: 0.0909\n",
      "Generator Losses:\n",
      "  G Adv: 0.6443, F Adv: 0.9689\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1777\n",
      "  Total G Loss: 4.1540\n",
      "Epoch [67/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0859, D_X Fake: 0.0955, D_X Total: 0.0907\n",
      "  D_Y Real: 0.0942, D_Y Fake: 0.0735, D_Y Total: 0.0839\n",
      "Generator Losses:\n",
      "  G Adv: 0.6044, F Adv: 0.6079\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1499, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.7054\n",
      "Epoch [67/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0437, D_X Fake: 0.1277, D_X Total: 0.0857\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0964, D_Y Total: 0.0690\n",
      "Generator Losses:\n",
      "  G Adv: 0.6501, F Adv: 0.4369\n",
      "  Cycle Photo: 0.0451, Cycle Monet: 0.0533\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.2206\n",
      "  Total G Loss: 4.0042\n",
      "Epoch [67/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1210, D_X Fake: 0.0694, D_X Total: 0.0952\n",
      "  D_Y Real: 0.0546, D_Y Fake: 0.1579, D_Y Total: 0.1063\n",
      "Generator Losses:\n",
      "  G Adv: 0.6990, F Adv: 0.5188\n",
      "  Cycle Photo: 0.0564, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1930, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.9918\n",
      "Epoch [67/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1230, D_X Fake: 0.1226, D_X Total: 0.1228\n",
      "  D_Y Real: 0.0761, D_Y Fake: 0.1390, D_Y Total: 0.1076\n",
      "Generator Losses:\n",
      "  G Adv: 0.5347, F Adv: 0.5251\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1671\n",
      "  Total G Loss: 3.2673\n",
      "Epoch [67/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2491, D_X Fake: 0.0534, D_X Total: 0.1512\n",
      "  D_Y Real: 0.0513, D_Y Fake: 0.2156, D_Y Total: 0.1335\n",
      "Generator Losses:\n",
      "  G Adv: 0.5429, F Adv: 0.8025\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1392, Perceptual Monet: 0.1567\n",
      "  Total G Loss: 3.7336\n",
      "Epoch [67/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0479, D_X Fake: 0.1720, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0348, D_Y Fake: 0.1193, D_Y Total: 0.0770\n",
      "Generator Losses:\n",
      "  G Adv: 0.4285, F Adv: 0.3059\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1863, Perceptual Monet: 0.1678\n",
      "  Total G Loss: 3.3396\n",
      "Epoch [67/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0698, D_X Fake: 0.1667, D_X Total: 0.1182\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0937, D_Y Total: 0.0565\n",
      "Generator Losses:\n",
      "  G Adv: 0.7160, F Adv: 0.3511\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1469, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.4448\n",
      "Epoch [67/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0788, D_X Fake: 0.0934, D_X Total: 0.0861\n",
      "  D_Y Real: 0.0597, D_Y Fake: 0.1380, D_Y Total: 0.0988\n",
      "Generator Losses:\n",
      "  G Adv: 0.5994, F Adv: 0.6676\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1118, Perceptual Monet: 0.1881\n",
      "  Total G Loss: 3.5660\n",
      "Epoch [67/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0481, D_X Fake: 0.1479, D_X Total: 0.0980\n",
      "  D_Y Real: 0.0647, D_Y Fake: 0.0405, D_Y Total: 0.0526\n",
      "Generator Losses:\n",
      "  G Adv: 0.6692, F Adv: 0.3900\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1602, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.3825\n",
      "Epoch [67/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4065, D_X Fake: 0.0320, D_X Total: 0.2193\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.0383, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.6662, F Adv: 0.7133\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.8101\n",
      "Epoch [67/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1441, D_X Fake: 0.0539, D_X Total: 0.0990\n",
      "  D_Y Real: 0.0721, D_Y Fake: 0.0583, D_Y Total: 0.0652\n",
      "Generator Losses:\n",
      "  G Adv: 0.8832, F Adv: 0.6850\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.1493\n",
      "  Total G Loss: 3.8835\n",
      "Epoch [67/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1044, D_X Fake: 0.0562, D_X Total: 0.0803\n",
      "  D_Y Real: 0.0469, D_Y Fake: 0.0849, D_Y Total: 0.0659\n",
      "Generator Losses:\n",
      "  G Adv: 0.6926, F Adv: 0.3733\n",
      "  Cycle Photo: 0.0415, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1279, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.4040\n",
      "Epoch [67/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1546, D_X Fake: 0.1875, D_X Total: 0.1711\n",
      "  D_Y Real: 0.0952, D_Y Fake: 0.0709, D_Y Total: 0.0830\n",
      "Generator Losses:\n",
      "  G Adv: 0.7496, F Adv: 0.5927\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1519, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 3.8291\n",
      "Epoch [67/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1211, D_X Fake: 0.2446, D_X Total: 0.1829\n",
      "  D_Y Real: 0.0824, D_Y Fake: 0.0910, D_Y Total: 0.0867\n",
      "Generator Losses:\n",
      "  G Adv: 0.7784, F Adv: 0.3345\n",
      "  Cycle Photo: 0.0839, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.2012, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 4.2112\n",
      "Epoch [67/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1390, D_X Fake: 0.0431, D_X Total: 0.0911\n",
      "  D_Y Real: 0.1411, D_Y Fake: 0.0424, D_Y Total: 0.0917\n",
      "Generator Losses:\n",
      "  G Adv: 0.9927, F Adv: 0.6618\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1900\n",
      "  Total G Loss: 4.1972\n",
      "Epoch [67/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0617, D_X Fake: 0.1812, D_X Total: 0.1214\n",
      "  D_Y Real: 0.1728, D_Y Fake: 0.0333, D_Y Total: 0.1030\n",
      "Generator Losses:\n",
      "  G Adv: 0.8564, F Adv: 0.3019\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1564, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.4349\n",
      "Epoch [67/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1271, D_X Fake: 0.0921, D_X Total: 0.1096\n",
      "  D_Y Real: 0.0770, D_Y Fake: 0.0694, D_Y Total: 0.0732\n",
      "Generator Losses:\n",
      "  G Adv: 0.6918, F Adv: 0.5700\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 3.5817\n",
      "Epoch [67/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1376, D_X Fake: 0.0974, D_X Total: 0.1175\n",
      "  D_Y Real: 0.0544, D_Y Fake: 0.0749, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.9604, F Adv: 0.5933\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.8543\n",
      "Epoch [67/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1741, D_X Fake: 0.1801, D_X Total: 0.1771\n",
      "  D_Y Real: 0.1709, D_Y Fake: 0.0557, D_Y Total: 0.1133\n",
      "Generator Losses:\n",
      "  G Adv: 0.8059, F Adv: 0.3812\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1477\n",
      "  Total G Loss: 3.2913\n",
      "Epoch [67/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1497, D_X Fake: 0.0878, D_X Total: 0.1187\n",
      "  D_Y Real: 0.2173, D_Y Fake: 0.0972, D_Y Total: 0.1573\n",
      "Generator Losses:\n",
      "  G Adv: 0.9473, F Adv: 0.4591\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.6687\n",
      "Epoch [68/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2593, D_X Fake: 0.0371, D_X Total: 0.1482\n",
      "  D_Y Real: 0.0748, D_Y Fake: 0.1181, D_Y Total: 0.0964\n",
      "Generator Losses:\n",
      "  G Adv: 0.7261, F Adv: 0.8932\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1870, Perceptual Monet: 0.1537\n",
      "  Total G Loss: 4.1670\n",
      "Epoch [68/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0283, D_X Fake: 0.0680, D_X Total: 0.0482\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.1271, D_Y Total: 0.0807\n",
      "Generator Losses:\n",
      "  G Adv: 0.6026, F Adv: 0.5514\n",
      "  Cycle Photo: 0.0634, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1186, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.5109\n",
      "Epoch [68/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.1301, D_X Total: 0.1107\n",
      "  D_Y Real: 0.0744, D_Y Fake: 0.2611, D_Y Total: 0.1678\n",
      "Generator Losses:\n",
      "  G Adv: 0.6864, F Adv: 0.6463\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.1635, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.9007\n",
      "Epoch [68/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0360, D_X Fake: 0.2224, D_X Total: 0.1292\n",
      "  D_Y Real: 0.0722, D_Y Fake: 0.1483, D_Y Total: 0.1103\n",
      "Generator Losses:\n",
      "  G Adv: 0.4515, F Adv: 0.3828\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1388\n",
      "  Total G Loss: 2.8801\n",
      "Epoch [68/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0961, D_X Fake: 0.1103, D_X Total: 0.1032\n",
      "  D_Y Real: 0.2414, D_Y Fake: 0.0683, D_Y Total: 0.1548\n",
      "Generator Losses:\n",
      "  G Adv: 1.0901, F Adv: 0.5206\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1127, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 3.7603\n",
      "Epoch [68/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0357, D_X Fake: 0.0634, D_X Total: 0.0495\n",
      "  D_Y Real: 0.0479, D_Y Fake: 0.0325, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.7294, F Adv: 0.5482\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.7032\n",
      "Epoch [68/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0875, D_X Fake: 0.1405, D_X Total: 0.1140\n",
      "  D_Y Real: 0.0723, D_Y Fake: 0.0638, D_Y Total: 0.0680\n",
      "Generator Losses:\n",
      "  G Adv: 0.7257, F Adv: 0.4608\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 3.5057\n",
      "Epoch [68/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0611, D_X Fake: 0.1603, D_X Total: 0.1107\n",
      "  D_Y Real: 0.0423, D_Y Fake: 0.0385, D_Y Total: 0.0404\n",
      "Generator Losses:\n",
      "  G Adv: 0.6609, F Adv: 0.4293\n",
      "  Cycle Photo: 0.0549, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.4387\n",
      "Epoch [68/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1733, D_X Fake: 0.1688, D_X Total: 0.1710\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.1425, D_Y Total: 0.0976\n",
      "Generator Losses:\n",
      "  G Adv: 0.3821, F Adv: 0.3135\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.1156\n",
      "Epoch [68/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0632, D_X Fake: 0.1535, D_X Total: 0.1084\n",
      "  D_Y Real: 0.2059, D_Y Fake: 0.0423, D_Y Total: 0.1241\n",
      "Generator Losses:\n",
      "  G Adv: 1.0399, F Adv: 0.3499\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1259, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.5147\n",
      "Epoch [68/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0443, D_X Fake: 0.1690, D_X Total: 0.1066\n",
      "  D_Y Real: 0.0910, D_Y Fake: 0.0696, D_Y Total: 0.0803\n",
      "Generator Losses:\n",
      "  G Adv: 0.7936, F Adv: 0.4442\n",
      "  Cycle Photo: 0.0613, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1573, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.8292\n",
      "Epoch [68/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2576, D_X Fake: 0.0874, D_X Total: 0.1725\n",
      "  D_Y Real: 0.1693, D_Y Fake: 0.0493, D_Y Total: 0.1093\n",
      "Generator Losses:\n",
      "  G Adv: 0.8886, F Adv: 0.5116\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1945, Perceptual Monet: 0.1425\n",
      "  Total G Loss: 3.9087\n",
      "Epoch [68/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0546, D_X Fake: 0.0405, D_X Total: 0.0475\n",
      "  D_Y Real: 0.0658, D_Y Fake: 0.0690, D_Y Total: 0.0674\n",
      "Generator Losses:\n",
      "  G Adv: 0.6993, F Adv: 0.8932\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.8786\n",
      "Epoch [68/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0814, D_X Fake: 0.1493, D_X Total: 0.1154\n",
      "  D_Y Real: 0.1446, D_Y Fake: 0.0713, D_Y Total: 0.1080\n",
      "Generator Losses:\n",
      "  G Adv: 0.8182, F Adv: 0.3927\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.6684\n",
      "Epoch [68/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0691, D_X Fake: 0.1497, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0677, D_Y Fake: 0.0914, D_Y Total: 0.0796\n",
      "Generator Losses:\n",
      "  G Adv: 0.5406, F Adv: 0.3285\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0428\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.1905\n",
      "Epoch [68/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0723, D_X Fake: 0.0516, D_X Total: 0.0619\n",
      "  D_Y Real: 0.1001, D_Y Fake: 0.1080, D_Y Total: 0.1040\n",
      "Generator Losses:\n",
      "  G Adv: 0.8720, F Adv: 0.7017\n",
      "  Cycle Photo: 0.0544, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1996, Perceptual Monet: 0.1864\n",
      "  Total G Loss: 4.4530\n",
      "Epoch [68/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1301, D_X Fake: 0.0571, D_X Total: 0.0936\n",
      "  D_Y Real: 0.0367, D_Y Fake: 0.0927, D_Y Total: 0.0647\n",
      "Generator Losses:\n",
      "  G Adv: 0.3929, F Adv: 0.5526\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.1867\n",
      "Epoch [68/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0573, D_X Fake: 0.1955, D_X Total: 0.1264\n",
      "  D_Y Real: 0.0568, D_Y Fake: 0.0673, D_Y Total: 0.0621\n",
      "Generator Losses:\n",
      "  G Adv: 0.6690, F Adv: 0.2879\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0468\n",
      "  Perceptual Photo: 0.1228, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.3162\n",
      "Epoch [68/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0501, D_X Fake: 0.2248, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0714, D_Y Fake: 0.1018, D_Y Total: 0.0866\n",
      "Generator Losses:\n",
      "  G Adv: 0.6086, F Adv: 0.3597\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.4776\n",
      "Epoch [68/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1937, D_X Fake: 0.0598, D_X Total: 0.1268\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.1093, D_Y Total: 0.0738\n",
      "Generator Losses:\n",
      "  G Adv: 0.5689, F Adv: 0.7438\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1404\n",
      "  Total G Loss: 3.3503\n",
      "Epoch [68/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0611, D_X Fake: 0.1132, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0891, D_Y Total: 0.0643\n",
      "Generator Losses:\n",
      "  G Adv: 0.5809, F Adv: 0.4576\n",
      "  Cycle Photo: 0.0536, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.5119\n",
      "Epoch [68/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0895, D_X Fake: 0.0727, D_X Total: 0.0811\n",
      "  D_Y Real: 0.0766, D_Y Fake: 0.0722, D_Y Total: 0.0744\n",
      "Generator Losses:\n",
      "  G Adv: 0.7689, F Adv: 0.7568\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.7970\n",
      "Epoch [68/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.1336, D_X Total: 0.1011\n",
      "  D_Y Real: 0.0658, D_Y Fake: 0.0733, D_Y Total: 0.0695\n",
      "Generator Losses:\n",
      "  G Adv: 0.7195, F Adv: 0.5377\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.6832\n",
      "Epoch [68/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0933, D_X Fake: 0.0855, D_X Total: 0.0894\n",
      "  D_Y Real: 0.0402, D_Y Fake: 0.1313, D_Y Total: 0.0857\n",
      "Generator Losses:\n",
      "  G Adv: 0.5103, F Adv: 0.4889\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.0997\n",
      "Epoch [69/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0849, D_X Fake: 0.2574, D_X Total: 0.1711\n",
      "  D_Y Real: 0.0599, D_Y Fake: 0.0413, D_Y Total: 0.0506\n",
      "Generator Losses:\n",
      "  G Adv: 0.8812, F Adv: 0.2920\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 3.6782\n",
      "Epoch [69/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1265, D_X Fake: 0.1930, D_X Total: 0.1597\n",
      "  D_Y Real: 0.0957, D_Y Fake: 0.0728, D_Y Total: 0.0843\n",
      "Generator Losses:\n",
      "  G Adv: 0.8636, F Adv: 0.3971\n",
      "  Cycle Photo: 0.0502, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1965, Perceptual Monet: 0.1816\n",
      "  Total G Loss: 4.0617\n",
      "Epoch [69/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0679, D_X Fake: 0.2123, D_X Total: 0.1401\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.1045, D_Y Total: 0.0748\n",
      "Generator Losses:\n",
      "  G Adv: 0.4367, F Adv: 0.2632\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 2.9656\n",
      "Epoch [69/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0932, D_X Fake: 0.1140, D_X Total: 0.1036\n",
      "  D_Y Real: 0.0355, D_Y Fake: 0.0813, D_Y Total: 0.0584\n",
      "Generator Losses:\n",
      "  G Adv: 0.5691, F Adv: 0.2851\n",
      "  Cycle Photo: 0.0389, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 2.9801\n",
      "Epoch [69/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0773, D_X Fake: 0.0587, D_X Total: 0.0680\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.0818, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 1.0185, F Adv: 0.8522\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1380, Perceptual Monet: 0.1871\n",
      "  Total G Loss: 4.3192\n",
      "Epoch [69/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1418, D_X Fake: 0.1314, D_X Total: 0.1366\n",
      "  D_Y Real: 0.0619, D_Y Fake: 0.0567, D_Y Total: 0.0593\n",
      "Generator Losses:\n",
      "  G Adv: 0.8078, F Adv: 0.4739\n",
      "  Cycle Photo: 0.0560, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1790, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 4.0282\n",
      "Epoch [69/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0358, D_X Fake: 0.2812, D_X Total: 0.1585\n",
      "  D_Y Real: 0.0638, D_Y Fake: 0.0769, D_Y Total: 0.0704\n",
      "Generator Losses:\n",
      "  G Adv: 0.7238, F Adv: 0.2563\n",
      "  Cycle Photo: 0.0533, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.5000\n",
      "Epoch [69/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4219, D_X Fake: 0.0337, D_X Total: 0.2278\n",
      "  D_Y Real: 0.0357, D_Y Fake: 0.1106, D_Y Total: 0.0731\n",
      "Generator Losses:\n",
      "  G Adv: 0.5243, F Adv: 1.0845\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1828, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 4.1681\n",
      "Epoch [69/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0521, D_X Fake: 0.3311, D_X Total: 0.1916\n",
      "  D_Y Real: 0.0471, D_Y Fake: 0.1485, D_Y Total: 0.0978\n",
      "Generator Losses:\n",
      "  G Adv: 0.7069, F Adv: 0.3054\n",
      "  Cycle Photo: 0.0543, Cycle Monet: 0.0571\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1884\n",
      "  Total G Loss: 3.9055\n",
      "Epoch [69/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1365, D_X Fake: 0.0846, D_X Total: 0.1106\n",
      "  D_Y Real: 0.1422, D_Y Fake: 0.0577, D_Y Total: 0.0999\n",
      "Generator Losses:\n",
      "  G Adv: 0.8315, F Adv: 0.6263\n",
      "  Cycle Photo: 0.0589, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.9824\n",
      "Epoch [69/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1074, D_X Fake: 0.0688, D_X Total: 0.0881\n",
      "  D_Y Real: 0.0787, D_Y Fake: 0.0825, D_Y Total: 0.0806\n",
      "Generator Losses:\n",
      "  G Adv: 0.8187, F Adv: 0.9207\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 4.2577\n",
      "Epoch [69/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1682, D_X Fake: 0.0575, D_X Total: 0.1129\n",
      "  D_Y Real: 0.0921, D_Y Fake: 0.0583, D_Y Total: 0.0752\n",
      "Generator Losses:\n",
      "  G Adv: 0.9772, F Adv: 0.6402\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1868, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 4.0454\n",
      "Epoch [69/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0900, D_X Fake: 0.0848, D_X Total: 0.0874\n",
      "  D_Y Real: 0.1319, D_Y Fake: 0.0423, D_Y Total: 0.0871\n",
      "Generator Losses:\n",
      "  G Adv: 0.8324, F Adv: 0.4575\n",
      "  Cycle Photo: 0.0422, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1456\n",
      "  Total G Loss: 3.5176\n",
      "Epoch [69/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0429, D_X Fake: 0.3568, D_X Total: 0.1998\n",
      "  D_Y Real: 0.0504, D_Y Fake: 0.1294, D_Y Total: 0.0899\n",
      "Generator Losses:\n",
      "  G Adv: 0.5532, F Adv: 0.2750\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1571, Perceptual Monet: 0.1864\n",
      "  Total G Loss: 3.3907\n",
      "Epoch [69/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0877, D_X Fake: 0.0809, D_X Total: 0.0843\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.0766, D_Y Total: 0.0554\n",
      "Generator Losses:\n",
      "  G Adv: 0.6992, F Adv: 0.4389\n",
      "  Cycle Photo: 0.0810, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1752, Perceptual Monet: 0.1459\n",
      "  Total G Loss: 3.8591\n",
      "Epoch [69/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0847, D_X Fake: 0.1775, D_X Total: 0.1311\n",
      "  D_Y Real: 0.0935, D_Y Fake: 0.0418, D_Y Total: 0.0676\n",
      "Generator Losses:\n",
      "  G Adv: 0.8354, F Adv: 0.3358\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1456\n",
      "  Total G Loss: 3.3710\n",
      "Epoch [69/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1619, D_X Fake: 0.0669, D_X Total: 0.1144\n",
      "  D_Y Real: 0.1160, D_Y Fake: 0.1079, D_Y Total: 0.1120\n",
      "Generator Losses:\n",
      "  G Adv: 1.1333, F Adv: 0.6781\n",
      "  Cycle Photo: 0.0484, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1585\n",
      "  Total G Loss: 4.2026\n",
      "Epoch [69/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1424, D_X Fake: 0.0731, D_X Total: 0.1078\n",
      "  D_Y Real: 0.0529, D_Y Fake: 0.2074, D_Y Total: 0.1302\n",
      "Generator Losses:\n",
      "  G Adv: 0.3568, F Adv: 0.5504\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.2046\n",
      "  Total G Loss: 3.5144\n",
      "Epoch [69/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0794, D_X Fake: 0.0875, D_X Total: 0.0835\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.1606, D_Y Total: 0.1061\n",
      "Generator Losses:\n",
      "  G Adv: 0.5777, F Adv: 0.9310\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.9426\n",
      "Epoch [69/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.2130, D_X Total: 0.1440\n",
      "  D_Y Real: 0.0698, D_Y Fake: 0.0877, D_Y Total: 0.0788\n",
      "Generator Losses:\n",
      "  G Adv: 0.5963, F Adv: 0.3212\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.2239\n",
      "Epoch [69/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0889, D_X Fake: 0.1304, D_X Total: 0.1097\n",
      "  D_Y Real: 0.0758, D_Y Fake: 0.0773, D_Y Total: 0.0765\n",
      "Generator Losses:\n",
      "  G Adv: 0.8510, F Adv: 0.3665\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1496, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.4575\n",
      "Epoch [69/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0510, D_X Fake: 0.1898, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.1252, D_Y Total: 0.0787\n",
      "Generator Losses:\n",
      "  G Adv: 0.5813, F Adv: 0.3785\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1395\n",
      "  Total G Loss: 3.1259\n",
      "Epoch [69/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0819, D_X Fake: 0.0331, D_X Total: 0.0575\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0497, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.8757, F Adv: 0.6501\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.2183, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 4.3251\n",
      "Epoch [69/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0369, D_X Fake: 0.2626, D_X Total: 0.1498\n",
      "  D_Y Real: 0.1528, D_Y Fake: 0.0470, D_Y Total: 0.0999\n",
      "Generator Losses:\n",
      "  G Adv: 0.8786, F Adv: 0.3147\n",
      "  Cycle Photo: 0.0455, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.4358\n",
      "Epoch [70/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0643, D_X Fake: 0.1060, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0601, D_Y Fake: 0.0684, D_Y Total: 0.0643\n",
      "Generator Losses:\n",
      "  G Adv: 0.5574, F Adv: 0.2639\n",
      "  Cycle Photo: 0.0698, Cycle Monet: 0.0486\n",
      "  Perceptual Photo: 0.1322, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.4732\n",
      "Epoch [70/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1849, D_X Fake: 0.1949, D_X Total: 0.1899\n",
      "  D_Y Real: 0.0749, D_Y Fake: 0.1601, D_Y Total: 0.1175\n",
      "Generator Losses:\n",
      "  G Adv: 0.3740, F Adv: 0.4369\n",
      "  Cycle Photo: 0.0611, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.4636\n",
      "Epoch [70/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1521, D_X Fake: 0.0439, D_X Total: 0.0980\n",
      "  D_Y Real: 0.1827, D_Y Fake: 0.0370, D_Y Total: 0.1099\n",
      "Generator Losses:\n",
      "  G Adv: 0.9285, F Adv: 0.7838\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.9163\n",
      "Epoch [70/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1087, D_X Fake: 0.1533, D_X Total: 0.1310\n",
      "  D_Y Real: 0.1103, D_Y Fake: 0.0962, D_Y Total: 0.1033\n",
      "Generator Losses:\n",
      "  G Adv: 0.6602, F Adv: 0.4805\n",
      "  Cycle Photo: 0.0587, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.2151, Perceptual Monet: 0.1508\n",
      "  Total G Loss: 3.9625\n",
      "Epoch [70/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0450, D_X Fake: 0.0716, D_X Total: 0.0583\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.0499, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.8281, F Adv: 0.5580\n",
      "  Cycle Photo: 0.0384, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1563\n",
      "  Total G Loss: 3.5846\n",
      "Epoch [70/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0979, D_X Fake: 0.1408, D_X Total: 0.1193\n",
      "  D_Y Real: 0.1978, D_Y Fake: 0.0634, D_Y Total: 0.1306\n",
      "Generator Losses:\n",
      "  G Adv: 0.6639, F Adv: 0.4084\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.6545\n",
      "Epoch [70/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0412, D_X Fake: 0.1572, D_X Total: 0.0992\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.0728, D_Y Total: 0.0565\n",
      "Generator Losses:\n",
      "  G Adv: 0.7187, F Adv: 0.5784\n",
      "  Cycle Photo: 0.0631, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.8334\n",
      "Epoch [70/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2429, D_X Fake: 0.3292, D_X Total: 0.2860\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0531, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.7268, F Adv: 0.2903\n",
      "  Cycle Photo: 0.0702, Cycle Monet: 0.0595\n",
      "  Perceptual Photo: 0.1836, Perceptual Monet: 0.2463\n",
      "  Total G Loss: 4.4639\n",
      "Epoch [70/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2272, D_X Fake: 0.2937, D_X Total: 0.2605\n",
      "  D_Y Real: 0.0411, D_Y Fake: 0.1097, D_Y Total: 0.0754\n",
      "Generator Losses:\n",
      "  G Adv: 0.5556, F Adv: 0.2843\n",
      "  Cycle Photo: 0.0436, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1559\n",
      "  Total G Loss: 3.2323\n",
      "Epoch [70/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2329, D_X Fake: 0.1843, D_X Total: 0.2086\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.1514, D_Y Total: 0.0956\n",
      "Generator Losses:\n",
      "  G Adv: 0.4358, F Adv: 0.3519\n",
      "  Cycle Photo: 0.0518, Cycle Monet: 0.0414\n",
      "  Perceptual Photo: 0.1359, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.2694\n",
      "Epoch [70/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1932, D_X Fake: 0.2471, D_X Total: 0.2201\n",
      "  D_Y Real: 0.0682, D_Y Fake: 0.0890, D_Y Total: 0.0786\n",
      "Generator Losses:\n",
      "  G Adv: 0.7351, F Adv: 0.3197\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1518, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.3083\n",
      "Epoch [70/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3283, D_X Fake: 0.2676, D_X Total: 0.2979\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.1189, D_Y Total: 0.0748\n",
      "Generator Losses:\n",
      "  G Adv: 0.4242, F Adv: 0.2280\n",
      "  Cycle Photo: 0.0452, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1686, Perceptual Monet: 0.1332\n",
      "  Total G Loss: 2.9807\n",
      "Epoch [70/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3789, D_X Fake: 0.1635, D_X Total: 0.2712\n",
      "  D_Y Real: 0.0539, D_Y Fake: 0.0794, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.5573, F Adv: 0.4081\n",
      "  Cycle Photo: 0.0496, Cycle Monet: 0.0428\n",
      "  Perceptual Photo: 0.2095, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.7738\n",
      "Epoch [70/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3514, D_X Fake: 0.2166, D_X Total: 0.2840\n",
      "  D_Y Real: 0.1798, D_Y Fake: 0.0859, D_Y Total: 0.1329\n",
      "Generator Losses:\n",
      "  G Adv: 0.9321, F Adv: 0.2932\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1431\n",
      "  Total G Loss: 3.5387\n",
      "Epoch [70/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2106, D_X Fake: 0.2721, D_X Total: 0.2414\n",
      "  D_Y Real: 0.1047, D_Y Fake: 0.0385, D_Y Total: 0.0716\n",
      "Generator Losses:\n",
      "  G Adv: 0.9926, F Adv: 0.2701\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1902, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.8238\n",
      "Epoch [70/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2646, D_X Fake: 0.2509, D_X Total: 0.2577\n",
      "  D_Y Real: 0.0993, D_Y Fake: 0.0542, D_Y Total: 0.0767\n",
      "Generator Losses:\n",
      "  G Adv: 0.8147, F Adv: 0.3058\n",
      "  Cycle Photo: 0.0481, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1136\n",
      "  Total G Loss: 3.1822\n",
      "Epoch [70/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2657, D_X Fake: 0.2289, D_X Total: 0.2473\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.1867, D_Y Total: 0.1089\n",
      "Generator Losses:\n",
      "  G Adv: 0.4526, F Adv: 0.3426\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1842, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.5147\n",
      "Epoch [70/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2876, D_X Fake: 0.2432, D_X Total: 0.2654\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0463, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.8641, F Adv: 0.3034\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1802, Perceptual Monet: 0.1237\n",
      "  Total G Loss: 3.4753\n",
      "Epoch [70/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2555, D_X Fake: 0.2008, D_X Total: 0.2281\n",
      "  D_Y Real: 0.0757, D_Y Fake: 0.0585, D_Y Total: 0.0671\n",
      "Generator Losses:\n",
      "  G Adv: 0.8982, F Adv: 0.3849\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1156, Perceptual Monet: 0.1395\n",
      "  Total G Loss: 3.4113\n",
      "Epoch [70/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2598, D_X Fake: 0.2320, D_X Total: 0.2459\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.0482, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.6950, F Adv: 0.2589\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1655, Perceptual Monet: 0.1505\n",
      "  Total G Loss: 3.2735\n",
      "Epoch [70/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2142, D_X Fake: 0.1885, D_X Total: 0.2013\n",
      "  D_Y Real: 0.0665, D_Y Fake: 0.0361, D_Y Total: 0.0513\n",
      "Generator Losses:\n",
      "  G Adv: 0.8386, F Adv: 0.3629\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1225\n",
      "  Total G Loss: 3.1779\n",
      "Epoch [70/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2617, D_X Fake: 0.2259, D_X Total: 0.2438\n",
      "  D_Y Real: 0.0487, D_Y Fake: 0.0606, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.7558, F Adv: 0.3219\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1431, Perceptual Monet: 0.1104\n",
      "  Total G Loss: 3.0311\n",
      "Epoch [70/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2085, D_X Fake: 0.2498, D_X Total: 0.2292\n",
      "  D_Y Real: 0.0624, D_Y Fake: 0.0572, D_Y Total: 0.0598\n",
      "Generator Losses:\n",
      "  G Adv: 0.6172, F Adv: 0.2096\n",
      "  Cycle Photo: 0.0632, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1209\n",
      "  Total G Loss: 3.0634\n",
      "Epoch [70/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2597, D_X Fake: 0.1966, D_X Total: 0.2281\n",
      "  D_Y Real: 0.2674, D_Y Fake: 0.0509, D_Y Total: 0.1592\n",
      "Generator Losses:\n",
      "  G Adv: 0.8664, F Adv: 0.2380\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1654, Perceptual Monet: 0.1204\n",
      "  Total G Loss: 3.2798\n",
      "Epoch [71/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1707, D_X Fake: 0.5041, D_X Total: 0.3374\n",
      "  D_Y Real: 0.1058, D_Y Fake: 0.1204, D_Y Total: 0.1131\n",
      "Generator Losses:\n",
      "  G Adv: 0.6621, F Adv: 0.1116\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1433, Perceptual Monet: 0.1251\n",
      "  Total G Loss: 2.7733\n",
      "Epoch [71/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2779, D_X Fake: 0.2848, D_X Total: 0.2813\n",
      "  D_Y Real: 0.1030, D_Y Fake: 0.0721, D_Y Total: 0.0875\n",
      "Generator Losses:\n",
      "  G Adv: 0.6922, F Adv: 0.2770\n",
      "  Cycle Photo: 0.0376, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1144\n",
      "  Total G Loss: 3.0029\n",
      "Epoch [71/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2595, D_X Fake: 0.2169, D_X Total: 0.2382\n",
      "  D_Y Real: 0.0618, D_Y Fake: 0.0528, D_Y Total: 0.0573\n",
      "Generator Losses:\n",
      "  G Adv: 0.9065, F Adv: 0.2787\n",
      "  Cycle Photo: 0.0600, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1982, Perceptual Monet: 0.1187\n",
      "  Total G Loss: 3.6368\n",
      "Epoch [71/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4481, D_X Fake: 0.1609, D_X Total: 0.3045\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.1626, D_Y Total: 0.1071\n",
      "Generator Losses:\n",
      "  G Adv: 0.5164, F Adv: 0.4349\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1568, Perceptual Monet: 0.1349\n",
      "  Total G Loss: 3.1516\n",
      "Epoch [71/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2588, D_X Fake: 0.1823, D_X Total: 0.2205\n",
      "  D_Y Real: 0.0474, D_Y Fake: 0.1136, D_Y Total: 0.0805\n",
      "Generator Losses:\n",
      "  G Adv: 0.6575, F Adv: 0.2952\n",
      "  Cycle Photo: 0.0453, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1332\n",
      "  Total G Loss: 3.1952\n",
      "Epoch [71/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1515, D_X Fake: 0.3116, D_X Total: 0.2316\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.1277, D_Y Total: 0.0791\n",
      "Generator Losses:\n",
      "  G Adv: 0.7311, F Adv: 0.2211\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1170\n",
      "  Total G Loss: 3.0375\n",
      "Epoch [71/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2321, D_X Fake: 0.2307, D_X Total: 0.2314\n",
      "  D_Y Real: 0.0499, D_Y Fake: 0.0624, D_Y Total: 0.0561\n",
      "Generator Losses:\n",
      "  G Adv: 0.6304, F Adv: 0.2941\n",
      "  Cycle Photo: 0.0542, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1267\n",
      "  Total G Loss: 3.0914\n",
      "Epoch [71/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1992, D_X Fake: 0.2794, D_X Total: 0.2393\n",
      "  D_Y Real: 0.0918, D_Y Fake: 0.0433, D_Y Total: 0.0675\n",
      "Generator Losses:\n",
      "  G Adv: 0.9298, F Adv: 0.2445\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1315\n",
      "  Total G Loss: 3.1834\n",
      "Epoch [71/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3067, D_X Fake: 0.2004, D_X Total: 0.2536\n",
      "  D_Y Real: 0.0347, D_Y Fake: 0.1521, D_Y Total: 0.0934\n",
      "Generator Losses:\n",
      "  G Adv: 0.4581, F Adv: 0.2729\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1311\n",
      "  Total G Loss: 3.0381\n",
      "Epoch [71/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2904, D_X Fake: 0.1865, D_X Total: 0.2384\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.0576, D_Y Total: 0.0493\n",
      "Generator Losses:\n",
      "  G Adv: 0.6274, F Adv: 0.3564\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1105\n",
      "  Total G Loss: 2.8414\n",
      "Epoch [71/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1611, D_X Fake: 0.2830, D_X Total: 0.2221\n",
      "  D_Y Real: 0.0339, D_Y Fake: 0.0399, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.8595, F Adv: 0.2536\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1565, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.3851\n",
      "Epoch [71/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1830, D_X Fake: 0.2070, D_X Total: 0.1950\n",
      "  D_Y Real: 0.1837, D_Y Fake: 0.0482, D_Y Total: 0.1160\n",
      "Generator Losses:\n",
      "  G Adv: 1.2129, F Adv: 0.2822\n",
      "  Cycle Photo: 0.0533, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1852, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 4.0490\n",
      "Epoch [71/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1152, D_X Fake: 0.3414, D_X Total: 0.2283\n",
      "  D_Y Real: 0.0418, D_Y Fake: 0.0587, D_Y Total: 0.0503\n",
      "Generator Losses:\n",
      "  G Adv: 0.7021, F Adv: 0.1958\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1421\n",
      "  Total G Loss: 2.9798\n",
      "Epoch [71/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2156, D_X Fake: 0.2543, D_X Total: 0.2350\n",
      "  D_Y Real: 0.0562, D_Y Fake: 0.0922, D_Y Total: 0.0742\n",
      "Generator Losses:\n",
      "  G Adv: 0.7240, F Adv: 0.3375\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1222\n",
      "  Total G Loss: 3.1503\n",
      "Epoch [71/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1278, D_X Fake: 0.1434, D_X Total: 0.1356\n",
      "  D_Y Real: 0.1067, D_Y Fake: 0.0702, D_Y Total: 0.0885\n",
      "Generator Losses:\n",
      "  G Adv: 0.6418, F Adv: 0.3390\n",
      "  Cycle Photo: 0.0453, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.4322\n",
      "Epoch [71/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0839, D_X Fake: 0.1047, D_X Total: 0.0943\n",
      "  D_Y Real: 0.0553, D_Y Fake: 0.0568, D_Y Total: 0.0561\n",
      "Generator Losses:\n",
      "  G Adv: 0.8362, F Adv: 0.5573\n",
      "  Cycle Photo: 0.0599, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1095, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.6158\n",
      "Epoch [71/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0776, D_X Fake: 0.1353, D_X Total: 0.1064\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0305, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.7761, F Adv: 0.4435\n",
      "  Cycle Photo: 0.0613, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.7064\n",
      "Epoch [71/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2839, D_X Fake: 0.0862, D_X Total: 0.1851\n",
      "  D_Y Real: 0.1210, D_Y Fake: 0.0436, D_Y Total: 0.0823\n",
      "Generator Losses:\n",
      "  G Adv: 0.7704, F Adv: 0.6103\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0466\n",
      "  Perceptual Photo: 0.1580, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.9694\n",
      "Epoch [71/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1488, D_X Fake: 0.0621, D_X Total: 0.1054\n",
      "  D_Y Real: 0.0841, D_Y Fake: 0.0432, D_Y Total: 0.0637\n",
      "Generator Losses:\n",
      "  G Adv: 0.7462, F Adv: 0.5901\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1694, Perceptual Monet: 0.1712\n",
      "  Total G Loss: 4.0090\n",
      "Epoch [71/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.3442, D_X Total: 0.2170\n",
      "  D_Y Real: 0.0455, D_Y Fake: 0.0513, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.6049, F Adv: 0.2983\n",
      "  Cycle Photo: 0.0633, Cycle Monet: 0.0495\n",
      "  Perceptual Photo: 0.1869, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.8917\n",
      "Epoch [71/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1014, D_X Fake: 0.0586, D_X Total: 0.0800\n",
      "  D_Y Real: 0.1364, D_Y Fake: 0.1606, D_Y Total: 0.1485\n",
      "Generator Losses:\n",
      "  G Adv: 0.4384, F Adv: 0.6042\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1325\n",
      "  Total G Loss: 3.0142\n",
      "Epoch [71/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0478, D_X Fake: 0.2471, D_X Total: 0.1475\n",
      "  D_Y Real: 0.0639, D_Y Fake: 0.0326, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.7204, F Adv: 0.3240\n",
      "  Cycle Photo: 0.0438, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1752\n",
      "  Total G Loss: 3.4948\n",
      "Epoch [71/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0283, D_X Fake: 0.1903, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0826, D_Y Fake: 0.0479, D_Y Total: 0.0652\n",
      "Generator Losses:\n",
      "  G Adv: 0.5949, F Adv: 0.2959\n",
      "  Cycle Photo: 0.0814, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1892, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.8325\n",
      "Epoch [71/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1854, D_X Fake: 0.0460, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0772, D_Y Total: 0.0544\n",
      "Generator Losses:\n",
      "  G Adv: 0.6115, F Adv: 0.5630\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1622, Perceptual Monet: 0.1552\n",
      "  Total G Loss: 3.6272\n",
      "Epoch [72/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0352, D_X Fake: 0.2478, D_X Total: 0.1415\n",
      "  D_Y Real: 0.0729, D_Y Fake: 0.0828, D_Y Total: 0.0778\n",
      "Generator Losses:\n",
      "  G Adv: 0.5105, F Adv: 0.3438\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1302, Perceptual Monet: 0.1493\n",
      "  Total G Loss: 3.0053\n",
      "Epoch [72/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0263, D_X Fake: 0.0569, D_X Total: 0.0416\n",
      "  D_Y Real: 0.0879, D_Y Fake: 0.0634, D_Y Total: 0.0757\n",
      "Generator Losses:\n",
      "  G Adv: 0.9100, F Adv: 0.4416\n",
      "  Cycle Photo: 0.0570, Cycle Monet: 0.0495\n",
      "  Perceptual Photo: 0.1744, Perceptual Monet: 0.1980\n",
      "  Total G Loss: 4.2786\n",
      "Epoch [72/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0947, D_X Fake: 0.2008, D_X Total: 0.1478\n",
      "  D_Y Real: 0.1693, D_Y Fake: 0.1312, D_Y Total: 0.1502\n",
      "Generator Losses:\n",
      "  G Adv: 0.5868, F Adv: 0.3641\n",
      "  Cycle Photo: 0.0587, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1435\n",
      "  Total G Loss: 3.3000\n",
      "Epoch [72/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2171, D_X Fake: 0.0417, D_X Total: 0.1294\n",
      "  D_Y Real: 0.1779, D_Y Fake: 0.0404, D_Y Total: 0.1092\n",
      "Generator Losses:\n",
      "  G Adv: 0.9753, F Adv: 0.6837\n",
      "  Cycle Photo: 0.0450, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1687, Perceptual Monet: 0.2068\n",
      "  Total G Loss: 4.4735\n",
      "Epoch [72/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1106, D_X Fake: 0.2200, D_X Total: 0.1653\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.1107, D_Y Total: 0.0751\n",
      "Generator Losses:\n",
      "  G Adv: 0.8731, F Adv: 0.3940\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1240, Perceptual Monet: 0.1553\n",
      "  Total G Loss: 3.3630\n",
      "Epoch [72/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1511, D_X Fake: 0.0585, D_X Total: 0.1048\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.1738, D_Y Total: 0.1057\n",
      "Generator Losses:\n",
      "  G Adv: 0.4383, F Adv: 0.9176\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 3.7328\n",
      "Epoch [72/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0646, D_X Fake: 0.2195, D_X Total: 0.1421\n",
      "  D_Y Real: 0.0559, D_Y Fake: 0.0499, D_Y Total: 0.0529\n",
      "Generator Losses:\n",
      "  G Adv: 0.6673, F Adv: 0.4290\n",
      "  Cycle Photo: 0.0595, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.6787\n",
      "Epoch [72/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1456, D_X Fake: 0.0476, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.0835, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.5238, F Adv: 0.7142\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.6506\n",
      "Epoch [72/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0473, D_X Fake: 0.1897, D_X Total: 0.1185\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0551, D_Y Total: 0.0494\n",
      "Generator Losses:\n",
      "  G Adv: 0.7774, F Adv: 0.3811\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1452\n",
      "  Total G Loss: 3.1076\n",
      "Epoch [72/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0395, D_X Fake: 0.1297, D_X Total: 0.0846\n",
      "  D_Y Real: 0.1188, D_Y Fake: 0.0828, D_Y Total: 0.1008\n",
      "Generator Losses:\n",
      "  G Adv: 0.6123, F Adv: 0.5960\n",
      "  Cycle Photo: 0.0545, Cycle Monet: 0.0547\n",
      "  Perceptual Photo: 0.1195, Perceptual Monet: 0.2113\n",
      "  Total G Loss: 3.9540\n",
      "Epoch [72/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0402, D_X Fake: 0.4439, D_X Total: 0.2420\n",
      "  D_Y Real: 0.0983, D_Y Fake: 0.0290, D_Y Total: 0.0636\n",
      "Generator Losses:\n",
      "  G Adv: 1.0167, F Adv: 0.2300\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.5357\n",
      "Epoch [72/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0788, D_X Fake: 0.0880, D_X Total: 0.0834\n",
      "  D_Y Real: 0.1320, D_Y Fake: 0.0393, D_Y Total: 0.0856\n",
      "Generator Losses:\n",
      "  G Adv: 0.9169, F Adv: 0.5419\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.9265\n",
      "Epoch [72/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1440, D_X Fake: 0.1613, D_X Total: 0.1526\n",
      "  D_Y Real: 0.0641, D_Y Fake: 0.1000, D_Y Total: 0.0820\n",
      "Generator Losses:\n",
      "  G Adv: 0.5584, F Adv: 0.5139\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1538\n",
      "  Total G Loss: 3.3207\n",
      "Epoch [72/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0820, D_X Fake: 0.1078, D_X Total: 0.0949\n",
      "  D_Y Real: 0.0510, D_Y Fake: 0.0647, D_Y Total: 0.0579\n",
      "Generator Losses:\n",
      "  G Adv: 0.7013, F Adv: 0.5935\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.5103\n",
      "Epoch [72/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0463, D_X Fake: 0.1322, D_X Total: 0.0893\n",
      "  D_Y Real: 0.0563, D_Y Fake: 0.0639, D_Y Total: 0.0601\n",
      "Generator Losses:\n",
      "  G Adv: 0.8614, F Adv: 0.4253\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1293, Perceptual Monet: 0.1377\n",
      "  Total G Loss: 3.3348\n",
      "Epoch [72/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1186, D_X Fake: 0.0732, D_X Total: 0.0959\n",
      "  D_Y Real: 0.0735, D_Y Fake: 0.1397, D_Y Total: 0.1066\n",
      "Generator Losses:\n",
      "  G Adv: 0.4306, F Adv: 0.6884\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0678\n",
      "  Perceptual Photo: 0.2016, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 4.2459\n",
      "Epoch [72/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0695, D_X Fake: 0.0989, D_X Total: 0.0842\n",
      "  D_Y Real: 0.0992, D_Y Fake: 0.1360, D_Y Total: 0.1176\n",
      "Generator Losses:\n",
      "  G Adv: 0.7248, F Adv: 0.4752\n",
      "  Cycle Photo: 0.0777, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1998, Perceptual Monet: 0.1396\n",
      "  Total G Loss: 4.0383\n",
      "Epoch [72/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3366, D_X Fake: 0.0501, D_X Total: 0.1933\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.1252, D_Y Total: 0.0781\n",
      "Generator Losses:\n",
      "  G Adv: 0.6639, F Adv: 0.8208\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1468, Perceptual Monet: 0.1244\n",
      "  Total G Loss: 3.5679\n",
      "Epoch [72/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1534, D_X Fake: 0.0490, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0860, D_Y Fake: 0.1057, D_Y Total: 0.0958\n",
      "Generator Losses:\n",
      "  G Adv: 0.6705, F Adv: 0.8269\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1608, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.9138\n",
      "Epoch [72/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0354, D_X Fake: 0.1380, D_X Total: 0.0867\n",
      "  D_Y Real: 0.1706, D_Y Fake: 0.0457, D_Y Total: 0.1082\n",
      "Generator Losses:\n",
      "  G Adv: 1.0923, F Adv: 0.2367\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1408, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 3.8478\n",
      "Epoch [72/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1204, D_X Fake: 0.2256, D_X Total: 0.1730\n",
      "  D_Y Real: 0.0864, D_Y Fake: 0.0530, D_Y Total: 0.0697\n",
      "Generator Losses:\n",
      "  G Adv: 0.8348, F Adv: 0.6472\n",
      "  Cycle Photo: 0.0729, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1775, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 4.2843\n",
      "Epoch [72/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0445, D_X Fake: 0.1174, D_X Total: 0.0809\n",
      "  D_Y Real: 0.0898, D_Y Fake: 0.0772, D_Y Total: 0.0835\n",
      "Generator Losses:\n",
      "  G Adv: 0.7965, F Adv: 0.4407\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.5040\n",
      "Epoch [72/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1518, D_X Fake: 0.1431, D_X Total: 0.1474\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.1268, D_Y Total: 0.0955\n",
      "Generator Losses:\n",
      "  G Adv: 0.6193, F Adv: 0.3584\n",
      "  Cycle Photo: 0.0521, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1881, Perceptual Monet: 0.1602\n",
      "  Total G Loss: 3.6066\n",
      "Epoch [72/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0498, D_X Fake: 0.1118, D_X Total: 0.0808\n",
      "  D_Y Real: 0.0443, D_Y Fake: 0.0941, D_Y Total: 0.0692\n",
      "Generator Losses:\n",
      "  G Adv: 0.8345, F Adv: 0.3978\n",
      "  Cycle Photo: 0.0643, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1945, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.9295\n",
      "Epoch [73/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0571, D_X Fake: 0.2236, D_X Total: 0.1404\n",
      "  D_Y Real: 0.0957, D_Y Fake: 0.0665, D_Y Total: 0.0811\n",
      "Generator Losses:\n",
      "  G Adv: 0.8158, F Adv: 0.2203\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.2825\n",
      "Epoch [73/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1226, D_X Fake: 0.1342, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0575, D_Y Fake: 0.1061, D_Y Total: 0.0818\n",
      "Generator Losses:\n",
      "  G Adv: 0.4770, F Adv: 0.4705\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 3.4070\n",
      "Epoch [73/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0465, D_X Fake: 0.1745, D_X Total: 0.1105\n",
      "  D_Y Real: 0.1167, D_Y Fake: 0.0608, D_Y Total: 0.0887\n",
      "Generator Losses:\n",
      "  G Adv: 0.7192, F Adv: 0.2382\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1844\n",
      "  Total G Loss: 3.2563\n",
      "Epoch [73/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0801, D_X Fake: 0.1415, D_X Total: 0.1108\n",
      "  D_Y Real: 0.0499, D_Y Fake: 0.1471, D_Y Total: 0.0985\n",
      "Generator Losses:\n",
      "  G Adv: 0.6302, F Adv: 0.4234\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.3022\n",
      "Epoch [73/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1106, D_X Fake: 0.0813, D_X Total: 0.0959\n",
      "  D_Y Real: 0.0544, D_Y Fake: 0.1000, D_Y Total: 0.0772\n",
      "Generator Losses:\n",
      "  G Adv: 0.6434, F Adv: 0.5607\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.1396\n",
      "  Total G Loss: 3.3269\n",
      "Epoch [73/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1443, D_X Fake: 0.0851, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0849, D_Y Fake: 0.0664, D_Y Total: 0.0757\n",
      "Generator Losses:\n",
      "  G Adv: 0.9510, F Adv: 0.3879\n",
      "  Cycle Photo: 0.0513, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1125, Perceptual Monet: 0.1264\n",
      "  Total G Loss: 3.3254\n",
      "Epoch [73/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1169, D_X Fake: 0.1151, D_X Total: 0.1160\n",
      "  D_Y Real: 0.1266, D_Y Fake: 0.0946, D_Y Total: 0.1106\n",
      "Generator Losses:\n",
      "  G Adv: 0.9017, F Adv: 0.4855\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.7554\n",
      "Epoch [73/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1192, D_X Fake: 0.2185, D_X Total: 0.1689\n",
      "  D_Y Real: 0.0635, D_Y Fake: 0.0889, D_Y Total: 0.0762\n",
      "Generator Losses:\n",
      "  G Adv: 0.6324, F Adv: 0.3660\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1626, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.4354\n",
      "Epoch [73/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0701, D_X Fake: 0.1168, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0786, D_Y Fake: 0.0706, D_Y Total: 0.0746\n",
      "Generator Losses:\n",
      "  G Adv: 0.7636, F Adv: 0.5219\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1705, Perceptual Monet: 0.1473\n",
      "  Total G Loss: 3.5666\n",
      "Epoch [73/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3078, D_X Fake: 0.0665, D_X Total: 0.1871\n",
      "  D_Y Real: 0.1124, D_Y Fake: 0.1222, D_Y Total: 0.1173\n",
      "Generator Losses:\n",
      "  G Adv: 0.5839, F Adv: 0.6978\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1179, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.4930\n",
      "Epoch [73/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0874, D_X Fake: 0.1133, D_X Total: 0.1004\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0855, D_Y Total: 0.0577\n",
      "Generator Losses:\n",
      "  G Adv: 0.8557, F Adv: 0.3830\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1182, Perceptual Monet: 0.1464\n",
      "  Total G Loss: 3.2750\n",
      "Epoch [73/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2237, D_X Fake: 0.1587, D_X Total: 0.1912\n",
      "  D_Y Real: 0.1477, D_Y Fake: 0.1237, D_Y Total: 0.1357\n",
      "Generator Losses:\n",
      "  G Adv: 0.6306, F Adv: 0.4997\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1257, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.3918\n",
      "Epoch [73/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1129, D_X Fake: 0.0815, D_X Total: 0.0972\n",
      "  D_Y Real: 0.0685, D_Y Fake: 0.1348, D_Y Total: 0.1017\n",
      "Generator Losses:\n",
      "  G Adv: 0.4548, F Adv: 0.3107\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0519\n",
      "  Perceptual Photo: 0.1531, Perceptual Monet: 0.1950\n",
      "  Total G Loss: 3.4329\n",
      "Epoch [73/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1048, D_X Fake: 0.0879, D_X Total: 0.0963\n",
      "  D_Y Real: 0.0973, D_Y Fake: 0.0962, D_Y Total: 0.0967\n",
      "Generator Losses:\n",
      "  G Adv: 0.8461, F Adv: 0.4563\n",
      "  Cycle Photo: 0.0419, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1772, Perceptual Monet: 0.1357\n",
      "  Total G Loss: 3.5368\n",
      "Epoch [73/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0392, D_X Fake: 0.0436, D_X Total: 0.0414\n",
      "  D_Y Real: 0.0583, D_Y Fake: 0.0501, D_Y Total: 0.0542\n",
      "Generator Losses:\n",
      "  G Adv: 0.9326, F Adv: 0.5113\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0432\n",
      "  Perceptual Photo: 0.1568, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.9976\n",
      "Epoch [73/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1492, D_X Fake: 0.0630, D_X Total: 0.1061\n",
      "  D_Y Real: 0.0654, D_Y Fake: 0.0913, D_Y Total: 0.0783\n",
      "Generator Losses:\n",
      "  G Adv: 0.7538, F Adv: 0.6305\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1214\n",
      "  Total G Loss: 3.4339\n",
      "Epoch [73/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1003, D_X Fake: 0.1311, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.1502, D_Y Total: 0.0988\n",
      "Generator Losses:\n",
      "  G Adv: 0.5294, F Adv: 0.4130\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1579\n",
      "  Total G Loss: 3.2984\n",
      "Epoch [73/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2251, D_X Fake: 0.1274, D_X Total: 0.1762\n",
      "  D_Y Real: 0.0949, D_Y Fake: 0.1385, D_Y Total: 0.1167\n",
      "Generator Losses:\n",
      "  G Adv: 0.5086, F Adv: 0.5378\n",
      "  Cycle Photo: 0.0640, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.2030, Perceptual Monet: 0.1477\n",
      "  Total G Loss: 3.7159\n",
      "Epoch [73/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1277, D_X Fake: 0.0750, D_X Total: 0.1014\n",
      "  D_Y Real: 0.0431, D_Y Fake: 0.0470, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 0.4943, F Adv: 0.5555\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.1567, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 3.5166\n",
      "Epoch [73/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1465, D_X Fake: 0.0718, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0555, D_Y Fake: 0.1167, D_Y Total: 0.0861\n",
      "Generator Losses:\n",
      "  G Adv: 0.6129, F Adv: 0.6547\n",
      "  Cycle Photo: 0.0600, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1385\n",
      "  Total G Loss: 3.6404\n",
      "Epoch [73/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0373, D_X Fake: 0.1375, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0514, D_Y Fake: 0.0778, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.4966, F Adv: 0.5965\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.4849\n",
      "Epoch [73/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0819, D_X Fake: 0.2259, D_X Total: 0.1539\n",
      "  D_Y Real: 0.0524, D_Y Fake: 0.1163, D_Y Total: 0.0843\n",
      "Generator Losses:\n",
      "  G Adv: 0.5204, F Adv: 0.3321\n",
      "  Cycle Photo: 0.0559, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1410\n",
      "  Total G Loss: 3.1213\n",
      "Epoch [73/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2645, D_X Fake: 0.0432, D_X Total: 0.1539\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0658, D_Y Total: 0.0493\n",
      "Generator Losses:\n",
      "  G Adv: 0.6620, F Adv: 0.9680\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1285, Perceptual Monet: 0.1782\n",
      "  Total G Loss: 4.0309\n",
      "Epoch [73/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2274, D_X Fake: 0.0625, D_X Total: 0.1450\n",
      "  D_Y Real: 0.0929, D_Y Fake: 0.0777, D_Y Total: 0.0853\n",
      "Generator Losses:\n",
      "  G Adv: 0.6405, F Adv: 0.7119\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1729, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.7703\n",
      "Epoch [74/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0425, D_X Fake: 0.2071, D_X Total: 0.1248\n",
      "  D_Y Real: 0.0255, D_Y Fake: 0.1152, D_Y Total: 0.0703\n",
      "Generator Losses:\n",
      "  G Adv: 0.6312, F Adv: 0.2089\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1270, Perceptual Monet: 0.1715\n",
      "  Total G Loss: 3.2034\n",
      "Epoch [74/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1455, D_X Fake: 0.0600, D_X Total: 0.1028\n",
      "  D_Y Real: 0.0953, D_Y Fake: 0.0481, D_Y Total: 0.0717\n",
      "Generator Losses:\n",
      "  G Adv: 0.7710, F Adv: 0.6286\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1490, Perceptual Monet: 0.1473\n",
      "  Total G Loss: 3.5995\n",
      "Epoch [74/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.0898, D_X Total: 0.0866\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.0702, D_Y Total: 0.0561\n",
      "Generator Losses:\n",
      "  G Adv: 0.5835, F Adv: 0.5116\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1529, Perceptual Monet: 0.1389\n",
      "  Total G Loss: 3.1879\n",
      "Epoch [74/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1317, D_X Fake: 0.0901, D_X Total: 0.1109\n",
      "  D_Y Real: 0.1479, D_Y Fake: 0.0805, D_Y Total: 0.1142\n",
      "Generator Losses:\n",
      "  G Adv: 1.0868, F Adv: 0.7594\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 4.1015\n",
      "Epoch [74/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2340, D_X Fake: 0.0969, D_X Total: 0.1654\n",
      "  D_Y Real: 0.1062, D_Y Fake: 0.1292, D_Y Total: 0.1177\n",
      "Generator Losses:\n",
      "  G Adv: 0.5067, F Adv: 0.5849\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.5398\n",
      "Epoch [74/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0630, D_X Fake: 0.0831, D_X Total: 0.0730\n",
      "  D_Y Real: 0.0612, D_Y Fake: 0.0828, D_Y Total: 0.0720\n",
      "Generator Losses:\n",
      "  G Adv: 0.5733, F Adv: 0.6769\n",
      "  Cycle Photo: 0.0452, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1845, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.8375\n",
      "Epoch [74/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0901, D_X Fake: 0.1600, D_X Total: 0.1250\n",
      "  D_Y Real: 0.0617, D_Y Fake: 0.0491, D_Y Total: 0.0554\n",
      "Generator Losses:\n",
      "  G Adv: 0.8041, F Adv: 0.3898\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1527, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.5674\n",
      "Epoch [74/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2432, D_X Fake: 0.0861, D_X Total: 0.1647\n",
      "  D_Y Real: 0.0521, D_Y Fake: 0.0479, D_Y Total: 0.0500\n",
      "Generator Losses:\n",
      "  G Adv: 0.7784, F Adv: 0.8126\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 4.0145\n",
      "Epoch [74/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1131, D_X Fake: 0.1627, D_X Total: 0.1379\n",
      "  D_Y Real: 0.0875, D_Y Fake: 0.0714, D_Y Total: 0.0795\n",
      "Generator Losses:\n",
      "  G Adv: 0.7565, F Adv: 0.4953\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0468\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.2123\n",
      "  Total G Loss: 3.7401\n",
      "Epoch [74/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0596, D_X Fake: 0.1011, D_X Total: 0.0804\n",
      "  D_Y Real: 0.1332, D_Y Fake: 0.0559, D_Y Total: 0.0946\n",
      "Generator Losses:\n",
      "  G Adv: 0.9318, F Adv: 0.6515\n",
      "  Cycle Photo: 0.0606, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1597, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 4.3475\n",
      "Epoch [74/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1311, D_X Fake: 0.1109, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0551, D_Y Fake: 0.0512, D_Y Total: 0.0532\n",
      "Generator Losses:\n",
      "  G Adv: 0.6644, F Adv: 0.4680\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1815, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 3.7875\n",
      "Epoch [74/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0712, D_X Fake: 0.1214, D_X Total: 0.0963\n",
      "  D_Y Real: 0.0757, D_Y Fake: 0.0486, D_Y Total: 0.0622\n",
      "Generator Losses:\n",
      "  G Adv: 0.9535, F Adv: 0.3709\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1725, Perceptual Monet: 0.1414\n",
      "  Total G Loss: 3.6203\n",
      "Epoch [74/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2136, D_X Fake: 0.0328, D_X Total: 0.1232\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0496, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.8870, F Adv: 1.0378\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1827, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 4.5801\n",
      "Epoch [74/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1498, D_X Fake: 0.1202, D_X Total: 0.1350\n",
      "  D_Y Real: 0.0627, D_Y Fake: 0.0694, D_Y Total: 0.0660\n",
      "Generator Losses:\n",
      "  G Adv: 0.6342, F Adv: 0.6451\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1396, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.6268\n",
      "Epoch [74/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0475, D_X Fake: 0.2263, D_X Total: 0.1369\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0810, D_Y Total: 0.0532\n",
      "Generator Losses:\n",
      "  G Adv: 0.6242, F Adv: 0.3749\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.1967\n",
      "Epoch [74/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0549, D_X Fake: 0.2853, D_X Total: 0.1701\n",
      "  D_Y Real: 0.0691, D_Y Fake: 0.1202, D_Y Total: 0.0947\n",
      "Generator Losses:\n",
      "  G Adv: 0.5712, F Adv: 0.2505\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1394\n",
      "  Total G Loss: 3.0536\n",
      "Epoch [74/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1693, D_X Fake: 0.0511, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.1291, D_Y Total: 0.0811\n",
      "Generator Losses:\n",
      "  G Adv: 0.5841, F Adv: 0.7454\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.4665\n",
      "Epoch [74/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1500, D_X Fake: 0.0537, D_X Total: 0.1018\n",
      "  D_Y Real: 0.0614, D_Y Fake: 0.1104, D_Y Total: 0.0859\n",
      "Generator Losses:\n",
      "  G Adv: 0.7822, F Adv: 0.8603\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1521, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 4.0253\n",
      "Epoch [74/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0764, D_X Fake: 0.1190, D_X Total: 0.0977\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.1369, D_Y Total: 0.0894\n",
      "Generator Losses:\n",
      "  G Adv: 0.4927, F Adv: 0.4527\n",
      "  Cycle Photo: 0.0561, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1642, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.3573\n",
      "Epoch [74/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2598, D_X Fake: 0.1309, D_X Total: 0.1954\n",
      "  D_Y Real: 0.0798, D_Y Fake: 0.0819, D_Y Total: 0.0809\n",
      "Generator Losses:\n",
      "  G Adv: 0.6250, F Adv: 1.0952\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 4.2037\n",
      "Epoch [74/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0871, D_X Fake: 0.0888, D_X Total: 0.0879\n",
      "  D_Y Real: 0.1738, D_Y Fake: 0.0477, D_Y Total: 0.1107\n",
      "Generator Losses:\n",
      "  G Adv: 0.8789, F Adv: 0.6129\n",
      "  Cycle Photo: 0.0479, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1572, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.9046\n",
      "Epoch [74/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1490, D_X Fake: 0.1035, D_X Total: 0.1262\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0688, D_Y Total: 0.0602\n",
      "Generator Losses:\n",
      "  G Adv: 0.6118, F Adv: 0.5916\n",
      "  Cycle Photo: 0.0530, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1078, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.4299\n",
      "Epoch [74/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0904, D_X Fake: 0.0691, D_X Total: 0.0798\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.1086, D_Y Total: 0.0749\n",
      "Generator Losses:\n",
      "  G Adv: 0.3838, F Adv: 0.5064\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0473\n",
      "  Perceptual Photo: 0.1726, Perceptual Monet: 0.1628\n",
      "  Total G Loss: 3.4524\n",
      "Epoch [74/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0423, D_X Fake: 0.2569, D_X Total: 0.1496\n",
      "  D_Y Real: 0.0649, D_Y Fake: 0.1109, D_Y Total: 0.0879\n",
      "Generator Losses:\n",
      "  G Adv: 0.6060, F Adv: 0.3126\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1873, Perceptual Monet: 0.1508\n",
      "  Total G Loss: 3.3531\n",
      "Epoch [75/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.1048, D_X Total: 0.0980\n",
      "  D_Y Real: 0.0631, D_Y Fake: 0.1065, D_Y Total: 0.0848\n",
      "Generator Losses:\n",
      "  G Adv: 0.4503, F Adv: 0.4062\n",
      "  Cycle Photo: 0.0450, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1299, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.0717\n",
      "Epoch [75/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1466, D_X Fake: 0.0447, D_X Total: 0.0956\n",
      "  D_Y Real: 0.0554, D_Y Fake: 0.0774, D_Y Total: 0.0664\n",
      "Generator Losses:\n",
      "  G Adv: 0.6653, F Adv: 0.6097\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0413\n",
      "  Perceptual Photo: 0.1606, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.8742\n",
      "Epoch [75/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2602, D_X Fake: 0.0466, D_X Total: 0.1534\n",
      "  D_Y Real: 0.0606, D_Y Fake: 0.1226, D_Y Total: 0.0916\n",
      "Generator Losses:\n",
      "  G Adv: 0.6384, F Adv: 0.9895\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0440\n",
      "  Perceptual Photo: 0.1551, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 4.1015\n",
      "Epoch [75/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0272, D_X Fake: 0.0903, D_X Total: 0.0587\n",
      "  D_Y Real: 0.0813, D_Y Fake: 0.0704, D_Y Total: 0.0759\n",
      "Generator Losses:\n",
      "  G Adv: 0.8348, F Adv: 0.6250\n",
      "  Cycle Photo: 0.0452, Cycle Monet: 0.0453\n",
      "  Perceptual Photo: 0.1058, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.7662\n",
      "Epoch [75/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1533, D_X Fake: 0.1460, D_X Total: 0.1497\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.1053, D_Y Total: 0.0726\n",
      "Generator Losses:\n",
      "  G Adv: 0.6332, F Adv: 0.5226\n",
      "  Cycle Photo: 0.0454, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.5487\n",
      "Epoch [75/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0784, D_X Fake: 0.0452, D_X Total: 0.0618\n",
      "  D_Y Real: 0.0783, D_Y Fake: 0.1521, D_Y Total: 0.1152\n",
      "Generator Losses:\n",
      "  G Adv: 0.5608, F Adv: 0.6534\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1467, Perceptual Monet: 0.1944\n",
      "  Total G Loss: 3.7743\n",
      "Epoch [75/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0510, D_X Fake: 0.3167, D_X Total: 0.1838\n",
      "  D_Y Real: 0.0448, D_Y Fake: 0.1232, D_Y Total: 0.0840\n",
      "Generator Losses:\n",
      "  G Adv: 0.5146, F Adv: 0.2153\n",
      "  Cycle Photo: 0.0586, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1536, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.1762\n",
      "Epoch [75/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0596, D_X Fake: 0.1343, D_X Total: 0.0969\n",
      "  D_Y Real: 0.0750, D_Y Fake: 0.1241, D_Y Total: 0.0995\n",
      "Generator Losses:\n",
      "  G Adv: 0.4783, F Adv: 0.5217\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.5185\n",
      "Epoch [75/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1719, D_X Fake: 0.0535, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0729, D_Y Fake: 0.0933, D_Y Total: 0.0831\n",
      "Generator Losses:\n",
      "  G Adv: 0.5719, F Adv: 0.9104\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0433\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.1865\n",
      "  Total G Loss: 4.0840\n",
      "Epoch [75/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1052, D_X Fake: 0.2015, D_X Total: 0.1534\n",
      "  D_Y Real: 0.0635, D_Y Fake: 0.0704, D_Y Total: 0.0670\n",
      "Generator Losses:\n",
      "  G Adv: 0.7412, F Adv: 0.5879\n",
      "  Cycle Photo: 0.0419, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1702, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.7549\n",
      "Epoch [75/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1271, D_X Fake: 0.0731, D_X Total: 0.1001\n",
      "  D_Y Real: 0.0569, D_Y Fake: 0.1052, D_Y Total: 0.0810\n",
      "Generator Losses:\n",
      "  G Adv: 0.6223, F Adv: 0.5797\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.4588\n",
      "Epoch [75/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0799, D_X Fake: 0.2801, D_X Total: 0.1800\n",
      "  D_Y Real: 0.0375, D_Y Fake: 0.0674, D_Y Total: 0.0524\n",
      "Generator Losses:\n",
      "  G Adv: 0.6945, F Adv: 0.1805\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1857, Perceptual Monet: 0.1702\n",
      "  Total G Loss: 3.4683\n",
      "Epoch [75/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1251, D_X Fake: 0.1219, D_X Total: 0.1235\n",
      "  D_Y Real: 0.0636, D_Y Fake: 0.2049, D_Y Total: 0.1343\n",
      "Generator Losses:\n",
      "  G Adv: 0.4406, F Adv: 0.5548\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.3256\n",
      "Epoch [75/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0666, D_X Fake: 0.1860, D_X Total: 0.1263\n",
      "  D_Y Real: 0.1291, D_Y Fake: 0.0676, D_Y Total: 0.0983\n",
      "Generator Losses:\n",
      "  G Adv: 0.7538, F Adv: 0.3222\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.6244\n",
      "Epoch [75/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1883, D_X Fake: 0.0596, D_X Total: 0.1239\n",
      "  D_Y Real: 0.0771, D_Y Fake: 0.0605, D_Y Total: 0.0688\n",
      "Generator Losses:\n",
      "  G Adv: 0.9793, F Adv: 0.8565\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1571\n",
      "  Total G Loss: 4.0690\n",
      "Epoch [75/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0715, D_X Fake: 0.1259, D_X Total: 0.0987\n",
      "  D_Y Real: 0.1254, D_Y Fake: 0.0378, D_Y Total: 0.0816\n",
      "Generator Losses:\n",
      "  G Adv: 0.8057, F Adv: 0.1813\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1610, Perceptual Monet: 0.1569\n",
      "  Total G Loss: 3.2933\n",
      "Epoch [75/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0724, D_X Fake: 0.3909, D_X Total: 0.2317\n",
      "  D_Y Real: 0.1368, D_Y Fake: 0.0960, D_Y Total: 0.1164\n",
      "Generator Losses:\n",
      "  G Adv: 0.7967, F Adv: 0.2181\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1498\n",
      "  Total G Loss: 3.1051\n",
      "Epoch [75/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0575, D_X Fake: 0.1089, D_X Total: 0.0832\n",
      "  D_Y Real: 0.1178, D_Y Fake: 0.0468, D_Y Total: 0.0823\n",
      "Generator Losses:\n",
      "  G Adv: 0.8708, F Adv: 0.5223\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.6497\n",
      "Epoch [75/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0741, D_X Fake: 0.2115, D_X Total: 0.1428\n",
      "  D_Y Real: 0.1027, D_Y Fake: 0.0565, D_Y Total: 0.0796\n",
      "Generator Losses:\n",
      "  G Adv: 0.8506, F Adv: 0.2606\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1633, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 3.8103\n",
      "Epoch [75/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2047, D_X Fake: 0.1675, D_X Total: 0.1861\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.0933, D_Y Total: 0.0644\n",
      "Generator Losses:\n",
      "  G Adv: 0.5320, F Adv: 0.4223\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.3530\n",
      "Epoch [75/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0922, D_X Fake: 0.1056, D_X Total: 0.0989\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.1118, D_Y Total: 0.0880\n",
      "Generator Losses:\n",
      "  G Adv: 0.7200, F Adv: 0.5281\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.5727\n",
      "Epoch [75/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0525, D_X Fake: 0.1283, D_X Total: 0.0904\n",
      "  D_Y Real: 0.1101, D_Y Fake: 0.0599, D_Y Total: 0.0850\n",
      "Generator Losses:\n",
      "  G Adv: 1.0749, F Adv: 0.4553\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1518, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.9539\n",
      "Epoch [75/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.0666, D_X Total: 0.0738\n",
      "  D_Y Real: 0.0738, D_Y Fake: 0.0463, D_Y Total: 0.0601\n",
      "Generator Losses:\n",
      "  G Adv: 0.9029, F Adv: 0.5775\n",
      "  Cycle Photo: 0.0497, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.2107, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 4.2055\n",
      "Epoch [75/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1173, D_X Fake: 0.0877, D_X Total: 0.1025\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.0997, D_Y Total: 0.0690\n",
      "Generator Losses:\n",
      "  G Adv: 0.5769, F Adv: 0.6696\n",
      "  Cycle Photo: 0.0548, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.6466\n",
      "Epoch [76/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0967, D_X Fake: 0.0842, D_X Total: 0.0905\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0597, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.7480, F Adv: 0.6444\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1606, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.7444\n",
      "Epoch [76/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0423, D_X Fake: 0.1532, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0690, D_Y Fake: 0.0664, D_Y Total: 0.0677\n",
      "Generator Losses:\n",
      "  G Adv: 0.8990, F Adv: 0.4517\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1218, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.3309\n",
      "Epoch [76/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2697, D_X Fake: 0.0620, D_X Total: 0.1659\n",
      "  D_Y Real: 0.0430, D_Y Fake: 0.0803, D_Y Total: 0.0616\n",
      "Generator Losses:\n",
      "  G Adv: 0.4274, F Adv: 0.7368\n",
      "  Cycle Photo: 0.0574, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1934, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.8441\n",
      "Epoch [76/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1434, D_X Fake: 0.0685, D_X Total: 0.1059\n",
      "  D_Y Real: 0.1737, D_Y Fake: 0.0898, D_Y Total: 0.1318\n",
      "Generator Losses:\n",
      "  G Adv: 0.7332, F Adv: 0.7389\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0456\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1759\n",
      "  Total G Loss: 3.8169\n",
      "Epoch [76/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2222, D_X Fake: 0.1246, D_X Total: 0.1734\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0462, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.6328, F Adv: 0.5540\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.1849, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.7922\n",
      "Epoch [76/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1897, D_X Fake: 0.0785, D_X Total: 0.1341\n",
      "  D_Y Real: 0.1489, D_Y Fake: 0.1104, D_Y Total: 0.1296\n",
      "Generator Losses:\n",
      "  G Adv: 1.2207, F Adv: 0.7530\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1218, Perceptual Monet: 0.2064\n",
      "  Total G Loss: 4.3445\n",
      "Epoch [76/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0605, D_X Fake: 0.3321, D_X Total: 0.1963\n",
      "  D_Y Real: 0.0931, D_Y Fake: 0.0566, D_Y Total: 0.0749\n",
      "Generator Losses:\n",
      "  G Adv: 0.8362, F Adv: 0.3418\n",
      "  Cycle Photo: 0.0554, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1410\n",
      "  Total G Loss: 3.5189\n",
      "Epoch [76/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1640, D_X Fake: 0.0618, D_X Total: 0.1129\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0637, D_Y Total: 0.0505\n",
      "Generator Losses:\n",
      "  G Adv: 0.6127, F Adv: 0.8384\n",
      "  Cycle Photo: 0.0438, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.6084\n",
      "Epoch [76/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0464, D_X Fake: 0.0801, D_X Total: 0.0632\n",
      "  D_Y Real: 0.0392, D_Y Fake: 0.1494, D_Y Total: 0.0943\n",
      "Generator Losses:\n",
      "  G Adv: 0.6637, F Adv: 0.6934\n",
      "  Cycle Photo: 0.0420, Cycle Monet: 0.0479\n",
      "  Perceptual Photo: 0.1417, Perceptual Monet: 0.2005\n",
      "  Total G Loss: 3.9676\n",
      "Epoch [76/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0761, D_X Fake: 0.0328, D_X Total: 0.0545\n",
      "  D_Y Real: 0.0723, D_Y Fake: 0.0717, D_Y Total: 0.0720\n",
      "Generator Losses:\n",
      "  G Adv: 0.8360, F Adv: 0.6819\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0446\n",
      "  Perceptual Photo: 0.1526, Perceptual Monet: 0.1913\n",
      "  Total G Loss: 4.0290\n",
      "Epoch [76/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0303, D_X Fake: 0.2396, D_X Total: 0.1349\n",
      "  D_Y Real: 0.0596, D_Y Fake: 0.0556, D_Y Total: 0.0576\n",
      "Generator Losses:\n",
      "  G Adv: 0.6862, F Adv: 0.2329\n",
      "  Cycle Photo: 0.0425, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.2572\n",
      "Epoch [76/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1026, D_X Fake: 0.0905, D_X Total: 0.0965\n",
      "  D_Y Real: 0.0599, D_Y Fake: 0.0692, D_Y Total: 0.0645\n",
      "Generator Losses:\n",
      "  G Adv: 0.6980, F Adv: 0.4926\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.3893\n",
      "Epoch [76/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2037, D_X Fake: 0.1260, D_X Total: 0.1649\n",
      "  D_Y Real: 0.0443, D_Y Fake: 0.1123, D_Y Total: 0.0783\n",
      "Generator Losses:\n",
      "  G Adv: 0.6286, F Adv: 0.5096\n",
      "  Cycle Photo: 0.0454, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1815, Perceptual Monet: 0.1293\n",
      "  Total G Loss: 3.4161\n",
      "Epoch [76/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0623, D_X Fake: 0.4440, D_X Total: 0.2531\n",
      "  D_Y Real: 0.0879, D_Y Fake: 0.0974, D_Y Total: 0.0926\n",
      "Generator Losses:\n",
      "  G Adv: 0.7139, F Adv: 0.1596\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.2061, Perceptual Monet: 0.1307\n",
      "  Total G Loss: 3.3747\n",
      "Epoch [76/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1645, D_X Fake: 0.1568, D_X Total: 0.1606\n",
      "  D_Y Real: 0.0772, D_Y Fake: 0.0822, D_Y Total: 0.0797\n",
      "Generator Losses:\n",
      "  G Adv: 0.5511, F Adv: 0.4690\n",
      "  Cycle Photo: 0.0807, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1890, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.9222\n",
      "Epoch [76/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.0901, D_X Total: 0.1028\n",
      "  D_Y Real: 0.0725, D_Y Fake: 0.1026, D_Y Total: 0.0875\n",
      "Generator Losses:\n",
      "  G Adv: 0.5981, F Adv: 0.4763\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.2027, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 3.8878\n",
      "Epoch [76/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1276, D_X Fake: 0.0560, D_X Total: 0.0918\n",
      "  D_Y Real: 0.0640, D_Y Fake: 0.0422, D_Y Total: 0.0531\n",
      "Generator Losses:\n",
      "  G Adv: 0.8727, F Adv: 0.7451\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1142, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.7342\n",
      "Epoch [76/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0478, D_X Fake: 0.0687, D_X Total: 0.0582\n",
      "  D_Y Real: 0.0847, D_Y Fake: 0.0574, D_Y Total: 0.0711\n",
      "Generator Losses:\n",
      "  G Adv: 0.8909, F Adv: 0.2526\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1328, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.4315\n",
      "Epoch [76/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0473, D_X Fake: 0.1125, D_X Total: 0.0799\n",
      "  D_Y Real: 0.0657, D_Y Fake: 0.0381, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 1.2086, F Adv: 0.3670\n",
      "  Cycle Photo: 0.0618, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 4.2261\n",
      "Epoch [76/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1423, D_X Fake: 0.1705, D_X Total: 0.1564\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.0381, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.6436, F Adv: 0.4891\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0395\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.1392\n",
      "  Total G Loss: 3.5540\n",
      "Epoch [76/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.0450, D_X Total: 0.0577\n",
      "  D_Y Real: 0.1074, D_Y Fake: 0.0523, D_Y Total: 0.0798\n",
      "Generator Losses:\n",
      "  G Adv: 0.8693, F Adv: 0.8689\n",
      "  Cycle Photo: 0.0649, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1538\n",
      "  Total G Loss: 4.1435\n",
      "Epoch [76/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1970, D_X Fake: 0.0732, D_X Total: 0.1351\n",
      "  D_Y Real: 0.0448, D_Y Fake: 0.2244, D_Y Total: 0.1346\n",
      "Generator Losses:\n",
      "  G Adv: 0.4385, F Adv: 0.4973\n",
      "  Cycle Photo: 0.0629, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.1939\n",
      "Epoch [76/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1063, D_X Fake: 0.0851, D_X Total: 0.0957\n",
      "  D_Y Real: 0.0758, D_Y Fake: 0.0709, D_Y Total: 0.0734\n",
      "Generator Losses:\n",
      "  G Adv: 0.7593, F Adv: 0.5794\n",
      "  Cycle Photo: 0.0550, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1496\n",
      "  Total G Loss: 3.8489\n",
      "Epoch [76/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2273, D_X Fake: 0.0869, D_X Total: 0.1571\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0529, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 0.6266, F Adv: 0.7482\n",
      "  Cycle Photo: 0.0759, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1640, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 4.1762\n",
      "Epoch [77/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0336, D_X Fake: 0.1281, D_X Total: 0.0808\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.0592, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.6399, F Adv: 0.3345\n",
      "  Cycle Photo: 0.0431, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1331, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.3316\n",
      "Epoch [77/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1236, D_X Fake: 0.0704, D_X Total: 0.0970\n",
      "  D_Y Real: 0.0523, D_Y Fake: 0.0944, D_Y Total: 0.0733\n",
      "Generator Losses:\n",
      "  G Adv: 0.8641, F Adv: 0.6990\n",
      "  Cycle Photo: 0.0659, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.2092, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 4.5565\n",
      "Epoch [77/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0973, D_X Fake: 0.0606, D_X Total: 0.0789\n",
      "  D_Y Real: 0.0576, D_Y Fake: 0.0822, D_Y Total: 0.0699\n",
      "Generator Losses:\n",
      "  G Adv: 0.6364, F Adv: 0.8628\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1921\n",
      "  Total G Loss: 4.0436\n",
      "Epoch [77/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2694, D_X Fake: 0.0535, D_X Total: 0.1614\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0383, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.9910, F Adv: 0.7650\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1742, Perceptual Monet: 0.1346\n",
      "  Total G Loss: 3.9675\n",
      "Epoch [77/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0342, D_X Fake: 0.0808, D_X Total: 0.0575\n",
      "  D_Y Real: 0.0884, D_Y Fake: 0.0702, D_Y Total: 0.0793\n",
      "Generator Losses:\n",
      "  G Adv: 0.9076, F Adv: 0.6345\n",
      "  Cycle Photo: 0.0475, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 3.9764\n",
      "Epoch [77/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0747, D_X Fake: 0.1072, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0506, D_Y Total: 0.0404\n",
      "Generator Losses:\n",
      "  G Adv: 0.8226, F Adv: 0.4419\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1885, Perceptual Monet: 0.1311\n",
      "  Total G Loss: 3.6426\n",
      "Epoch [77/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1342, D_X Fake: 0.0613, D_X Total: 0.0977\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.1311, D_Y Total: 0.0828\n",
      "Generator Losses:\n",
      "  G Adv: 0.5209, F Adv: 0.7041\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1287, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.5205\n",
      "Epoch [77/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2603, D_X Fake: 0.0466, D_X Total: 0.1534\n",
      "  D_Y Real: 0.0529, D_Y Fake: 0.1906, D_Y Total: 0.1218\n",
      "Generator Losses:\n",
      "  G Adv: 0.4537, F Adv: 0.9373\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.7033\n",
      "Epoch [77/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1046, D_X Fake: 0.1301, D_X Total: 0.1173\n",
      "  D_Y Real: 0.0636, D_Y Fake: 0.0668, D_Y Total: 0.0652\n",
      "Generator Losses:\n",
      "  G Adv: 0.8112, F Adv: 0.3907\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1695, Perceptual Monet: 0.1187\n",
      "  Total G Loss: 3.3163\n",
      "Epoch [77/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0508, D_X Fake: 0.1106, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0584, D_Y Fake: 0.0440, D_Y Total: 0.0512\n",
      "Generator Losses:\n",
      "  G Adv: 0.8638, F Adv: 0.4715\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1742, Perceptual Monet: 0.1328\n",
      "  Total G Loss: 3.7368\n",
      "Epoch [77/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0331, D_X Fake: 0.1546, D_X Total: 0.0939\n",
      "  D_Y Real: 0.0406, D_Y Fake: 0.0287, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.8753, F Adv: 0.4741\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.6503\n",
      "Epoch [77/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0852, D_X Fake: 0.0818, D_X Total: 0.0835\n",
      "  D_Y Real: 0.0794, D_Y Fake: 0.0327, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.9127, F Adv: 0.5487\n",
      "  Cycle Photo: 0.0618, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.2096, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 4.4189\n",
      "Epoch [77/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.2017, D_X Total: 0.1666\n",
      "  D_Y Real: 0.2309, D_Y Fake: 0.0758, D_Y Total: 0.1534\n",
      "Generator Losses:\n",
      "  G Adv: 0.9770, F Adv: 0.3962\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.7710\n",
      "Epoch [77/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0400, D_X Fake: 0.1423, D_X Total: 0.0911\n",
      "  D_Y Real: 0.1261, D_Y Fake: 0.0435, D_Y Total: 0.0848\n",
      "Generator Losses:\n",
      "  G Adv: 0.9529, F Adv: 0.3451\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1033, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 3.2327\n",
      "Epoch [77/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1434, D_X Fake: 0.0489, D_X Total: 0.0962\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.0827, D_Y Total: 0.0585\n",
      "Generator Losses:\n",
      "  G Adv: 0.7408, F Adv: 0.5559\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1211, Perceptual Monet: 0.1710\n",
      "  Total G Loss: 3.5998\n",
      "Epoch [77/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1174, D_X Fake: 0.0929, D_X Total: 0.1051\n",
      "  D_Y Real: 0.1566, D_Y Fake: 0.0993, D_Y Total: 0.1279\n",
      "Generator Losses:\n",
      "  G Adv: 0.7641, F Adv: 0.5040\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1544, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.7796\n",
      "Epoch [77/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1726, D_X Fake: 0.0608, D_X Total: 0.1167\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.1058, D_Y Total: 0.0704\n",
      "Generator Losses:\n",
      "  G Adv: 0.5351, F Adv: 0.6835\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0482\n",
      "  Perceptual Photo: 0.1574, Perceptual Monet: 0.1592\n",
      "  Total G Loss: 3.8291\n",
      "Epoch [77/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.1787, D_X Total: 0.1289\n",
      "  D_Y Real: 0.0833, D_Y Fake: 0.0504, D_Y Total: 0.0668\n",
      "Generator Losses:\n",
      "  G Adv: 0.8045, F Adv: 0.1858\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.2767\n",
      "Epoch [77/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0830, D_X Fake: 0.0755, D_X Total: 0.0793\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.0923, D_Y Total: 0.0648\n",
      "Generator Losses:\n",
      "  G Adv: 0.5869, F Adv: 0.5879\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.2051, Perceptual Monet: 0.1586\n",
      "  Total G Loss: 3.8582\n",
      "Epoch [77/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1298, D_X Fake: 0.0812, D_X Total: 0.1055\n",
      "  D_Y Real: 0.1003, D_Y Fake: 0.0749, D_Y Total: 0.0876\n",
      "Generator Losses:\n",
      "  G Adv: 1.1584, F Adv: 0.6101\n",
      "  Cycle Photo: 0.0432, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.2046, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 4.2666\n",
      "Epoch [77/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0695, D_X Fake: 0.1707, D_X Total: 0.1201\n",
      "  D_Y Real: 0.1196, D_Y Fake: 0.0648, D_Y Total: 0.0922\n",
      "Generator Losses:\n",
      "  G Adv: 0.8195, F Adv: 0.3090\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0475\n",
      "  Perceptual Photo: 0.1591, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.6651\n",
      "Epoch [77/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1343, D_X Fake: 0.1048, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.1416, D_Y Total: 0.0886\n",
      "Generator Losses:\n",
      "  G Adv: 0.4155, F Adv: 0.4426\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 3.1191\n",
      "Epoch [77/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1239, D_X Fake: 0.1163, D_X Total: 0.1201\n",
      "  D_Y Real: 0.0574, D_Y Fake: 0.0678, D_Y Total: 0.0626\n",
      "Generator Losses:\n",
      "  G Adv: 0.6093, F Adv: 0.6517\n",
      "  Cycle Photo: 0.0546, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.2185, Perceptual Monet: 0.1505\n",
      "  Total G Loss: 3.9398\n",
      "Epoch [77/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1517, D_X Fake: 0.1340, D_X Total: 0.1429\n",
      "  D_Y Real: 0.0650, D_Y Fake: 0.0533, D_Y Total: 0.0592\n",
      "Generator Losses:\n",
      "  G Adv: 0.7390, F Adv: 0.6499\n",
      "  Cycle Photo: 0.0695, Cycle Monet: 0.0529\n",
      "  Perceptual Photo: 0.1269, Perceptual Monet: 0.2139\n",
      "  Total G Loss: 4.3168\n",
      "Epoch [78/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1853, D_X Fake: 0.0525, D_X Total: 0.1189\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0573, D_Y Total: 0.0489\n",
      "Generator Losses:\n",
      "  G Adv: 0.7328, F Adv: 0.6116\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0463\n",
      "  Perceptual Photo: 0.1726, Perceptual Monet: 0.1927\n",
      "  Total G Loss: 4.1163\n",
      "Epoch [78/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1365, D_X Fake: 0.1064, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0452, D_Y Fake: 0.2189, D_Y Total: 0.1321\n",
      "Generator Losses:\n",
      "  G Adv: 0.6794, F Adv: 0.4542\n",
      "  Cycle Photo: 0.0684, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1557\n",
      "  Total G Loss: 3.6790\n",
      "Epoch [78/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2137, D_X Fake: 0.0740, D_X Total: 0.1438\n",
      "  D_Y Real: 0.0824, D_Y Fake: 0.0613, D_Y Total: 0.0719\n",
      "Generator Losses:\n",
      "  G Adv: 0.7989, F Adv: 0.7206\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.8512\n",
      "Epoch [78/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1859, D_X Fake: 0.0899, D_X Total: 0.1379\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0576, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 0.7597, F Adv: 0.5149\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.0993, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 3.3024\n",
      "Epoch [78/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0361, D_X Fake: 0.0466, D_X Total: 0.0414\n",
      "  D_Y Real: 0.0884, D_Y Fake: 0.0568, D_Y Total: 0.0726\n",
      "Generator Losses:\n",
      "  G Adv: 0.7963, F Adv: 0.6433\n",
      "  Cycle Photo: 0.0715, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1193, Perceptual Monet: 0.1794\n",
      "  Total G Loss: 4.0334\n",
      "Epoch [78/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1198, D_X Fake: 0.1720, D_X Total: 0.1459\n",
      "  D_Y Real: 0.0463, D_Y Fake: 0.0943, D_Y Total: 0.0703\n",
      "Generator Losses:\n",
      "  G Adv: 0.6804, F Adv: 0.5098\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1335\n",
      "  Total G Loss: 3.4748\n",
      "Epoch [78/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1603, D_X Fake: 0.1030, D_X Total: 0.1316\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0720, D_Y Total: 0.0595\n",
      "Generator Losses:\n",
      "  G Adv: 0.7911, F Adv: 0.5546\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1031, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.3926\n",
      "Epoch [78/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0709, D_X Fake: 0.0964, D_X Total: 0.0836\n",
      "  D_Y Real: 0.0610, D_Y Fake: 0.0466, D_Y Total: 0.0538\n",
      "Generator Losses:\n",
      "  G Adv: 0.8148, F Adv: 0.4640\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.1573, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.7509\n",
      "Epoch [78/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1576, D_X Fake: 0.0631, D_X Total: 0.1103\n",
      "  D_Y Real: 0.1036, D_Y Fake: 0.0646, D_Y Total: 0.0841\n",
      "Generator Losses:\n",
      "  G Adv: 0.7724, F Adv: 0.4873\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1496\n",
      "  Total G Loss: 3.4702\n",
      "Epoch [78/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0660, D_X Fake: 0.1385, D_X Total: 0.1023\n",
      "  D_Y Real: 0.0815, D_Y Fake: 0.1190, D_Y Total: 0.1002\n",
      "Generator Losses:\n",
      "  G Adv: 0.7014, F Adv: 0.4901\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1168, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.2352\n",
      "Epoch [78/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0402, D_X Fake: 0.1507, D_X Total: 0.0954\n",
      "  D_Y Real: 0.0769, D_Y Fake: 0.1135, D_Y Total: 0.0952\n",
      "Generator Losses:\n",
      "  G Adv: 0.5333, F Adv: 0.4002\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.0354\n",
      "Epoch [78/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1537, D_X Fake: 0.0812, D_X Total: 0.1175\n",
      "  D_Y Real: 0.1235, D_Y Fake: 0.0571, D_Y Total: 0.0903\n",
      "Generator Losses:\n",
      "  G Adv: 0.9350, F Adv: 0.5544\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.8115\n",
      "Epoch [78/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2390, D_X Fake: 0.0495, D_X Total: 0.1442\n",
      "  D_Y Real: 0.1020, D_Y Fake: 0.0456, D_Y Total: 0.0738\n",
      "Generator Losses:\n",
      "  G Adv: 1.0094, F Adv: 0.8094\n",
      "  Cycle Photo: 0.0510, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 4.1417\n",
      "Epoch [78/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1295, D_X Fake: 0.1150, D_X Total: 0.1223\n",
      "  D_Y Real: 0.0406, D_Y Fake: 0.0867, D_Y Total: 0.0636\n",
      "Generator Losses:\n",
      "  G Adv: 0.6755, F Adv: 0.5592\n",
      "  Cycle Photo: 0.0627, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1874\n",
      "  Total G Loss: 3.8341\n",
      "Epoch [78/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1370, D_X Fake: 0.1486, D_X Total: 0.1428\n",
      "  D_Y Real: 0.0515, D_Y Fake: 0.1332, D_Y Total: 0.0923\n",
      "Generator Losses:\n",
      "  G Adv: 0.5343, F Adv: 0.5007\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1679, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.2972\n",
      "Epoch [78/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.2782, D_X Total: 0.1734\n",
      "  D_Y Real: 0.0773, D_Y Fake: 0.0656, D_Y Total: 0.0715\n",
      "Generator Losses:\n",
      "  G Adv: 0.6844, F Adv: 0.2901\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1438\n",
      "  Total G Loss: 3.2336\n",
      "Epoch [78/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0542, D_X Fake: 0.0838, D_X Total: 0.0690\n",
      "  D_Y Real: 0.0481, D_Y Fake: 0.0799, D_Y Total: 0.0640\n",
      "Generator Losses:\n",
      "  G Adv: 0.6693, F Adv: 0.5536\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.5149\n",
      "Epoch [78/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2471, D_X Fake: 0.0604, D_X Total: 0.1538\n",
      "  D_Y Real: 0.0592, D_Y Fake: 0.0916, D_Y Total: 0.0754\n",
      "Generator Losses:\n",
      "  G Adv: 0.8847, F Adv: 0.6546\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1283, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.6838\n",
      "Epoch [78/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0498, D_X Fake: 0.3001, D_X Total: 0.1750\n",
      "  D_Y Real: 0.0948, D_Y Fake: 0.0879, D_Y Total: 0.0914\n",
      "Generator Losses:\n",
      "  G Adv: 0.6954, F Adv: 0.2890\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1255, Perceptual Monet: 0.1423\n",
      "  Total G Loss: 3.0647\n",
      "Epoch [78/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3410, D_X Fake: 0.0525, D_X Total: 0.1967\n",
      "  D_Y Real: 0.0769, D_Y Fake: 0.0697, D_Y Total: 0.0733\n",
      "Generator Losses:\n",
      "  G Adv: 0.9518, F Adv: 0.9240\n",
      "  Cycle Photo: 0.0415, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1707, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 4.3654\n",
      "Epoch [78/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0963, D_X Fake: 0.0768, D_X Total: 0.0866\n",
      "  D_Y Real: 0.0528, D_Y Fake: 0.0623, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.7509, F Adv: 0.7857\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1449\n",
      "  Total G Loss: 3.7502\n",
      "Epoch [78/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1062, D_X Fake: 0.0396, D_X Total: 0.0729\n",
      "  D_Y Real: 0.0665, D_Y Fake: 0.0435, D_Y Total: 0.0550\n",
      "Generator Losses:\n",
      "  G Adv: 0.8007, F Adv: 0.4929\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.4990\n",
      "Epoch [78/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0784, D_X Fake: 0.1313, D_X Total: 0.1049\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.1222, D_Y Total: 0.0761\n",
      "Generator Losses:\n",
      "  G Adv: 0.5213, F Adv: 0.4738\n",
      "  Cycle Photo: 0.0436, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.1924\n",
      "  Total G Loss: 3.6782\n",
      "Epoch [78/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1576, D_X Fake: 0.0409, D_X Total: 0.0992\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.1418, D_Y Total: 0.0878\n",
      "Generator Losses:\n",
      "  G Adv: 0.5613, F Adv: 0.6693\n",
      "  Cycle Photo: 0.0391, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1655, Perceptual Monet: 0.1203\n",
      "  Total G Loss: 3.2845\n",
      "Epoch [79/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1214, D_X Fake: 0.3299, D_X Total: 0.2256\n",
      "  D_Y Real: 0.1115, D_Y Fake: 0.0696, D_Y Total: 0.0905\n",
      "Generator Losses:\n",
      "  G Adv: 0.7317, F Adv: 0.2354\n",
      "  Cycle Photo: 0.0626, Cycle Monet: 0.0439\n",
      "  Perceptual Photo: 0.1747, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.7718\n",
      "Epoch [79/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1666, D_X Fake: 0.0469, D_X Total: 0.1067\n",
      "  D_Y Real: 0.0946, D_Y Fake: 0.0508, D_Y Total: 0.0727\n",
      "Generator Losses:\n",
      "  G Adv: 0.8366, F Adv: 0.4465\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1794, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.7606\n",
      "Epoch [79/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1156, D_X Fake: 0.1513, D_X Total: 0.1334\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.2342, D_Y Total: 0.1379\n",
      "Generator Losses:\n",
      "  G Adv: 0.5264, F Adv: 0.5426\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1510, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.6080\n",
      "Epoch [79/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0930, D_X Fake: 0.0713, D_X Total: 0.0821\n",
      "  D_Y Real: 0.0622, D_Y Fake: 0.0672, D_Y Total: 0.0647\n",
      "Generator Losses:\n",
      "  G Adv: 0.5671, F Adv: 0.5364\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 3.2315\n",
      "Epoch [79/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1794, D_X Fake: 0.0746, D_X Total: 0.1270\n",
      "  D_Y Real: 0.0870, D_Y Fake: 0.1264, D_Y Total: 0.1067\n",
      "Generator Losses:\n",
      "  G Adv: 0.5984, F Adv: 0.5298\n",
      "  Cycle Photo: 0.0436, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1832, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.5398\n",
      "Epoch [79/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3234, D_X Fake: 0.0382, D_X Total: 0.1808\n",
      "  D_Y Real: 0.0534, D_Y Fake: 0.0386, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.7192, F Adv: 0.8785\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1531\n",
      "  Total G Loss: 3.9352\n",
      "Epoch [79/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2091, D_X Fake: 0.0873, D_X Total: 0.1482\n",
      "  D_Y Real: 0.1773, D_Y Fake: 0.0401, D_Y Total: 0.1087\n",
      "Generator Losses:\n",
      "  G Adv: 0.8438, F Adv: 0.7132\n",
      "  Cycle Photo: 0.0745, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1949, Perceptual Monet: 0.1916\n",
      "  Total G Loss: 4.6496\n",
      "Epoch [79/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2746, D_X Fake: 0.0566, D_X Total: 0.1656\n",
      "  D_Y Real: 0.0801, D_Y Fake: 0.0565, D_Y Total: 0.0683\n",
      "Generator Losses:\n",
      "  G Adv: 0.8173, F Adv: 0.8176\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0444\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.1971\n",
      "  Total G Loss: 4.0082\n",
      "Epoch [79/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1548, D_X Fake: 0.0988, D_X Total: 0.1268\n",
      "  D_Y Real: 0.0537, D_Y Fake: 0.1030, D_Y Total: 0.0784\n",
      "Generator Losses:\n",
      "  G Adv: 0.6435, F Adv: 0.5783\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1392, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.6055\n",
      "Epoch [79/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2065, D_X Fake: 0.2452, D_X Total: 0.2259\n",
      "  D_Y Real: 0.0637, D_Y Fake: 0.0726, D_Y Total: 0.0682\n",
      "Generator Losses:\n",
      "  G Adv: 0.6896, F Adv: 0.4895\n",
      "  Cycle Photo: 0.0438, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.3305\n",
      "Epoch [79/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0390, D_X Fake: 0.2229, D_X Total: 0.1309\n",
      "  D_Y Real: 0.0486, D_Y Fake: 0.0610, D_Y Total: 0.0548\n",
      "Generator Losses:\n",
      "  G Adv: 0.9625, F Adv: 0.4375\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1523\n",
      "  Total G Loss: 3.5816\n",
      "Epoch [79/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0527, D_X Fake: 0.1418, D_X Total: 0.0972\n",
      "  D_Y Real: 0.1057, D_Y Fake: 0.0343, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.9476, F Adv: 0.3209\n",
      "  Cycle Photo: 0.0365, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1349, Perceptual Monet: 0.1354\n",
      "  Total G Loss: 3.2977\n",
      "Epoch [79/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0572, D_X Fake: 0.1461, D_X Total: 0.1017\n",
      "  D_Y Real: 0.0519, D_Y Fake: 0.0899, D_Y Total: 0.0709\n",
      "Generator Losses:\n",
      "  G Adv: 0.4707, F Adv: 0.3018\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 2.9046\n",
      "Epoch [79/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1120, D_X Fake: 0.0856, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0781, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.6361, F Adv: 0.2991\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1831\n",
      "  Total G Loss: 3.3498\n",
      "Epoch [79/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0914, D_X Fake: 0.1339, D_X Total: 0.1126\n",
      "  D_Y Real: 0.0454, D_Y Fake: 0.0605, D_Y Total: 0.0529\n",
      "Generator Losses:\n",
      "  G Adv: 0.6883, F Adv: 0.3350\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.3242\n",
      "Epoch [79/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0723, D_X Fake: 0.0894, D_X Total: 0.0809\n",
      "  D_Y Real: 0.1700, D_Y Fake: 0.0363, D_Y Total: 0.1031\n",
      "Generator Losses:\n",
      "  G Adv: 0.9957, F Adv: 0.4991\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1186, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.5904\n",
      "Epoch [79/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1854, D_X Fake: 0.0673, D_X Total: 0.1263\n",
      "  D_Y Real: 0.0335, D_Y Fake: 0.0461, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.4436, F Adv: 0.7600\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.7532\n",
      "Epoch [79/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0403, D_X Fake: 0.1017, D_X Total: 0.0710\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0722, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.5755, F Adv: 0.5719\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1619, Perceptual Monet: 0.1506\n",
      "  Total G Loss: 3.5770\n",
      "Epoch [79/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1484, D_X Fake: 0.0566, D_X Total: 0.1025\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.0832, D_Y Total: 0.0591\n",
      "Generator Losses:\n",
      "  G Adv: 0.4883, F Adv: 0.5708\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1159, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.2242\n",
      "Epoch [79/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1549, D_X Fake: 0.0857, D_X Total: 0.1203\n",
      "  D_Y Real: 0.0472, D_Y Fake: 0.1372, D_Y Total: 0.0922\n",
      "Generator Losses:\n",
      "  G Adv: 0.5601, F Adv: 0.5272\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1567, Perceptual Monet: 0.1497\n",
      "  Total G Loss: 3.2630\n",
      "Epoch [79/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1206, D_X Fake: 0.1291, D_X Total: 0.1248\n",
      "  D_Y Real: 0.1250, D_Y Fake: 0.0332, D_Y Total: 0.0791\n",
      "Generator Losses:\n",
      "  G Adv: 1.0381, F Adv: 0.4517\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 4.0653\n",
      "Epoch [79/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0595, D_X Fake: 0.0688, D_X Total: 0.0642\n",
      "  D_Y Real: 0.0681, D_Y Fake: 0.0575, D_Y Total: 0.0628\n",
      "Generator Losses:\n",
      "  G Adv: 0.8447, F Adv: 0.6143\n",
      "  Cycle Photo: 0.0572, Cycle Monet: 0.0415\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.9668\n",
      "Epoch [79/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2635, D_X Fake: 0.2304, D_X Total: 0.2469\n",
      "  D_Y Real: 0.1543, D_Y Fake: 0.0499, D_Y Total: 0.1021\n",
      "Generator Losses:\n",
      "  G Adv: 0.8301, F Adv: 0.4246\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5710\n",
      "Epoch [79/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1117, D_X Fake: 0.0904, D_X Total: 0.1010\n",
      "  D_Y Real: 0.0661, D_Y Fake: 0.0481, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.7209, F Adv: 0.4905\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1076, Perceptual Monet: 0.1368\n",
      "  Total G Loss: 3.1404\n",
      "Epoch [80/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2223, D_X Fake: 0.0623, D_X Total: 0.1423\n",
      "  D_Y Real: 0.0737, D_Y Fake: 0.1372, D_Y Total: 0.1055\n",
      "Generator Losses:\n",
      "  G Adv: 0.3899, F Adv: 0.6770\n",
      "  Cycle Photo: 0.0477, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.4282\n",
      "Epoch [80/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2008, D_X Fake: 0.0591, D_X Total: 0.1300\n",
      "  D_Y Real: 0.0442, D_Y Fake: 0.0635, D_Y Total: 0.0538\n",
      "Generator Losses:\n",
      "  G Adv: 0.5652, F Adv: 0.7771\n",
      "  Cycle Photo: 0.0428, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1853, Perceptual Monet: 0.1511\n",
      "  Total G Loss: 3.7666\n",
      "Epoch [80/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2387, D_X Fake: 0.0538, D_X Total: 0.1463\n",
      "  D_Y Real: 0.0553, D_Y Fake: 0.0673, D_Y Total: 0.0613\n",
      "Generator Losses:\n",
      "  G Adv: 0.6123, F Adv: 0.7839\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1550, Perceptual Monet: 0.1887\n",
      "  Total G Loss: 3.8601\n",
      "Epoch [80/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1131, D_X Fake: 0.2672, D_X Total: 0.1902\n",
      "  D_Y Real: 0.0472, D_Y Fake: 0.0878, D_Y Total: 0.0675\n",
      "Generator Losses:\n",
      "  G Adv: 0.3418, F Adv: 0.3249\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1527, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.0598\n",
      "Epoch [80/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3235, D_X Fake: 0.0605, D_X Total: 0.1920\n",
      "  D_Y Real: 0.0422, D_Y Fake: 0.0590, D_Y Total: 0.0506\n",
      "Generator Losses:\n",
      "  G Adv: 0.6719, F Adv: 0.8053\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1126, Perceptual Monet: 0.1465\n",
      "  Total G Loss: 3.3788\n",
      "Epoch [80/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0404, D_X Fake: 0.2569, D_X Total: 0.1487\n",
      "  D_Y Real: 0.0442, D_Y Fake: 0.0534, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 0.7946, F Adv: 0.2048\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.2285\n",
      "Epoch [80/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1039, D_X Fake: 0.0441, D_X Total: 0.0740\n",
      "  D_Y Real: 0.0936, D_Y Fake: 0.0755, D_Y Total: 0.0845\n",
      "Generator Losses:\n",
      "  G Adv: 0.6093, F Adv: 0.7195\n",
      "  Cycle Photo: 0.0485, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1578, Perceptual Monet: 0.1278\n",
      "  Total G Loss: 3.5003\n",
      "Epoch [80/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2067, D_X Fake: 0.0809, D_X Total: 0.1438\n",
      "  D_Y Real: 0.1857, D_Y Fake: 0.0610, D_Y Total: 0.1234\n",
      "Generator Losses:\n",
      "  G Adv: 0.7120, F Adv: 0.7024\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1377, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.5878\n",
      "Epoch [80/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1490, D_X Fake: 0.0985, D_X Total: 0.1238\n",
      "  D_Y Real: 0.0899, D_Y Fake: 0.0495, D_Y Total: 0.0697\n",
      "Generator Losses:\n",
      "  G Adv: 0.7040, F Adv: 0.4992\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1584, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.6190\n",
      "Epoch [80/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0679, D_X Fake: 0.0445, D_X Total: 0.0562\n",
      "  D_Y Real: 0.0365, D_Y Fake: 0.0579, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.6828, F Adv: 0.6889\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1772\n",
      "  Total G Loss: 3.8035\n",
      "Epoch [80/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1080, D_X Fake: 0.0713, D_X Total: 0.0897\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.1457, D_Y Total: 0.0947\n",
      "Generator Losses:\n",
      "  G Adv: 0.5387, F Adv: 0.6984\n",
      "  Cycle Photo: 0.0481, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1343, Perceptual Monet: 0.1974\n",
      "  Total G Loss: 3.8023\n",
      "Epoch [80/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0598, D_X Fake: 0.3927, D_X Total: 0.2263\n",
      "  D_Y Real: 0.0656, D_Y Fake: 0.0381, D_Y Total: 0.0518\n",
      "Generator Losses:\n",
      "  G Adv: 1.0314, F Adv: 0.2261\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0414\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1799\n",
      "  Total G Loss: 3.6798\n",
      "Epoch [80/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1148, D_X Fake: 0.1085, D_X Total: 0.1117\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.1454, D_Y Total: 0.0918\n",
      "Generator Losses:\n",
      "  G Adv: 0.6649, F Adv: 0.5882\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1932\n",
      "  Total G Loss: 3.8604\n",
      "Epoch [80/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0508, D_X Fake: 0.2290, D_X Total: 0.1399\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0818, D_Y Total: 0.0567\n",
      "Generator Losses:\n",
      "  G Adv: 0.7095, F Adv: 0.2303\n",
      "  Cycle Photo: 0.0520, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1520, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.4242\n",
      "Epoch [80/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0491, D_X Fake: 0.2215, D_X Total: 0.1353\n",
      "  D_Y Real: 0.0457, D_Y Fake: 0.0835, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.6554, F Adv: 0.3871\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.4313\n",
      "Epoch [80/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0902, D_X Fake: 0.0402, D_X Total: 0.0652\n",
      "  D_Y Real: 0.0737, D_Y Fake: 0.1076, D_Y Total: 0.0907\n",
      "Generator Losses:\n",
      "  G Adv: 0.5305, F Adv: 1.0350\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0487\n",
      "  Perceptual Photo: 0.1145, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 3.8475\n",
      "Epoch [80/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.0637, D_X Total: 0.0735\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0871, D_Y Total: 0.0557\n",
      "Generator Losses:\n",
      "  G Adv: 0.4591, F Adv: 0.5006\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.1491\n",
      "Epoch [80/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1689, D_X Fake: 0.0497, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.0832, D_Y Total: 0.0617\n",
      "Generator Losses:\n",
      "  G Adv: 0.4932, F Adv: 0.4055\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1362\n",
      "  Total G Loss: 2.8814\n",
      "Epoch [80/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0848, D_X Fake: 0.1084, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0715, D_Y Fake: 0.0415, D_Y Total: 0.0565\n",
      "Generator Losses:\n",
      "  G Adv: 0.9236, F Adv: 0.5817\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1276, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.8388\n",
      "Epoch [80/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0870, D_X Fake: 0.2857, D_X Total: 0.1864\n",
      "  D_Y Real: 0.0546, D_Y Fake: 0.0807, D_Y Total: 0.0676\n",
      "Generator Losses:\n",
      "  G Adv: 0.6915, F Adv: 0.2233\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1270\n",
      "  Total G Loss: 3.0746\n",
      "Epoch [80/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2005, D_X Fake: 0.0612, D_X Total: 0.1309\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.0770, D_Y Total: 0.0596\n",
      "Generator Losses:\n",
      "  G Adv: 0.8045, F Adv: 0.8728\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1544, Perceptual Monet: 0.1510\n",
      "  Total G Loss: 3.9441\n",
      "Epoch [80/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3790, D_X Fake: 0.0719, D_X Total: 0.2254\n",
      "  D_Y Real: 0.0569, D_Y Fake: 0.0507, D_Y Total: 0.0538\n",
      "Generator Losses:\n",
      "  G Adv: 0.7464, F Adv: 0.8941\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 4.0302\n",
      "Epoch [80/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3140, D_X Fake: 0.3553, D_X Total: 0.3347\n",
      "  D_Y Real: 0.0557, D_Y Fake: 0.0848, D_Y Total: 0.0703\n",
      "Generator Losses:\n",
      "  G Adv: 0.6968, F Adv: 0.2533\n",
      "  Cycle Photo: 0.0578, Cycle Monet: 0.0465\n",
      "  Perceptual Photo: 0.1895, Perceptual Monet: 0.1764\n",
      "  Total G Loss: 3.8225\n",
      "Epoch [80/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3791, D_X Fake: 0.1892, D_X Total: 0.2841\n",
      "  D_Y Real: 0.0914, D_Y Fake: 0.0529, D_Y Total: 0.0721\n",
      "Generator Losses:\n",
      "  G Adv: 0.9112, F Adv: 0.2860\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.3209\n",
      "Saved checkpoint at epoch 80\n",
      "Epoch [81/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3808, D_X Fake: 0.3136, D_X Total: 0.3472\n",
      "  D_Y Real: 0.0509, D_Y Fake: 0.1148, D_Y Total: 0.0828\n",
      "Generator Losses:\n",
      "  G Adv: 0.4630, F Adv: 0.3359\n",
      "  Cycle Photo: 0.0576, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1616, Perceptual Monet: 0.1401\n",
      "  Total G Loss: 3.2251\n",
      "Epoch [81/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3884, D_X Fake: 0.2360, D_X Total: 0.3122\n",
      "  D_Y Real: 0.0968, D_Y Fake: 0.1073, D_Y Total: 0.1020\n",
      "Generator Losses:\n",
      "  G Adv: 0.4795, F Adv: 0.3235\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 2.8867\n",
      "Epoch [81/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3350, D_X Fake: 0.2024, D_X Total: 0.2687\n",
      "  D_Y Real: 0.0494, D_Y Fake: 0.0557, D_Y Total: 0.0525\n",
      "Generator Losses:\n",
      "  G Adv: 0.9153, F Adv: 0.2897\n",
      "  Cycle Photo: 0.0766, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1666, Perceptual Monet: 0.1252\n",
      "  Total G Loss: 3.7712\n",
      "Epoch [81/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1736, D_X Fake: 0.3182, D_X Total: 0.2459\n",
      "  D_Y Real: 0.0683, D_Y Fake: 0.0402, D_Y Total: 0.0543\n",
      "Generator Losses:\n",
      "  G Adv: 0.9384, F Adv: 0.2349\n",
      "  Cycle Photo: 0.0450, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1267, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.3326\n",
      "Epoch [81/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2990, D_X Fake: 0.2988, D_X Total: 0.2989\n",
      "  D_Y Real: 0.0488, D_Y Fake: 0.0955, D_Y Total: 0.0721\n",
      "Generator Losses:\n",
      "  G Adv: 0.5029, F Adv: 0.2406\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1567, Perceptual Monet: 0.1269\n",
      "  Total G Loss: 2.8445\n",
      "Epoch [81/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3094, D_X Fake: 0.2319, D_X Total: 0.2707\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.1360, D_Y Total: 0.0846\n",
      "Generator Losses:\n",
      "  G Adv: 0.4412, F Adv: 0.3911\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1186, Perceptual Monet: 0.1256\n",
      "  Total G Loss: 2.8450\n",
      "Epoch [81/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2597, D_X Fake: 0.2404, D_X Total: 0.2501\n",
      "  D_Y Real: 0.1538, D_Y Fake: 0.1395, D_Y Total: 0.1467\n",
      "Generator Losses:\n",
      "  G Adv: 0.6237, F Adv: 0.2497\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1698, Perceptual Monet: 0.1289\n",
      "  Total G Loss: 3.0758\n",
      "Epoch [81/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2360, D_X Fake: 0.3206, D_X Total: 0.2783\n",
      "  D_Y Real: 0.0616, D_Y Fake: 0.1757, D_Y Total: 0.1187\n",
      "Generator Losses:\n",
      "  G Adv: 0.4090, F Adv: 0.2340\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1161, Perceptual Monet: 0.1046\n",
      "  Total G Loss: 2.3240\n",
      "Epoch [81/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3334, D_X Fake: 0.1938, D_X Total: 0.2636\n",
      "  D_Y Real: 0.0612, D_Y Fake: 0.0726, D_Y Total: 0.0669\n",
      "Generator Losses:\n",
      "  G Adv: 0.7824, F Adv: 0.3525\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1444, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.5487\n",
      "Epoch [81/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2088, D_X Fake: 0.3219, D_X Total: 0.2654\n",
      "  D_Y Real: 0.0625, D_Y Fake: 0.0997, D_Y Total: 0.0811\n",
      "Generator Losses:\n",
      "  G Adv: 0.6937, F Adv: 0.2331\n",
      "  Cycle Photo: 0.0506, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1274\n",
      "  Total G Loss: 3.1795\n",
      "Epoch [81/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1904, D_X Fake: 0.2981, D_X Total: 0.2442\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.0380, D_Y Total: 0.0530\n",
      "Generator Losses:\n",
      "  G Adv: 0.9574, F Adv: 0.2709\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1410, Perceptual Monet: 0.1371\n",
      "  Total G Loss: 3.3113\n",
      "Epoch [81/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2626, D_X Fake: 0.3065, D_X Total: 0.2845\n",
      "  D_Y Real: 0.1519, D_Y Fake: 0.0389, D_Y Total: 0.0954\n",
      "Generator Losses:\n",
      "  G Adv: 1.0093, F Adv: 0.3150\n",
      "  Cycle Photo: 0.0480, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.6952\n",
      "Epoch [81/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2800, D_X Fake: 0.2827, D_X Total: 0.2813\n",
      "  D_Y Real: 0.1334, D_Y Fake: 0.0662, D_Y Total: 0.0998\n",
      "Generator Losses:\n",
      "  G Adv: 0.8719, F Adv: 0.2615\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1417, Perceptual Monet: 0.1421\n",
      "  Total G Loss: 3.2930\n",
      "Epoch [81/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2240, D_X Fake: 0.2467, D_X Total: 0.2353\n",
      "  D_Y Real: 0.1061, D_Y Fake: 0.0746, D_Y Total: 0.0903\n",
      "Generator Losses:\n",
      "  G Adv: 0.6968, F Adv: 0.2661\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1190, Perceptual Monet: 0.1297\n",
      "  Total G Loss: 2.8200\n",
      "Epoch [81/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1950, D_X Fake: 0.2692, D_X Total: 0.2321\n",
      "  D_Y Real: 0.0403, D_Y Fake: 0.0858, D_Y Total: 0.0631\n",
      "Generator Losses:\n",
      "  G Adv: 0.9057, F Adv: 0.2437\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1299, Perceptual Monet: 0.1100\n",
      "  Total G Loss: 2.9958\n",
      "Epoch [81/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2838, D_X Fake: 0.2548, D_X Total: 0.2693\n",
      "  D_Y Real: 0.0663, D_Y Fake: 0.0341, D_Y Total: 0.0502\n",
      "Generator Losses:\n",
      "  G Adv: 0.9424, F Adv: 0.3507\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1344, Perceptual Monet: 0.1212\n",
      "  Total G Loss: 3.1983\n",
      "Epoch [81/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2954, D_X Fake: 0.1914, D_X Total: 0.2434\n",
      "  D_Y Real: 0.0662, D_Y Fake: 0.1114, D_Y Total: 0.0888\n",
      "Generator Losses:\n",
      "  G Adv: 0.6066, F Adv: 0.3187\n",
      "  Cycle Photo: 0.0619, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1445\n",
      "  Total G Loss: 3.2856\n",
      "Epoch [81/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3578, D_X Fake: 0.1793, D_X Total: 0.2685\n",
      "  D_Y Real: 0.0708, D_Y Fake: 0.0382, D_Y Total: 0.0545\n",
      "Generator Losses:\n",
      "  G Adv: 0.9015, F Adv: 0.2820\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1291, Perceptual Monet: 0.1088\n",
      "  Total G Loss: 3.0346\n",
      "Epoch [81/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1837, D_X Fake: 0.1724, D_X Total: 0.1780\n",
      "  D_Y Real: 0.0469, D_Y Fake: 0.0663, D_Y Total: 0.0566\n",
      "Generator Losses:\n",
      "  G Adv: 0.7541, F Adv: 0.2865\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1218, Perceptual Monet: 0.1134\n",
      "  Total G Loss: 2.8739\n",
      "Epoch [81/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2434, D_X Fake: 0.2183, D_X Total: 0.2309\n",
      "  D_Y Real: 0.0524, D_Y Fake: 0.0748, D_Y Total: 0.0636\n",
      "Generator Losses:\n",
      "  G Adv: 0.6082, F Adv: 0.2431\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1363\n",
      "  Total G Loss: 2.7742\n",
      "Epoch [81/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2763, D_X Fake: 0.2588, D_X Total: 0.2676\n",
      "  D_Y Real: 0.1014, D_Y Fake: 0.0346, D_Y Total: 0.0680\n",
      "Generator Losses:\n",
      "  G Adv: 0.7405, F Adv: 0.2608\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1319, Perceptual Monet: 0.0942\n",
      "  Total G Loss: 2.8426\n",
      "Epoch [81/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2944, D_X Fake: 0.1380, D_X Total: 0.2162\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0545, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.5896, F Adv: 0.3743\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1853, Perceptual Monet: 0.1266\n",
      "  Total G Loss: 3.3086\n",
      "Epoch [81/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1400, D_X Fake: 0.1439, D_X Total: 0.1419\n",
      "  D_Y Real: 0.0942, D_Y Fake: 0.0461, D_Y Total: 0.0702\n",
      "Generator Losses:\n",
      "  G Adv: 0.9986, F Adv: 0.4213\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1154\n",
      "  Total G Loss: 3.3404\n",
      "Epoch [81/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0961, D_X Fake: 0.0667, D_X Total: 0.0814\n",
      "  D_Y Real: 0.1251, D_Y Fake: 0.0815, D_Y Total: 0.1033\n",
      "Generator Losses:\n",
      "  G Adv: 0.9392, F Adv: 0.4160\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1362, Perceptual Monet: 0.1509\n",
      "  Total G Loss: 3.5598\n",
      "Epoch [82/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1205, D_X Fake: 0.0963, D_X Total: 0.1084\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.1351, D_Y Total: 0.0880\n",
      "Generator Losses:\n",
      "  G Adv: 0.6430, F Adv: 0.5009\n",
      "  Cycle Photo: 0.0549, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1389, Perceptual Monet: 0.1104\n",
      "  Total G Loss: 3.1733\n",
      "Epoch [82/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0826, D_X Fake: 0.1674, D_X Total: 0.1250\n",
      "  D_Y Real: 0.0480, D_Y Fake: 0.0734, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.7286, F Adv: 0.3464\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1523\n",
      "  Total G Loss: 3.3778\n",
      "Epoch [82/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0537, D_X Fake: 0.1036, D_X Total: 0.0787\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.1440, D_Y Total: 0.0926\n",
      "Generator Losses:\n",
      "  G Adv: 0.4943, F Adv: 0.4567\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.1194\n",
      "Epoch [82/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1007, D_X Fake: 0.0789, D_X Total: 0.0898\n",
      "  D_Y Real: 0.0730, D_Y Fake: 0.0441, D_Y Total: 0.0586\n",
      "Generator Losses:\n",
      "  G Adv: 0.8512, F Adv: 0.5957\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.7765\n",
      "Epoch [82/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0679, D_X Fake: 0.0719, D_X Total: 0.0699\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.1423, D_Y Total: 0.0929\n",
      "Generator Losses:\n",
      "  G Adv: 0.6259, F Adv: 0.5660\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1684, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.4690\n",
      "Epoch [82/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1003, D_X Fake: 0.0979, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0365, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.9161, F Adv: 0.4860\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1563\n",
      "  Total G Loss: 3.7359\n",
      "Epoch [82/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1616, D_X Fake: 0.0836, D_X Total: 0.1226\n",
      "  D_Y Real: 0.0371, D_Y Fake: 0.0686, D_Y Total: 0.0528\n",
      "Generator Losses:\n",
      "  G Adv: 0.9450, F Adv: 0.5099\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1626\n",
      "  Total G Loss: 3.7085\n",
      "Epoch [82/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0570, D_X Fake: 0.0769, D_X Total: 0.0669\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.1127, D_Y Total: 0.0771\n",
      "Generator Losses:\n",
      "  G Adv: 0.6074, F Adv: 0.4494\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.4565\n",
      "Epoch [82/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1577, D_X Fake: 0.0275, D_X Total: 0.0926\n",
      "  D_Y Real: 0.0755, D_Y Fake: 0.0848, D_Y Total: 0.0802\n",
      "Generator Losses:\n",
      "  G Adv: 0.5621, F Adv: 0.6352\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.5471\n",
      "Epoch [82/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0634, D_X Fake: 0.0632, D_X Total: 0.0633\n",
      "  D_Y Real: 0.0531, D_Y Fake: 0.0697, D_Y Total: 0.0614\n",
      "Generator Losses:\n",
      "  G Adv: 0.6152, F Adv: 0.4066\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1384, Perceptual Monet: 0.1577\n",
      "  Total G Loss: 3.2755\n",
      "Epoch [82/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0660, D_X Fake: 0.1253, D_X Total: 0.0957\n",
      "  D_Y Real: 0.1379, D_Y Fake: 0.0626, D_Y Total: 0.1003\n",
      "Generator Losses:\n",
      "  G Adv: 0.8167, F Adv: 0.5054\n",
      "  Cycle Photo: 0.0503, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.6257\n",
      "Epoch [82/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0959, D_X Fake: 0.1996, D_X Total: 0.1478\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0816, D_Y Total: 0.0603\n",
      "Generator Losses:\n",
      "  G Adv: 0.6537, F Adv: 0.2977\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1677, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.4367\n",
      "Epoch [82/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1024, D_X Fake: 0.1557, D_X Total: 0.1290\n",
      "  D_Y Real: 0.0545, D_Y Fake: 0.0983, D_Y Total: 0.0764\n",
      "Generator Losses:\n",
      "  G Adv: 0.7232, F Adv: 0.4093\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.4969\n",
      "Epoch [82/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2567, D_X Fake: 0.0396, D_X Total: 0.1482\n",
      "  D_Y Real: 0.0836, D_Y Fake: 0.0415, D_Y Total: 0.0626\n",
      "Generator Losses:\n",
      "  G Adv: 0.9264, F Adv: 0.6683\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1590, Perceptual Monet: 0.1559\n",
      "  Total G Loss: 3.9374\n",
      "Epoch [82/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2158, D_X Fake: 0.0629, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0785, D_Y Fake: 0.0907, D_Y Total: 0.0846\n",
      "Generator Losses:\n",
      "  G Adv: 0.7589, F Adv: 0.6436\n",
      "  Cycle Photo: 0.0565, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1879, Perceptual Monet: 0.1174\n",
      "  Total G Loss: 3.7433\n",
      "Epoch [82/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1492, D_X Fake: 0.2308, D_X Total: 0.1900\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0604, D_Y Total: 0.0457\n",
      "Generator Losses:\n",
      "  G Adv: 0.5849, F Adv: 0.2556\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1515\n",
      "  Total G Loss: 2.8880\n",
      "Epoch [82/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0357, D_X Fake: 0.0590, D_X Total: 0.0474\n",
      "  D_Y Real: 0.0555, D_Y Fake: 0.0992, D_Y Total: 0.0774\n",
      "Generator Losses:\n",
      "  G Adv: 0.5905, F Adv: 0.5904\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0426\n",
      "  Perceptual Photo: 0.1640, Perceptual Monet: 0.1933\n",
      "  Total G Loss: 3.8709\n",
      "Epoch [82/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0603, D_X Fake: 0.2449, D_X Total: 0.1526\n",
      "  D_Y Real: 0.0634, D_Y Fake: 0.0553, D_Y Total: 0.0593\n",
      "Generator Losses:\n",
      "  G Adv: 0.7058, F Adv: 0.4630\n",
      "  Cycle Photo: 0.0567, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.5871\n",
      "Epoch [82/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0510, D_X Fake: 0.1123, D_X Total: 0.0817\n",
      "  D_Y Real: 0.1404, D_Y Fake: 0.0464, D_Y Total: 0.0934\n",
      "Generator Losses:\n",
      "  G Adv: 1.2288, F Adv: 0.4318\n",
      "  Cycle Photo: 0.0451, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1958, Perceptual Monet: 0.1431\n",
      "  Total G Loss: 4.2291\n",
      "Epoch [82/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0324, D_X Fake: 0.0542, D_X Total: 0.0433\n",
      "  D_Y Real: 0.0791, D_Y Fake: 0.0343, D_Y Total: 0.0567\n",
      "Generator Losses:\n",
      "  G Adv: 0.7860, F Adv: 0.5703\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0455\n",
      "  Perceptual Photo: 0.1202, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 3.6752\n",
      "Epoch [82/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0665, D_X Fake: 0.0621, D_X Total: 0.0643\n",
      "  D_Y Real: 0.1770, D_Y Fake: 0.0541, D_Y Total: 0.1156\n",
      "Generator Losses:\n",
      "  G Adv: 1.1716, F Adv: 0.5518\n",
      "  Cycle Photo: 0.0425, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1550\n",
      "  Total G Loss: 3.9243\n",
      "Epoch [82/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.0999, D_X Total: 0.1882\n",
      "  D_Y Real: 0.0453, D_Y Fake: 0.0676, D_Y Total: 0.0564\n",
      "Generator Losses:\n",
      "  G Adv: 0.6580, F Adv: 0.5806\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1554, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.5624\n",
      "Epoch [82/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0736, D_X Fake: 0.1888, D_X Total: 0.1312\n",
      "  D_Y Real: 0.1651, D_Y Fake: 0.0573, D_Y Total: 0.1112\n",
      "Generator Losses:\n",
      "  G Adv: 1.0932, F Adv: 0.3541\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1790, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.9622\n",
      "Epoch [82/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0940, D_X Fake: 0.1341, D_X Total: 0.1140\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.1731, D_Y Total: 0.0994\n",
      "Generator Losses:\n",
      "  G Adv: 0.5802, F Adv: 0.2883\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1089, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 2.9003\n",
      "Epoch [83/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0697, D_X Fake: 0.0370, D_X Total: 0.0534\n",
      "  D_Y Real: 0.0674, D_Y Fake: 0.1251, D_Y Total: 0.0963\n",
      "Generator Losses:\n",
      "  G Adv: 0.6454, F Adv: 0.7717\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0448\n",
      "  Perceptual Photo: 0.1113, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.5758\n",
      "Epoch [83/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1259, D_X Fake: 0.0534, D_X Total: 0.0897\n",
      "  D_Y Real: 0.1452, D_Y Fake: 0.0468, D_Y Total: 0.0960\n",
      "Generator Losses:\n",
      "  G Adv: 1.0747, F Adv: 0.7383\n",
      "  Cycle Photo: 0.0532, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1931, Perceptual Monet: 0.1365\n",
      "  Total G Loss: 4.2467\n",
      "Epoch [83/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2879, D_X Fake: 0.0643, D_X Total: 0.1761\n",
      "  D_Y Real: 0.0506, D_Y Fake: 0.0448, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.6421, F Adv: 0.7527\n",
      "  Cycle Photo: 0.0422, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.6800\n",
      "Epoch [83/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3008, D_X Fake: 0.0775, D_X Total: 0.1892\n",
      "  D_Y Real: 0.0428, D_Y Fake: 0.2253, D_Y Total: 0.1341\n",
      "Generator Losses:\n",
      "  G Adv: 0.3374, F Adv: 0.6224\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1571\n",
      "  Total G Loss: 3.1639\n",
      "Epoch [83/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1987, D_X Fake: 0.0707, D_X Total: 0.1347\n",
      "  D_Y Real: 0.0514, D_Y Fake: 0.0894, D_Y Total: 0.0704\n",
      "Generator Losses:\n",
      "  G Adv: 0.7222, F Adv: 0.5665\n",
      "  Cycle Photo: 0.0610, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.1929, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 4.0755\n",
      "Epoch [83/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1020, D_X Fake: 0.1688, D_X Total: 0.1354\n",
      "  D_Y Real: 0.1095, D_Y Fake: 0.0983, D_Y Total: 0.1039\n",
      "Generator Losses:\n",
      "  G Adv: 0.7861, F Adv: 0.3111\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1862\n",
      "  Total G Loss: 3.5288\n",
      "Epoch [83/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1582, D_X Fake: 0.1081, D_X Total: 0.1331\n",
      "  D_Y Real: 0.0365, D_Y Fake: 0.0713, D_Y Total: 0.0539\n",
      "Generator Losses:\n",
      "  G Adv: 0.6701, F Adv: 0.5654\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.2004, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.8577\n",
      "Epoch [83/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2669, D_X Fake: 0.1359, D_X Total: 0.2014\n",
      "  D_Y Real: 0.0711, D_Y Fake: 0.1243, D_Y Total: 0.0977\n",
      "Generator Losses:\n",
      "  G Adv: 0.6678, F Adv: 0.5134\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.2258\n",
      "Epoch [83/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2268, D_X Fake: 0.0481, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0583, D_Y Fake: 0.0468, D_Y Total: 0.0526\n",
      "Generator Losses:\n",
      "  G Adv: 0.7432, F Adv: 0.8079\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.9827\n",
      "Epoch [83/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1879, D_X Fake: 0.0433, D_X Total: 0.1156\n",
      "  D_Y Real: 0.0370, D_Y Fake: 0.2020, D_Y Total: 0.1195\n",
      "Generator Losses:\n",
      "  G Adv: 0.4974, F Adv: 0.7430\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1199, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.2091\n",
      "Epoch [83/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1439, D_X Fake: 0.1067, D_X Total: 0.1253\n",
      "  D_Y Real: 0.0760, D_Y Fake: 0.1591, D_Y Total: 0.1175\n",
      "Generator Losses:\n",
      "  G Adv: 0.5127, F Adv: 0.5122\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0425\n",
      "  Perceptual Photo: 0.1112, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.1066\n",
      "Epoch [83/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0972, D_X Fake: 0.1189, D_X Total: 0.1080\n",
      "  D_Y Real: 0.0615, D_Y Fake: 0.0739, D_Y Total: 0.0677\n",
      "Generator Losses:\n",
      "  G Adv: 0.6609, F Adv: 0.3964\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1400\n",
      "  Total G Loss: 3.2524\n",
      "Epoch [83/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1462, D_X Fake: 0.0998, D_X Total: 0.1230\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.1865, D_Y Total: 0.1132\n",
      "Generator Losses:\n",
      "  G Adv: 0.3979, F Adv: 0.7707\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1468, Perceptual Monet: 0.1497\n",
      "  Total G Loss: 3.3795\n",
      "Epoch [83/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0558, D_X Fake: 0.1087, D_X Total: 0.0822\n",
      "  D_Y Real: 0.1601, D_Y Fake: 0.0826, D_Y Total: 0.1213\n",
      "Generator Losses:\n",
      "  G Adv: 0.5481, F Adv: 0.3779\n",
      "  Cycle Photo: 0.0562, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1684, Perceptual Monet: 0.1812\n",
      "  Total G Loss: 3.6132\n",
      "Epoch [83/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1420, D_X Fake: 0.1519, D_X Total: 0.1469\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.1794, D_Y Total: 0.1090\n",
      "Generator Losses:\n",
      "  G Adv: 0.4509, F Adv: 0.4963\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1254, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.0449\n",
      "Epoch [83/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2199, D_X Fake: 0.0817, D_X Total: 0.1508\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.1014, D_Y Total: 0.0725\n",
      "Generator Losses:\n",
      "  G Adv: 0.5514, F Adv: 0.5703\n",
      "  Cycle Photo: 0.0543, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1457, Perceptual Monet: 0.1640\n",
      "  Total G Loss: 3.5559\n",
      "Epoch [83/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1743, D_X Fake: 0.0814, D_X Total: 0.1279\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.0853, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.6114, F Adv: 0.4834\n",
      "  Cycle Photo: 0.0471, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1739, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.4983\n",
      "Epoch [83/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0688, D_X Fake: 0.1308, D_X Total: 0.0998\n",
      "  D_Y Real: 0.0507, D_Y Fake: 0.0605, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.8377, F Adv: 0.3387\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1625, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.5262\n",
      "Epoch [83/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0793, D_X Fake: 0.1235, D_X Total: 0.1014\n",
      "  D_Y Real: 0.0700, D_Y Fake: 0.0397, D_Y Total: 0.0549\n",
      "Generator Losses:\n",
      "  G Adv: 0.9150, F Adv: 0.4844\n",
      "  Cycle Photo: 0.0593, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 3.9586\n",
      "Epoch [83/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1473, D_X Fake: 0.1859, D_X Total: 0.1666\n",
      "  D_Y Real: 0.0448, D_Y Fake: 0.0509, D_Y Total: 0.0479\n",
      "Generator Losses:\n",
      "  G Adv: 0.7710, F Adv: 0.3745\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1569, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.3819\n",
      "Epoch [83/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2344, D_X Fake: 0.1117, D_X Total: 0.1730\n",
      "  D_Y Real: 0.0286, D_Y Fake: 0.0427, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.8308, F Adv: 0.6406\n",
      "  Cycle Photo: 0.0432, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1543\n",
      "  Total G Loss: 3.8276\n",
      "Epoch [83/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1365, D_X Fake: 0.0516, D_X Total: 0.0941\n",
      "  D_Y Real: 0.0567, D_Y Fake: 0.0471, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.9109, F Adv: 0.6598\n",
      "  Cycle Photo: 0.0697, Cycle Monet: 0.0391\n",
      "  Perceptual Photo: 0.1128, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 4.0839\n",
      "Epoch [83/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0755, D_X Fake: 0.2006, D_X Total: 0.1380\n",
      "  D_Y Real: 0.1141, D_Y Fake: 0.0415, D_Y Total: 0.0778\n",
      "Generator Losses:\n",
      "  G Adv: 1.2658, F Adv: 0.4021\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1717, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 4.1114\n",
      "Epoch [83/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0926, D_X Fake: 0.1592, D_X Total: 0.1259\n",
      "  D_Y Real: 0.0664, D_Y Fake: 0.0443, D_Y Total: 0.0553\n",
      "Generator Losses:\n",
      "  G Adv: 0.8986, F Adv: 0.3232\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.7046\n",
      "Epoch [84/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2379, D_X Fake: 0.0510, D_X Total: 0.1444\n",
      "  D_Y Real: 0.1037, D_Y Fake: 0.0686, D_Y Total: 0.0862\n",
      "Generator Losses:\n",
      "  G Adv: 0.8504, F Adv: 0.5103\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1606, Perceptual Monet: 0.1359\n",
      "  Total G Loss: 3.4528\n",
      "Epoch [84/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0836, D_X Fake: 0.1331, D_X Total: 0.1084\n",
      "  D_Y Real: 0.2549, D_Y Fake: 0.0843, D_Y Total: 0.1696\n",
      "Generator Losses:\n",
      "  G Adv: 1.0628, F Adv: 0.6605\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1299, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 4.2264\n",
      "Epoch [84/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0624, D_X Fake: 0.1625, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0532, D_Y Fake: 0.0833, D_Y Total: 0.0683\n",
      "Generator Losses:\n",
      "  G Adv: 0.7327, F Adv: 0.3197\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1963\n",
      "  Total G Loss: 3.4916\n",
      "Epoch [84/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2497, D_X Fake: 0.1394, D_X Total: 0.1945\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0376, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8483, F Adv: 0.4942\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.4598\n",
      "Epoch [84/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1172, D_X Fake: 0.1197, D_X Total: 0.1184\n",
      "  D_Y Real: 0.1312, D_Y Fake: 0.0478, D_Y Total: 0.0895\n",
      "Generator Losses:\n",
      "  G Adv: 0.8430, F Adv: 0.4985\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.9047\n",
      "Epoch [84/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2272, D_X Fake: 0.2005, D_X Total: 0.2138\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.0439, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.4545, F Adv: 0.2497\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0475\n",
      "  Perceptual Photo: 0.1204, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.0268\n",
      "Epoch [84/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0857, D_X Fake: 0.0929, D_X Total: 0.0893\n",
      "  D_Y Real: 0.0444, D_Y Fake: 0.1601, D_Y Total: 0.1022\n",
      "Generator Losses:\n",
      "  G Adv: 0.3754, F Adv: 0.5368\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1581, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.0589\n",
      "Epoch [84/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1677, D_X Fake: 0.0712, D_X Total: 0.1195\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.2467, D_Y Total: 0.1444\n",
      "Generator Losses:\n",
      "  G Adv: 0.3637, F Adv: 0.6514\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1188\n",
      "  Total G Loss: 3.1042\n",
      "Epoch [84/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2010, D_X Fake: 0.1177, D_X Total: 0.1593\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.0782, D_Y Total: 0.0577\n",
      "Generator Losses:\n",
      "  G Adv: 0.7386, F Adv: 0.5616\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0413\n",
      "  Perceptual Photo: 0.1486, Perceptual Monet: 0.1538\n",
      "  Total G Loss: 3.6833\n",
      "Epoch [84/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.0410, D_X Total: 0.1588\n",
      "  D_Y Real: 0.0598, D_Y Fake: 0.0652, D_Y Total: 0.0625\n",
      "Generator Losses:\n",
      "  G Adv: 0.7722, F Adv: 0.7969\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1785\n",
      "  Total G Loss: 3.9395\n",
      "Epoch [84/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0640, D_X Fake: 0.1097, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.1641, D_Y Total: 0.1056\n",
      "Generator Losses:\n",
      "  G Adv: 0.5220, F Adv: 0.6640\n",
      "  Cycle Photo: 0.0501, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1103, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 3.4779\n",
      "Epoch [84/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0617, D_X Fake: 0.1488, D_X Total: 0.1053\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0961, D_Y Total: 0.0683\n",
      "Generator Losses:\n",
      "  G Adv: 0.8211, F Adv: 0.4728\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1457, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.6295\n",
      "Epoch [84/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2745, D_X Fake: 0.1846, D_X Total: 0.2295\n",
      "  D_Y Real: 0.0494, D_Y Fake: 0.1764, D_Y Total: 0.1129\n",
      "Generator Losses:\n",
      "  G Adv: 0.6076, F Adv: 0.2986\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1517\n",
      "  Total G Loss: 3.1706\n",
      "Epoch [84/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1744, D_X Fake: 0.1232, D_X Total: 0.1488\n",
      "  D_Y Real: 0.0429, D_Y Fake: 0.1070, D_Y Total: 0.0749\n",
      "Generator Losses:\n",
      "  G Adv: 0.6479, F Adv: 0.5453\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1665, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.7476\n",
      "Epoch [84/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1640, D_X Fake: 0.0706, D_X Total: 0.1173\n",
      "  D_Y Real: 0.1209, D_Y Fake: 0.0432, D_Y Total: 0.0821\n",
      "Generator Losses:\n",
      "  G Adv: 0.9896, F Adv: 0.5363\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1481, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.7940\n",
      "Epoch [84/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1660, D_X Fake: 0.0611, D_X Total: 0.1136\n",
      "  D_Y Real: 0.0652, D_Y Fake: 0.0363, D_Y Total: 0.0507\n",
      "Generator Losses:\n",
      "  G Adv: 0.8678, F Adv: 0.5340\n",
      "  Cycle Photo: 0.0447, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1665, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.8263\n",
      "Epoch [84/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1348, D_X Fake: 0.0391, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0939, D_Y Total: 0.0672\n",
      "Generator Losses:\n",
      "  G Adv: 0.7198, F Adv: 0.6613\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.7223\n",
      "Epoch [84/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5425, D_X Fake: 0.0875, D_X Total: 0.3150\n",
      "  D_Y Real: 0.0688, D_Y Fake: 0.0986, D_Y Total: 0.0837\n",
      "Generator Losses:\n",
      "  G Adv: 0.6250, F Adv: 1.0133\n",
      "  Cycle Photo: 0.0376, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1130, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.8485\n",
      "Epoch [84/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2046, D_X Fake: 0.1461, D_X Total: 0.1754\n",
      "  D_Y Real: 0.0730, D_Y Fake: 0.0846, D_Y Total: 0.0788\n",
      "Generator Losses:\n",
      "  G Adv: 0.5155, F Adv: 0.3966\n",
      "  Cycle Photo: 0.0656, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1709, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.5500\n",
      "Epoch [84/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0981, D_X Fake: 0.1190, D_X Total: 0.1086\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0579, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.7261, F Adv: 0.4665\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.5871\n",
      "Epoch [84/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1440, D_X Fake: 0.1607, D_X Total: 0.1523\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.0592, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.7022, F Adv: 0.5812\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1289, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 3.4489\n",
      "Epoch [84/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2222, D_X Fake: 0.1521, D_X Total: 0.1871\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.1742, D_Y Total: 0.0975\n",
      "Generator Losses:\n",
      "  G Adv: 0.5145, F Adv: 0.9927\n",
      "  Cycle Photo: 0.0661, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1885, Perceptual Monet: 0.1419\n",
      "  Total G Loss: 4.1364\n",
      "Epoch [84/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0854, D_X Fake: 0.1666, D_X Total: 0.1260\n",
      "  D_Y Real: 0.1437, D_Y Fake: 0.0627, D_Y Total: 0.1032\n",
      "Generator Losses:\n",
      "  G Adv: 0.9679, F Adv: 0.4068\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1463\n",
      "  Total G Loss: 3.6063\n",
      "Epoch [84/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1293, D_X Fake: 0.0422, D_X Total: 0.0858\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.1300, D_Y Total: 0.0825\n",
      "Generator Losses:\n",
      "  G Adv: 0.4771, F Adv: 0.6450\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1781, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.5525\n",
      "Epoch [85/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0375, D_X Fake: 0.2669, D_X Total: 0.1522\n",
      "  D_Y Real: 0.1338, D_Y Fake: 0.0578, D_Y Total: 0.0958\n",
      "Generator Losses:\n",
      "  G Adv: 1.0541, F Adv: 0.3228\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1833\n",
      "  Total G Loss: 3.9794\n",
      "Epoch [85/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1216, D_X Fake: 0.0595, D_X Total: 0.0905\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.1472, D_Y Total: 0.1057\n",
      "Generator Losses:\n",
      "  G Adv: 0.6591, F Adv: 0.6475\n",
      "  Cycle Photo: 0.0569, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1787\n",
      "  Total G Loss: 3.9412\n",
      "Epoch [85/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1407, D_X Fake: 0.1240, D_X Total: 0.1324\n",
      "  D_Y Real: 0.1430, D_Y Fake: 0.0529, D_Y Total: 0.0979\n",
      "Generator Losses:\n",
      "  G Adv: 1.2116, F Adv: 0.5895\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1407\n",
      "  Total G Loss: 4.0754\n",
      "Epoch [85/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2485, D_X Fake: 0.0598, D_X Total: 0.1541\n",
      "  D_Y Real: 0.0775, D_Y Fake: 0.1820, D_Y Total: 0.1297\n",
      "Generator Losses:\n",
      "  G Adv: 0.4865, F Adv: 0.8126\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1211, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.5056\n",
      "Epoch [85/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1471, D_X Fake: 0.2550, D_X Total: 0.2010\n",
      "  D_Y Real: 0.0778, D_Y Fake: 0.0618, D_Y Total: 0.0698\n",
      "Generator Losses:\n",
      "  G Adv: 0.7392, F Adv: 0.2808\n",
      "  Cycle Photo: 0.0604, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 3.4939\n",
      "Epoch [85/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3191, D_X Fake: 0.0604, D_X Total: 0.1897\n",
      "  D_Y Real: 0.0613, D_Y Fake: 0.0474, D_Y Total: 0.0544\n",
      "Generator Losses:\n",
      "  G Adv: 0.9248, F Adv: 0.6556\n",
      "  Cycle Photo: 0.0494, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 4.1297\n",
      "Epoch [85/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1793, D_X Fake: 0.0843, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.1135, D_Y Total: 0.0762\n",
      "Generator Losses:\n",
      "  G Adv: 0.6639, F Adv: 0.8121\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.8230\n",
      "Epoch [85/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1518, D_X Fake: 0.1085, D_X Total: 0.1302\n",
      "  D_Y Real: 0.0363, D_Y Fake: 0.0603, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 0.8334, F Adv: 0.4797\n",
      "  Cycle Photo: 0.0560, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1649, Perceptual Monet: 0.1562\n",
      "  Total G Loss: 3.8625\n",
      "Epoch [85/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2559, D_X Fake: 0.0280, D_X Total: 0.1419\n",
      "  D_Y Real: 0.0486, D_Y Fake: 0.0620, D_Y Total: 0.0553\n",
      "Generator Losses:\n",
      "  G Adv: 0.8106, F Adv: 0.6342\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1487, Perceptual Monet: 0.1124\n",
      "  Total G Loss: 3.3126\n",
      "Epoch [85/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1035, D_X Fake: 0.3541, D_X Total: 0.2288\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0919, D_Y Total: 0.0614\n",
      "Generator Losses:\n",
      "  G Adv: 0.6341, F Adv: 0.2275\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1259, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.1572\n",
      "Epoch [85/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.2330, D_X Total: 0.1540\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.2151, D_Y Total: 0.1235\n",
      "Generator Losses:\n",
      "  G Adv: 0.3538, F Adv: 0.4108\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1511\n",
      "  Total G Loss: 3.0263\n",
      "Epoch [85/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1748, D_X Fake: 0.2070, D_X Total: 0.1909\n",
      "  D_Y Real: 0.0593, D_Y Fake: 0.0562, D_Y Total: 0.0577\n",
      "Generator Losses:\n",
      "  G Adv: 0.7318, F Adv: 0.4815\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1377, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.4441\n",
      "Epoch [85/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2361, D_X Fake: 0.1198, D_X Total: 0.1780\n",
      "  D_Y Real: 0.0393, D_Y Fake: 0.0494, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.5712, F Adv: 0.5157\n",
      "  Cycle Photo: 0.0431, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1826, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.5898\n",
      "Epoch [85/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1949, D_X Fake: 0.0534, D_X Total: 0.1241\n",
      "  D_Y Real: 0.0723, D_Y Fake: 0.0953, D_Y Total: 0.0838\n",
      "Generator Losses:\n",
      "  G Adv: 0.7264, F Adv: 0.8953\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.9422\n",
      "Epoch [85/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0476, D_X Fake: 0.1891, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0943, D_Y Fake: 0.0464, D_Y Total: 0.0703\n",
      "Generator Losses:\n",
      "  G Adv: 1.0829, F Adv: 0.4097\n",
      "  Cycle Photo: 0.0438, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1367\n",
      "  Total G Loss: 3.5464\n",
      "Epoch [85/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1663, D_X Fake: 0.0891, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0692, D_Y Fake: 0.0627, D_Y Total: 0.0659\n",
      "Generator Losses:\n",
      "  G Adv: 0.7559, F Adv: 0.5543\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0450\n",
      "  Perceptual Photo: 0.1723, Perceptual Monet: 0.2063\n",
      "  Total G Loss: 4.0418\n",
      "Epoch [85/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.1642, D_X Total: 0.1068\n",
      "  D_Y Real: 0.0460, D_Y Fake: 0.1526, D_Y Total: 0.0993\n",
      "Generator Losses:\n",
      "  G Adv: 0.6000, F Adv: 0.2729\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.0507\n",
      "Epoch [85/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1917, D_X Fake: 0.0604, D_X Total: 0.1261\n",
      "  D_Y Real: 0.0483, D_Y Fake: 0.0448, D_Y Total: 0.0466\n",
      "Generator Losses:\n",
      "  G Adv: 0.8531, F Adv: 0.6808\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1205\n",
      "  Total G Loss: 3.3592\n",
      "Epoch [85/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1318, D_X Fake: 0.0858, D_X Total: 0.1088\n",
      "  D_Y Real: 0.0740, D_Y Fake: 0.0864, D_Y Total: 0.0802\n",
      "Generator Losses:\n",
      "  G Adv: 0.7776, F Adv: 0.5588\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1531\n",
      "  Total G Loss: 3.7103\n",
      "Epoch [85/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1165, D_X Fake: 0.0598, D_X Total: 0.0881\n",
      "  D_Y Real: 0.0844, D_Y Fake: 0.1050, D_Y Total: 0.0947\n",
      "Generator Losses:\n",
      "  G Adv: 0.7112, F Adv: 0.5486\n",
      "  Cycle Photo: 0.0481, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.6090\n",
      "Epoch [85/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1149, D_X Fake: 0.1287, D_X Total: 0.1218\n",
      "  D_Y Real: 0.0493, D_Y Fake: 0.0783, D_Y Total: 0.0638\n",
      "Generator Losses:\n",
      "  G Adv: 0.7824, F Adv: 0.4833\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1536, Perceptual Monet: 0.1953\n",
      "  Total G Loss: 3.9136\n",
      "Epoch [85/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2255, D_X Fake: 0.0512, D_X Total: 0.1384\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.1323, D_Y Total: 0.0849\n",
      "Generator Losses:\n",
      "  G Adv: 0.5431, F Adv: 0.8290\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1831\n",
      "  Total G Loss: 3.9824\n",
      "Epoch [85/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2049, D_X Fake: 0.0564, D_X Total: 0.1307\n",
      "  D_Y Real: 0.0640, D_Y Fake: 0.0447, D_Y Total: 0.0544\n",
      "Generator Losses:\n",
      "  G Adv: 0.6612, F Adv: 0.7570\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1463\n",
      "  Total G Loss: 3.5934\n",
      "Epoch [85/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0937, D_X Fake: 0.1452, D_X Total: 0.1195\n",
      "  D_Y Real: 0.1180, D_Y Fake: 0.0468, D_Y Total: 0.0824\n",
      "Generator Losses:\n",
      "  G Adv: 0.7242, F Adv: 0.2968\n",
      "  Cycle Photo: 0.0482, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.4609\n",
      "Epoch [86/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0575, D_X Fake: 0.0673, D_X Total: 0.0624\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0995, D_Y Total: 0.0630\n",
      "Generator Losses:\n",
      "  G Adv: 0.6632, F Adv: 0.3927\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1744, Perceptual Monet: 0.1789\n",
      "  Total G Loss: 3.6176\n",
      "Epoch [86/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0475, D_X Fake: 0.0676, D_X Total: 0.0575\n",
      "  D_Y Real: 0.1470, D_Y Fake: 0.0413, D_Y Total: 0.0941\n",
      "Generator Losses:\n",
      "  G Adv: 0.9852, F Adv: 0.4691\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.7035\n",
      "Epoch [86/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0782, D_X Fake: 0.1411, D_X Total: 0.1096\n",
      "  D_Y Real: 0.1345, D_Y Fake: 0.0459, D_Y Total: 0.0902\n",
      "Generator Losses:\n",
      "  G Adv: 1.0065, F Adv: 0.5008\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1334, Perceptual Monet: 0.1234\n",
      "  Total G Loss: 3.4791\n",
      "Epoch [86/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0551, D_X Fake: 0.1507, D_X Total: 0.1029\n",
      "  D_Y Real: 0.0590, D_Y Fake: 0.1194, D_Y Total: 0.0892\n",
      "Generator Losses:\n",
      "  G Adv: 0.6015, F Adv: 0.4517\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0386\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.4070\n",
      "Epoch [86/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1868, D_X Fake: 0.0461, D_X Total: 0.1165\n",
      "  D_Y Real: 0.0411, D_Y Fake: 0.0357, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 0.7945, F Adv: 0.7216\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.9870\n",
      "Epoch [86/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0679, D_X Fake: 0.2518, D_X Total: 0.1599\n",
      "  D_Y Real: 0.0521, D_Y Fake: 0.1574, D_Y Total: 0.1047\n",
      "Generator Losses:\n",
      "  G Adv: 0.5150, F Adv: 0.3271\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.0940, Perceptual Monet: 0.1565\n",
      "  Total G Loss: 2.7953\n",
      "Epoch [86/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1658, D_X Fake: 0.0494, D_X Total: 0.1076\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0707, D_Y Total: 0.0478\n",
      "Generator Losses:\n",
      "  G Adv: 0.8462, F Adv: 0.7154\n",
      "  Cycle Photo: 0.0415, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.9954\n",
      "Epoch [86/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0525, D_X Fake: 0.2049, D_X Total: 0.1287\n",
      "  D_Y Real: 0.0355, D_Y Fake: 0.1189, D_Y Total: 0.0772\n",
      "Generator Losses:\n",
      "  G Adv: 0.5669, F Adv: 0.1133\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1589, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 2.9639\n",
      "Epoch [86/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1510, D_X Fake: 0.0667, D_X Total: 0.1088\n",
      "  D_Y Real: 0.0592, D_Y Fake: 0.1024, D_Y Total: 0.0808\n",
      "Generator Losses:\n",
      "  G Adv: 0.6047, F Adv: 0.5867\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.3475\n",
      "Epoch [86/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1452, D_X Fake: 0.1441, D_X Total: 0.1447\n",
      "  D_Y Real: 0.1142, D_Y Fake: 0.0574, D_Y Total: 0.0858\n",
      "Generator Losses:\n",
      "  G Adv: 0.9813, F Adv: 0.4226\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1245, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.6254\n",
      "Epoch [86/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0759, D_X Fake: 0.2345, D_X Total: 0.1552\n",
      "  D_Y Real: 0.0831, D_Y Fake: 0.0494, D_Y Total: 0.0662\n",
      "Generator Losses:\n",
      "  G Adv: 0.9815, F Adv: 0.4152\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1522, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.8421\n",
      "Epoch [86/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1024, D_X Fake: 0.2978, D_X Total: 0.2001\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.1465, D_Y Total: 0.0922\n",
      "Generator Losses:\n",
      "  G Adv: 0.5228, F Adv: 0.2181\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1649, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.2465\n",
      "Epoch [86/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0440, D_X Fake: 0.3281, D_X Total: 0.1860\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0702, D_Y Total: 0.0580\n",
      "Generator Losses:\n",
      "  G Adv: 0.5474, F Adv: 0.2019\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1483, Perceptual Monet: 0.1300\n",
      "  Total G Loss: 2.7563\n",
      "Epoch [86/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1654, D_X Fake: 0.2019, D_X Total: 0.1836\n",
      "  D_Y Real: 0.0574, D_Y Fake: 0.0844, D_Y Total: 0.0709\n",
      "Generator Losses:\n",
      "  G Adv: 0.7543, F Adv: 0.3505\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0448\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 3.6014\n",
      "Epoch [86/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2288, D_X Fake: 0.1082, D_X Total: 0.1685\n",
      "  D_Y Real: 0.0631, D_Y Fake: 0.0440, D_Y Total: 0.0536\n",
      "Generator Losses:\n",
      "  G Adv: 0.7910, F Adv: 0.6791\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1874\n",
      "  Total G Loss: 3.8943\n",
      "Epoch [86/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0747, D_X Fake: 0.1056, D_X Total: 0.0902\n",
      "  D_Y Real: 0.0556, D_Y Fake: 0.0536, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.8325, F Adv: 0.3381\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1841, Perceptual Monet: 0.1829\n",
      "  Total G Loss: 3.9005\n",
      "Epoch [86/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0694, D_X Fake: 0.0838, D_X Total: 0.0766\n",
      "  D_Y Real: 0.0464, D_Y Fake: 0.1042, D_Y Total: 0.0753\n",
      "Generator Losses:\n",
      "  G Adv: 0.6613, F Adv: 0.6927\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.3996\n",
      "Epoch [86/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1561, D_X Fake: 0.0884, D_X Total: 0.1223\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.1332, D_Y Total: 0.0830\n",
      "Generator Losses:\n",
      "  G Adv: 0.5159, F Adv: 0.7660\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1426\n",
      "  Total G Loss: 3.3904\n",
      "Epoch [86/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0883, D_X Fake: 0.1330, D_X Total: 0.1107\n",
      "  D_Y Real: 0.0964, D_Y Fake: 0.0819, D_Y Total: 0.0892\n",
      "Generator Losses:\n",
      "  G Adv: 0.7780, F Adv: 0.5322\n",
      "  Cycle Photo: 0.0633, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1560, Perceptual Monet: 0.1273\n",
      "  Total G Loss: 3.6642\n",
      "Epoch [86/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0982, D_X Fake: 0.0736, D_X Total: 0.0859\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0604, D_Y Total: 0.0493\n",
      "Generator Losses:\n",
      "  G Adv: 0.6763, F Adv: 0.5621\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1200, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.3958\n",
      "Epoch [86/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0975, D_X Fake: 0.0554, D_X Total: 0.0764\n",
      "  D_Y Real: 0.1052, D_Y Fake: 0.0429, D_Y Total: 0.0740\n",
      "Generator Losses:\n",
      "  G Adv: 0.8296, F Adv: 0.7284\n",
      "  Cycle Photo: 0.0953, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1621\n",
      "  Total G Loss: 4.2969\n",
      "Epoch [86/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2264, D_X Fake: 0.0512, D_X Total: 0.1388\n",
      "  D_Y Real: 0.0737, D_Y Fake: 0.1077, D_Y Total: 0.0907\n",
      "Generator Losses:\n",
      "  G Adv: 1.1423, F Adv: 0.8704\n",
      "  Cycle Photo: 0.0422, Cycle Monet: 0.0421\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 4.3575\n",
      "Epoch [86/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4943, D_X Fake: 0.0329, D_X Total: 0.2636\n",
      "  D_Y Real: 0.0484, D_Y Fake: 0.0628, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.5735, F Adv: 0.7728\n",
      "  Cycle Photo: 0.0592, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1531, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.9307\n",
      "Epoch [86/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1650, D_X Fake: 0.0471, D_X Total: 0.1060\n",
      "  D_Y Real: 0.0994, D_Y Fake: 0.1245, D_Y Total: 0.1119\n",
      "Generator Losses:\n",
      "  G Adv: 0.4752, F Adv: 0.7805\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1074, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.1820\n",
      "Epoch [87/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1905, D_X Fake: 0.0684, D_X Total: 0.1294\n",
      "  D_Y Real: 0.0528, D_Y Fake: 0.0947, D_Y Total: 0.0737\n",
      "Generator Losses:\n",
      "  G Adv: 0.7852, F Adv: 0.6049\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1222\n",
      "  Total G Loss: 3.6132\n",
      "Epoch [87/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0955, D_X Fake: 0.0353, D_X Total: 0.0654\n",
      "  D_Y Real: 0.0956, D_Y Fake: 0.0984, D_Y Total: 0.0970\n",
      "Generator Losses:\n",
      "  G Adv: 0.6703, F Adv: 0.9706\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 4.0717\n",
      "Epoch [87/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2129, D_X Fake: 0.0906, D_X Total: 0.1518\n",
      "  D_Y Real: 0.1958, D_Y Fake: 0.0649, D_Y Total: 0.1303\n",
      "Generator Losses:\n",
      "  G Adv: 0.7884, F Adv: 0.6096\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1504, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.7321\n",
      "Epoch [87/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1258, D_X Fake: 0.0770, D_X Total: 0.1014\n",
      "  D_Y Real: 0.0821, D_Y Fake: 0.0485, D_Y Total: 0.0653\n",
      "Generator Losses:\n",
      "  G Adv: 0.9389, F Adv: 0.6255\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1486, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.8727\n",
      "Epoch [87/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0739, D_X Fake: 0.2713, D_X Total: 0.1726\n",
      "  D_Y Real: 0.1726, D_Y Fake: 0.0750, D_Y Total: 0.1238\n",
      "Generator Losses:\n",
      "  G Adv: 0.8298, F Adv: 0.2826\n",
      "  Cycle Photo: 0.0481, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1717, Perceptual Monet: 0.1538\n",
      "  Total G Loss: 3.6245\n",
      "Epoch [87/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2658, D_X Fake: 0.1017, D_X Total: 0.1838\n",
      "  D_Y Real: 0.0459, D_Y Fake: 0.0486, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.8094, F Adv: 0.4786\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1748, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.6655\n",
      "Epoch [87/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0715, D_X Fake: 0.2090, D_X Total: 0.1402\n",
      "  D_Y Real: 0.0581, D_Y Fake: 0.0850, D_Y Total: 0.0715\n",
      "Generator Losses:\n",
      "  G Adv: 0.6303, F Adv: 0.3840\n",
      "  Cycle Photo: 0.0559, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1310, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.3233\n",
      "Epoch [87/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0316, D_X Fake: 0.0715, D_X Total: 0.0515\n",
      "  D_Y Real: 0.0545, D_Y Fake: 0.0577, D_Y Total: 0.0561\n",
      "Generator Losses:\n",
      "  G Adv: 0.7781, F Adv: 0.3209\n",
      "  Cycle Photo: 0.0521, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.1749, Perceptual Monet: 0.2050\n",
      "  Total G Loss: 3.9423\n",
      "Epoch [87/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0438, D_X Fake: 0.1655, D_X Total: 0.1047\n",
      "  D_Y Real: 0.0886, D_Y Fake: 0.0913, D_Y Total: 0.0900\n",
      "Generator Losses:\n",
      "  G Adv: 0.5566, F Adv: 0.4029\n",
      "  Cycle Photo: 0.0414, Cycle Monet: 0.0434\n",
      "  Perceptual Photo: 0.1049, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 3.2117\n",
      "Epoch [87/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0552, D_X Fake: 0.1239, D_X Total: 0.0896\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.1066, D_Y Total: 0.0765\n",
      "Generator Losses:\n",
      "  G Adv: 0.7360, F Adv: 0.5185\n",
      "  Cycle Photo: 0.0514, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1146, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 3.5458\n",
      "Epoch [87/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2465, D_X Fake: 0.0817, D_X Total: 0.1641\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.0704, D_Y Total: 0.0558\n",
      "Generator Losses:\n",
      "  G Adv: 0.6013, F Adv: 0.5181\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.2808\n",
      "Epoch [87/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1728, D_X Fake: 0.0369, D_X Total: 0.1048\n",
      "  D_Y Real: 0.0749, D_Y Fake: 0.1238, D_Y Total: 0.0993\n",
      "Generator Losses:\n",
      "  G Adv: 0.9395, F Adv: 0.9577\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1150, Perceptual Monet: 0.1753\n",
      "  Total G Loss: 4.0193\n",
      "Epoch [87/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1004, D_X Fake: 0.0739, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0402, D_Y Fake: 0.0772, D_Y Total: 0.0587\n",
      "Generator Losses:\n",
      "  G Adv: 0.6326, F Adv: 0.6568\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1365\n",
      "  Total G Loss: 3.3240\n",
      "Epoch [87/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2097, D_X Fake: 0.0606, D_X Total: 0.1352\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0759, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.7834, F Adv: 0.4778\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1764, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 3.7719\n",
      "Epoch [87/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2104, D_X Fake: 0.0994, D_X Total: 0.1549\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.0329, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 0.7870, F Adv: 0.5949\n",
      "  Cycle Photo: 0.0414, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1748, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.7393\n",
      "Epoch [87/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0997, D_X Fake: 0.0698, D_X Total: 0.0848\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.1085, D_Y Total: 0.0715\n",
      "Generator Losses:\n",
      "  G Adv: 0.5916, F Adv: 0.6880\n",
      "  Cycle Photo: 0.0436, Cycle Monet: 0.0452\n",
      "  Perceptual Photo: 0.1211, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 3.6694\n",
      "Epoch [87/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0389, D_X Fake: 0.3271, D_X Total: 0.1830\n",
      "  D_Y Real: 0.0447, D_Y Fake: 0.0774, D_Y Total: 0.0610\n",
      "Generator Losses:\n",
      "  G Adv: 0.7176, F Adv: 0.3178\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1085, Perceptual Monet: 0.1538\n",
      "  Total G Loss: 3.0506\n",
      "Epoch [87/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0509, D_X Fake: 0.0861, D_X Total: 0.0685\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.0656, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.6054, F Adv: 0.3637\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0460\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.2572\n",
      "Epoch [87/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1602, D_X Fake: 0.1554, D_X Total: 0.1578\n",
      "  D_Y Real: 0.0958, D_Y Fake: 0.0495, D_Y Total: 0.0726\n",
      "Generator Losses:\n",
      "  G Adv: 0.8456, F Adv: 0.5520\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1438\n",
      "  Total G Loss: 3.4550\n",
      "Epoch [87/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2407, D_X Fake: 0.0849, D_X Total: 0.1628\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.1121, D_Y Total: 0.0784\n",
      "Generator Losses:\n",
      "  G Adv: 0.4848, F Adv: 0.6284\n",
      "  Cycle Photo: 0.0505, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1512\n",
      "  Total G Loss: 3.3676\n",
      "Epoch [87/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1527, D_X Fake: 0.0635, D_X Total: 0.1081\n",
      "  D_Y Real: 0.0586, D_Y Fake: 0.0668, D_Y Total: 0.0627\n",
      "Generator Losses:\n",
      "  G Adv: 0.8704, F Adv: 0.6062\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.5564\n",
      "Epoch [87/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2159, D_X Fake: 0.0485, D_X Total: 0.1322\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.1136, D_Y Total: 0.0758\n",
      "Generator Losses:\n",
      "  G Adv: 0.6106, F Adv: 0.9302\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1135, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.5911\n",
      "Epoch [87/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0539, D_X Fake: 0.0710, D_X Total: 0.0624\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.1213, D_Y Total: 0.0738\n",
      "Generator Losses:\n",
      "  G Adv: 0.5663, F Adv: 0.7550\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1630, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.7803\n",
      "Epoch [87/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1337, D_X Fake: 0.0614, D_X Total: 0.0976\n",
      "  D_Y Real: 0.0505, D_Y Fake: 0.0558, D_Y Total: 0.0531\n",
      "Generator Losses:\n",
      "  G Adv: 0.7027, F Adv: 0.7150\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.6210\n",
      "Epoch [88/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0675, D_X Fake: 0.1377, D_X Total: 0.1026\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0766, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.5753, F Adv: 0.4930\n",
      "  Cycle Photo: 0.0431, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1231, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.2854\n",
      "Epoch [88/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0629, D_X Fake: 0.2277, D_X Total: 0.1453\n",
      "  D_Y Real: 0.0385, D_Y Fake: 0.0764, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.7795, F Adv: 0.3092\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.0952, Perceptual Monet: 0.1678\n",
      "  Total G Loss: 3.3018\n",
      "Epoch [88/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0375, D_X Fake: 0.1310, D_X Total: 0.0842\n",
      "  D_Y Real: 0.0595, D_Y Fake: 0.0707, D_Y Total: 0.0651\n",
      "Generator Losses:\n",
      "  G Adv: 0.7316, F Adv: 0.3179\n",
      "  Cycle Photo: 0.0719, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 3.5288\n",
      "Epoch [88/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0666, D_X Fake: 0.1647, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.1523, D_Y Total: 0.0972\n",
      "Generator Losses:\n",
      "  G Adv: 0.4383, F Adv: 0.2841\n",
      "  Cycle Photo: 0.0590, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1587, Perceptual Monet: 0.1567\n",
      "  Total G Loss: 3.2539\n",
      "Epoch [88/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0413, D_X Fake: 0.1449, D_X Total: 0.0931\n",
      "  D_Y Real: 0.1138, D_Y Fake: 0.0690, D_Y Total: 0.0914\n",
      "Generator Losses:\n",
      "  G Adv: 0.8028, F Adv: 0.3857\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.0949, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 3.2757\n",
      "Epoch [88/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0857, D_X Fake: 0.3065, D_X Total: 0.1961\n",
      "  D_Y Real: 0.0957, D_Y Fake: 0.1894, D_Y Total: 0.1425\n",
      "Generator Losses:\n",
      "  G Adv: 0.6702, F Adv: 0.2136\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1838, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.3669\n",
      "Epoch [88/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1041, D_X Fake: 0.0834, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0650, D_Y Fake: 0.1251, D_Y Total: 0.0951\n",
      "Generator Losses:\n",
      "  G Adv: 0.6260, F Adv: 0.5031\n",
      "  Cycle Photo: 0.0518, Cycle Monet: 0.0465\n",
      "  Perceptual Photo: 0.1344, Perceptual Monet: 0.1897\n",
      "  Total G Loss: 3.7328\n",
      "Epoch [88/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0379, D_X Fake: 0.2379, D_X Total: 0.1379\n",
      "  D_Y Real: 0.0429, D_Y Fake: 0.0323, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.7467, F Adv: 0.2110\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1272, Perceptual Monet: 0.1429\n",
      "  Total G Loss: 3.0036\n",
      "Epoch [88/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0744, D_X Fake: 0.2135, D_X Total: 0.1439\n",
      "  D_Y Real: 0.0578, D_Y Fake: 0.0637, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.8507, F Adv: 0.2567\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1366, Perceptual Monet: 0.1563\n",
      "  Total G Loss: 3.2794\n",
      "Epoch [88/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0658, D_X Fake: 0.0687, D_X Total: 0.0673\n",
      "  D_Y Real: 0.0825, D_Y Fake: 0.0309, D_Y Total: 0.0567\n",
      "Generator Losses:\n",
      "  G Adv: 0.9784, F Adv: 0.5002\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1170, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.4799\n",
      "Epoch [88/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2728, D_X Fake: 0.0444, D_X Total: 0.1586\n",
      "  D_Y Real: 0.0703, D_Y Fake: 0.0734, D_Y Total: 0.0719\n",
      "Generator Losses:\n",
      "  G Adv: 0.9526, F Adv: 0.7656\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1954\n",
      "  Total G Loss: 4.1180\n",
      "Epoch [88/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1588, D_X Fake: 0.1179, D_X Total: 0.1383\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.1094, D_Y Total: 0.0739\n",
      "Generator Losses:\n",
      "  G Adv: 0.5485, F Adv: 0.5107\n",
      "  Cycle Photo: 0.0443, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1494\n",
      "  Total G Loss: 3.2458\n",
      "Epoch [88/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.0326, D_X Total: 0.0642\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0694, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.6187, F Adv: 1.3210\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1322, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 4.0720\n",
      "Epoch [88/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1188, D_X Fake: 0.1326, D_X Total: 0.1257\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0817, D_Y Total: 0.0596\n",
      "Generator Losses:\n",
      "  G Adv: 0.7685, F Adv: 0.4140\n",
      "  Cycle Photo: 0.0478, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.5673\n",
      "Epoch [88/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1637, D_X Fake: 0.1416, D_X Total: 0.1526\n",
      "  D_Y Real: 0.0573, D_Y Fake: 0.0457, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 0.7223, F Adv: 0.4576\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1409, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.3533\n",
      "Epoch [88/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1681, D_X Fake: 0.2985, D_X Total: 0.2333\n",
      "  D_Y Real: 0.0850, D_Y Fake: 0.0678, D_Y Total: 0.0764\n",
      "Generator Losses:\n",
      "  G Adv: 0.7135, F Adv: 0.2972\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1303\n",
      "  Total G Loss: 3.0625\n",
      "Epoch [88/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0835, D_X Fake: 0.2626, D_X Total: 0.1731\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0976, D_Y Total: 0.0628\n",
      "Generator Losses:\n",
      "  G Adv: 0.6370, F Adv: 0.3290\n",
      "  Cycle Photo: 0.0499, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1197, Perceptual Monet: 0.1916\n",
      "  Total G Loss: 3.3932\n",
      "Epoch [88/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2451, D_X Fake: 0.0995, D_X Total: 0.1723\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.1641, D_Y Total: 0.0983\n",
      "Generator Losses:\n",
      "  G Adv: 0.3227, F Adv: 0.5161\n",
      "  Cycle Photo: 0.0583, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1844\n",
      "  Total G Loss: 3.5082\n",
      "Epoch [88/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0487, D_X Fake: 0.2595, D_X Total: 0.1541\n",
      "  D_Y Real: 0.0671, D_Y Fake: 0.0426, D_Y Total: 0.0549\n",
      "Generator Losses:\n",
      "  G Adv: 0.9689, F Adv: 0.1637\n",
      "  Cycle Photo: 0.0376, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1408, Perceptual Monet: 0.1370\n",
      "  Total G Loss: 3.1969\n",
      "Epoch [88/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0640, D_X Fake: 0.2457, D_X Total: 0.1549\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.1164, D_Y Total: 0.0694\n",
      "Generator Losses:\n",
      "  G Adv: 0.6869, F Adv: 0.3145\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1897\n",
      "  Total G Loss: 3.4546\n",
      "Epoch [88/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0752, D_X Fake: 0.2425, D_X Total: 0.1588\n",
      "  D_Y Real: 0.0441, D_Y Fake: 0.1491, D_Y Total: 0.0966\n",
      "Generator Losses:\n",
      "  G Adv: 0.6290, F Adv: 0.3383\n",
      "  Cycle Photo: 0.0425, Cycle Monet: 0.0466\n",
      "  Perceptual Photo: 0.1748, Perceptual Monet: 0.1945\n",
      "  Total G Loss: 3.7047\n",
      "Epoch [88/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0883, D_X Fake: 0.0679, D_X Total: 0.0781\n",
      "  D_Y Real: 0.0339, D_Y Fake: 0.0533, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.8190, F Adv: 0.3460\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1096, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.2227\n",
      "Epoch [88/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.1170, D_X Total: 0.0937\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0550, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.8853, F Adv: 0.5343\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1184, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.5118\n",
      "Epoch [88/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1012, D_X Fake: 0.0690, D_X Total: 0.0851\n",
      "  D_Y Real: 0.1210, D_Y Fake: 0.0761, D_Y Total: 0.0985\n",
      "Generator Losses:\n",
      "  G Adv: 0.7046, F Adv: 0.4134\n",
      "  Cycle Photo: 0.0391, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.4113\n",
      "Epoch [89/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1283, D_X Fake: 0.1829, D_X Total: 0.1556\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.0636, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.6804, F Adv: 0.4081\n",
      "  Cycle Photo: 0.0683, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.5308\n",
      "Epoch [89/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3072, D_X Fake: 0.0499, D_X Total: 0.1785\n",
      "  D_Y Real: 0.1000, D_Y Fake: 0.0597, D_Y Total: 0.0799\n",
      "Generator Losses:\n",
      "  G Adv: 0.8137, F Adv: 0.7253\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1410, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.7578\n",
      "Epoch [89/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0627, D_X Fake: 0.2011, D_X Total: 0.1319\n",
      "  D_Y Real: 0.0751, D_Y Fake: 0.0645, D_Y Total: 0.0698\n",
      "Generator Losses:\n",
      "  G Adv: 0.7523, F Adv: 0.3414\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1747, Perceptual Monet: 0.1515\n",
      "  Total G Loss: 3.5367\n",
      "Epoch [89/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1427, D_X Fake: 0.3210, D_X Total: 0.2319\n",
      "  D_Y Real: 0.0972, D_Y Fake: 0.0390, D_Y Total: 0.0681\n",
      "Generator Losses:\n",
      "  G Adv: 0.8910, F Adv: 0.2307\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1585\n",
      "  Total G Loss: 3.3375\n",
      "Epoch [89/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2466, D_X Fake: 0.1060, D_X Total: 0.1763\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.0676, D_Y Total: 0.0524\n",
      "Generator Losses:\n",
      "  G Adv: 0.5946, F Adv: 0.6344\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 3.5821\n",
      "Epoch [89/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.1099, D_X Total: 0.0915\n",
      "  D_Y Real: 0.1815, D_Y Fake: 0.0591, D_Y Total: 0.1203\n",
      "Generator Losses:\n",
      "  G Adv: 0.9983, F Adv: 0.5047\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1531\n",
      "  Total G Loss: 3.6865\n",
      "Epoch [89/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1138, D_X Fake: 0.2372, D_X Total: 0.1755\n",
      "  D_Y Real: 0.0441, D_Y Fake: 0.0673, D_Y Total: 0.0557\n",
      "Generator Losses:\n",
      "  G Adv: 0.7134, F Adv: 0.3665\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1552, Perceptual Monet: 0.1487\n",
      "  Total G Loss: 3.2011\n",
      "Epoch [89/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2322, D_X Fake: 0.0320, D_X Total: 0.1321\n",
      "  D_Y Real: 0.0710, D_Y Fake: 0.1503, D_Y Total: 0.1107\n",
      "Generator Losses:\n",
      "  G Adv: 0.5720, F Adv: 0.7574\n",
      "  Cycle Photo: 0.0550, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1825, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.9092\n",
      "Epoch [89/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1225, D_X Fake: 0.1058, D_X Total: 0.1141\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0914, D_Y Total: 0.0607\n",
      "Generator Losses:\n",
      "  G Adv: 0.5605, F Adv: 0.5955\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.3902\n",
      "Epoch [89/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1399, D_X Fake: 0.1351, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0376, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.8995, F Adv: 0.4591\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.8712\n",
      "Epoch [89/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1006, D_X Fake: 0.2264, D_X Total: 0.1635\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.1198, D_Y Total: 0.0836\n",
      "Generator Losses:\n",
      "  G Adv: 0.6047, F Adv: 0.5689\n",
      "  Cycle Photo: 0.0535, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1622, Perceptual Monet: 0.1378\n",
      "  Total G Loss: 3.4847\n",
      "Epoch [89/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0881, D_X Fake: 0.1119, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.0636, D_Y Total: 0.0658\n",
      "Generator Losses:\n",
      "  G Adv: 0.8435, F Adv: 0.6311\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0414\n",
      "  Perceptual Photo: 0.1638, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 4.0007\n",
      "Epoch [89/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1156, D_X Fake: 0.0350, D_X Total: 0.0753\n",
      "  D_Y Real: 0.0634, D_Y Fake: 0.0515, D_Y Total: 0.0574\n",
      "Generator Losses:\n",
      "  G Adv: 0.8701, F Adv: 0.5112\n",
      "  Cycle Photo: 0.0497, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.7428\n",
      "Epoch [89/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1670, D_X Fake: 0.0718, D_X Total: 0.1194\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0790, D_Y Total: 0.0524\n",
      "Generator Losses:\n",
      "  G Adv: 0.8254, F Adv: 0.6385\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1301\n",
      "  Total G Loss: 3.4294\n",
      "Epoch [89/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0578, D_X Fake: 0.2506, D_X Total: 0.1542\n",
      "  D_Y Real: 0.1787, D_Y Fake: 0.0471, D_Y Total: 0.1129\n",
      "Generator Losses:\n",
      "  G Adv: 0.9197, F Adv: 0.3341\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1475\n",
      "  Total G Loss: 3.5442\n",
      "Epoch [89/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0865, D_X Fake: 0.0655, D_X Total: 0.0760\n",
      "  D_Y Real: 0.0411, D_Y Fake: 0.0920, D_Y Total: 0.0665\n",
      "Generator Losses:\n",
      "  G Adv: 0.7432, F Adv: 0.4666\n",
      "  Cycle Photo: 0.0450, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1635, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.6577\n",
      "Epoch [89/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1254, D_X Fake: 0.0575, D_X Total: 0.0914\n",
      "  D_Y Real: 0.1521, D_Y Fake: 0.1317, D_Y Total: 0.1419\n",
      "Generator Losses:\n",
      "  G Adv: 0.9085, F Adv: 0.7902\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.9158\n",
      "Epoch [89/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0751, D_X Fake: 0.0982, D_X Total: 0.0866\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.0549, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.7436, F Adv: 0.5451\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.6658\n",
      "Epoch [89/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1848, D_X Fake: 0.0638, D_X Total: 0.1243\n",
      "  D_Y Real: 0.1132, D_Y Fake: 0.0705, D_Y Total: 0.0919\n",
      "Generator Losses:\n",
      "  G Adv: 1.0982, F Adv: 0.6562\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1435, Perceptual Monet: 0.1387\n",
      "  Total G Loss: 3.8018\n",
      "Epoch [89/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1205, D_X Fake: 0.2340, D_X Total: 0.1773\n",
      "  D_Y Real: 0.0563, D_Y Fake: 0.0411, D_Y Total: 0.0487\n",
      "Generator Losses:\n",
      "  G Adv: 0.8192, F Adv: 0.3318\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1381, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.3588\n",
      "Epoch [89/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1898, D_X Fake: 0.1467, D_X Total: 0.1683\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.0741, D_Y Total: 0.0609\n",
      "Generator Losses:\n",
      "  G Adv: 0.6664, F Adv: 0.5209\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1702\n",
      "  Total G Loss: 3.3914\n",
      "Epoch [89/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2839, D_X Fake: 0.0540, D_X Total: 0.1689\n",
      "  D_Y Real: 0.0460, D_Y Fake: 0.0784, D_Y Total: 0.0622\n",
      "Generator Losses:\n",
      "  G Adv: 0.8451, F Adv: 0.5353\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0404\n",
      "  Perceptual Photo: 0.1774, Perceptual Monet: 0.1838\n",
      "  Total G Loss: 4.1425\n",
      "Epoch [89/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1654, D_X Fake: 0.0896, D_X Total: 0.1275\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.0626, D_Y Total: 0.0504\n",
      "Generator Losses:\n",
      "  G Adv: 0.7386, F Adv: 0.5965\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1482\n",
      "  Total G Loss: 3.5245\n",
      "Epoch [89/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0394, D_X Fake: 0.1404, D_X Total: 0.0899\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0742, D_Y Total: 0.0557\n",
      "Generator Losses:\n",
      "  G Adv: 0.7244, F Adv: 0.4723\n",
      "  Cycle Photo: 0.0509, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1258, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.4983\n",
      "Epoch [90/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1798, D_X Fake: 0.0851, D_X Total: 0.1325\n",
      "  D_Y Real: 0.0393, D_Y Fake: 0.1371, D_Y Total: 0.0882\n",
      "Generator Losses:\n",
      "  G Adv: 0.5215, F Adv: 0.6030\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1431, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.4378\n",
      "Epoch [90/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.1986, D_X Total: 0.1239\n",
      "  D_Y Real: 0.0753, D_Y Fake: 0.1498, D_Y Total: 0.1126\n",
      "Generator Losses:\n",
      "  G Adv: 0.6219, F Adv: 0.2940\n",
      "  Cycle Photo: 0.0451, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1362, Perceptual Monet: 0.1513\n",
      "  Total G Loss: 3.1266\n",
      "Epoch [90/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1533, D_X Fake: 0.2293, D_X Total: 0.1913\n",
      "  D_Y Real: 0.1327, D_Y Fake: 0.0395, D_Y Total: 0.0861\n",
      "Generator Losses:\n",
      "  G Adv: 1.0163, F Adv: 0.3404\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1985, Perceptual Monet: 0.1527\n",
      "  Total G Loss: 3.8647\n",
      "Epoch [90/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1977, D_X Fake: 0.1094, D_X Total: 0.1536\n",
      "  D_Y Real: 0.0571, D_Y Fake: 0.1434, D_Y Total: 0.1002\n",
      "Generator Losses:\n",
      "  G Adv: 0.5582, F Adv: 0.5544\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1502, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.4280\n",
      "Epoch [90/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1593, D_X Fake: 0.1532, D_X Total: 0.1563\n",
      "  D_Y Real: 0.1663, D_Y Fake: 0.0370, D_Y Total: 0.1016\n",
      "Generator Losses:\n",
      "  G Adv: 1.0765, F Adv: 0.5313\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1801, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 4.1219\n",
      "Epoch [90/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2519, D_X Fake: 0.0840, D_X Total: 0.1680\n",
      "  D_Y Real: 0.0429, D_Y Fake: 0.0384, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.9042, F Adv: 0.5835\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.9388\n",
      "Epoch [90/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1217, D_X Fake: 0.1482, D_X Total: 0.1350\n",
      "  D_Y Real: 0.0417, D_Y Fake: 0.0658, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.7172, F Adv: 0.6656\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1659, Perceptual Monet: 0.1831\n",
      "  Total G Loss: 3.8942\n",
      "Epoch [90/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1810, D_X Fake: 0.0397, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0897, D_Y Fake: 0.0360, D_Y Total: 0.0628\n",
      "Generator Losses:\n",
      "  G Adv: 0.8735, F Adv: 0.5694\n",
      "  Cycle Photo: 0.0448, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.6884\n",
      "Epoch [90/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0880, D_X Fake: 0.0356, D_X Total: 0.0618\n",
      "  D_Y Real: 0.0629, D_Y Fake: 0.1166, D_Y Total: 0.0898\n",
      "Generator Losses:\n",
      "  G Adv: 0.4809, F Adv: 0.8439\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.8691\n",
      "Epoch [90/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2060, D_X Fake: 0.1293, D_X Total: 0.1676\n",
      "  D_Y Real: 0.1387, D_Y Fake: 0.0660, D_Y Total: 0.1024\n",
      "Generator Losses:\n",
      "  G Adv: 1.0281, F Adv: 0.6248\n",
      "  Cycle Photo: 0.0508, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1825, Perceptual Monet: 0.1470\n",
      "  Total G Loss: 4.1181\n",
      "Epoch [90/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1517, D_X Fake: 0.1902, D_X Total: 0.1709\n",
      "  D_Y Real: 0.0638, D_Y Fake: 0.1455, D_Y Total: 0.1047\n",
      "Generator Losses:\n",
      "  G Adv: 0.7278, F Adv: 0.5280\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1968\n",
      "  Total G Loss: 3.6884\n",
      "Epoch [90/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1041, D_X Fake: 0.1436, D_X Total: 0.1239\n",
      "  D_Y Real: 0.0689, D_Y Fake: 0.0887, D_Y Total: 0.0788\n",
      "Generator Losses:\n",
      "  G Adv: 0.7162, F Adv: 0.3989\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1778, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.6474\n",
      "Epoch [90/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0703, D_X Fake: 0.0873, D_X Total: 0.0788\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0879, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.5482, F Adv: 0.4984\n",
      "  Cycle Photo: 0.0630, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1642, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.6977\n",
      "Epoch [90/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1294, D_X Fake: 0.0574, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0991, D_Y Fake: 0.0618, D_Y Total: 0.0804\n",
      "Generator Losses:\n",
      "  G Adv: 0.7737, F Adv: 0.6567\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1574, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.9164\n",
      "Epoch [90/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2434, D_X Fake: 0.0894, D_X Total: 0.1664\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.0973, D_Y Total: 0.0703\n",
      "Generator Losses:\n",
      "  G Adv: 0.5605, F Adv: 0.5865\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1173, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.1654\n",
      "Epoch [90/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1184, D_X Fake: 0.1311, D_X Total: 0.1247\n",
      "  D_Y Real: 0.0788, D_Y Fake: 0.0515, D_Y Total: 0.0652\n",
      "Generator Losses:\n",
      "  G Adv: 1.0523, F Adv: 0.4583\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.1552\n",
      "  Total G Loss: 3.6955\n",
      "Epoch [90/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0676, D_X Fake: 0.0842, D_X Total: 0.0759\n",
      "  D_Y Real: 0.0519, D_Y Fake: 0.0690, D_Y Total: 0.0605\n",
      "Generator Losses:\n",
      "  G Adv: 0.7677, F Adv: 0.3150\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.2237\n",
      "Epoch [90/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0476, D_X Fake: 0.1397, D_X Total: 0.0936\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0599, D_Y Total: 0.0454\n",
      "Generator Losses:\n",
      "  G Adv: 0.6737, F Adv: 0.4879\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.4034\n",
      "Epoch [90/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0681, D_X Fake: 0.1318, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.0580, D_Y Total: 0.0446\n",
      "Generator Losses:\n",
      "  G Adv: 0.6689, F Adv: 0.6446\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.7800\n",
      "Epoch [90/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0946, D_X Fake: 0.1797, D_X Total: 0.1371\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.1506, D_Y Total: 0.0894\n",
      "Generator Losses:\n",
      "  G Adv: 0.5276, F Adv: 0.3276\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1418\n",
      "  Total G Loss: 3.1210\n",
      "Epoch [90/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2558, D_X Fake: 0.2120, D_X Total: 0.2339\n",
      "  D_Y Real: 0.0497, D_Y Fake: 0.0396, D_Y Total: 0.0447\n",
      "Generator Losses:\n",
      "  G Adv: 0.8430, F Adv: 0.3165\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0466\n",
      "  Perceptual Photo: 0.1729, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 3.8728\n",
      "Epoch [90/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2282, D_X Fake: 0.2390, D_X Total: 0.2336\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0434, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9464, F Adv: 0.3327\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1372\n",
      "  Total G Loss: 3.2944\n",
      "Epoch [90/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2981, D_X Fake: 0.2919, D_X Total: 0.2950\n",
      "  D_Y Real: 0.0578, D_Y Fake: 0.0715, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.6871, F Adv: 0.3569\n",
      "  Cycle Photo: 0.0527, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1421, Perceptual Monet: 0.1457\n",
      "  Total G Loss: 3.3139\n",
      "Epoch [90/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2477, D_X Fake: 0.2624, D_X Total: 0.2550\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0792, D_Y Total: 0.0613\n",
      "Generator Losses:\n",
      "  G Adv: 0.6072, F Adv: 0.2266\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1402\n",
      "  Total G Loss: 3.1440\n",
      "Epoch [91/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3165, D_X Fake: 0.3448, D_X Total: 0.3307\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.0804, D_Y Total: 0.0591\n",
      "Generator Losses:\n",
      "  G Adv: 0.9853, F Adv: 0.2503\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1556, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.4943\n",
      "Epoch [91/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0942, D_X Fake: 0.2850, D_X Total: 0.1896\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0557, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.8190, F Adv: 0.2313\n",
      "  Cycle Photo: 0.0559, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1247, Perceptual Monet: 0.1259\n",
      "  Total G Loss: 3.1392\n",
      "Epoch [91/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2249, D_X Fake: 0.1941, D_X Total: 0.2095\n",
      "  D_Y Real: 0.0538, D_Y Fake: 0.0558, D_Y Total: 0.0548\n",
      "Generator Losses:\n",
      "  G Adv: 0.6689, F Adv: 0.3222\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1285\n",
      "  Total G Loss: 3.1092\n",
      "Epoch [91/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1277, D_X Fake: 0.1044, D_X Total: 0.1161\n",
      "  D_Y Real: 0.0525, D_Y Fake: 0.0574, D_Y Total: 0.0550\n",
      "Generator Losses:\n",
      "  G Adv: 0.8281, F Adv: 0.3531\n",
      "  Cycle Photo: 0.0447, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1737, Perceptual Monet: 0.1409\n",
      "  Total G Loss: 3.5368\n",
      "Epoch [91/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0885, D_X Fake: 0.3049, D_X Total: 0.1967\n",
      "  D_Y Real: 0.0609, D_Y Fake: 0.0510, D_Y Total: 0.0559\n",
      "Generator Losses:\n",
      "  G Adv: 1.0071, F Adv: 0.2451\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1445\n",
      "  Total G Loss: 3.4094\n",
      "Epoch [91/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1062, D_X Fake: 0.1018, D_X Total: 0.1040\n",
      "  D_Y Real: 0.0556, D_Y Fake: 0.0575, D_Y Total: 0.0566\n",
      "Generator Losses:\n",
      "  G Adv: 0.8521, F Adv: 0.3781\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1343\n",
      "  Total G Loss: 3.0115\n",
      "Epoch [91/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1435, D_X Fake: 0.0750, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0585, D_Y Fake: 0.0398, D_Y Total: 0.0491\n",
      "Generator Losses:\n",
      "  G Adv: 0.9716, F Adv: 0.5726\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1602, Perceptual Monet: 0.1324\n",
      "  Total G Loss: 3.6181\n",
      "Epoch [91/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1204, D_X Fake: 0.2793, D_X Total: 0.1998\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.0501, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.8894, F Adv: 0.2691\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0391\n",
      "  Perceptual Photo: 0.1544, Perceptual Monet: 0.1694\n",
      "  Total G Loss: 3.5498\n",
      "Epoch [91/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1500, D_X Fake: 0.0897, D_X Total: 0.1199\n",
      "  D_Y Real: 0.0698, D_Y Fake: 0.0678, D_Y Total: 0.0688\n",
      "Generator Losses:\n",
      "  G Adv: 0.8410, F Adv: 0.5054\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1274, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.5903\n",
      "Epoch [91/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1009, D_X Fake: 0.1753, D_X Total: 0.1381\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0480, D_Y Total: 0.0446\n",
      "Generator Losses:\n",
      "  G Adv: 0.9791, F Adv: 0.4074\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.1244\n",
      "  Total G Loss: 3.5494\n",
      "Epoch [91/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2121, D_X Fake: 0.0457, D_X Total: 0.1289\n",
      "  D_Y Real: 0.0583, D_Y Fake: 0.1049, D_Y Total: 0.0816\n",
      "Generator Losses:\n",
      "  G Adv: 0.5539, F Adv: 0.6593\n",
      "  Cycle Photo: 0.0415, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1318, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.4084\n",
      "Epoch [91/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0953, D_X Fake: 0.2070, D_X Total: 0.1511\n",
      "  D_Y Real: 0.0659, D_Y Fake: 0.0614, D_Y Total: 0.0636\n",
      "Generator Losses:\n",
      "  G Adv: 0.6802, F Adv: 0.3097\n",
      "  Cycle Photo: 0.0420, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.3309\n",
      "Epoch [91/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1931, D_X Fake: 0.0705, D_X Total: 0.1318\n",
      "  D_Y Real: 0.1021, D_Y Fake: 0.0851, D_Y Total: 0.0936\n",
      "Generator Losses:\n",
      "  G Adv: 0.5437, F Adv: 0.6610\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 3.5202\n",
      "Epoch [91/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0908, D_X Fake: 0.1788, D_X Total: 0.1348\n",
      "  D_Y Real: 0.1013, D_Y Fake: 0.0566, D_Y Total: 0.0790\n",
      "Generator Losses:\n",
      "  G Adv: 0.6878, F Adv: 0.3236\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1300\n",
      "  Total G Loss: 2.9781\n",
      "Epoch [91/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0500, D_X Fake: 0.1578, D_X Total: 0.1039\n",
      "  D_Y Real: 0.0462, D_Y Fake: 0.1246, D_Y Total: 0.0854\n",
      "Generator Losses:\n",
      "  G Adv: 0.8375, F Adv: 0.4382\n",
      "  Cycle Photo: 0.0394, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1615, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.6467\n",
      "Epoch [91/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1068, D_X Fake: 0.0923, D_X Total: 0.0995\n",
      "  D_Y Real: 0.1366, D_Y Fake: 0.1005, D_Y Total: 0.1186\n",
      "Generator Losses:\n",
      "  G Adv: 0.5470, F Adv: 0.5262\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0462\n",
      "  Perceptual Photo: 0.1294, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 3.3435\n",
      "Epoch [91/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1642, D_X Fake: 0.0693, D_X Total: 0.1167\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.0562, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 0.7533, F Adv: 0.6007\n",
      "  Cycle Photo: 0.0468, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.5895\n",
      "Epoch [91/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0417, D_X Fake: 0.2151, D_X Total: 0.1284\n",
      "  D_Y Real: 0.1086, D_Y Fake: 0.0631, D_Y Total: 0.0859\n",
      "Generator Losses:\n",
      "  G Adv: 0.7827, F Adv: 0.3846\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0436\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.2053\n",
      "  Total G Loss: 3.6864\n",
      "Epoch [91/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0900, D_X Fake: 0.0733, D_X Total: 0.0816\n",
      "  D_Y Real: 0.0667, D_Y Fake: 0.0402, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.8553, F Adv: 0.4882\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1166\n",
      "  Total G Loss: 3.2212\n",
      "Epoch [91/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1517, D_X Fake: 0.2045, D_X Total: 0.1781\n",
      "  D_Y Real: 0.1219, D_Y Fake: 0.0576, D_Y Total: 0.0898\n",
      "Generator Losses:\n",
      "  G Adv: 0.7554, F Adv: 0.2922\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.4209\n",
      "Epoch [91/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2045, D_X Fake: 0.0553, D_X Total: 0.1299\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0655, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.6865, F Adv: 0.6184\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1859\n",
      "  Total G Loss: 3.5799\n",
      "Epoch [91/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0996, D_X Fake: 0.0842, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0352, D_Y Fake: 0.0812, D_Y Total: 0.0582\n",
      "Generator Losses:\n",
      "  G Adv: 0.6004, F Adv: 0.7259\n",
      "  Cycle Photo: 0.0484, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1219, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.6399\n",
      "Epoch [91/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1025, D_X Fake: 0.1948, D_X Total: 0.1486\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.1070, D_Y Total: 0.0768\n",
      "Generator Losses:\n",
      "  G Adv: 0.6890, F Adv: 0.2075\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1510, Perceptual Monet: 0.1368\n",
      "  Total G Loss: 3.0003\n",
      "Epoch [91/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.0905, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0391, D_Y Fake: 0.0325, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.4253, F Adv: 0.2993\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.0265\n",
      "Epoch [92/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1341, D_X Fake: 0.1122, D_X Total: 0.1232\n",
      "  D_Y Real: 0.0414, D_Y Fake: 0.0520, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.7302, F Adv: 0.4414\n",
      "  Cycle Photo: 0.0456, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1837, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.6600\n",
      "Epoch [92/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1912, D_X Fake: 0.0625, D_X Total: 0.1269\n",
      "  D_Y Real: 0.0471, D_Y Fake: 0.0759, D_Y Total: 0.0615\n",
      "Generator Losses:\n",
      "  G Adv: 0.7696, F Adv: 0.5449\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1576, Perceptual Monet: 0.1487\n",
      "  Total G Loss: 3.6782\n",
      "Epoch [92/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1243, D_X Fake: 0.1942, D_X Total: 0.1592\n",
      "  D_Y Real: 0.1299, D_Y Fake: 0.0703, D_Y Total: 0.1001\n",
      "Generator Losses:\n",
      "  G Adv: 0.7815, F Adv: 0.2853\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1565, Perceptual Monet: 0.1585\n",
      "  Total G Loss: 3.3091\n",
      "Epoch [92/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2399, D_X Fake: 0.0378, D_X Total: 0.1389\n",
      "  D_Y Real: 0.0487, D_Y Fake: 0.0333, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 0.9150, F Adv: 0.7349\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1158, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.8386\n",
      "Epoch [92/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1037, D_X Fake: 0.2830, D_X Total: 0.1933\n",
      "  D_Y Real: 0.1066, D_Y Fake: 0.0745, D_Y Total: 0.0906\n",
      "Generator Losses:\n",
      "  G Adv: 0.7411, F Adv: 0.2580\n",
      "  Cycle Photo: 0.0389, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1263, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.0722\n",
      "Epoch [92/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1708, D_X Fake: 0.1133, D_X Total: 0.1421\n",
      "  D_Y Real: 0.0496, D_Y Fake: 0.0659, D_Y Total: 0.0577\n",
      "Generator Losses:\n",
      "  G Adv: 0.7131, F Adv: 0.5432\n",
      "  Cycle Photo: 0.0675, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.7083\n",
      "Epoch [92/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1304, D_X Fake: 0.0524, D_X Total: 0.0914\n",
      "  D_Y Real: 0.0838, D_Y Fake: 0.0409, D_Y Total: 0.0623\n",
      "Generator Losses:\n",
      "  G Adv: 0.5710, F Adv: 0.6293\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.1620\n",
      "  Total G Loss: 3.4637\n",
      "Epoch [92/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1095, D_X Fake: 0.1151, D_X Total: 0.1123\n",
      "  D_Y Real: 0.1598, D_Y Fake: 0.0422, D_Y Total: 0.1010\n",
      "Generator Losses:\n",
      "  G Adv: 1.0348, F Adv: 0.4619\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.9215\n",
      "Epoch [92/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1381, D_X Fake: 0.0415, D_X Total: 0.0898\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.2493, D_Y Total: 0.1428\n",
      "Generator Losses:\n",
      "  G Adv: 0.3245, F Adv: 0.7565\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1301, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.4515\n",
      "Epoch [92/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0624, D_X Fake: 0.1623, D_X Total: 0.1124\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0492, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.7604, F Adv: 0.4191\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1102, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 3.2273\n",
      "Epoch [92/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0613, D_X Fake: 0.0963, D_X Total: 0.0788\n",
      "  D_Y Real: 0.0581, D_Y Fake: 0.0356, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 0.9453, F Adv: 0.4296\n",
      "  Cycle Photo: 0.0553, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1574, Perceptual Monet: 0.1525\n",
      "  Total G Loss: 3.8324\n",
      "Epoch [92/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0935, D_X Fake: 0.0378, D_X Total: 0.0656\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0957, D_Y Total: 0.0677\n",
      "Generator Losses:\n",
      "  G Adv: 0.6699, F Adv: 0.7529\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1373, Perceptual Monet: 0.1441\n",
      "  Total G Loss: 3.4996\n",
      "Epoch [92/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1574, D_X Fake: 0.1106, D_X Total: 0.1340\n",
      "  D_Y Real: 0.0441, D_Y Fake: 0.0893, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.7247, F Adv: 0.4872\n",
      "  Cycle Photo: 0.0461, Cycle Monet: 0.0422\n",
      "  Perceptual Photo: 0.1827, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.9097\n",
      "Epoch [92/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1702, D_X Fake: 0.0475, D_X Total: 0.1088\n",
      "  D_Y Real: 0.0351, D_Y Fake: 0.0720, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.5123, F Adv: 0.9285\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1245, Perceptual Monet: 0.1752\n",
      "  Total G Loss: 3.6440\n",
      "Epoch [92/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0530, D_X Fake: 0.2346, D_X Total: 0.1438\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.1068, D_Y Total: 0.0704\n",
      "Generator Losses:\n",
      "  G Adv: 0.6710, F Adv: 0.3750\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.2268\n",
      "Epoch [92/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1779, D_X Fake: 0.0439, D_X Total: 0.1109\n",
      "  D_Y Real: 0.0720, D_Y Fake: 0.0474, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.7943, F Adv: 0.6958\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.7461\n",
      "Epoch [92/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2090, D_X Fake: 0.1110, D_X Total: 0.1600\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.0936, D_Y Total: 0.0731\n",
      "Generator Losses:\n",
      "  G Adv: 0.7236, F Adv: 0.5893\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1082, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.3252\n",
      "Epoch [92/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1804, D_X Fake: 0.0494, D_X Total: 0.1149\n",
      "  D_Y Real: 0.0436, D_Y Fake: 0.0486, D_Y Total: 0.0461\n",
      "Generator Losses:\n",
      "  G Adv: 1.0565, F Adv: 0.6030\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.1403\n",
      "  Total G Loss: 3.5761\n",
      "Epoch [92/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0943, D_X Fake: 0.0613, D_X Total: 0.0778\n",
      "  D_Y Real: 0.0758, D_Y Fake: 0.0479, D_Y Total: 0.0618\n",
      "Generator Losses:\n",
      "  G Adv: 0.9295, F Adv: 0.4639\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1458, Perceptual Monet: 0.1608\n",
      "  Total G Loss: 3.8439\n",
      "Epoch [92/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1499, D_X Fake: 0.1215, D_X Total: 0.1357\n",
      "  D_Y Real: 0.0644, D_Y Fake: 0.1402, D_Y Total: 0.1023\n",
      "Generator Losses:\n",
      "  G Adv: 0.5978, F Adv: 0.6027\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1692, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.6048\n",
      "Epoch [92/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0610, D_X Fake: 0.1258, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0687, D_Y Fake: 0.0773, D_Y Total: 0.0730\n",
      "Generator Losses:\n",
      "  G Adv: 0.8616, F Adv: 0.2581\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.4990\n",
      "Epoch [92/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1350, D_X Fake: 0.1079, D_X Total: 0.1215\n",
      "  D_Y Real: 0.0859, D_Y Fake: 0.0718, D_Y Total: 0.0788\n",
      "Generator Losses:\n",
      "  G Adv: 0.7370, F Adv: 0.6029\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1299\n",
      "  Total G Loss: 3.3472\n",
      "Epoch [92/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0980, D_X Fake: 0.2267, D_X Total: 0.1623\n",
      "  D_Y Real: 0.1543, D_Y Fake: 0.0704, D_Y Total: 0.1124\n",
      "Generator Losses:\n",
      "  G Adv: 0.7312, F Adv: 0.2629\n",
      "  Cycle Photo: 0.0463, Cycle Monet: 0.0441\n",
      "  Perceptual Photo: 0.1541, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.5559\n",
      "Epoch [92/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1678, D_X Fake: 0.1194, D_X Total: 0.1436\n",
      "  D_Y Real: 0.1212, D_Y Fake: 0.0488, D_Y Total: 0.0850\n",
      "Generator Losses:\n",
      "  G Adv: 1.1016, F Adv: 0.4602\n",
      "  Cycle Photo: 0.0508, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1201\n",
      "  Total G Loss: 3.6981\n",
      "Epoch [93/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0628, D_X Fake: 0.2266, D_X Total: 0.1447\n",
      "  D_Y Real: 0.0802, D_Y Fake: 0.0907, D_Y Total: 0.0855\n",
      "Generator Losses:\n",
      "  G Adv: 0.6102, F Adv: 0.2524\n",
      "  Cycle Photo: 0.0480, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 3.3457\n",
      "Epoch [93/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1484, D_X Fake: 0.0619, D_X Total: 0.1051\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0514, D_Y Total: 0.0457\n",
      "Generator Losses:\n",
      "  G Adv: 0.7641, F Adv: 0.6523\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1107, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.4179\n",
      "Epoch [93/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2352, D_X Fake: 0.0857, D_X Total: 0.1605\n",
      "  D_Y Real: 0.0671, D_Y Fake: 0.0496, D_Y Total: 0.0584\n",
      "Generator Losses:\n",
      "  G Adv: 0.7815, F Adv: 0.5653\n",
      "  Cycle Photo: 0.0389, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.6884\n",
      "Epoch [93/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0514, D_X Fake: 0.1310, D_X Total: 0.0912\n",
      "  D_Y Real: 0.0955, D_Y Fake: 0.0559, D_Y Total: 0.0757\n",
      "Generator Losses:\n",
      "  G Adv: 0.9156, F Adv: 0.3553\n",
      "  Cycle Photo: 0.0447, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1433, Perceptual Monet: 0.1482\n",
      "  Total G Loss: 3.5151\n",
      "Epoch [93/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1389, D_X Fake: 0.0325, D_X Total: 0.0857\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0463, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.9022, F Adv: 0.5073\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 3.6524\n",
      "Epoch [93/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1817, D_X Fake: 0.0888, D_X Total: 0.1353\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.1514, D_Y Total: 0.0956\n",
      "Generator Losses:\n",
      "  G Adv: 0.5411, F Adv: 0.5778\n",
      "  Cycle Photo: 0.0515, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.2245, Perceptual Monet: 0.1398\n",
      "  Total G Loss: 3.7780\n",
      "Epoch [93/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3738, D_X Fake: 0.0510, D_X Total: 0.2124\n",
      "  D_Y Real: 0.0495, D_Y Fake: 0.0892, D_Y Total: 0.0693\n",
      "Generator Losses:\n",
      "  G Adv: 0.5840, F Adv: 0.7978\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1663, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.8734\n",
      "Epoch [93/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0570, D_X Fake: 0.2679, D_X Total: 0.1624\n",
      "  D_Y Real: 0.0440, D_Y Fake: 0.0643, D_Y Total: 0.0541\n",
      "Generator Losses:\n",
      "  G Adv: 0.6982, F Adv: 0.2965\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.2381\n",
      "Epoch [93/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0564, D_X Fake: 0.1485, D_X Total: 0.1025\n",
      "  D_Y Real: 0.0659, D_Y Fake: 0.1060, D_Y Total: 0.0859\n",
      "Generator Losses:\n",
      "  G Adv: 0.4482, F Adv: 0.5282\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0575\n",
      "  Perceptual Photo: 0.1230, Perceptual Monet: 0.2210\n",
      "  Total G Loss: 3.5895\n",
      "Epoch [93/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1102, D_X Fake: 0.0876, D_X Total: 0.0989\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0584, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.7847, F Adv: 0.6711\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1270, Perceptual Monet: 0.1346\n",
      "  Total G Loss: 3.4616\n",
      "Epoch [93/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1313, D_X Fake: 0.1417, D_X Total: 0.1365\n",
      "  D_Y Real: 0.0500, D_Y Fake: 0.0411, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.7170, F Adv: 0.5477\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.0946, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.0879\n",
      "Epoch [93/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0995, D_X Fake: 0.0700, D_X Total: 0.0847\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.1490, D_Y Total: 0.0892\n",
      "Generator Losses:\n",
      "  G Adv: 0.4900, F Adv: 0.7045\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 3.3859\n",
      "Epoch [93/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2496, D_X Fake: 0.0898, D_X Total: 0.1697\n",
      "  D_Y Real: 0.0626, D_Y Fake: 0.0549, D_Y Total: 0.0587\n",
      "Generator Losses:\n",
      "  G Adv: 0.7967, F Adv: 0.5048\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1460\n",
      "  Total G Loss: 3.3789\n",
      "Epoch [93/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0873, D_X Fake: 0.0759, D_X Total: 0.0816\n",
      "  D_Y Real: 0.0917, D_Y Fake: 0.0744, D_Y Total: 0.0831\n",
      "Generator Losses:\n",
      "  G Adv: 0.8555, F Adv: 0.3977\n",
      "  Cycle Photo: 0.0519, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1119\n",
      "  Total G Loss: 3.2705\n",
      "Epoch [93/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0553, D_X Fake: 0.0608, D_X Total: 0.0580\n",
      "  D_Y Real: 0.0784, D_Y Fake: 0.0802, D_Y Total: 0.0793\n",
      "Generator Losses:\n",
      "  G Adv: 0.5514, F Adv: 0.4152\n",
      "  Cycle Photo: 0.0497, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1183, Perceptual Monet: 0.1220\n",
      "  Total G Loss: 2.9840\n",
      "Epoch [93/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0546, D_X Fake: 0.1285, D_X Total: 0.0916\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0683, D_Y Total: 0.0494\n",
      "Generator Losses:\n",
      "  G Adv: 0.6295, F Adv: 0.5976\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5878\n",
      "Epoch [93/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0963, D_X Fake: 0.1942, D_X Total: 0.1453\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0664, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.7365, F Adv: 0.3091\n",
      "  Cycle Photo: 0.0490, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1946, Perceptual Monet: 0.1468\n",
      "  Total G Loss: 3.6427\n",
      "Epoch [93/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1397, D_X Fake: 0.0868, D_X Total: 0.1132\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.1359, D_Y Total: 0.0851\n",
      "Generator Losses:\n",
      "  G Adv: 0.6217, F Adv: 0.5910\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1726, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.5346\n",
      "Epoch [93/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0768, D_X Fake: 0.2340, D_X Total: 0.1554\n",
      "  D_Y Real: 0.1007, D_Y Fake: 0.0528, D_Y Total: 0.0768\n",
      "Generator Losses:\n",
      "  G Adv: 1.1169, F Adv: 0.2102\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1894, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.8071\n",
      "Epoch [93/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0477, D_X Fake: 0.1637, D_X Total: 0.1057\n",
      "  D_Y Real: 0.1023, D_Y Fake: 0.0545, D_Y Total: 0.0784\n",
      "Generator Losses:\n",
      "  G Adv: 0.9840, F Adv: 0.4445\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.8215\n",
      "Epoch [93/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0777, D_X Fake: 0.0848, D_X Total: 0.0812\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.1009, D_Y Total: 0.0694\n",
      "Generator Losses:\n",
      "  G Adv: 0.5972, F Adv: 0.5836\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1149, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.2417\n",
      "Epoch [93/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0821, D_X Fake: 0.0637, D_X Total: 0.0729\n",
      "  D_Y Real: 0.0389, D_Y Fake: 0.0660, D_Y Total: 0.0525\n",
      "Generator Losses:\n",
      "  G Adv: 0.6783, F Adv: 0.4721\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1425\n",
      "  Total G Loss: 3.0301\n",
      "Epoch [93/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1349, D_X Fake: 0.0753, D_X Total: 0.1051\n",
      "  D_Y Real: 0.0407, D_Y Fake: 0.0752, D_Y Total: 0.0579\n",
      "Generator Losses:\n",
      "  G Adv: 0.5232, F Adv: 0.6074\n",
      "  Cycle Photo: 0.0502, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1373, Perceptual Monet: 0.1562\n",
      "  Total G Loss: 3.4519\n",
      "Epoch [93/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0563, D_X Fake: 0.1221, D_X Total: 0.0892\n",
      "  D_Y Real: 0.0558, D_Y Fake: 0.0582, D_Y Total: 0.0570\n",
      "Generator Losses:\n",
      "  G Adv: 0.8668, F Adv: 0.4095\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1514, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.7616\n",
      "Epoch [94/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1557, D_X Fake: 0.0996, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.1101, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.5040, F Adv: 0.5631\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0404\n",
      "  Perceptual Photo: 0.1589, Perceptual Monet: 0.1583\n",
      "  Total G Loss: 3.4634\n",
      "Epoch [94/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2549, D_X Fake: 0.1168, D_X Total: 0.1859\n",
      "  D_Y Real: 0.0595, D_Y Fake: 0.1207, D_Y Total: 0.0901\n",
      "Generator Losses:\n",
      "  G Adv: 0.6735, F Adv: 0.4036\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1447\n",
      "  Total G Loss: 3.2154\n",
      "Epoch [94/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1953, D_X Fake: 0.1083, D_X Total: 0.1518\n",
      "  D_Y Real: 0.0402, D_Y Fake: 0.0824, D_Y Total: 0.0613\n",
      "Generator Losses:\n",
      "  G Adv: 0.6649, F Adv: 0.5193\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.4364\n",
      "Epoch [94/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1164, D_X Fake: 0.1342, D_X Total: 0.1253\n",
      "  D_Y Real: 0.1007, D_Y Fake: 0.0605, D_Y Total: 0.0806\n",
      "Generator Losses:\n",
      "  G Adv: 0.7922, F Adv: 0.4293\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0441\n",
      "  Perceptual Photo: 0.1483, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.7478\n",
      "Epoch [94/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1697, D_X Fake: 0.1340, D_X Total: 0.1518\n",
      "  D_Y Real: 0.0743, D_Y Fake: 0.0657, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.7352, F Adv: 0.4208\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1534, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.4496\n",
      "Epoch [94/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0733, D_X Fake: 0.0924, D_X Total: 0.0829\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0458, D_Y Total: 0.0420\n",
      "Generator Losses:\n",
      "  G Adv: 0.7576, F Adv: 0.4756\n",
      "  Cycle Photo: 0.0529, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1161, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.5524\n",
      "Epoch [94/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1702, D_X Fake: 0.0945, D_X Total: 0.1323\n",
      "  D_Y Real: 0.0501, D_Y Fake: 0.0741, D_Y Total: 0.0621\n",
      "Generator Losses:\n",
      "  G Adv: 0.6120, F Adv: 0.5857\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.5288\n",
      "Epoch [94/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3141, D_X Fake: 0.2217, D_X Total: 0.2679\n",
      "  D_Y Real: 0.0646, D_Y Fake: 0.0492, D_Y Total: 0.0569\n",
      "Generator Losses:\n",
      "  G Adv: 0.7865, F Adv: 0.4480\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1560\n",
      "  Total G Loss: 3.5917\n",
      "Epoch [94/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1481, D_X Fake: 0.0875, D_X Total: 0.1178\n",
      "  D_Y Real: 0.0833, D_Y Fake: 0.0492, D_Y Total: 0.0663\n",
      "Generator Losses:\n",
      "  G Adv: 0.7324, F Adv: 0.4623\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1193, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.2856\n",
      "Epoch [94/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2716, D_X Fake: 0.0598, D_X Total: 0.1657\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0597, D_Y Total: 0.0516\n",
      "Generator Losses:\n",
      "  G Adv: 0.8097, F Adv: 0.7623\n",
      "  Cycle Photo: 0.0525, Cycle Monet: 0.0402\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 4.1870\n",
      "Epoch [94/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0639, D_X Fake: 0.1054, D_X Total: 0.0847\n",
      "  D_Y Real: 0.0450, D_Y Fake: 0.0405, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.7690, F Adv: 0.3860\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1363, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.2170\n",
      "Epoch [94/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1045, D_X Fake: 0.0687, D_X Total: 0.0866\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0519, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.9540, F Adv: 0.4650\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1646, Perceptual Monet: 0.1203\n",
      "  Total G Loss: 3.5693\n",
      "Epoch [94/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1539, D_X Fake: 0.1465, D_X Total: 0.1502\n",
      "  D_Y Real: 0.0460, D_Y Fake: 0.0590, D_Y Total: 0.0525\n",
      "Generator Losses:\n",
      "  G Adv: 0.7601, F Adv: 0.4680\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1269, Perceptual Monet: 0.1546\n",
      "  Total G Loss: 3.4419\n",
      "Epoch [94/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1022, D_X Fake: 0.0654, D_X Total: 0.0838\n",
      "  D_Y Real: 0.1605, D_Y Fake: 0.0356, D_Y Total: 0.0980\n",
      "Generator Losses:\n",
      "  G Adv: 0.8342, F Adv: 0.5350\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1150, Perceptual Monet: 0.1552\n",
      "  Total G Loss: 3.4652\n",
      "Epoch [94/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1123, D_X Fake: 0.0972, D_X Total: 0.1047\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.0693, D_Y Total: 0.0552\n",
      "Generator Losses:\n",
      "  G Adv: 0.5707, F Adv: 0.5165\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.2554\n",
      "Epoch [94/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0416, D_X Fake: 0.0842, D_X Total: 0.0629\n",
      "  D_Y Real: 0.0558, D_Y Fake: 0.0332, D_Y Total: 0.0445\n",
      "Generator Losses:\n",
      "  G Adv: 0.9420, F Adv: 0.5206\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.0973, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 3.4586\n",
      "Epoch [94/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0940, D_X Fake: 0.0543, D_X Total: 0.0742\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0366, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.9503, F Adv: 0.6825\n",
      "  Cycle Photo: 0.0453, Cycle Monet: 0.0407\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 4.1641\n",
      "Epoch [94/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1302, D_X Fake: 0.1305, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.1664, D_Y Total: 0.1003\n",
      "Generator Losses:\n",
      "  G Adv: 0.5410, F Adv: 0.5233\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.2812\n",
      "Epoch [94/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.0966, D_X Total: 0.1061\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0629, D_Y Total: 0.0543\n",
      "Generator Losses:\n",
      "  G Adv: 1.0381, F Adv: 0.4642\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1768, Perceptual Monet: 0.1452\n",
      "  Total G Loss: 3.9183\n",
      "Epoch [94/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1096, D_X Fake: 0.0334, D_X Total: 0.0715\n",
      "  D_Y Real: 0.0443, D_Y Fake: 0.0949, D_Y Total: 0.0696\n",
      "Generator Losses:\n",
      "  G Adv: 0.6088, F Adv: 0.6888\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.5305\n",
      "Epoch [94/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0990, D_X Fake: 0.0282, D_X Total: 0.0636\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0774, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.7646, F Adv: 0.4585\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0447\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1482\n",
      "  Total G Loss: 3.6340\n",
      "Epoch [94/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0933, D_X Fake: 0.1247, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0773, D_Y Fake: 0.0508, D_Y Total: 0.0640\n",
      "Generator Losses:\n",
      "  G Adv: 1.1031, F Adv: 0.4417\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.7920\n",
      "Epoch [94/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3091, D_X Fake: 0.0451, D_X Total: 0.1771\n",
      "  D_Y Real: 0.0658, D_Y Fake: 0.0496, D_Y Total: 0.0577\n",
      "Generator Losses:\n",
      "  G Adv: 0.8167, F Adv: 0.5189\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1637, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.7826\n",
      "Epoch [94/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1458, D_X Fake: 0.0668, D_X Total: 0.1063\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.1033, D_Y Total: 0.0660\n",
      "Generator Losses:\n",
      "  G Adv: 0.8546, F Adv: 0.5810\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1097, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.4883\n",
      "Epoch [95/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0725, D_X Fake: 0.1963, D_X Total: 0.1344\n",
      "  D_Y Real: 0.0245, D_Y Fake: 0.0652, D_Y Total: 0.0448\n",
      "Generator Losses:\n",
      "  G Adv: 0.7320, F Adv: 0.4434\n",
      "  Cycle Photo: 0.0517, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1331, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.6000\n",
      "Epoch [95/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0828, D_X Fake: 0.0583, D_X Total: 0.0705\n",
      "  D_Y Real: 0.0609, D_Y Fake: 0.0424, D_Y Total: 0.0516\n",
      "Generator Losses:\n",
      "  G Adv: 0.9399, F Adv: 0.7734\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1556, Perceptual Monet: 0.1560\n",
      "  Total G Loss: 4.0594\n",
      "Epoch [95/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0980, D_X Fake: 0.1701, D_X Total: 0.1341\n",
      "  D_Y Real: 0.0444, D_Y Fake: 0.0755, D_Y Total: 0.0599\n",
      "Generator Losses:\n",
      "  G Adv: 0.5393, F Adv: 0.4271\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1322\n",
      "  Total G Loss: 3.0028\n",
      "Epoch [95/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2069, D_X Fake: 0.0396, D_X Total: 0.1232\n",
      "  D_Y Real: 0.0617, D_Y Fake: 0.0641, D_Y Total: 0.0629\n",
      "Generator Losses:\n",
      "  G Adv: 0.7606, F Adv: 0.8387\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1302, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.7175\n",
      "Epoch [95/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2759, D_X Fake: 0.1184, D_X Total: 0.1971\n",
      "  D_Y Real: 0.0505, D_Y Fake: 0.1235, D_Y Total: 0.0870\n",
      "Generator Losses:\n",
      "  G Adv: 0.6147, F Adv: 0.4780\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1219, Perceptual Monet: 0.1436\n",
      "  Total G Loss: 3.0405\n",
      "Epoch [95/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0484, D_X Fake: 0.0367, D_X Total: 0.0425\n",
      "  D_Y Real: 0.0546, D_Y Fake: 0.1240, D_Y Total: 0.0893\n",
      "Generator Losses:\n",
      "  G Adv: 0.6447, F Adv: 0.8902\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1287, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.7956\n",
      "Epoch [95/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1322, D_X Fake: 0.0662, D_X Total: 0.0992\n",
      "  D_Y Real: 0.0643, D_Y Fake: 0.1562, D_Y Total: 0.1103\n",
      "Generator Losses:\n",
      "  G Adv: 0.6344, F Adv: 0.6730\n",
      "  Cycle Photo: 0.0498, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1487, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.6792\n",
      "Epoch [95/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0405, D_X Fake: 0.0547, D_X Total: 0.0476\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.1232, D_Y Total: 0.0794\n",
      "Generator Losses:\n",
      "  G Adv: 0.6173, F Adv: 0.4227\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1223, Perceptual Monet: 0.1574\n",
      "  Total G Loss: 3.1580\n",
      "Epoch [95/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1258, D_X Fake: 0.1635, D_X Total: 0.1447\n",
      "  D_Y Real: 0.1311, D_Y Fake: 0.0438, D_Y Total: 0.0875\n",
      "Generator Losses:\n",
      "  G Adv: 0.9801, F Adv: 0.3275\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1265\n",
      "  Total G Loss: 3.2872\n",
      "Epoch [95/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0954, D_X Fake: 0.1588, D_X Total: 0.1271\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0596, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.7367, F Adv: 0.4603\n",
      "  Cycle Photo: 0.0435, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1472, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.5335\n",
      "Epoch [95/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1902, D_X Fake: 0.0586, D_X Total: 0.1244\n",
      "  D_Y Real: 0.0860, D_Y Fake: 0.0832, D_Y Total: 0.0846\n",
      "Generator Losses:\n",
      "  G Adv: 0.7655, F Adv: 0.6104\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1507, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.5973\n",
      "Epoch [95/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0656, D_X Fake: 0.1096, D_X Total: 0.0876\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0936, D_Y Total: 0.0726\n",
      "Generator Losses:\n",
      "  G Adv: 0.6011, F Adv: 0.3656\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1171, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.0872\n",
      "Epoch [95/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0353, D_X Fake: 0.2282, D_X Total: 0.1317\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0608, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.7912, F Adv: 0.2227\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1227, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.1435\n",
      "Epoch [95/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3579, D_X Fake: 0.0660, D_X Total: 0.2119\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.1827, D_Y Total: 0.1146\n",
      "Generator Losses:\n",
      "  G Adv: 0.7675, F Adv: 0.8596\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 4.1324\n",
      "Epoch [95/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1967, D_X Fake: 0.0803, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0472, D_Y Fake: 0.1161, D_Y Total: 0.0817\n",
      "Generator Losses:\n",
      "  G Adv: 0.5264, F Adv: 0.6448\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1352, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.5439\n",
      "Epoch [95/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4677, D_X Fake: 0.0359, D_X Total: 0.2518\n",
      "  D_Y Real: 0.0488, D_Y Fake: 0.0617, D_Y Total: 0.0553\n",
      "Generator Losses:\n",
      "  G Adv: 0.5365, F Adv: 1.1971\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.9488\n",
      "Epoch [95/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0552, D_X Fake: 0.2398, D_X Total: 0.1475\n",
      "  D_Y Real: 0.0431, D_Y Fake: 0.0427, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.4128, F Adv: 0.2706\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 2.8789\n",
      "Epoch [95/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.1246, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0616, D_Y Fake: 0.0839, D_Y Total: 0.0728\n",
      "Generator Losses:\n",
      "  G Adv: 0.8271, F Adv: 0.5559\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1364, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 3.4794\n",
      "Epoch [95/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0790, D_X Fake: 0.1188, D_X Total: 0.0989\n",
      "  D_Y Real: 0.1046, D_Y Fake: 0.0594, D_Y Total: 0.0820\n",
      "Generator Losses:\n",
      "  G Adv: 0.8556, F Adv: 0.3920\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1523\n",
      "  Total G Loss: 3.3276\n",
      "Epoch [95/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1816, D_X Fake: 0.0507, D_X Total: 0.1161\n",
      "  D_Y Real: 0.0574, D_Y Fake: 0.0460, D_Y Total: 0.0517\n",
      "Generator Losses:\n",
      "  G Adv: 0.8044, F Adv: 0.7844\n",
      "  Cycle Photo: 0.0464, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.8964\n",
      "Epoch [95/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0858, D_X Fake: 0.0637, D_X Total: 0.0747\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.1082, D_Y Total: 0.0739\n",
      "Generator Losses:\n",
      "  G Adv: 0.7137, F Adv: 0.6430\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0481\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1904\n",
      "  Total G Loss: 4.0733\n",
      "Epoch [95/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1824, D_X Fake: 0.1828, D_X Total: 0.1826\n",
      "  D_Y Real: 0.0583, D_Y Fake: 0.0507, D_Y Total: 0.0545\n",
      "Generator Losses:\n",
      "  G Adv: 0.7376, F Adv: 0.5861\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1145, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.2754\n",
      "Epoch [95/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0978, D_X Fake: 0.0374, D_X Total: 0.0676\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0572, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 0.6099, F Adv: 0.8679\n",
      "  Cycle Photo: 0.0636, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1469\n",
      "  Total G Loss: 3.8734\n",
      "Epoch [95/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2306, D_X Fake: 0.0911, D_X Total: 0.1608\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.0953, D_Y Total: 0.0714\n",
      "Generator Losses:\n",
      "  G Adv: 0.6649, F Adv: 0.6069\n",
      "  Cycle Photo: 0.0470, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1273, Perceptual Monet: 0.1322\n",
      "  Total G Loss: 3.3013\n",
      "Epoch [96/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0891, D_X Fake: 0.0729, D_X Total: 0.0810\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.1504, D_Y Total: 0.0944\n",
      "Generator Losses:\n",
      "  G Adv: 0.5226, F Adv: 0.5871\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1025, Perceptual Monet: 0.1385\n",
      "  Total G Loss: 2.9584\n",
      "Epoch [96/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2168, D_X Fake: 0.0462, D_X Total: 0.1315\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0888, D_Y Total: 0.0642\n",
      "Generator Losses:\n",
      "  G Adv: 0.4068, F Adv: 0.8107\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1379, Perceptual Monet: 0.1404\n",
      "  Total G Loss: 3.2655\n",
      "Epoch [96/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.0974, D_X Total: 0.0965\n",
      "  D_Y Real: 0.1114, D_Y Fake: 0.0492, D_Y Total: 0.0803\n",
      "Generator Losses:\n",
      "  G Adv: 0.8930, F Adv: 0.5023\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1586\n",
      "  Total G Loss: 3.6556\n",
      "Epoch [96/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1480, D_X Fake: 0.0614, D_X Total: 0.1047\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0973, D_Y Total: 0.0637\n",
      "Generator Losses:\n",
      "  G Adv: 0.7040, F Adv: 0.6357\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1273\n",
      "  Total G Loss: 3.3121\n",
      "Epoch [96/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1966, D_X Fake: 0.1321, D_X Total: 0.1643\n",
      "  D_Y Real: 0.1195, D_Y Fake: 0.0703, D_Y Total: 0.0949\n",
      "Generator Losses:\n",
      "  G Adv: 1.1332, F Adv: 0.4969\n",
      "  Cycle Photo: 0.0657, Cycle Monet: 0.0484\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1997\n",
      "  Total G Loss: 4.4963\n",
      "Epoch [96/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1255, D_X Fake: 0.0496, D_X Total: 0.0876\n",
      "  D_Y Real: 0.0522, D_Y Fake: 0.1274, D_Y Total: 0.0898\n",
      "Generator Losses:\n",
      "  G Adv: 0.5948, F Adv: 0.7396\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1148, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.5194\n",
      "Epoch [96/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0551, D_X Fake: 0.2503, D_X Total: 0.1527\n",
      "  D_Y Real: 0.1368, D_Y Fake: 0.0605, D_Y Total: 0.0987\n",
      "Generator Losses:\n",
      "  G Adv: 0.8865, F Adv: 0.2587\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0420\n",
      "  Perceptual Photo: 0.1591, Perceptual Monet: 0.1962\n",
      "  Total G Loss: 3.7521\n",
      "Epoch [96/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1188, D_X Fake: 0.1240, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0691, D_Y Fake: 0.0981, D_Y Total: 0.0836\n",
      "Generator Losses:\n",
      "  G Adv: 0.5831, F Adv: 0.4742\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.4540\n",
      "Epoch [96/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0834, D_X Fake: 0.1065, D_X Total: 0.0949\n",
      "  D_Y Real: 0.0735, D_Y Fake: 0.0548, D_Y Total: 0.0641\n",
      "Generator Losses:\n",
      "  G Adv: 0.7633, F Adv: 0.5403\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1136, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.4650\n",
      "Epoch [96/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0673, D_X Fake: 0.1796, D_X Total: 0.1235\n",
      "  D_Y Real: 0.0745, D_Y Fake: 0.0955, D_Y Total: 0.0850\n",
      "Generator Losses:\n",
      "  G Adv: 0.6439, F Adv: 0.4374\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1550\n",
      "  Total G Loss: 3.2978\n",
      "Epoch [96/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1660, D_X Fake: 0.0953, D_X Total: 0.1306\n",
      "  D_Y Real: 0.1077, D_Y Fake: 0.0455, D_Y Total: 0.0766\n",
      "Generator Losses:\n",
      "  G Adv: 0.8522, F Adv: 0.6351\n",
      "  Cycle Photo: 0.0466, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.9027\n",
      "Epoch [96/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0568, D_X Fake: 0.0842, D_X Total: 0.0705\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0465, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8140, F Adv: 1.0430\n",
      "  Cycle Photo: 0.0566, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1453\n",
      "  Total G Loss: 4.0791\n",
      "Epoch [96/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0749, D_X Fake: 0.2019, D_X Total: 0.1384\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0880, D_Y Total: 0.0579\n",
      "Generator Losses:\n",
      "  G Adv: 0.5964, F Adv: 0.3748\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1302, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.1331\n",
      "Epoch [96/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0695, D_X Fake: 0.1163, D_X Total: 0.0929\n",
      "  D_Y Real: 0.0482, D_Y Fake: 0.0798, D_Y Total: 0.0640\n",
      "Generator Losses:\n",
      "  G Adv: 0.6928, F Adv: 0.4507\n",
      "  Cycle Photo: 0.0457, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1369\n",
      "  Total G Loss: 3.2895\n",
      "Epoch [96/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0825, D_X Fake: 0.1221, D_X Total: 0.1023\n",
      "  D_Y Real: 0.1189, D_Y Fake: 0.0502, D_Y Total: 0.0846\n",
      "Generator Losses:\n",
      "  G Adv: 1.0252, F Adv: 0.4592\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1609, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.8717\n",
      "Epoch [96/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4250, D_X Fake: 0.0521, D_X Total: 0.2385\n",
      "  D_Y Real: 0.0457, D_Y Fake: 0.0570, D_Y Total: 0.0513\n",
      "Generator Losses:\n",
      "  G Adv: 0.6893, F Adv: 0.6990\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1328, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.4807\n",
      "Epoch [96/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1323, D_X Fake: 0.0529, D_X Total: 0.0926\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.0948, D_Y Total: 0.0685\n",
      "Generator Losses:\n",
      "  G Adv: 0.5561, F Adv: 0.6106\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1168, Perceptual Monet: 0.1574\n",
      "  Total G Loss: 3.2424\n",
      "Epoch [96/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1425, D_X Fake: 0.0634, D_X Total: 0.1029\n",
      "  D_Y Real: 0.0477, D_Y Fake: 0.0866, D_Y Total: 0.0672\n",
      "Generator Losses:\n",
      "  G Adv: 0.6029, F Adv: 0.5790\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1534\n",
      "  Total G Loss: 3.2124\n",
      "Epoch [96/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0420, D_X Fake: 0.0522, D_X Total: 0.0471\n",
      "  D_Y Real: 0.0711, D_Y Fake: 0.0474, D_Y Total: 0.0593\n",
      "Generator Losses:\n",
      "  G Adv: 1.1845, F Adv: 0.5258\n",
      "  Cycle Photo: 0.0480, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1235, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 4.1267\n",
      "Epoch [96/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1569, D_X Fake: 0.0871, D_X Total: 0.1220\n",
      "  D_Y Real: 0.0528, D_Y Fake: 0.0495, D_Y Total: 0.0511\n",
      "Generator Losses:\n",
      "  G Adv: 0.7288, F Adv: 0.6183\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0509\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1376\n",
      "  Total G Loss: 3.6406\n",
      "Epoch [96/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0920, D_X Fake: 0.1344, D_X Total: 0.1132\n",
      "  D_Y Real: 0.1028, D_Y Fake: 0.0719, D_Y Total: 0.0874\n",
      "Generator Losses:\n",
      "  G Adv: 1.0152, F Adv: 0.3960\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1587, Perceptual Monet: 0.1678\n",
      "  Total G Loss: 3.8019\n",
      "Epoch [96/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0604, D_X Fake: 0.2752, D_X Total: 0.1678\n",
      "  D_Y Real: 0.0371, D_Y Fake: 0.0589, D_Y Total: 0.0480\n",
      "Generator Losses:\n",
      "  G Adv: 0.7639, F Adv: 0.2821\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.2125\n",
      "Epoch [96/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1038, D_X Fake: 0.0405, D_X Total: 0.0721\n",
      "  D_Y Real: 0.0633, D_Y Fake: 0.0519, D_Y Total: 0.0576\n",
      "Generator Losses:\n",
      "  G Adv: 1.0060, F Adv: 0.7196\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1506\n",
      "  Total G Loss: 3.9661\n",
      "Epoch [96/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2455, D_X Fake: 0.2025, D_X Total: 0.2240\n",
      "  D_Y Real: 0.0673, D_Y Fake: 0.0861, D_Y Total: 0.0767\n",
      "Generator Losses:\n",
      "  G Adv: 0.6209, F Adv: 0.4803\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1178, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.1709\n",
      "Epoch [97/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2545, D_X Fake: 0.0787, D_X Total: 0.1666\n",
      "  D_Y Real: 0.0466, D_Y Fake: 0.1116, D_Y Total: 0.0791\n",
      "Generator Losses:\n",
      "  G Adv: 0.5685, F Adv: 0.4623\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1178, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 3.1491\n",
      "Epoch [97/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0698, D_X Fake: 0.0774, D_X Total: 0.0736\n",
      "  D_Y Real: 0.0589, D_Y Fake: 0.1459, D_Y Total: 0.1024\n",
      "Generator Losses:\n",
      "  G Adv: 0.4245, F Adv: 0.5019\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0449\n",
      "  Perceptual Photo: 0.1187, Perceptual Monet: 0.1518\n",
      "  Total G Loss: 3.1864\n",
      "Epoch [97/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0850, D_X Fake: 0.1281, D_X Total: 0.1066\n",
      "  D_Y Real: 0.0588, D_Y Fake: 0.0332, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 1.0005, F Adv: 0.4830\n",
      "  Cycle Photo: 0.0642, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.2015, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 4.3839\n",
      "Epoch [97/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1060, D_X Fake: 0.0748, D_X Total: 0.0904\n",
      "  D_Y Real: 0.0604, D_Y Fake: 0.0395, D_Y Total: 0.0499\n",
      "Generator Losses:\n",
      "  G Adv: 0.8726, F Adv: 0.5564\n",
      "  Cycle Photo: 0.0473, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1633, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.9500\n",
      "Epoch [97/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0758, D_X Fake: 0.1057, D_X Total: 0.0908\n",
      "  D_Y Real: 0.1139, D_Y Fake: 0.0455, D_Y Total: 0.0797\n",
      "Generator Losses:\n",
      "  G Adv: 1.0899, F Adv: 0.4154\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 3.6240\n",
      "Epoch [97/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0428, D_X Fake: 0.0851, D_X Total: 0.0639\n",
      "  D_Y Real: 0.0378, D_Y Fake: 0.1353, D_Y Total: 0.0866\n",
      "Generator Losses:\n",
      "  G Adv: 0.5457, F Adv: 0.4428\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1502, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.2188\n",
      "Epoch [97/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0910, D_X Fake: 0.1193, D_X Total: 0.1052\n",
      "  D_Y Real: 0.0823, D_Y Fake: 0.0644, D_Y Total: 0.0734\n",
      "Generator Losses:\n",
      "  G Adv: 0.5849, F Adv: 0.4300\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1127, Perceptual Monet: 0.1340\n",
      "  Total G Loss: 2.7934\n",
      "Epoch [97/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2104, D_X Fake: 0.1640, D_X Total: 0.1872\n",
      "  D_Y Real: 0.0286, D_Y Fake: 0.1590, D_Y Total: 0.0938\n",
      "Generator Losses:\n",
      "  G Adv: 0.5154, F Adv: 0.3248\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0428\n",
      "  Perceptual Photo: 0.1363, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 2.9951\n",
      "Epoch [97/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0922, D_X Fake: 0.1282, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0859, D_Y Fake: 0.0688, D_Y Total: 0.0774\n",
      "Generator Losses:\n",
      "  G Adv: 0.7824, F Adv: 0.5359\n",
      "  Cycle Photo: 0.0552, Cycle Monet: 0.0524\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.2103\n",
      "  Total G Loss: 4.1009\n",
      "Epoch [97/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0603, D_X Fake: 0.0928, D_X Total: 0.0765\n",
      "  D_Y Real: 0.0627, D_Y Fake: 0.0278, D_Y Total: 0.0452\n",
      "Generator Losses:\n",
      "  G Adv: 1.0756, F Adv: 0.3919\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1522, Perceptual Monet: 0.1471\n",
      "  Total G Loss: 3.7792\n",
      "Epoch [97/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0736, D_X Fake: 0.2211, D_X Total: 0.1474\n",
      "  D_Y Real: 0.0549, D_Y Fake: 0.0522, D_Y Total: 0.0536\n",
      "Generator Losses:\n",
      "  G Adv: 0.7705, F Adv: 0.2747\n",
      "  Cycle Photo: 0.0732, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.2027, Perceptual Monet: 0.1563\n",
      "  Total G Loss: 3.8667\n",
      "Epoch [97/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0554, D_X Fake: 0.1869, D_X Total: 0.1212\n",
      "  D_Y Real: 0.0514, D_Y Fake: 0.0479, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.8807, F Adv: 0.3322\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1208, Perceptual Monet: 0.1640\n",
      "  Total G Loss: 3.3977\n",
      "Epoch [97/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1496, D_X Fake: 0.1375, D_X Total: 0.1435\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0881, D_Y Total: 0.0604\n",
      "Generator Losses:\n",
      "  G Adv: 0.5660, F Adv: 0.4689\n",
      "  Cycle Photo: 0.0376, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.3183\n",
      "Epoch [97/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1659, D_X Fake: 0.0610, D_X Total: 0.1135\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0786, D_Y Total: 0.0510\n",
      "Generator Losses:\n",
      "  G Adv: 0.6932, F Adv: 0.6220\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.4474\n",
      "Epoch [97/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1167, D_X Fake: 0.0691, D_X Total: 0.0929\n",
      "  D_Y Real: 0.0555, D_Y Fake: 0.0881, D_Y Total: 0.0718\n",
      "Generator Losses:\n",
      "  G Adv: 0.8666, F Adv: 0.4437\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0442\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1819\n",
      "  Total G Loss: 3.8371\n",
      "Epoch [97/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0891, D_X Fake: 0.1074, D_X Total: 0.0982\n",
      "  D_Y Real: 0.0539, D_Y Fake: 0.0770, D_Y Total: 0.0655\n",
      "Generator Losses:\n",
      "  G Adv: 0.6179, F Adv: 0.5395\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1214, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.2295\n",
      "Epoch [97/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0635, D_X Fake: 0.1867, D_X Total: 0.1251\n",
      "  D_Y Real: 0.0548, D_Y Fake: 0.0805, D_Y Total: 0.0677\n",
      "Generator Losses:\n",
      "  G Adv: 0.5689, F Adv: 0.3928\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0406\n",
      "  Perceptual Photo: 0.1215, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.0930\n",
      "Epoch [97/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2410, D_X Fake: 0.0738, D_X Total: 0.1574\n",
      "  D_Y Real: 0.0440, D_Y Fake: 0.2463, D_Y Total: 0.1452\n",
      "Generator Losses:\n",
      "  G Adv: 0.4040, F Adv: 0.6044\n",
      "  Cycle Photo: 0.0365, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1707\n",
      "  Total G Loss: 3.1562\n",
      "Epoch [97/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3336, D_X Fake: 0.0478, D_X Total: 0.1907\n",
      "  D_Y Real: 0.0516, D_Y Fake: 0.1028, D_Y Total: 0.0772\n",
      "Generator Losses:\n",
      "  G Adv: 0.5303, F Adv: 0.8787\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1625, Perceptual Monet: 0.1900\n",
      "  Total G Loss: 4.0753\n",
      "Epoch [97/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1666, D_X Fake: 0.1121, D_X Total: 0.1394\n",
      "  D_Y Real: 0.0573, D_Y Fake: 0.1806, D_Y Total: 0.1189\n",
      "Generator Losses:\n",
      "  G Adv: 0.6945, F Adv: 0.4360\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1470\n",
      "  Total G Loss: 3.1516\n",
      "Epoch [97/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3220, D_X Fake: 0.0785, D_X Total: 0.2003\n",
      "  D_Y Real: 0.0846, D_Y Fake: 0.0365, D_Y Total: 0.0606\n",
      "Generator Losses:\n",
      "  G Adv: 0.9317, F Adv: 1.1660\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1615, Perceptual Monet: 0.1394\n",
      "  Total G Loss: 4.3069\n",
      "Epoch [97/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0872, D_X Fake: 0.0975, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0803, D_Y Fake: 0.0432, D_Y Total: 0.0618\n",
      "Generator Losses:\n",
      "  G Adv: 0.8701, F Adv: 0.5291\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1171\n",
      "  Total G Loss: 3.3291\n",
      "Epoch [97/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0540, D_X Fake: 0.2114, D_X Total: 0.1327\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.1961, D_Y Total: 0.1163\n",
      "Generator Losses:\n",
      "  G Adv: 0.4787, F Adv: 0.3591\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1620, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 3.1220\n",
      "Epoch [97/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3350, D_X Fake: 0.0576, D_X Total: 0.1963\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0555, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 1.1400, F Adv: 1.1508\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1449, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 4.5584\n",
      "Epoch [98/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1564, D_X Fake: 0.1684, D_X Total: 0.1624\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0373, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.5671, F Adv: 0.4030\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1255\n",
      "  Total G Loss: 3.1746\n",
      "Epoch [98/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1342, D_X Fake: 0.1463, D_X Total: 0.1403\n",
      "  D_Y Real: 0.0906, D_Y Fake: 0.0401, D_Y Total: 0.0654\n",
      "Generator Losses:\n",
      "  G Adv: 0.9893, F Adv: 0.3859\n",
      "  Cycle Photo: 0.0530, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.1191\n",
      "  Total G Loss: 3.5881\n",
      "Epoch [98/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0606, D_X Fake: 0.2459, D_X Total: 0.1532\n",
      "  D_Y Real: 0.0489, D_Y Fake: 0.0973, D_Y Total: 0.0731\n",
      "Generator Losses:\n",
      "  G Adv: 0.7756, F Adv: 0.2689\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1137, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.1197\n",
      "Epoch [98/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1577, D_X Fake: 0.0372, D_X Total: 0.0975\n",
      "  D_Y Real: 0.0427, D_Y Fake: 0.1006, D_Y Total: 0.0717\n",
      "Generator Losses:\n",
      "  G Adv: 0.4915, F Adv: 0.7017\n",
      "  Cycle Photo: 0.0474, Cycle Monet: 0.0467\n",
      "  Perceptual Photo: 0.1310, Perceptual Monet: 0.1897\n",
      "  Total G Loss: 3.7380\n",
      "Epoch [98/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0805, D_X Fake: 0.0966, D_X Total: 0.0886\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0554, D_Y Total: 0.0523\n",
      "Generator Losses:\n",
      "  G Adv: 0.7891, F Adv: 0.3582\n",
      "  Cycle Photo: 0.0444, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1438\n",
      "  Total G Loss: 3.4874\n",
      "Epoch [98/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1124, D_X Fake: 0.0991, D_X Total: 0.1058\n",
      "  D_Y Real: 0.0349, D_Y Fake: 0.1181, D_Y Total: 0.0765\n",
      "Generator Losses:\n",
      "  G Adv: 0.5921, F Adv: 0.5005\n",
      "  Cycle Photo: 0.0489, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1495\n",
      "  Total G Loss: 3.3739\n",
      "Epoch [98/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1160, D_X Fake: 0.0732, D_X Total: 0.0946\n",
      "  D_Y Real: 0.1183, D_Y Fake: 0.0595, D_Y Total: 0.0889\n",
      "Generator Losses:\n",
      "  G Adv: 0.7661, F Adv: 0.5424\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1489\n",
      "  Total G Loss: 3.5290\n",
      "Epoch [98/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1583, D_X Fake: 0.1431, D_X Total: 0.1507\n",
      "  D_Y Real: 0.0594, D_Y Fake: 0.0388, D_Y Total: 0.0491\n",
      "Generator Losses:\n",
      "  G Adv: 0.8019, F Adv: 0.5096\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1356\n",
      "  Total G Loss: 3.3680\n",
      "Epoch [98/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1199, D_X Fake: 0.2648, D_X Total: 0.1924\n",
      "  D_Y Real: 0.0544, D_Y Fake: 0.0470, D_Y Total: 0.0507\n",
      "Generator Losses:\n",
      "  G Adv: 0.9238, F Adv: 0.2392\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1510, Perceptual Monet: 0.1894\n",
      "  Total G Loss: 3.5848\n",
      "Epoch [98/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2261, D_X Fake: 0.0517, D_X Total: 0.1389\n",
      "  D_Y Real: 0.0681, D_Y Fake: 0.0425, D_Y Total: 0.0553\n",
      "Generator Losses:\n",
      "  G Adv: 0.6922, F Adv: 0.8852\n",
      "  Cycle Photo: 0.0488, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1228, Perceptual Monet: 0.1419\n",
      "  Total G Loss: 3.7050\n",
      "Epoch [98/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1252, D_X Fake: 0.1139, D_X Total: 0.1195\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.0438, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.9718, F Adv: 0.3654\n",
      "  Cycle Photo: 0.0531, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.6760\n",
      "Epoch [98/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1406, D_X Fake: 0.0806, D_X Total: 0.1106\n",
      "  D_Y Real: 0.0508, D_Y Fake: 0.1176, D_Y Total: 0.0842\n",
      "Generator Losses:\n",
      "  G Adv: 0.6440, F Adv: 0.5837\n",
      "  Cycle Photo: 0.0519, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1752, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.8222\n",
      "Epoch [98/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1695, D_X Fake: 0.0433, D_X Total: 0.1064\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.0469, D_Y Total: 0.0445\n",
      "Generator Losses:\n",
      "  G Adv: 0.6672, F Adv: 0.7436\n",
      "  Cycle Photo: 0.0452, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.6833\n",
      "Epoch [98/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2127, D_X Fake: 0.0419, D_X Total: 0.1273\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.1145, D_Y Total: 0.0810\n",
      "Generator Losses:\n",
      "  G Adv: 0.5913, F Adv: 0.7117\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1728\n",
      "  Total G Loss: 3.6168\n",
      "Epoch [98/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2118, D_X Fake: 0.1798, D_X Total: 0.1958\n",
      "  D_Y Real: 0.1278, D_Y Fake: 0.0850, D_Y Total: 0.1064\n",
      "Generator Losses:\n",
      "  G Adv: 0.9485, F Adv: 0.4167\n",
      "  Cycle Photo: 0.0382, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1226\n",
      "  Total G Loss: 3.3569\n",
      "Epoch [98/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2313, D_X Fake: 0.1055, D_X Total: 0.1684\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.1948, D_Y Total: 0.1134\n",
      "Generator Losses:\n",
      "  G Adv: 0.4600, F Adv: 0.5717\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1550\n",
      "  Total G Loss: 3.2965\n",
      "Epoch [98/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.0949, D_X Total: 0.1052\n",
      "  D_Y Real: 0.1004, D_Y Fake: 0.0990, D_Y Total: 0.0997\n",
      "Generator Losses:\n",
      "  G Adv: 0.6561, F Adv: 0.4790\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.4719\n",
      "Epoch [98/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1110, D_X Fake: 0.0816, D_X Total: 0.0963\n",
      "  D_Y Real: 0.0418, D_Y Fake: 0.0643, D_Y Total: 0.0531\n",
      "Generator Losses:\n",
      "  G Adv: 0.5427, F Adv: 0.4992\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1571, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.2434\n",
      "Epoch [98/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2360, D_X Fake: 0.0597, D_X Total: 0.1479\n",
      "  D_Y Real: 0.0694, D_Y Fake: 0.1608, D_Y Total: 0.1151\n",
      "Generator Losses:\n",
      "  G Adv: 0.5058, F Adv: 0.7026\n",
      "  Cycle Photo: 0.0582, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1903\n",
      "  Total G Loss: 3.8341\n",
      "Epoch [98/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2091, D_X Fake: 0.0346, D_X Total: 0.1219\n",
      "  D_Y Real: 0.0496, D_Y Fake: 0.0395, D_Y Total: 0.0446\n",
      "Generator Losses:\n",
      "  G Adv: 0.8197, F Adv: 0.7984\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.9417\n",
      "Epoch [98/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1147, D_X Fake: 0.0863, D_X Total: 0.1005\n",
      "  D_Y Real: 0.0809, D_Y Fake: 0.0462, D_Y Total: 0.0635\n",
      "Generator Losses:\n",
      "  G Adv: 0.9127, F Adv: 0.4588\n",
      "  Cycle Photo: 0.0458, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1368\n",
      "  Total G Loss: 3.5082\n",
      "Epoch [98/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0615, D_X Fake: 0.0954, D_X Total: 0.0785\n",
      "  D_Y Real: 0.0587, D_Y Fake: 0.0745, D_Y Total: 0.0666\n",
      "Generator Losses:\n",
      "  G Adv: 0.4960, F Adv: 0.3827\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1389, Perceptual Monet: 0.1293\n",
      "  Total G Loss: 2.7495\n",
      "Epoch [98/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0949, D_X Fake: 0.0845, D_X Total: 0.0897\n",
      "  D_Y Real: 0.1533, D_Y Fake: 0.0494, D_Y Total: 0.1014\n",
      "Generator Losses:\n",
      "  G Adv: 0.9457, F Adv: 0.4651\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1247, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.5913\n",
      "Epoch [98/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3051, D_X Fake: 0.0535, D_X Total: 0.1793\n",
      "  D_Y Real: 0.0338, D_Y Fake: 0.0409, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.8084, F Adv: 0.8628\n",
      "  Cycle Photo: 0.0404, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1280, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.8524\n",
      "Epoch [99/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0701, D_X Fake: 0.0886, D_X Total: 0.0793\n",
      "  D_Y Real: 0.0558, D_Y Fake: 0.0962, D_Y Total: 0.0760\n",
      "Generator Losses:\n",
      "  G Adv: 0.7822, F Adv: 0.4154\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1443, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.5320\n",
      "Epoch [99/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3233, D_X Fake: 0.0624, D_X Total: 0.1929\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.0715, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.8494, F Adv: 0.6059\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1881, Perceptual Monet: 0.1798\n",
      "  Total G Loss: 4.2428\n",
      "Epoch [99/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1014, D_X Fake: 0.0363, D_X Total: 0.0689\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0889, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.7258, F Adv: 0.8351\n",
      "  Cycle Photo: 0.0472, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.0961, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.6962\n",
      "Epoch [99/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2240, D_X Fake: 0.0402, D_X Total: 0.1321\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0868, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.4964, F Adv: 0.9063\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0391\n",
      "  Perceptual Photo: 0.1041, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.4124\n",
      "Epoch [99/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2589, D_X Fake: 0.1041, D_X Total: 0.1815\n",
      "  D_Y Real: 0.1199, D_Y Fake: 0.0549, D_Y Total: 0.0874\n",
      "Generator Losses:\n",
      "  G Adv: 1.2973, F Adv: 0.6969\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1587, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 4.3479\n",
      "Epoch [99/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1276, D_X Fake: 0.1482, D_X Total: 0.1379\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0890, D_Y Total: 0.0703\n",
      "Generator Losses:\n",
      "  G Adv: 0.4919, F Adv: 0.4327\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1176, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.0490\n",
      "Epoch [99/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2500, D_X Fake: 0.0539, D_X Total: 0.1519\n",
      "  D_Y Real: 0.0692, D_Y Fake: 0.0538, D_Y Total: 0.0615\n",
      "Generator Losses:\n",
      "  G Adv: 0.6912, F Adv: 0.8061\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1507\n",
      "  Total G Loss: 3.7149\n",
      "Epoch [99/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2134, D_X Fake: 0.0729, D_X Total: 0.1432\n",
      "  D_Y Real: 0.0696, D_Y Fake: 0.0812, D_Y Total: 0.0754\n",
      "Generator Losses:\n",
      "  G Adv: 0.6750, F Adv: 0.5914\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 3.6466\n",
      "Epoch [99/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.5445, D_X Fake: 0.4825, D_X Total: 0.5135\n",
      "  D_Y Real: 0.0578, D_Y Fake: 0.0474, D_Y Total: 0.0526\n",
      "Generator Losses:\n",
      "  G Adv: 0.8518, F Adv: 0.3471\n",
      "  Cycle Photo: 0.0455, Cycle Monet: 0.0549\n",
      "  Perceptual Photo: 0.1755, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.9427\n",
      "Epoch [99/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2497, D_X Fake: 0.2513, D_X Total: 0.2505\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0542, D_Y Total: 0.0422\n",
      "Generator Losses:\n",
      "  G Adv: 0.7012, F Adv: 0.2759\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0431\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.4218\n",
      "Epoch [99/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3663, D_X Fake: 0.2572, D_X Total: 0.3118\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.0411, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.6872, F Adv: 0.2071\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0479\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1919\n",
      "  Total G Loss: 3.4032\n",
      "Epoch [99/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2578, D_X Fake: 0.4269, D_X Total: 0.3424\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0593, D_Y Total: 0.0456\n",
      "Generator Losses:\n",
      "  G Adv: 0.7151, F Adv: 0.1565\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0490\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1241\n",
      "  Total G Loss: 3.2075\n",
      "Epoch [99/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3041, D_X Fake: 0.3556, D_X Total: 0.3298\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0553, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.7957, F Adv: 0.1976\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1630, Perceptual Monet: 0.1305\n",
      "  Total G Loss: 3.1297\n",
      "Epoch [99/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2520, D_X Fake: 0.1760, D_X Total: 0.2140\n",
      "  D_Y Real: 0.0846, D_Y Fake: 0.0547, D_Y Total: 0.0697\n",
      "Generator Losses:\n",
      "  G Adv: 1.1299, F Adv: 0.3783\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1528, Perceptual Monet: 0.1356\n",
      "  Total G Loss: 3.6677\n",
      "Epoch [99/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2613, D_X Fake: 0.1895, D_X Total: 0.2254\n",
      "  D_Y Real: 0.0454, D_Y Fake: 0.0553, D_Y Total: 0.0504\n",
      "Generator Losses:\n",
      "  G Adv: 0.8234, F Adv: 0.2626\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.1765\n",
      "  Total G Loss: 3.4200\n",
      "Epoch [99/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2846, D_X Fake: 0.2645, D_X Total: 0.2745\n",
      "  D_Y Real: 0.0963, D_Y Fake: 0.0362, D_Y Total: 0.0663\n",
      "Generator Losses:\n",
      "  G Adv: 0.8083, F Adv: 0.2783\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.1963\n",
      "Epoch [99/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1960, D_X Fake: 0.2773, D_X Total: 0.2367\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0998, D_Y Total: 0.0672\n",
      "Generator Losses:\n",
      "  G Adv: 0.6424, F Adv: 0.2484\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1272, Perceptual Monet: 0.1566\n",
      "  Total G Loss: 3.0465\n",
      "Epoch [99/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2535, D_X Fake: 0.2561, D_X Total: 0.2548\n",
      "  D_Y Real: 0.0624, D_Y Fake: 0.0666, D_Y Total: 0.0645\n",
      "Generator Losses:\n",
      "  G Adv: 0.9080, F Adv: 0.3177\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1480\n",
      "  Total G Loss: 3.5655\n",
      "Epoch [99/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2463, D_X Fake: 0.3083, D_X Total: 0.2773\n",
      "  D_Y Real: 0.0395, D_Y Fake: 0.0368, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.8194, F Adv: 0.2507\n",
      "  Cycle Photo: 0.0504, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1302\n",
      "  Total G Loss: 3.2918\n",
      "Epoch [99/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1876, D_X Fake: 0.2545, D_X Total: 0.2210\n",
      "  D_Y Real: 0.0664, D_Y Fake: 0.0755, D_Y Total: 0.0709\n",
      "Generator Losses:\n",
      "  G Adv: 0.3320, F Adv: 0.2722\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1317, Perceptual Monet: 0.1279\n",
      "  Total G Loss: 2.5679\n",
      "Epoch [99/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3366, D_X Fake: 0.2339, D_X Total: 0.2852\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.1398, D_Y Total: 0.0825\n",
      "Generator Losses:\n",
      "  G Adv: 0.5629, F Adv: 0.2972\n",
      "  Cycle Photo: 0.0634, Cycle Monet: 0.0458\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1284\n",
      "  Total G Loss: 3.4081\n",
      "Epoch [99/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1879, D_X Fake: 0.2950, D_X Total: 0.2414\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0556, D_Y Total: 0.0478\n",
      "Generator Losses:\n",
      "  G Adv: 0.6365, F Adv: 0.2347\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.1220\n",
      "  Total G Loss: 2.8386\n",
      "Epoch [99/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2099, D_X Fake: 0.2865, D_X Total: 0.2482\n",
      "  D_Y Real: 0.0497, D_Y Fake: 0.0589, D_Y Total: 0.0543\n",
      "Generator Losses:\n",
      "  G Adv: 0.6349, F Adv: 0.2002\n",
      "  Cycle Photo: 0.0460, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.1329\n",
      "  Total G Loss: 2.9218\n",
      "Epoch [99/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2530, D_X Fake: 0.1895, D_X Total: 0.2213\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0365, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.8607, F Adv: 0.2852\n",
      "  Cycle Photo: 0.0459, Cycle Monet: 0.0416\n",
      "  Perceptual Photo: 0.1616, Perceptual Monet: 0.1230\n",
      "  Total G Loss: 3.4441\n",
      "Epoch [100/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3153, D_X Fake: 0.2322, D_X Total: 0.2737\n",
      "  D_Y Real: 0.0640, D_Y Fake: 0.1210, D_Y Total: 0.0925\n",
      "Generator Losses:\n",
      "  G Adv: 0.5754, F Adv: 0.3620\n",
      "  Cycle Photo: 0.0471, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1306, Perceptual Monet: 0.1414\n",
      "  Total G Loss: 3.0561\n",
      "Epoch [100/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2310, D_X Fake: 0.2875, D_X Total: 0.2592\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0314, D_Y Total: 0.0289\n",
      "Generator Losses:\n",
      "  G Adv: 0.8017, F Adv: 0.2852\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.3254\n",
      "Epoch [100/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2792, D_X Fake: 0.2724, D_X Total: 0.2758\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0347, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.7850, F Adv: 0.2714\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1117\n",
      "  Total G Loss: 2.9438\n",
      "Epoch [100/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2130, D_X Fake: 0.2615, D_X Total: 0.2373\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.0406, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.8216, F Adv: 0.2573\n",
      "  Cycle Photo: 0.0228, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1045, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 2.9311\n",
      "Epoch [100/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2229, D_X Fake: 0.2771, D_X Total: 0.2500\n",
      "  D_Y Real: 0.0302, D_Y Fake: 0.0479, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.8067, F Adv: 0.2842\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1202, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 2.9431\n",
      "Epoch [100/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2128, D_X Fake: 0.2239, D_X Total: 0.2183\n",
      "  D_Y Real: 0.0351, D_Y Fake: 0.0581, D_Y Total: 0.0466\n",
      "Generator Losses:\n",
      "  G Adv: 0.7549, F Adv: 0.3343\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1148, Perceptual Monet: 0.1431\n",
      "  Total G Loss: 3.0526\n",
      "Epoch [100/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2890, D_X Fake: 0.2215, D_X Total: 0.2552\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0595, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.8378, F Adv: 0.2836\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0208\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1158\n",
      "  Total G Loss: 2.9274\n",
      "Epoch [100/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1868, D_X Fake: 0.2161, D_X Total: 0.2015\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0474, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.7775, F Adv: 0.2301\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1173, Perceptual Monet: 0.1411\n",
      "  Total G Loss: 2.8958\n",
      "Epoch [100/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2930, D_X Fake: 0.1795, D_X Total: 0.2362\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0530, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.7297, F Adv: 0.3399\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1307\n",
      "  Total G Loss: 2.9157\n",
      "Epoch [100/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1688, D_X Fake: 0.3194, D_X Total: 0.2441\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0291, D_Y Total: 0.0237\n",
      "Generator Losses:\n",
      "  G Adv: 0.8403, F Adv: 0.2862\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1310\n",
      "  Total G Loss: 3.1208\n",
      "Epoch [100/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2216, D_X Fake: 0.2704, D_X Total: 0.2460\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0439, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.7783, F Adv: 0.2000\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.1211\n",
      "  Total G Loss: 2.6737\n",
      "Epoch [100/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1370, D_X Fake: 0.2587, D_X Total: 0.1978\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0366, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.8375, F Adv: 0.3340\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1096, Perceptual Monet: 0.1314\n",
      "  Total G Loss: 3.0511\n",
      "Epoch [100/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3493, D_X Fake: 0.2559, D_X Total: 0.3026\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0378, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8148, F Adv: 0.2829\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1216, Perceptual Monet: 0.1243\n",
      "  Total G Loss: 2.8215\n",
      "Epoch [100/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2897, D_X Fake: 0.2744, D_X Total: 0.2821\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0956, D_Y Total: 0.0595\n",
      "Generator Losses:\n",
      "  G Adv: 0.6153, F Adv: 0.2771\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1300\n",
      "  Total G Loss: 3.0417\n",
      "Epoch [100/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2922, D_X Fake: 0.2652, D_X Total: 0.2787\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0456, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.8814, F Adv: 0.3074\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1137, Perceptual Monet: 0.1449\n",
      "  Total G Loss: 3.1779\n",
      "Epoch [100/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2573, D_X Fake: 0.2364, D_X Total: 0.2469\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0637, D_Y Total: 0.0473\n",
      "Generator Losses:\n",
      "  G Adv: 0.6890, F Adv: 0.2934\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1191, Perceptual Monet: 0.1251\n",
      "  Total G Loss: 2.7399\n",
      "Epoch [100/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2113, D_X Fake: 0.2312, D_X Total: 0.2212\n",
      "  D_Y Real: 0.0388, D_Y Fake: 0.0656, D_Y Total: 0.0522\n",
      "Generator Losses:\n",
      "  G Adv: 0.9662, F Adv: 0.2734\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.0958, Perceptual Monet: 0.1205\n",
      "  Total G Loss: 2.8326\n",
      "Epoch [100/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1668, D_X Fake: 0.2360, D_X Total: 0.2014\n",
      "  D_Y Real: 0.0289, D_Y Fake: 0.0326, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.7079, F Adv: 0.3137\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1294, Perceptual Monet: 0.1275\n",
      "  Total G Loss: 2.8639\n",
      "Epoch [100/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2939, D_X Fake: 0.2518, D_X Total: 0.2728\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0347, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.6474, F Adv: 0.2638\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0181\n",
      "  Perceptual Photo: 0.1165, Perceptual Monet: 0.1032\n",
      "  Total G Loss: 2.4338\n",
      "Epoch [100/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1320, D_X Fake: 0.2326, D_X Total: 0.1823\n",
      "  D_Y Real: 0.0454, D_Y Fake: 0.0562, D_Y Total: 0.0508\n",
      "Generator Losses:\n",
      "  G Adv: 0.9016, F Adv: 0.2973\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0216\n",
      "  Perceptual Photo: 0.1257, Perceptual Monet: 0.1187\n",
      "  Total G Loss: 3.0324\n",
      "Epoch [100/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3275, D_X Fake: 0.2297, D_X Total: 0.2786\n",
      "  D_Y Real: 0.1026, D_Y Fake: 0.0433, D_Y Total: 0.0730\n",
      "Generator Losses:\n",
      "  G Adv: 0.7989, F Adv: 0.3315\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.1262\n",
      "  Total G Loss: 3.1508\n",
      "Epoch [100/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2820, D_X Fake: 0.1799, D_X Total: 0.2309\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0542, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.7774, F Adv: 0.3379\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1310, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.1968\n",
      "Epoch [100/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2761, D_X Fake: 0.2190, D_X Total: 0.2476\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0612, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.6663, F Adv: 0.2639\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1166\n",
      "  Total G Loss: 2.7544\n",
      "Epoch [100/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1928, D_X Fake: 0.1795, D_X Total: 0.1862\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0499, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.8660, F Adv: 0.2912\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1072, Perceptual Monet: 0.1312\n",
      "  Total G Loss: 2.8850\n",
      "Saved checkpoint at epoch 100\n",
      "Epoch [101/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2549, D_X Fake: 0.2297, D_X Total: 0.2423\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0391, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8977, F Adv: 0.2461\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.1236\n",
      "  Total G Loss: 2.8565\n",
      "Epoch [101/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2802, D_X Fake: 0.2413, D_X Total: 0.2607\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0264, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 1.0263, F Adv: 0.3192\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1352, Perceptual Monet: 0.1284\n",
      "  Total G Loss: 3.2306\n",
      "Epoch [101/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2172, D_X Fake: 0.2056, D_X Total: 0.2114\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0484, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.9303, F Adv: 0.3086\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0203\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1064\n",
      "  Total G Loss: 3.0429\n",
      "Epoch [101/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2566, D_X Fake: 0.2575, D_X Total: 0.2570\n",
      "  D_Y Real: 0.0512, D_Y Fake: 0.0805, D_Y Total: 0.0659\n",
      "Generator Losses:\n",
      "  G Adv: 0.7262, F Adv: 0.3089\n",
      "  Cycle Photo: 0.0487, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1980, Perceptual Monet: 0.1251\n",
      "  Total G Loss: 3.3571\n",
      "Epoch [101/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2502, D_X Fake: 0.2617, D_X Total: 0.2559\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0474, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.8830, F Adv: 0.3332\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.1231\n",
      "  Total G Loss: 2.9317\n",
      "Epoch [101/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2119, D_X Fake: 0.2159, D_X Total: 0.2139\n",
      "  D_Y Real: 0.0428, D_Y Fake: 0.0261, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.9389, F Adv: 0.2978\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1046, Perceptual Monet: 0.1463\n",
      "  Total G Loss: 3.0443\n",
      "Epoch [101/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2663, D_X Fake: 0.2744, D_X Total: 0.2703\n",
      "  D_Y Real: 0.0371, D_Y Fake: 0.0328, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.7341, F Adv: 0.3107\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1180\n",
      "  Total G Loss: 2.9006\n",
      "Epoch [101/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3159, D_X Fake: 0.2207, D_X Total: 0.2683\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0429, D_Y Total: 0.0311\n",
      "Generator Losses:\n",
      "  G Adv: 0.8060, F Adv: 0.2882\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.2017, Perceptual Monet: 0.1167\n",
      "  Total G Loss: 3.3554\n",
      "Epoch [101/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3025, D_X Fake: 0.2038, D_X Total: 0.2531\n",
      "  D_Y Real: 0.0632, D_Y Fake: 0.0602, D_Y Total: 0.0617\n",
      "Generator Losses:\n",
      "  G Adv: 0.8105, F Adv: 0.3223\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0213\n",
      "  Perceptual Photo: 0.1181, Perceptual Monet: 0.1238\n",
      "  Total G Loss: 2.8039\n",
      "Epoch [101/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2437, D_X Fake: 0.2049, D_X Total: 0.2243\n",
      "  D_Y Real: 0.0467, D_Y Fake: 0.0513, D_Y Total: 0.0490\n",
      "Generator Losses:\n",
      "  G Adv: 0.7562, F Adv: 0.3227\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1303\n",
      "  Total G Loss: 2.8270\n",
      "Epoch [101/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2287, D_X Fake: 0.2097, D_X Total: 0.2192\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0853, D_Y Total: 0.0545\n",
      "Generator Losses:\n",
      "  G Adv: 0.6743, F Adv: 0.3106\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0199\n",
      "  Perceptual Photo: 0.1110, Perceptual Monet: 0.1210\n",
      "  Total G Loss: 2.6069\n",
      "Epoch [101/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2056, D_X Fake: 0.1539, D_X Total: 0.1797\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.0530, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.8819, F Adv: 0.4111\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0159\n",
      "  Perceptual Photo: 0.1057, Perceptual Monet: 0.0877\n",
      "  Total G Loss: 2.6650\n",
      "Epoch [101/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1830, D_X Fake: 0.2373, D_X Total: 0.2102\n",
      "  D_Y Real: 0.0650, D_Y Fake: 0.0642, D_Y Total: 0.0646\n",
      "Generator Losses:\n",
      "  G Adv: 0.7240, F Adv: 0.3349\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0200\n",
      "  Perceptual Photo: 0.1289, Perceptual Monet: 0.1152\n",
      "  Total G Loss: 2.7851\n",
      "Epoch [101/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2273, D_X Fake: 0.2103, D_X Total: 0.2188\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.0367, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.7558, F Adv: 0.3335\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.1325\n",
      "  Total G Loss: 3.0367\n",
      "Epoch [101/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1791, D_X Fake: 0.2455, D_X Total: 0.2123\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0323, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.8446, F Adv: 0.2619\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0198\n",
      "  Perceptual Photo: 0.0830, Perceptual Monet: 0.1052\n",
      "  Total G Loss: 2.5120\n",
      "Epoch [101/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2120, D_X Fake: 0.1830, D_X Total: 0.1975\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0548, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.7818, F Adv: 0.3762\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1222\n",
      "  Total G Loss: 2.8587\n",
      "Epoch [101/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2148, D_X Fake: 0.1235, D_X Total: 0.1692\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.0576, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.8276, F Adv: 0.3267\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0189\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1103\n",
      "  Total G Loss: 2.8715\n",
      "Epoch [101/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1999, D_X Fake: 0.1731, D_X Total: 0.1865\n",
      "  D_Y Real: 0.0466, D_Y Fake: 0.0564, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 0.8409, F Adv: 0.4144\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1362, Perceptual Monet: 0.1244\n",
      "  Total G Loss: 3.0742\n",
      "Epoch [101/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1625, D_X Fake: 0.1784, D_X Total: 0.1705\n",
      "  D_Y Real: 0.0447, D_Y Fake: 0.0542, D_Y Total: 0.0495\n",
      "Generator Losses:\n",
      "  G Adv: 0.7927, F Adv: 0.3762\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0180\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1111\n",
      "  Total G Loss: 2.8914\n",
      "Epoch [101/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1473, D_X Fake: 0.1002, D_X Total: 0.1238\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0554, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.8034, F Adv: 0.5166\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1915, Perceptual Monet: 0.1487\n",
      "  Total G Loss: 3.7028\n",
      "Epoch [101/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1451, D_X Fake: 0.1048, D_X Total: 0.1250\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0611, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.7678, F Adv: 0.4376\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1357\n",
      "  Total G Loss: 3.1966\n",
      "Epoch [101/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1455, D_X Fake: 0.1413, D_X Total: 0.1434\n",
      "  D_Y Real: 0.0948, D_Y Fake: 0.0374, D_Y Total: 0.0661\n",
      "Generator Losses:\n",
      "  G Adv: 0.8470, F Adv: 0.4466\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.3157\n",
      "Epoch [101/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1082, D_X Fake: 0.1496, D_X Total: 0.1289\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0730, D_Y Total: 0.0473\n",
      "Generator Losses:\n",
      "  G Adv: 0.8855, F Adv: 0.4556\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0155\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.0944\n",
      "  Total G Loss: 3.0013\n",
      "Epoch [101/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1710, D_X Fake: 0.1076, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0471, D_Y Fake: 0.0689, D_Y Total: 0.0580\n",
      "Generator Losses:\n",
      "  G Adv: 0.7511, F Adv: 0.5264\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.1767\n",
      "Epoch [102/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0953, D_X Fake: 0.1066, D_X Total: 0.1009\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0369, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 0.8102, F Adv: 0.5229\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1249, Perceptual Monet: 0.1348\n",
      "  Total G Loss: 3.1399\n",
      "Epoch [102/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1738, D_X Fake: 0.1064, D_X Total: 0.1401\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.1042, D_Y Total: 0.0670\n",
      "Generator Losses:\n",
      "  G Adv: 0.7131, F Adv: 0.5120\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0203\n",
      "  Perceptual Photo: 0.1173, Perceptual Monet: 0.1204\n",
      "  Total G Loss: 2.9158\n",
      "Epoch [102/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1483, D_X Fake: 0.0692, D_X Total: 0.1087\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0301, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 0.8404, F Adv: 0.5584\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0198\n",
      "  Perceptual Photo: 0.1084, Perceptual Monet: 0.1132\n",
      "  Total G Loss: 2.9526\n",
      "Epoch [102/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1454, D_X Fake: 0.1079, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0371, D_Y Fake: 0.0607, D_Y Total: 0.0489\n",
      "Generator Losses:\n",
      "  G Adv: 0.9728, F Adv: 0.5284\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0180\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1076\n",
      "  Total G Loss: 3.2693\n",
      "Epoch [102/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1608, D_X Fake: 0.0910, D_X Total: 0.1259\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0692, D_Y Total: 0.0452\n",
      "Generator Losses:\n",
      "  G Adv: 0.7231, F Adv: 0.5740\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1331, Perceptual Monet: 0.1322\n",
      "  Total G Loss: 3.1331\n",
      "Epoch [102/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0798, D_X Fake: 0.0916, D_X Total: 0.0857\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0344, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9078, F Adv: 0.4911\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1412, Perceptual Monet: 0.1316\n",
      "  Total G Loss: 3.3515\n",
      "Epoch [102/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0621, D_X Fake: 0.1005, D_X Total: 0.0813\n",
      "  D_Y Real: 0.0716, D_Y Fake: 0.0836, D_Y Total: 0.0776\n",
      "Generator Losses:\n",
      "  G Adv: 0.8645, F Adv: 0.5162\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1438\n",
      "  Total G Loss: 3.2569\n",
      "Epoch [102/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.1203, D_X Total: 0.0848\n",
      "  D_Y Real: 0.0504, D_Y Fake: 0.0402, D_Y Total: 0.0453\n",
      "Generator Losses:\n",
      "  G Adv: 0.9269, F Adv: 0.5310\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1194, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.4235\n",
      "Epoch [102/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0653, D_X Fake: 0.0962, D_X Total: 0.0808\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.0396, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.8555, F Adv: 0.5602\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1223, Perceptual Monet: 0.1409\n",
      "  Total G Loss: 3.2341\n",
      "Epoch [102/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0927, D_X Fake: 0.1091, D_X Total: 0.1009\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0317, D_Y Total: 0.0253\n",
      "Generator Losses:\n",
      "  G Adv: 0.9225, F Adv: 0.5602\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1156, Perceptual Monet: 0.1340\n",
      "  Total G Loss: 3.2783\n",
      "Epoch [102/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1737, D_X Fake: 0.0629, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0486, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.8672, F Adv: 0.5813\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0202\n",
      "  Perceptual Photo: 0.1402, Perceptual Monet: 0.1124\n",
      "  Total G Loss: 3.2338\n",
      "Epoch [102/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2551, D_X Fake: 0.0867, D_X Total: 0.1709\n",
      "  D_Y Real: 0.0431, D_Y Fake: 0.0486, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.7236, F Adv: 0.4964\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1366, Perceptual Monet: 0.1463\n",
      "  Total G Loss: 3.1619\n",
      "Epoch [102/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0423, D_X Fake: 0.1571, D_X Total: 0.0997\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0356, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.8234, F Adv: 0.4107\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0198\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1132\n",
      "  Total G Loss: 3.0746\n",
      "Epoch [102/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0791, D_X Fake: 0.1026, D_X Total: 0.0909\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0822, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.6581, F Adv: 0.5508\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1181, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.1197\n",
      "Epoch [102/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0957, D_X Fake: 0.0994, D_X Total: 0.0976\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0428, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 1.0193, F Adv: 0.5460\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0191\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1247\n",
      "  Total G Loss: 3.5138\n",
      "Epoch [102/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1601, D_X Fake: 0.0621, D_X Total: 0.1111\n",
      "  D_Y Real: 0.0248, D_Y Fake: 0.0412, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.8692, F Adv: 0.6241\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1472\n",
      "  Total G Loss: 3.5560\n",
      "Epoch [102/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0821, D_X Fake: 0.0828, D_X Total: 0.0824\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0768, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.9084, F Adv: 0.5339\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1460, Perceptual Monet: 0.1434\n",
      "  Total G Loss: 3.4906\n",
      "Epoch [102/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0989, D_X Fake: 0.0715, D_X Total: 0.0852\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0377, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.9512, F Adv: 0.6130\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1120, Perceptual Monet: 0.1387\n",
      "  Total G Loss: 3.3641\n",
      "Epoch [102/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.0971, D_X Total: 0.0838\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0441, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.9454, F Adv: 0.5108\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0166\n",
      "  Perceptual Photo: 0.1209, Perceptual Monet: 0.1043\n",
      "  Total G Loss: 3.0501\n",
      "Epoch [102/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0673, D_X Fake: 0.0946, D_X Total: 0.0810\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0350, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.7912, F Adv: 0.5476\n",
      "  Cycle Photo: 0.0432, Cycle Monet: 0.0192\n",
      "  Perceptual Photo: 0.1258, Perceptual Monet: 0.1066\n",
      "  Total G Loss: 3.1248\n",
      "Epoch [102/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1244, D_X Fake: 0.0605, D_X Total: 0.0925\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0371, D_Y Total: 0.0319\n",
      "Generator Losses:\n",
      "  G Adv: 0.8962, F Adv: 0.5848\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1210, Perceptual Monet: 0.1436\n",
      "  Total G Loss: 3.3863\n",
      "Epoch [102/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1149, D_X Fake: 0.0874, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0670, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 0.7352, F Adv: 0.5503\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1412\n",
      "  Total G Loss: 3.2888\n",
      "Epoch [102/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1097, D_X Fake: 0.0966, D_X Total: 0.1032\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0450, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.8521, F Adv: 0.6380\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1885, Perceptual Monet: 0.1208\n",
      "  Total G Loss: 3.6523\n",
      "Epoch [102/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0576, D_X Fake: 0.0743, D_X Total: 0.0660\n",
      "  D_Y Real: 0.0477, D_Y Fake: 0.0485, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.7881, F Adv: 0.4594\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1149, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.0833\n",
      "Epoch [103/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0497, D_X Fake: 0.0929, D_X Total: 0.0713\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0316, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 1.0309, F Adv: 0.5131\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0203\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1237\n",
      "  Total G Loss: 3.5623\n",
      "Epoch [103/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0934, D_X Fake: 0.0961, D_X Total: 0.0947\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.0457, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.8003, F Adv: 0.5554\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.7335\n",
      "Epoch [103/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1395, D_X Fake: 0.0932, D_X Total: 0.1164\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0332, D_Y Total: 0.0250\n",
      "Generator Losses:\n",
      "  G Adv: 0.8407, F Adv: 0.6862\n",
      "  Cycle Photo: 0.0214, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.3799\n",
      "Epoch [103/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1118, D_X Fake: 0.1184, D_X Total: 0.1151\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0318, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.8793, F Adv: 0.4612\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1396, Perceptual Monet: 0.1473\n",
      "  Total G Loss: 3.3395\n",
      "Epoch [103/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0940, D_X Fake: 0.0804, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0330, D_Y Fake: 0.0414, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.8209, F Adv: 0.6720\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1212, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 3.4993\n",
      "Epoch [103/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1000, D_X Fake: 0.1230, D_X Total: 0.1115\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0472, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8387, F Adv: 0.5428\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0192\n",
      "  Perceptual Photo: 0.0987, Perceptual Monet: 0.1146\n",
      "  Total G Loss: 2.8611\n",
      "Epoch [103/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1060, D_X Fake: 0.0631, D_X Total: 0.0845\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0280, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 1.2991, F Adv: 0.6305\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1424\n",
      "  Total G Loss: 3.9627\n",
      "Epoch [103/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0675, D_X Fake: 0.0930, D_X Total: 0.0803\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0291, D_Y Total: 0.0252\n",
      "Generator Losses:\n",
      "  G Adv: 0.9922, F Adv: 0.5452\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0203\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1245\n",
      "  Total G Loss: 3.4882\n",
      "Epoch [103/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1250, D_X Fake: 0.0739, D_X Total: 0.0995\n",
      "  D_Y Real: 0.0147, D_Y Fake: 0.0387, D_Y Total: 0.0267\n",
      "Generator Losses:\n",
      "  G Adv: 0.7633, F Adv: 0.5481\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1564, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.4277\n",
      "Epoch [103/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1006, D_X Fake: 0.1571, D_X Total: 0.1289\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.0238, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 1.0444, F Adv: 0.5353\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1161, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.5224\n",
      "Epoch [103/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0757, D_X Fake: 0.1043, D_X Total: 0.0900\n",
      "  D_Y Real: 0.0481, D_Y Fake: 0.0487, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.8589, F Adv: 0.5530\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1245, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.2929\n",
      "Epoch [103/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0652, D_X Fake: 0.0863, D_X Total: 0.0757\n",
      "  D_Y Real: 0.0335, D_Y Fake: 0.0829, D_Y Total: 0.0582\n",
      "Generator Losses:\n",
      "  G Adv: 0.6993, F Adv: 0.5486\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1466, Perceptual Monet: 0.1459\n",
      "  Total G Loss: 3.2992\n",
      "Epoch [103/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1648, D_X Fake: 0.0657, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0633, D_Y Total: 0.0514\n",
      "Generator Losses:\n",
      "  G Adv: 0.7426, F Adv: 0.6762\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0218\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1281\n",
      "  Total G Loss: 3.3129\n",
      "Epoch [103/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0625, D_X Fake: 0.0837, D_X Total: 0.0731\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0392, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.9255, F Adv: 0.5784\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1457, Perceptual Monet: 0.1403\n",
      "  Total G Loss: 3.4794\n",
      "Epoch [103/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1106, D_X Fake: 0.0714, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0661, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 0.6922, F Adv: 0.5797\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1744, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.6362\n",
      "Epoch [103/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1606, D_X Fake: 0.1083, D_X Total: 0.1344\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0320, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.8316, F Adv: 0.5474\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1361\n",
      "  Total G Loss: 3.3842\n",
      "Epoch [103/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0918, D_X Fake: 0.0710, D_X Total: 0.0814\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.1005, D_Y Total: 0.0582\n",
      "Generator Losses:\n",
      "  G Adv: 0.7206, F Adv: 0.6259\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.5266\n",
      "Epoch [103/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0409, D_X Fake: 0.0719, D_X Total: 0.0564\n",
      "  D_Y Real: 0.0289, D_Y Fake: 0.0405, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.8884, F Adv: 0.5884\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1272, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.4794\n",
      "Epoch [103/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1510, D_X Fake: 0.0766, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0539, D_Y Fake: 0.0285, D_Y Total: 0.0412\n",
      "Generator Losses:\n",
      "  G Adv: 1.0196, F Adv: 0.6698\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.1718\n",
      "  Total G Loss: 3.9514\n",
      "Epoch [103/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0878, D_X Fake: 0.0626, D_X Total: 0.0752\n",
      "  D_Y Real: 0.0318, D_Y Fake: 0.0402, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.7604, F Adv: 0.5088\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.3740\n",
      "Epoch [103/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1413, D_X Fake: 0.0289, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0423, D_Y Total: 0.0304\n",
      "Generator Losses:\n",
      "  G Adv: 0.9128, F Adv: 0.7011\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1049, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.5979\n",
      "Epoch [103/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0749, D_X Fake: 0.0716, D_X Total: 0.0732\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0718, D_Y Total: 0.0450\n",
      "Generator Losses:\n",
      "  G Adv: 0.9966, F Adv: 0.5957\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1478\n",
      "  Total G Loss: 3.7576\n",
      "Epoch [103/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1579, D_X Fake: 0.0753, D_X Total: 0.1166\n",
      "  D_Y Real: 0.0330, D_Y Fake: 0.0557, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.8699, F Adv: 0.6175\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1541, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.6744\n",
      "Epoch [103/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0615, D_X Fake: 0.0753, D_X Total: 0.0684\n",
      "  D_Y Real: 0.0347, D_Y Fake: 0.0504, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.7619, F Adv: 0.5891\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1831, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.7264\n",
      "Epoch [104/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.1392, D_X Total: 0.1273\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0503, D_Y Total: 0.0510\n",
      "Generator Losses:\n",
      "  G Adv: 0.8922, F Adv: 0.4118\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.2499\n",
      "Epoch [104/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0919, D_X Fake: 0.0907, D_X Total: 0.0913\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.0420, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.9326, F Adv: 0.5364\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1258, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.3829\n",
      "Epoch [104/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1451, D_X Fake: 0.1045, D_X Total: 0.1248\n",
      "  D_Y Real: 0.0410, D_Y Fake: 0.0561, D_Y Total: 0.0485\n",
      "Generator Losses:\n",
      "  G Adv: 1.0870, F Adv: 0.5099\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1164, Perceptual Monet: 0.1315\n",
      "  Total G Loss: 3.3367\n",
      "Epoch [104/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0373, D_X Fake: 0.0699, D_X Total: 0.0536\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0395, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8405, F Adv: 0.6403\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1869, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.9138\n",
      "Epoch [104/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0850, D_X Fake: 0.0424, D_X Total: 0.0637\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0500, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 0.7801, F Adv: 0.7160\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1328, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.4912\n",
      "Epoch [104/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0643, D_X Fake: 0.0532, D_X Total: 0.0588\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0665, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.7842, F Adv: 0.5268\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.5180\n",
      "Epoch [104/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0991, D_X Fake: 0.1262, D_X Total: 0.1126\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0303, D_Y Total: 0.0266\n",
      "Generator Losses:\n",
      "  G Adv: 0.8940, F Adv: 0.4145\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1437\n",
      "  Total G Loss: 3.3058\n",
      "Epoch [104/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0928, D_X Fake: 0.0501, D_X Total: 0.0714\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0351, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8954, F Adv: 0.5648\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.7555\n",
      "Epoch [104/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0264, D_X Fake: 0.1134, D_X Total: 0.0699\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0680, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.8691, F Adv: 0.4965\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1191, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.4437\n",
      "Epoch [104/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1289, D_X Fake: 0.0771, D_X Total: 0.1030\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0447, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.8363, F Adv: 0.5814\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1249, Perceptual Monet: 0.1335\n",
      "  Total G Loss: 3.2265\n",
      "Epoch [104/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0794, D_X Fake: 0.1427, D_X Total: 0.1111\n",
      "  D_Y Real: 0.0614, D_Y Fake: 0.0794, D_Y Total: 0.0704\n",
      "Generator Losses:\n",
      "  G Adv: 0.8844, F Adv: 0.4169\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0149\n",
      "  Perceptual Photo: 0.1426, Perceptual Monet: 0.0962\n",
      "  Total G Loss: 2.9404\n",
      "Epoch [104/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0905, D_X Fake: 0.0901, D_X Total: 0.0903\n",
      "  D_Y Real: 0.0480, D_Y Fake: 0.0283, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 1.0729, F Adv: 0.5843\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.8015\n",
      "Epoch [104/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0643, D_X Fake: 0.0930, D_X Total: 0.0786\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0515, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.8452, F Adv: 0.5725\n",
      "  Cycle Photo: 0.0500, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1447\n",
      "  Total G Loss: 3.5653\n",
      "Epoch [104/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0648, D_X Fake: 0.0813, D_X Total: 0.0730\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0319, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 0.7737, F Adv: 0.6010\n",
      "  Cycle Photo: 0.0573, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1085, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.4899\n",
      "Epoch [104/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0873, D_X Fake: 0.0638, D_X Total: 0.0755\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.0322, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 1.0320, F Adv: 0.5555\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1525\n",
      "  Total G Loss: 3.6884\n",
      "Epoch [104/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1046, D_X Fake: 0.0763, D_X Total: 0.0904\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0415, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.8900, F Adv: 0.6432\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1392\n",
      "  Total G Loss: 3.3889\n",
      "Epoch [104/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1309, D_X Fake: 0.1223, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0417, D_Y Fake: 0.0504, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.7807, F Adv: 0.5980\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.6467\n",
      "Epoch [104/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1340, D_X Fake: 0.0708, D_X Total: 0.1024\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.0409, D_Y Total: 0.0404\n",
      "Generator Losses:\n",
      "  G Adv: 0.8327, F Adv: 0.6094\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.5836\n",
      "Epoch [104/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0568, D_X Fake: 0.0667, D_X Total: 0.0617\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0452, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 0.8249, F Adv: 0.6370\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1441\n",
      "  Total G Loss: 3.6125\n",
      "Epoch [104/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1619, D_X Fake: 0.0936, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.0309, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.9466, F Adv: 0.5790\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1204, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 3.4234\n",
      "Epoch [104/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0909, D_X Fake: 0.1285, D_X Total: 0.1097\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0377, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8798, F Adv: 0.5094\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1532, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 3.5361\n",
      "Epoch [104/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.0782, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0432, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.7013, F Adv: 0.5376\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1830, Perceptual Monet: 0.1562\n",
      "  Total G Loss: 3.5956\n",
      "Epoch [104/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.1135, D_X Total: 0.0984\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0363, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.8845, F Adv: 0.5855\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1113, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.4043\n",
      "Epoch [104/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1104, D_X Fake: 0.0568, D_X Total: 0.0836\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0607, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.7618, F Adv: 0.6859\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1573, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 3.7319\n",
      "Epoch [105/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1192, D_X Fake: 0.0552, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0525, D_Y Fake: 0.0810, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.5921, F Adv: 0.6934\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.0997, Perceptual Monet: 0.1367\n",
      "  Total G Loss: 2.9931\n",
      "Epoch [105/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0809, D_X Fake: 0.0911, D_X Total: 0.0860\n",
      "  D_Y Real: 0.0493, D_Y Fake: 0.0642, D_Y Total: 0.0568\n",
      "Generator Losses:\n",
      "  G Adv: 0.8221, F Adv: 0.5984\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1061, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.3574\n",
      "Epoch [105/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1058, D_X Fake: 0.0734, D_X Total: 0.0896\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0657, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.9772, F Adv: 0.7434\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1385, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.8366\n",
      "Epoch [105/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2096, D_X Fake: 0.1141, D_X Total: 0.1619\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0613, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.8534, F Adv: 0.5559\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1423\n",
      "  Total G Loss: 3.5499\n",
      "Epoch [105/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1924, D_X Fake: 0.0956, D_X Total: 0.1440\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0641, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.6754, F Adv: 0.5737\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1123, Perceptual Monet: 0.1382\n",
      "  Total G Loss: 2.9966\n",
      "Epoch [105/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1090, D_X Fake: 0.0727, D_X Total: 0.0909\n",
      "  D_Y Real: 0.0520, D_Y Fake: 0.0389, D_Y Total: 0.0454\n",
      "Generator Losses:\n",
      "  G Adv: 0.7996, F Adv: 0.6479\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1527\n",
      "  Total G Loss: 3.6574\n",
      "Epoch [105/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0845, D_X Fake: 0.0668, D_X Total: 0.0756\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.0358, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 1.1470, F Adv: 0.6519\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1464, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.9620\n",
      "Epoch [105/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0991, D_X Fake: 0.0682, D_X Total: 0.0837\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0501, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 1.0796, F Adv: 0.6092\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.7256\n",
      "Epoch [105/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1324, D_X Fake: 0.0985, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0262, D_Y Fake: 0.0460, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8467, F Adv: 0.5843\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1192, Perceptual Monet: 0.1557\n",
      "  Total G Loss: 3.3412\n",
      "Epoch [105/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1404, D_X Fake: 0.1687, D_X Total: 0.1545\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0421, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.7969, F Adv: 0.4457\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1273, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.1066\n",
      "Epoch [105/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.0542, D_X Total: 0.0727\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0581, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.8370, F Adv: 0.6128\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1343, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 3.5346\n",
      "Epoch [105/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1940, D_X Fake: 0.0718, D_X Total: 0.1329\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0548, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.8186, F Adv: 0.6380\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1357, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.4611\n",
      "Epoch [105/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0796, D_X Fake: 0.1227, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0558, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 1.1060, F Adv: 0.4821\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.7091\n",
      "Epoch [105/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0480, D_X Fake: 0.0499, D_X Total: 0.0489\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0680, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.6928, F Adv: 0.7218\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1514\n",
      "  Total G Loss: 3.3283\n",
      "Epoch [105/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1112, D_X Fake: 0.0969, D_X Total: 0.1041\n",
      "  D_Y Real: 0.0164, D_Y Fake: 0.0848, D_Y Total: 0.0506\n",
      "Generator Losses:\n",
      "  G Adv: 0.8229, F Adv: 0.6878\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1278, Perceptual Monet: 0.1974\n",
      "  Total G Loss: 3.7511\n",
      "Epoch [105/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1818, D_X Fake: 0.0766, D_X Total: 0.1292\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0463, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.7747, F Adv: 0.6633\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1515\n",
      "  Total G Loss: 3.5257\n",
      "Epoch [105/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1289, D_X Fake: 0.0618, D_X Total: 0.0953\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0831, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.8124, F Adv: 0.7395\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 3.7464\n",
      "Epoch [105/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1373, D_X Fake: 0.1045, D_X Total: 0.1209\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0777, D_Y Total: 0.0538\n",
      "Generator Losses:\n",
      "  G Adv: 0.7009, F Adv: 0.5803\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1496, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.4196\n",
      "Epoch [105/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.0983, D_X Total: 0.0970\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0355, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 1.0358, F Adv: 0.5476\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1159, Perceptual Monet: 0.1558\n",
      "  Total G Loss: 3.4266\n",
      "Epoch [105/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1072, D_X Fake: 0.0700, D_X Total: 0.0886\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0675, D_Y Total: 0.0522\n",
      "Generator Losses:\n",
      "  G Adv: 0.7183, F Adv: 0.6462\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.5589\n",
      "Epoch [105/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1421, D_X Fake: 0.0626, D_X Total: 0.1024\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0350, D_Y Total: 0.0270\n",
      "Generator Losses:\n",
      "  G Adv: 0.9506, F Adv: 0.5906\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.5672\n",
      "Epoch [105/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1286, D_X Fake: 0.0968, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.0294, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.9207, F Adv: 0.7629\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 3.8077\n",
      "Epoch [105/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0974, D_X Fake: 0.1465, D_X Total: 0.1219\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0436, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 1.1041, F Adv: 0.5382\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1903\n",
      "  Total G Loss: 3.9382\n",
      "Epoch [105/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0782, D_X Fake: 0.0800, D_X Total: 0.0791\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0461, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.9772, F Adv: 0.6230\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1217, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.4104\n",
      "Epoch [106/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1343, D_X Fake: 0.0912, D_X Total: 0.1128\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0411, D_Y Total: 0.0404\n",
      "Generator Losses:\n",
      "  G Adv: 0.8087, F Adv: 0.6304\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1565, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.7310\n",
      "Epoch [106/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0653, D_X Fake: 0.1003, D_X Total: 0.0828\n",
      "  D_Y Real: 0.0511, D_Y Fake: 0.0226, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 1.0146, F Adv: 0.4596\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.4395\n",
      "Epoch [106/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1057, D_X Fake: 0.1107, D_X Total: 0.1082\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0581, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.9356, F Adv: 0.5325\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.6861\n",
      "Epoch [106/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0817, D_X Fake: 0.0767, D_X Total: 0.0792\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0455, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.9056, F Adv: 0.7062\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1267, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.6159\n",
      "Epoch [106/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0454, D_X Fake: 0.1194, D_X Total: 0.0824\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0815, D_Y Total: 0.0539\n",
      "Generator Losses:\n",
      "  G Adv: 0.7276, F Adv: 0.4963\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1029, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.0167\n",
      "Epoch [106/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0945, D_X Fake: 0.1080, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0447, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 0.9427, F Adv: 0.4963\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.5509\n",
      "Epoch [106/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0564, D_X Fake: 0.0926, D_X Total: 0.0745\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0367, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.9126, F Adv: 0.5232\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1294, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.4568\n",
      "Epoch [106/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1248, D_X Fake: 0.0612, D_X Total: 0.0930\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0890, D_Y Total: 0.0559\n",
      "Generator Losses:\n",
      "  G Adv: 0.6971, F Adv: 0.6013\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.4361\n",
      "Epoch [106/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0578, D_X Fake: 0.0647, D_X Total: 0.0613\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0476, D_Y Total: 0.0422\n",
      "Generator Losses:\n",
      "  G Adv: 0.8374, F Adv: 0.6620\n",
      "  Cycle Photo: 0.0583, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1559, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 4.0222\n",
      "Epoch [106/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0876, D_X Fake: 0.1139, D_X Total: 0.1008\n",
      "  D_Y Real: 0.0359, D_Y Fake: 0.0942, D_Y Total: 0.0651\n",
      "Generator Losses:\n",
      "  G Adv: 1.0095, F Adv: 0.4912\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.6379\n",
      "Epoch [106/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2928, D_X Fake: 0.0659, D_X Total: 0.1793\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0331, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 1.0686, F Adv: 0.6417\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1367\n",
      "  Total G Loss: 3.8350\n",
      "Epoch [106/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1894, D_X Fake: 0.0979, D_X Total: 0.1436\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0602, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.6997, F Adv: 0.6418\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.4427\n",
      "Epoch [106/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0696, D_X Fake: 0.1146, D_X Total: 0.0921\n",
      "  D_Y Real: 0.0578, D_Y Fake: 0.0641, D_Y Total: 0.0609\n",
      "Generator Losses:\n",
      "  G Adv: 0.9714, F Adv: 0.4786\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1371, Perceptual Monet: 0.1479\n",
      "  Total G Loss: 3.3997\n",
      "Epoch [106/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0674, D_X Fake: 0.0928, D_X Total: 0.0801\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0358, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8578, F Adv: 0.5741\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1387\n",
      "  Total G Loss: 3.3995\n",
      "Epoch [106/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0963, D_X Fake: 0.0913, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0485, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.7951, F Adv: 0.5762\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.5351\n",
      "Epoch [106/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1564, D_X Fake: 0.0958, D_X Total: 0.1261\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0459, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.8639, F Adv: 0.5496\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1421, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.6261\n",
      "Epoch [106/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1604, D_X Fake: 0.0699, D_X Total: 0.1152\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.0555, D_Y Total: 0.0452\n",
      "Generator Losses:\n",
      "  G Adv: 0.8292, F Adv: 0.6025\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1216, Perceptual Monet: 0.1860\n",
      "  Total G Loss: 3.5441\n",
      "Epoch [106/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1013, D_X Fake: 0.0850, D_X Total: 0.0932\n",
      "  D_Y Real: 0.0487, D_Y Fake: 0.0385, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.9194, F Adv: 0.7799\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1184, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.6290\n",
      "Epoch [106/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1732, D_X Fake: 0.0719, D_X Total: 0.1226\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.1279, D_Y Total: 0.0769\n",
      "Generator Losses:\n",
      "  G Adv: 0.5665, F Adv: 0.5830\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1862\n",
      "  Total G Loss: 3.5112\n",
      "Epoch [106/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0579, D_X Fake: 0.0788, D_X Total: 0.0683\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0336, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 0.8749, F Adv: 0.5215\n",
      "  Cycle Photo: 0.0201, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1152, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.4179\n",
      "Epoch [106/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2986, D_X Fake: 0.0409, D_X Total: 0.1698\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0423, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.8124, F Adv: 0.6995\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1970\n",
      "  Total G Loss: 3.8871\n",
      "Epoch [106/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0972, D_X Fake: 0.1052, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0632, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.9008, F Adv: 0.6363\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1609, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.8746\n",
      "Epoch [106/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1648, D_X Fake: 0.0898, D_X Total: 0.1273\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0586, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.7563, F Adv: 0.6117\n",
      "  Cycle Photo: 0.0516, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1925, Perceptual Monet: 0.1777\n",
      "  Total G Loss: 4.0710\n",
      "Epoch [106/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0753, D_X Fake: 0.1309, D_X Total: 0.1031\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0374, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9884, F Adv: 0.5672\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1543, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.8549\n",
      "Epoch [107/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1461, D_X Fake: 0.1221, D_X Total: 0.1341\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0290, D_Y Total: 0.0236\n",
      "Generator Losses:\n",
      "  G Adv: 0.9584, F Adv: 0.5082\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1373, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.4526\n",
      "Epoch [107/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0510, D_X Fake: 0.0712, D_X Total: 0.0611\n",
      "  D_Y Real: 0.0443, D_Y Fake: 0.0737, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.6971, F Adv: 0.5474\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1208, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 3.2698\n",
      "Epoch [107/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0951, D_X Fake: 0.0630, D_X Total: 0.0790\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0385, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.7888, F Adv: 0.6719\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1249, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.2658\n",
      "Epoch [107/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1650, D_X Fake: 0.0619, D_X Total: 0.1135\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0434, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8821, F Adv: 0.7080\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1544, Perceptual Monet: 0.1527\n",
      "  Total G Loss: 3.6708\n",
      "Epoch [107/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0955, D_X Fake: 0.0793, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.0391, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 1.0030, F Adv: 0.6558\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.9562\n",
      "Epoch [107/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0620, D_X Fake: 0.1191, D_X Total: 0.0906\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0497, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 1.0700, F Adv: 0.5461\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1235, Perceptual Monet: 0.1764\n",
      "  Total G Loss: 3.7205\n",
      "Epoch [107/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1087, D_X Fake: 0.0792, D_X Total: 0.0940\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0241, D_Y Total: 0.0238\n",
      "Generator Losses:\n",
      "  G Adv: 1.1080, F Adv: 0.7231\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.9493\n",
      "Epoch [107/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1198, D_X Fake: 0.0725, D_X Total: 0.0962\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0440, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.8807, F Adv: 0.7017\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1664, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 4.0507\n",
      "Epoch [107/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1987, D_X Fake: 0.0658, D_X Total: 0.1323\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0639, D_Y Total: 0.0461\n",
      "Generator Losses:\n",
      "  G Adv: 0.8269, F Adv: 0.6651\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 3.5094\n",
      "Epoch [107/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0548, D_X Fake: 0.0871, D_X Total: 0.0709\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0320, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 1.0081, F Adv: 0.5767\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1629, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.9434\n",
      "Epoch [107/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1984, D_X Fake: 0.0925, D_X Total: 0.1455\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0433, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8323, F Adv: 0.4432\n",
      "  Cycle Photo: 0.0212, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1234, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.1212\n",
      "Epoch [107/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1387, D_X Fake: 0.0433, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0544, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.7928, F Adv: 0.7217\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.6623\n",
      "Epoch [107/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1304, D_X Fake: 0.0643, D_X Total: 0.0974\n",
      "  D_Y Real: 0.0156, D_Y Fake: 0.0502, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.7788, F Adv: 0.7077\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 3.6151\n",
      "Epoch [107/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1079, D_X Fake: 0.0878, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0556, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.8422, F Adv: 0.5285\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1677, Perceptual Monet: 0.1772\n",
      "  Total G Loss: 3.7654\n",
      "Epoch [107/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1277, D_X Fake: 0.0877, D_X Total: 0.1077\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0405, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.8157, F Adv: 0.6008\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1933, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 3.9099\n",
      "Epoch [107/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0729, D_X Fake: 0.0850, D_X Total: 0.0789\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0349, D_Y Total: 0.0262\n",
      "Generator Losses:\n",
      "  G Adv: 0.8437, F Adv: 0.5519\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1183, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.3141\n",
      "Epoch [107/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1153, D_X Fake: 0.1682, D_X Total: 0.1417\n",
      "  D_Y Real: 0.0375, D_Y Fake: 0.0627, D_Y Total: 0.0501\n",
      "Generator Losses:\n",
      "  G Adv: 0.8844, F Adv: 0.4084\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.2511\n",
      "Epoch [107/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.1011, D_X Total: 0.0922\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0446, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.9517, F Adv: 0.5401\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1576, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.7083\n",
      "Epoch [107/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1509, D_X Fake: 0.1241, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0349, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.8326, F Adv: 0.4784\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1716, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.4740\n",
      "Epoch [107/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0802, D_X Fake: 0.0488, D_X Total: 0.0645\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0416, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.6893, F Adv: 0.6439\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.3712\n",
      "Epoch [107/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1349, D_X Fake: 0.0901, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0542, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 0.9359, F Adv: 0.7135\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1449, Perceptual Monet: 0.1552\n",
      "  Total G Loss: 3.7511\n",
      "Epoch [107/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1003, D_X Fake: 0.0654, D_X Total: 0.0829\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0488, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.8416, F Adv: 0.5993\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1318, Perceptual Monet: 0.1926\n",
      "  Total G Loss: 3.6763\n",
      "Epoch [107/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1081, D_X Fake: 0.0986, D_X Total: 0.1034\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0335, D_Y Total: 0.0311\n",
      "Generator Losses:\n",
      "  G Adv: 0.9248, F Adv: 0.6338\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1375, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.6245\n",
      "Epoch [107/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0638, D_X Fake: 0.0511, D_X Total: 0.0575\n",
      "  D_Y Real: 0.0721, D_Y Fake: 0.0399, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.8973, F Adv: 0.7421\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1864\n",
      "  Total G Loss: 4.0215\n",
      "Epoch [108/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1181, D_X Fake: 0.0709, D_X Total: 0.0945\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0568, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 0.7653, F Adv: 0.5283\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.3605\n",
      "Epoch [108/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1256, D_X Fake: 0.0878, D_X Total: 0.1067\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0815, D_Y Total: 0.0493\n",
      "Generator Losses:\n",
      "  G Adv: 0.6765, F Adv: 0.6584\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1453, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.6470\n",
      "Epoch [108/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1990, D_X Fake: 0.0662, D_X Total: 0.1326\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0522, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.8905, F Adv: 0.7170\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1822, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.9554\n",
      "Epoch [108/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0684, D_X Fake: 0.0899, D_X Total: 0.0791\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0564, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.6848, F Adv: 0.6139\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0163\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.0998\n",
      "  Total G Loss: 3.1551\n",
      "Epoch [108/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2335, D_X Fake: 0.0940, D_X Total: 0.1638\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0455, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.9911, F Adv: 0.5456\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.5347\n",
      "Epoch [108/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0947, D_X Fake: 0.0765, D_X Total: 0.0856\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0391, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.9493, F Adv: 0.6586\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.6696\n",
      "Epoch [108/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1342, D_X Fake: 0.0529, D_X Total: 0.0935\n",
      "  D_Y Real: 0.0137, D_Y Fake: 0.0815, D_Y Total: 0.0476\n",
      "Generator Losses:\n",
      "  G Adv: 0.8107, F Adv: 0.7717\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1162, Perceptual Monet: 0.1380\n",
      "  Total G Loss: 3.3380\n",
      "Epoch [108/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1609, D_X Fake: 0.0714, D_X Total: 0.1162\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0555, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.9449, F Adv: 0.5843\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1419, Perceptual Monet: 0.1453\n",
      "  Total G Loss: 3.5430\n",
      "Epoch [108/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0806, D_X Fake: 0.0881, D_X Total: 0.0844\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0582, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.7833, F Adv: 0.5416\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1092, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.2383\n",
      "Epoch [108/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2501, D_X Fake: 0.0643, D_X Total: 0.1572\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0389, D_Y Total: 0.0291\n",
      "Generator Losses:\n",
      "  G Adv: 0.8979, F Adv: 0.6051\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1158, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.3932\n",
      "Epoch [108/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1287, D_X Fake: 0.0975, D_X Total: 0.1131\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.0350, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.9311, F Adv: 0.5902\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1036, Perceptual Monet: 0.1550\n",
      "  Total G Loss: 3.3020\n",
      "Epoch [108/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0915, D_X Fake: 0.0527, D_X Total: 0.0721\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0393, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 1.1293, F Adv: 0.7024\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1502, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.9764\n",
      "Epoch [108/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1202, D_X Fake: 0.0539, D_X Total: 0.0870\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0446, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 1.1261, F Adv: 0.6795\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.0955, Perceptual Monet: 0.1459\n",
      "  Total G Loss: 3.5538\n",
      "Epoch [108/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.1348, D_X Total: 0.1270\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0359, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 1.0211, F Adv: 0.5414\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1519, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.8129\n",
      "Epoch [108/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0460, D_X Fake: 0.0906, D_X Total: 0.0683\n",
      "  D_Y Real: 0.0543, D_Y Fake: 0.0601, D_Y Total: 0.0572\n",
      "Generator Losses:\n",
      "  G Adv: 1.0160, F Adv: 0.5400\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1507\n",
      "  Total G Loss: 3.7105\n",
      "Epoch [108/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2864, D_X Fake: 0.0900, D_X Total: 0.1882\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0447, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.7064, F Adv: 0.6176\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1684\n",
      "  Total G Loss: 3.6525\n",
      "Epoch [108/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1803, D_X Fake: 0.0804, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0445, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 0.7618, F Adv: 0.6144\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1834, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.7439\n",
      "Epoch [108/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1162, D_X Fake: 0.0881, D_X Total: 0.1021\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0558, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.9250, F Adv: 0.4751\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1456\n",
      "  Total G Loss: 3.4889\n",
      "Epoch [108/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0398, D_X Fake: 0.1693, D_X Total: 0.1046\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0820, D_Y Total: 0.0566\n",
      "Generator Losses:\n",
      "  G Adv: 0.7953, F Adv: 0.6352\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1499, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.4786\n",
      "Epoch [108/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0736, D_X Fake: 0.1367, D_X Total: 0.1052\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0431, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 1.0023, F Adv: 0.4652\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.4297\n",
      "Epoch [108/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0839, D_X Fake: 0.0842, D_X Total: 0.0841\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0466, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.9289, F Adv: 0.5445\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1020, Perceptual Monet: 0.1429\n",
      "  Total G Loss: 3.1554\n",
      "Epoch [108/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0969, D_X Fake: 0.1106, D_X Total: 0.1037\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0595, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.8803, F Adv: 0.5322\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1327, Perceptual Monet: 0.1392\n",
      "  Total G Loss: 3.3108\n",
      "Epoch [108/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0719, D_X Fake: 0.1006, D_X Total: 0.0863\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0520, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 0.8044, F Adv: 0.4844\n",
      "  Cycle Photo: 0.0476, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.2000, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.9417\n",
      "Epoch [108/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1403, D_X Fake: 0.0557, D_X Total: 0.0980\n",
      "  D_Y Real: 0.0484, D_Y Fake: 0.0483, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 1.0113, F Adv: 0.6595\n",
      "  Cycle Photo: 0.0220, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1119, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.5793\n",
      "Epoch [109/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1187, D_X Fake: 0.0704, D_X Total: 0.0946\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0338, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.9598, F Adv: 0.6269\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1131, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5998\n",
      "Epoch [109/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1254, D_X Fake: 0.0900, D_X Total: 0.1077\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0335, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9767, F Adv: 0.5696\n",
      "  Cycle Photo: 0.0432, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1851, Perceptual Monet: 0.1890\n",
      "  Total G Loss: 4.1981\n",
      "Epoch [109/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0913, D_X Fake: 0.0598, D_X Total: 0.0755\n",
      "  D_Y Real: 0.0422, D_Y Fake: 0.0725, D_Y Total: 0.0573\n",
      "Generator Losses:\n",
      "  G Adv: 0.7657, F Adv: 0.7456\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.6790\n",
      "Epoch [109/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0838, D_X Fake: 0.1044, D_X Total: 0.0941\n",
      "  D_Y Real: 0.0259, D_Y Fake: 0.0330, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 0.7941, F Adv: 0.6031\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1522, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 3.7187\n",
      "Epoch [109/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0903, D_X Fake: 0.1014, D_X Total: 0.0958\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0334, D_Y Total: 0.0269\n",
      "Generator Losses:\n",
      "  G Adv: 0.9764, F Adv: 0.6228\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1685, Perceptual Monet: 0.1565\n",
      "  Total G Loss: 3.8029\n",
      "Epoch [109/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1062, D_X Fake: 0.1111, D_X Total: 0.1086\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0373, D_Y Total: 0.0319\n",
      "Generator Losses:\n",
      "  G Adv: 0.8615, F Adv: 0.5312\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1518, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.6639\n",
      "Epoch [109/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0549, D_X Fake: 0.0794, D_X Total: 0.0672\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0778, D_Y Total: 0.0516\n",
      "Generator Losses:\n",
      "  G Adv: 0.7621, F Adv: 0.6226\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1179, Perceptual Monet: 0.1777\n",
      "  Total G Loss: 3.5925\n",
      "Epoch [109/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0856, D_X Fake: 0.1417, D_X Total: 0.1137\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0438, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.9151, F Adv: 0.4415\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1170, Perceptual Monet: 0.1518\n",
      "  Total G Loss: 3.2472\n",
      "Epoch [109/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2148, D_X Fake: 0.0644, D_X Total: 0.1396\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0344, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 0.9139, F Adv: 0.6698\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1468, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.6784\n",
      "Epoch [109/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0727, D_X Fake: 0.1027, D_X Total: 0.0877\n",
      "  D_Y Real: 0.0468, D_Y Fake: 0.0851, D_Y Total: 0.0660\n",
      "Generator Losses:\n",
      "  G Adv: 0.7315, F Adv: 0.5610\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.4954\n",
      "Epoch [109/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1979, D_X Fake: 0.0948, D_X Total: 0.1463\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0822, D_Y Total: 0.0609\n",
      "Generator Losses:\n",
      "  G Adv: 0.7759, F Adv: 0.6172\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1056, Perceptual Monet: 0.1860\n",
      "  Total G Loss: 3.4038\n",
      "Epoch [109/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1601, D_X Fake: 0.0887, D_X Total: 0.1244\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.0845, D_Y Total: 0.0503\n",
      "Generator Losses:\n",
      "  G Adv: 0.8605, F Adv: 0.5803\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1754, Perceptual Monet: 0.1509\n",
      "  Total G Loss: 3.8173\n",
      "Epoch [109/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1724, D_X Fake: 0.0711, D_X Total: 0.1217\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0331, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.8835, F Adv: 0.6192\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.5920\n",
      "Epoch [109/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0989, D_X Fake: 0.1644, D_X Total: 0.1317\n",
      "  D_Y Real: 0.0486, D_Y Fake: 0.0476, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.8303, F Adv: 0.4910\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1127, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.2644\n",
      "Epoch [109/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0825, D_X Fake: 0.1021, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.0604, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.8855, F Adv: 0.6395\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1519, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.8397\n",
      "Epoch [109/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1736, D_X Fake: 0.0874, D_X Total: 0.1305\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0396, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8770, F Adv: 0.6702\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1289\n",
      "  Total G Loss: 3.5385\n",
      "Epoch [109/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2044, D_X Fake: 0.0528, D_X Total: 0.1286\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.0422, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.9286, F Adv: 0.7648\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.8523\n",
      "Epoch [109/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0598, D_X Fake: 0.0687, D_X Total: 0.0642\n",
      "  D_Y Real: 0.0475, D_Y Fake: 0.0554, D_Y Total: 0.0514\n",
      "Generator Losses:\n",
      "  G Adv: 1.1770, F Adv: 0.6067\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.7442\n",
      "Epoch [109/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0437, D_X Fake: 0.1328, D_X Total: 0.0882\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0270, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.7236, F Adv: 0.5064\n",
      "  Cycle Photo: 0.0227, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1176, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.0712\n",
      "Epoch [109/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1803, D_X Fake: 0.0925, D_X Total: 0.1364\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0328, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 1.0266, F Adv: 0.5461\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.5453\n",
      "Epoch [109/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0499, D_X Fake: 0.0637, D_X Total: 0.0568\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0568, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.8427, F Adv: 0.5728\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0197\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1211\n",
      "  Total G Loss: 3.2094\n",
      "Epoch [109/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1195, D_X Fake: 0.0916, D_X Total: 0.1056\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0513, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 1.0066, F Adv: 0.5273\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.8313\n",
      "Epoch [109/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2323, D_X Fake: 0.1670, D_X Total: 0.1997\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0340, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.9241, F Adv: 0.4224\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1126, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 3.4048\n",
      "Epoch [109/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1078, D_X Fake: 0.0705, D_X Total: 0.0891\n",
      "  D_Y Real: 0.0431, D_Y Fake: 0.0646, D_Y Total: 0.0539\n",
      "Generator Losses:\n",
      "  G Adv: 0.7556, F Adv: 0.6522\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1794\n",
      "  Total G Loss: 3.5295\n",
      "Epoch [110/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2377, D_X Fake: 0.0777, D_X Total: 0.1577\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0497, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.7030, F Adv: 0.6129\n",
      "  Cycle Photo: 0.0587, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1153, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.5108\n",
      "Epoch [110/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0374, D_X Fake: 0.0598, D_X Total: 0.0486\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0418, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.7494, F Adv: 0.5558\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.0941, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.1535\n",
      "Epoch [110/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1445, D_X Fake: 0.0860, D_X Total: 0.1152\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0499, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.6285, F Adv: 0.6103\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1629, Perceptual Monet: 0.1397\n",
      "  Total G Loss: 3.2919\n",
      "Epoch [110/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2076, D_X Fake: 0.0865, D_X Total: 0.1470\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0390, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.8448, F Adv: 0.6248\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1145, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.3124\n",
      "Epoch [110/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1477, D_X Fake: 0.0632, D_X Total: 0.1054\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0628, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.7636, F Adv: 0.6539\n",
      "  Cycle Photo: 0.0217, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1054, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.3428\n",
      "Epoch [110/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1571, D_X Fake: 0.1118, D_X Total: 0.1344\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0486, D_Y Total: 0.0502\n",
      "Generator Losses:\n",
      "  G Adv: 0.8699, F Adv: 0.6474\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.7248\n",
      "Epoch [110/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0972, D_X Fake: 0.1257, D_X Total: 0.1114\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0313, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 0.8786, F Adv: 0.5828\n",
      "  Cycle Photo: 0.0219, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1071, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.1821\n",
      "Epoch [110/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0943, D_X Fake: 0.0619, D_X Total: 0.0781\n",
      "  D_Y Real: 0.0355, D_Y Fake: 0.0618, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 1.0029, F Adv: 0.7447\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0397\n",
      "  Perceptual Photo: 0.1238, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 4.0042\n",
      "Epoch [110/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0636, D_X Fake: 0.1331, D_X Total: 0.0984\n",
      "  D_Y Real: 0.0465, D_Y Fake: 0.0548, D_Y Total: 0.0507\n",
      "Generator Losses:\n",
      "  G Adv: 0.8191, F Adv: 0.5142\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1507\n",
      "  Total G Loss: 3.3984\n",
      "Epoch [110/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1242, D_X Fake: 0.1091, D_X Total: 0.1166\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0565, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8418, F Adv: 0.5306\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.3576\n",
      "Epoch [110/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0650, D_X Fake: 0.0951, D_X Total: 0.0800\n",
      "  D_Y Real: 0.0164, D_Y Fake: 0.0397, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 0.8072, F Adv: 0.5045\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1677, Perceptual Monet: 0.1441\n",
      "  Total G Loss: 3.4794\n",
      "Epoch [110/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1841, D_X Fake: 0.0898, D_X Total: 0.1370\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0953, D_Y Total: 0.0672\n",
      "Generator Losses:\n",
      "  G Adv: 0.7714, F Adv: 0.5293\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1330, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 3.4226\n",
      "Epoch [110/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0616, D_X Fake: 0.1238, D_X Total: 0.0927\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.1087, D_Y Total: 0.0713\n",
      "Generator Losses:\n",
      "  G Adv: 0.7527, F Adv: 0.5749\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1135, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 3.1248\n",
      "Epoch [110/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1766, D_X Fake: 0.1355, D_X Total: 0.1560\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0444, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.6630, F Adv: 0.5859\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1606, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.5135\n",
      "Epoch [110/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.0926, D_X Total: 0.0911\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0299, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.7885, F Adv: 0.5165\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1294, Perceptual Monet: 0.1393\n",
      "  Total G Loss: 3.1231\n",
      "Epoch [110/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1011, D_X Fake: 0.0920, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0351, D_Y Fake: 0.0614, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 0.7967, F Adv: 0.5745\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1435, Perceptual Monet: 0.1400\n",
      "  Total G Loss: 3.3257\n",
      "Epoch [110/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0729, D_X Fake: 0.0639, D_X Total: 0.0684\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0622, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.9732, F Adv: 0.4782\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.3772\n",
      "Epoch [110/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3594, D_X Fake: 0.1233, D_X Total: 0.2413\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0542, D_Y Total: 0.0517\n",
      "Generator Losses:\n",
      "  G Adv: 0.8802, F Adv: 0.5081\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0394\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1916\n",
      "  Total G Loss: 3.9172\n",
      "Epoch [110/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1119, D_X Fake: 0.1008, D_X Total: 0.1063\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0495, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.9949, F Adv: 0.5813\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1725\n",
      "  Total G Loss: 3.8368\n",
      "Epoch [110/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1906, D_X Fake: 0.0902, D_X Total: 0.1404\n",
      "  D_Y Real: 0.0706, D_Y Fake: 0.0433, D_Y Total: 0.0570\n",
      "Generator Losses:\n",
      "  G Adv: 1.0171, F Adv: 0.5751\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1440, Perceptual Monet: 0.1731\n",
      "  Total G Loss: 3.7903\n",
      "Epoch [110/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1181, D_X Fake: 0.0774, D_X Total: 0.0977\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.0580, D_Y Total: 0.0468\n",
      "Generator Losses:\n",
      "  G Adv: 0.9966, F Adv: 0.5862\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1465\n",
      "  Total G Loss: 3.6134\n",
      "Epoch [110/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2057, D_X Fake: 0.0538, D_X Total: 0.1298\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.0365, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 1.0216, F Adv: 0.8176\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1614, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 4.0860\n",
      "Epoch [110/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1251, D_X Fake: 0.0720, D_X Total: 0.0985\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0718, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.7085, F Adv: 0.6660\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 3.4021\n",
      "Epoch [110/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1629, D_X Fake: 0.1141, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0432, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8522, F Adv: 0.5157\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1190, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.2915\n",
      "Epoch [111/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1537, D_X Fake: 0.0872, D_X Total: 0.1205\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0768, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.8897, F Adv: 0.5696\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0213\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.1365\n",
      "  Total G Loss: 3.2668\n",
      "Epoch [111/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1236, D_X Fake: 0.1391, D_X Total: 0.1314\n",
      "  D_Y Real: 0.0576, D_Y Fake: 0.0639, D_Y Total: 0.0608\n",
      "Generator Losses:\n",
      "  G Adv: 0.7212, F Adv: 0.4841\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.6001\n",
      "Epoch [111/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2085, D_X Fake: 0.1148, D_X Total: 0.1616\n",
      "  D_Y Real: 0.0600, D_Y Fake: 0.0344, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.8381, F Adv: 0.5315\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1489\n",
      "  Total G Loss: 3.3944\n",
      "Epoch [111/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0457, D_X Fake: 0.1035, D_X Total: 0.0746\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0529, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.7703, F Adv: 0.4844\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0189\n",
      "  Perceptual Photo: 0.1253, Perceptual Monet: 0.1201\n",
      "  Total G Loss: 2.9355\n",
      "Epoch [111/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1135, D_X Fake: 0.1098, D_X Total: 0.1117\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0796, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.8987, F Adv: 0.5877\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.4409\n",
      "Epoch [111/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0791, D_X Fake: 0.0721, D_X Total: 0.0756\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0477, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.8760, F Adv: 0.6395\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.7165\n",
      "Epoch [111/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0406, D_X Fake: 0.1087, D_X Total: 0.0746\n",
      "  D_Y Real: 0.0443, D_Y Fake: 0.0448, D_Y Total: 0.0445\n",
      "Generator Losses:\n",
      "  G Adv: 1.1222, F Adv: 0.5372\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.8276\n",
      "Epoch [111/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1701, D_X Fake: 0.0802, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0468, D_Y Fake: 0.0585, D_Y Total: 0.0526\n",
      "Generator Losses:\n",
      "  G Adv: 1.0319, F Adv: 0.6159\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1252, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.7875\n",
      "Epoch [111/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1877, D_X Fake: 0.1069, D_X Total: 0.1473\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0711, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.6930, F Adv: 0.6178\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1664, Perceptual Monet: 0.1534\n",
      "  Total G Loss: 3.5117\n",
      "Epoch [111/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0867, D_X Fake: 0.0744, D_X Total: 0.0806\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0369, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8405, F Adv: 0.5172\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1429, Perceptual Monet: 0.1408\n",
      "  Total G Loss: 3.3253\n",
      "Epoch [111/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1936, D_X Fake: 0.0803, D_X Total: 0.1369\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0396, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.8725, F Adv: 0.5101\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1396\n",
      "  Total G Loss: 3.5916\n",
      "Epoch [111/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0982, D_X Fake: 0.0858, D_X Total: 0.0920\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0439, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 1.0531, F Adv: 0.5917\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1671, Perceptual Monet: 0.1498\n",
      "  Total G Loss: 3.7875\n",
      "Epoch [111/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0824, D_X Fake: 0.1531, D_X Total: 0.1178\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0750, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.7586, F Adv: 0.3771\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1110, Perceptual Monet: 0.1278\n",
      "  Total G Loss: 2.8034\n",
      "Epoch [111/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1490, D_X Fake: 0.0755, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0341, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.9532, F Adv: 0.6198\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1581, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.8267\n",
      "Epoch [111/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0533, D_X Fake: 0.0719, D_X Total: 0.0626\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0415, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.9591, F Adv: 0.5056\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1068, Perceptual Monet: 0.1754\n",
      "  Total G Loss: 3.4146\n",
      "Epoch [111/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1350, D_X Fake: 0.0976, D_X Total: 0.1163\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0645, D_Y Total: 0.0499\n",
      "Generator Losses:\n",
      "  G Adv: 0.8200, F Adv: 0.4890\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0206\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1333\n",
      "  Total G Loss: 3.3447\n",
      "Epoch [111/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1258, D_X Fake: 0.0844, D_X Total: 0.1051\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0291, D_Y Total: 0.0260\n",
      "Generator Losses:\n",
      "  G Adv: 0.8506, F Adv: 0.6940\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.7308\n",
      "Epoch [111/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3157, D_X Fake: 0.0825, D_X Total: 0.1991\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0506, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8599, F Adv: 0.6346\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1817, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.8658\n",
      "Epoch [111/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1683, D_X Fake: 0.0986, D_X Total: 0.1335\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0354, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.8903, F Adv: 0.6819\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1759, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.9379\n",
      "Epoch [111/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1248, D_X Fake: 0.1006, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0377, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 1.0318, F Adv: 0.5415\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1210, Perceptual Monet: 0.1620\n",
      "  Total G Loss: 3.6176\n",
      "Epoch [111/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0919, D_X Fake: 0.0603, D_X Total: 0.0761\n",
      "  D_Y Real: 0.0787, D_Y Fake: 0.0490, D_Y Total: 0.0639\n",
      "Generator Losses:\n",
      "  G Adv: 1.3356, F Adv: 0.6851\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1572, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 4.1115\n",
      "Epoch [111/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1402, D_X Fake: 0.1517, D_X Total: 0.1459\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0315, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.9526, F Adv: 0.4931\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1363, Perceptual Monet: 0.1431\n",
      "  Total G Loss: 3.3372\n",
      "Epoch [111/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1663, D_X Fake: 0.0922, D_X Total: 0.1292\n",
      "  D_Y Real: 0.0432, D_Y Fake: 0.0413, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.8635, F Adv: 0.6656\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1670, Perceptual Monet: 0.1956\n",
      "  Total G Loss: 4.0153\n",
      "Epoch [111/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1493, D_X Fake: 0.0844, D_X Total: 0.1168\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0324, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.9897, F Adv: 0.6400\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.7987\n",
      "Epoch [112/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0769, D_X Fake: 0.0791, D_X Total: 0.0780\n",
      "  D_Y Real: 0.0449, D_Y Fake: 0.0467, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.7069, F Adv: 0.5377\n",
      "  Cycle Photo: 0.0217, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1003, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.0605\n",
      "Epoch [112/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2215, D_X Fake: 0.0638, D_X Total: 0.1426\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0695, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.8506, F Adv: 0.6500\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1771, Perceptual Monet: 0.1608\n",
      "  Total G Loss: 3.7619\n",
      "Epoch [112/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1365, D_X Fake: 0.1031, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0591, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 0.8486, F Adv: 0.5622\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1936\n",
      "  Total G Loss: 3.8476\n",
      "Epoch [112/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0462, D_X Fake: 0.1084, D_X Total: 0.0773\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0466, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.9583, F Adv: 0.5565\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 3.7395\n",
      "Epoch [112/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1661, D_X Fake: 0.1148, D_X Total: 0.1405\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0462, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.7934, F Adv: 0.7233\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1074, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.5462\n",
      "Epoch [112/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1678, D_X Fake: 0.0538, D_X Total: 0.1108\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0358, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.8241, F Adv: 0.7619\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1920\n",
      "  Total G Loss: 3.8586\n",
      "Epoch [112/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1552, D_X Fake: 0.2110, D_X Total: 0.1831\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0578, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.6588, F Adv: 0.5231\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.3145\n",
      "Epoch [112/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0713, D_X Fake: 0.1035, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0512, D_Y Fake: 0.0411, D_Y Total: 0.0461\n",
      "Generator Losses:\n",
      "  G Adv: 0.8567, F Adv: 0.5687\n",
      "  Cycle Photo: 0.0190, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1093, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.2735\n",
      "Epoch [112/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1385, D_X Fake: 0.1002, D_X Total: 0.1193\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0500, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.7416, F Adv: 0.5813\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1168, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.2467\n",
      "Epoch [112/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1871, D_X Fake: 0.0862, D_X Total: 0.1367\n",
      "  D_Y Real: 0.0374, D_Y Fake: 0.0598, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.8353, F Adv: 0.6404\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1694\n",
      "  Total G Loss: 3.6483\n",
      "Epoch [112/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2192, D_X Fake: 0.0495, D_X Total: 0.1344\n",
      "  D_Y Real: 0.0355, D_Y Fake: 0.0382, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.9528, F Adv: 0.7266\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1416, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.7860\n",
      "Epoch [112/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2039, D_X Fake: 0.0843, D_X Total: 0.1441\n",
      "  D_Y Real: 0.0365, D_Y Fake: 0.0573, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 0.7518, F Adv: 0.5242\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1051, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.0511\n",
      "Epoch [112/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2432, D_X Fake: 0.0851, D_X Total: 0.1642\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0418, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.9179, F Adv: 0.5358\n",
      "  Cycle Photo: 0.0437, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1997, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.9455\n",
      "Epoch [112/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0938, D_X Fake: 0.1006, D_X Total: 0.0972\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0391, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8229, F Adv: 0.6031\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1711\n",
      "  Total G Loss: 3.5233\n",
      "Epoch [112/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0479, D_X Fake: 0.1304, D_X Total: 0.0892\n",
      "  D_Y Real: 0.0318, D_Y Fake: 0.0452, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.6180, F Adv: 0.5046\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1067, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.1054\n",
      "Epoch [112/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1335, D_X Fake: 0.1238, D_X Total: 0.1287\n",
      "  D_Y Real: 0.0363, D_Y Fake: 0.0745, D_Y Total: 0.0554\n",
      "Generator Losses:\n",
      "  G Adv: 0.6610, F Adv: 0.5743\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0209\n",
      "  Perceptual Photo: 0.1502, Perceptual Monet: 0.1322\n",
      "  Total G Loss: 3.1695\n",
      "Epoch [112/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0874, D_X Fake: 0.1054, D_X Total: 0.0964\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0566, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.8211, F Adv: 0.6010\n",
      "  Cycle Photo: 0.0483, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1792, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 4.0842\n",
      "Epoch [112/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1371, D_X Fake: 0.0956, D_X Total: 0.1164\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0525, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.6989, F Adv: 0.6050\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.4018\n",
      "Epoch [112/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1161, D_X Fake: 0.0557, D_X Total: 0.0859\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0636, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.8460, F Adv: 0.7796\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1401, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.9152\n",
      "Epoch [112/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0714, D_X Fake: 0.0687, D_X Total: 0.0700\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0685, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.7601, F Adv: 0.5805\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1206, Perceptual Monet: 0.1875\n",
      "  Total G Loss: 3.4814\n",
      "Epoch [112/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.1120, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0487, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.7788, F Adv: 0.5544\n",
      "  Cycle Photo: 0.0544, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1532, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.7072\n",
      "Epoch [112/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1203, D_X Fake: 0.0547, D_X Total: 0.0875\n",
      "  D_Y Real: 0.0443, D_Y Fake: 0.0578, D_Y Total: 0.0511\n",
      "Generator Losses:\n",
      "  G Adv: 0.8283, F Adv: 0.6737\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.5787\n",
      "Epoch [112/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1305, D_X Fake: 0.0915, D_X Total: 0.1110\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0893, D_Y Total: 0.0584\n",
      "Generator Losses:\n",
      "  G Adv: 0.8810, F Adv: 0.6165\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.7292\n",
      "Epoch [112/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.0770, D_X Total: 0.0781\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0834, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.8999, F Adv: 0.5403\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1038, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.3140\n",
      "Epoch [113/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0929, D_X Fake: 0.1324, D_X Total: 0.1126\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0485, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.8591, F Adv: 0.4848\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1260, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.3382\n",
      "Epoch [113/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0616, D_X Fake: 0.0975, D_X Total: 0.0795\n",
      "  D_Y Real: 0.0321, D_Y Fake: 0.0606, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.8540, F Adv: 0.6572\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1457\n",
      "  Total G Loss: 3.6016\n",
      "Epoch [113/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1089, D_X Fake: 0.0964, D_X Total: 0.1026\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0373, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.8152, F Adv: 0.5147\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1456, Perceptual Monet: 0.1377\n",
      "  Total G Loss: 3.3038\n",
      "Epoch [113/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0778, D_X Fake: 0.0691, D_X Total: 0.0734\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0380, D_Y Total: 0.0292\n",
      "Generator Losses:\n",
      "  G Adv: 1.0093, F Adv: 0.6082\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1232, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 3.5036\n",
      "Epoch [113/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.0917, D_X Total: 0.1024\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0434, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.7632, F Adv: 0.6199\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.2002\n",
      "  Total G Loss: 3.7624\n",
      "Epoch [113/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1960, D_X Fake: 0.0717, D_X Total: 0.1338\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0585, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 1.1482, F Adv: 0.7717\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1346, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.9719\n",
      "Epoch [113/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0953, D_X Fake: 0.0909, D_X Total: 0.0931\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0333, D_Y Total: 0.0256\n",
      "Generator Losses:\n",
      "  G Adv: 1.0045, F Adv: 0.5872\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0204\n",
      "  Perceptual Photo: 0.1379, Perceptual Monet: 0.1283\n",
      "  Total G Loss: 3.3896\n",
      "Epoch [113/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0621, D_X Fake: 0.0668, D_X Total: 0.0645\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.0397, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 1.0295, F Adv: 0.6473\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1464\n",
      "  Total G Loss: 3.6369\n",
      "Epoch [113/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0655, D_X Fake: 0.0739, D_X Total: 0.0697\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0410, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.9077, F Adv: 0.6608\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.5942\n",
      "Epoch [113/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1039, D_X Fake: 0.0810, D_X Total: 0.0924\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0380, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.8984, F Adv: 0.6541\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0196\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1277\n",
      "  Total G Loss: 3.3371\n",
      "Epoch [113/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2566, D_X Fake: 0.1232, D_X Total: 0.1899\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0515, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8960, F Adv: 0.5142\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1204, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.2909\n",
      "Epoch [113/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1642, D_X Fake: 0.1008, D_X Total: 0.1325\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0461, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.8314, F Adv: 0.5045\n",
      "  Cycle Photo: 0.0215, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.2088\n",
      "Epoch [113/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0845, D_X Fake: 0.0793, D_X Total: 0.0819\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0470, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.8914, F Adv: 0.7041\n",
      "  Cycle Photo: 0.0416, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1531, Perceptual Monet: 0.1583\n",
      "  Total G Loss: 3.8515\n",
      "Epoch [113/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0533, D_X Fake: 0.1301, D_X Total: 0.0917\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0428, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.8028, F Adv: 0.4688\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.0991, Perceptual Monet: 0.1498\n",
      "  Total G Loss: 3.0680\n",
      "Epoch [113/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1059, D_X Fake: 0.1009, D_X Total: 0.1034\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0702, D_Y Total: 0.0495\n",
      "Generator Losses:\n",
      "  G Adv: 0.8294, F Adv: 0.5920\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1750\n",
      "  Total G Loss: 3.7023\n",
      "Epoch [113/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0777, D_X Fake: 0.1612, D_X Total: 0.1195\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0428, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.9316, F Adv: 0.4395\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1441\n",
      "  Total G Loss: 3.1646\n",
      "Epoch [113/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0498, D_X Fake: 0.0917, D_X Total: 0.0707\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0443, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.9343, F Adv: 0.5282\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1571\n",
      "  Total G Loss: 3.3441\n",
      "Epoch [113/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0949, D_X Fake: 0.1357, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0677, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.9032, F Adv: 0.4898\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1421, Perceptual Monet: 0.1480\n",
      "  Total G Loss: 3.3803\n",
      "Epoch [113/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2169, D_X Fake: 0.1268, D_X Total: 0.1718\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0396, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.8836, F Adv: 0.4323\n",
      "  Cycle Photo: 0.0433, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.2115, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.9828\n",
      "Epoch [113/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0788, D_X Fake: 0.0960, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0548, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8698, F Adv: 0.4967\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.1340\n",
      "  Total G Loss: 3.1898\n",
      "Epoch [113/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0534, D_X Fake: 0.1094, D_X Total: 0.0814\n",
      "  D_Y Real: 0.0402, D_Y Fake: 0.0324, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.9051, F Adv: 0.5651\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1762, Perceptual Monet: 0.1382\n",
      "  Total G Loss: 3.6587\n",
      "Epoch [113/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1117, D_X Fake: 0.1165, D_X Total: 0.1141\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0581, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.7700, F Adv: 0.5498\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1431, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.5333\n",
      "Epoch [113/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2674, D_X Fake: 0.1445, D_X Total: 0.2059\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0385, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.9004, F Adv: 0.4898\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.5257\n",
      "Epoch [114/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1726, D_X Fake: 0.1250, D_X Total: 0.1488\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0425, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8032, F Adv: 0.5082\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0205\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1337\n",
      "  Total G Loss: 3.1702\n",
      "Epoch [114/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2621, D_X Fake: 0.0695, D_X Total: 0.1658\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0366, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 0.8078, F Adv: 0.6812\n",
      "  Cycle Photo: 0.0434, Cycle Monet: 0.0210\n",
      "  Perceptual Photo: 0.2019, Perceptual Monet: 0.1342\n",
      "  Total G Loss: 3.8144\n",
      "Epoch [114/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0567, D_X Fake: 0.0594, D_X Total: 0.0581\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0442, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8673, F Adv: 0.6202\n",
      "  Cycle Photo: 0.0447, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1974\n",
      "  Total G Loss: 4.0039\n",
      "Epoch [114/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0864, D_X Fake: 0.0965, D_X Total: 0.0914\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0725, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.8242, F Adv: 0.5499\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1580, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.5965\n",
      "Epoch [114/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0432, D_X Fake: 0.0648, D_X Total: 0.0540\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0553, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.9463, F Adv: 0.6470\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1144, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.6132\n",
      "Epoch [114/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0755, D_X Fake: 0.0538, D_X Total: 0.0647\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0418, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.9614, F Adv: 0.5427\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1655\n",
      "  Total G Loss: 3.6440\n",
      "Epoch [114/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1404, D_X Fake: 0.1861, D_X Total: 0.1632\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0414, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.8711, F Adv: 0.5133\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1324, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.3589\n",
      "Epoch [114/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1423, D_X Fake: 0.1334, D_X Total: 0.1379\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0463, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.7774, F Adv: 0.5330\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.4046\n",
      "Epoch [114/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1126, D_X Fake: 0.1116, D_X Total: 0.1121\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0378, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.9741, F Adv: 0.5414\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1111, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.3314\n",
      "Epoch [114/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1733, D_X Fake: 0.0730, D_X Total: 0.1232\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.1021, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.8961, F Adv: 0.6513\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.2037\n",
      "  Total G Loss: 3.8282\n",
      "Epoch [114/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0634, D_X Fake: 0.1574, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0285, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 1.1890, F Adv: 0.5017\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1048, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.4089\n",
      "Epoch [114/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2054, D_X Fake: 0.0948, D_X Total: 0.1501\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0458, D_Y Total: 0.0319\n",
      "Generator Losses:\n",
      "  G Adv: 1.1640, F Adv: 0.7024\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1443, Perceptual Monet: 0.1527\n",
      "  Total G Loss: 3.8578\n",
      "Epoch [114/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3443, D_X Fake: 0.1508, D_X Total: 0.2475\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0654, D_Y Total: 0.0466\n",
      "Generator Losses:\n",
      "  G Adv: 0.6150, F Adv: 0.4640\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1893\n",
      "  Total G Loss: 3.2726\n",
      "Epoch [114/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0965, D_X Fake: 0.1240, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0134, D_Y Fake: 0.0469, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.6177, F Adv: 0.5839\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1103, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 2.9818\n",
      "Epoch [114/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0988, D_X Fake: 0.0898, D_X Total: 0.0943\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0496, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.9323, F Adv: 0.6629\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1408\n",
      "  Total G Loss: 3.5967\n",
      "Epoch [114/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0850, D_X Fake: 0.1172, D_X Total: 0.1011\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0333, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 1.0199, F Adv: 0.5481\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1257, Perceptual Monet: 0.1511\n",
      "  Total G Loss: 3.5072\n",
      "Epoch [114/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2069, D_X Fake: 0.1210, D_X Total: 0.1640\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0606, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.8225, F Adv: 0.5848\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1426, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.6268\n",
      "Epoch [114/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1064, D_X Fake: 0.0927, D_X Total: 0.0996\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0638, D_Y Total: 0.0465\n",
      "Generator Losses:\n",
      "  G Adv: 0.7669, F Adv: 0.6751\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.7070\n",
      "Epoch [114/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1384, D_X Fake: 0.1227, D_X Total: 0.1305\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.0405, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.8669, F Adv: 0.5463\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1141, Perceptual Monet: 0.1513\n",
      "  Total G Loss: 3.2508\n",
      "Epoch [114/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1518, D_X Fake: 0.0854, D_X Total: 0.1186\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0582, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 0.8046, F Adv: 0.6178\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.7180\n",
      "Epoch [114/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2801, D_X Fake: 0.0886, D_X Total: 0.1843\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.1121, D_Y Total: 0.0717\n",
      "Generator Losses:\n",
      "  G Adv: 0.7089, F Adv: 0.5304\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1385, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.3482\n",
      "Epoch [114/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1178, D_X Fake: 0.0859, D_X Total: 0.1018\n",
      "  D_Y Real: 0.0218, D_Y Fake: 0.0507, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8343, F Adv: 0.5080\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1744, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.7133\n",
      "Epoch [114/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1411, D_X Fake: 0.0756, D_X Total: 0.1084\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0497, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.9364, F Adv: 0.6475\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1572, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.8991\n",
      "Epoch [114/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0741, D_X Fake: 0.0932, D_X Total: 0.0837\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0400, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.9331, F Adv: 0.5425\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1111, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 3.4577\n",
      "Epoch [115/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0771, D_X Fake: 0.0782, D_X Total: 0.0776\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.0386, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 1.0865, F Adv: 0.6012\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1211, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.6899\n",
      "Epoch [115/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1464, D_X Fake: 0.1089, D_X Total: 0.1276\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0408, D_Y Total: 0.0301\n",
      "Generator Losses:\n",
      "  G Adv: 0.9035, F Adv: 0.5698\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.5146\n",
      "Epoch [115/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1388, D_X Fake: 0.1403, D_X Total: 0.1395\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0544, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 1.1058, F Adv: 0.4938\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1567, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.8496\n",
      "Epoch [115/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0459, D_X Fake: 0.0644, D_X Total: 0.0551\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0327, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9390, F Adv: 0.6115\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1444, Perceptual Monet: 0.2007\n",
      "  Total G Loss: 3.9236\n",
      "Epoch [115/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1571, D_X Fake: 0.0781, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0412, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 0.9088, F Adv: 0.6937\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1693\n",
      "  Total G Loss: 3.8809\n",
      "Epoch [115/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0693, D_X Fake: 0.1193, D_X Total: 0.0943\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0331, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 1.0515, F Adv: 0.5229\n",
      "  Cycle Photo: 0.0492, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1579, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.9545\n",
      "Epoch [115/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1363, D_X Fake: 0.0932, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0487, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.8453, F Adv: 0.4646\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0203\n",
      "  Perceptual Photo: 0.1307, Perceptual Monet: 0.1313\n",
      "  Total G Loss: 3.1069\n",
      "Epoch [115/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1362, D_X Fake: 0.0775, D_X Total: 0.1069\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0434, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 0.8200, F Adv: 0.6415\n",
      "  Cycle Photo: 0.0384, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1635, Perceptual Monet: 0.1945\n",
      "  Total G Loss: 4.0191\n",
      "Epoch [115/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1257, D_X Fake: 0.1139, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0394, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9207, F Adv: 0.4989\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1726, Perceptual Monet: 0.1388\n",
      "  Total G Loss: 3.5481\n",
      "Epoch [115/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0644, D_X Fake: 0.0729, D_X Total: 0.0686\n",
      "  D_Y Real: 0.0359, D_Y Fake: 0.0361, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.9964, F Adv: 0.5951\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.6842\n",
      "Epoch [115/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2714, D_X Fake: 0.1418, D_X Total: 0.2066\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0589, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.7409, F Adv: 0.4474\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1745, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.4552\n",
      "Epoch [115/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1650, D_X Fake: 0.0628, D_X Total: 0.1139\n",
      "  D_Y Real: 0.0140, D_Y Fake: 0.0648, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.7403, F Adv: 0.6362\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1648\n",
      "  Total G Loss: 3.5091\n",
      "Epoch [115/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0988, D_X Fake: 0.1017, D_X Total: 0.1002\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0522, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.8972, F Adv: 0.5825\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1477, Perceptual Monet: 0.1877\n",
      "  Total G Loss: 3.7675\n",
      "Epoch [115/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0495, D_X Fake: 0.1564, D_X Total: 0.1030\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0687, D_Y Total: 0.0420\n",
      "Generator Losses:\n",
      "  G Adv: 0.5949, F Adv: 0.4658\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 3.2440\n",
      "Epoch [115/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1747, D_X Fake: 0.1418, D_X Total: 0.1583\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0320, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8906, F Adv: 0.4433\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0202\n",
      "  Perceptual Photo: 0.1431, Perceptual Monet: 0.1284\n",
      "  Total G Loss: 3.1484\n",
      "Epoch [115/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2092, D_X Fake: 0.1048, D_X Total: 0.1570\n",
      "  D_Y Real: 0.0399, D_Y Fake: 0.0399, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.9039, F Adv: 0.5533\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.4496\n",
      "Epoch [115/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1824, D_X Fake: 0.0953, D_X Total: 0.1389\n",
      "  D_Y Real: 0.0368, D_Y Fake: 0.0953, D_Y Total: 0.0660\n",
      "Generator Losses:\n",
      "  G Adv: 0.7624, F Adv: 0.5913\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1256, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.3124\n",
      "Epoch [115/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0906, D_X Fake: 0.0811, D_X Total: 0.0859\n",
      "  D_Y Real: 0.0425, D_Y Fake: 0.0559, D_Y Total: 0.0492\n",
      "Generator Losses:\n",
      "  G Adv: 0.9635, F Adv: 0.6776\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1240, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.6878\n",
      "Epoch [115/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0630, D_X Fake: 0.1392, D_X Total: 0.1011\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0636, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.7451, F Adv: 0.4844\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.3957\n",
      "Epoch [115/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1864, D_X Fake: 0.0912, D_X Total: 0.1388\n",
      "  D_Y Real: 0.0486, D_Y Fake: 0.0479, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 0.9897, F Adv: 0.5936\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1464, Perceptual Monet: 0.1434\n",
      "  Total G Loss: 3.5463\n",
      "Epoch [115/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1157, D_X Fake: 0.0880, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0259, D_Y Fake: 0.0329, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 1.0270, F Adv: 0.7062\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1414\n",
      "  Total G Loss: 3.6551\n",
      "Epoch [115/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1620, D_X Fake: 0.1340, D_X Total: 0.1480\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0481, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 0.9727, F Adv: 0.4572\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.5415\n",
      "Epoch [115/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1988, D_X Fake: 0.0648, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0440, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.7168, F Adv: 0.5360\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1110, Perceptual Monet: 0.1936\n",
      "  Total G Loss: 3.3802\n",
      "Epoch [115/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1689, D_X Fake: 0.1201, D_X Total: 0.1445\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0382, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 0.7961, F Adv: 0.5002\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0213\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1344\n",
      "  Total G Loss: 3.1560\n",
      "Epoch [116/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1265, D_X Fake: 0.0987, D_X Total: 0.1126\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0434, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.9073, F Adv: 0.6230\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1433, Perceptual Monet: 0.1626\n",
      "  Total G Loss: 3.6029\n",
      "Epoch [116/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1759, D_X Fake: 0.0565, D_X Total: 0.1162\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0525, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.8214, F Adv: 0.6787\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.6269\n",
      "Epoch [116/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2602, D_X Fake: 0.0830, D_X Total: 0.1716\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0849, D_Y Total: 0.0550\n",
      "Generator Losses:\n",
      "  G Adv: 0.6376, F Adv: 0.5452\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.1756\n",
      "Epoch [116/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0774, D_X Fake: 0.0838, D_X Total: 0.0806\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0835, D_Y Total: 0.0542\n",
      "Generator Losses:\n",
      "  G Adv: 0.6447, F Adv: 0.5497\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.0868, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.0543\n",
      "Epoch [116/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0916, D_X Fake: 0.1184, D_X Total: 0.1050\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0639, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.8230, F Adv: 0.5737\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.4974\n",
      "Epoch [116/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1056, D_X Fake: 0.1303, D_X Total: 0.1179\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0414, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.8853, F Adv: 0.4843\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1520, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.4719\n",
      "Epoch [116/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1786, D_X Fake: 0.1058, D_X Total: 0.1422\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0341, D_Y Total: 0.0286\n",
      "Generator Losses:\n",
      "  G Adv: 0.9228, F Adv: 0.5599\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1232, Perceptual Monet: 0.1325\n",
      "  Total G Loss: 3.2295\n",
      "Epoch [116/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0984, D_X Fake: 0.0822, D_X Total: 0.0903\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0367, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 1.1169, F Adv: 0.6018\n",
      "  Cycle Photo: 0.0541, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1849, Perceptual Monet: 0.1473\n",
      "  Total G Loss: 4.1749\n",
      "Epoch [116/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0563, D_X Fake: 0.0657, D_X Total: 0.0610\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0537, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.8832, F Adv: 0.5840\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1156, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.3534\n",
      "Epoch [116/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1373, D_X Fake: 0.0623, D_X Total: 0.0998\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0310, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 0.9134, F Adv: 0.6794\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1817, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 4.0787\n",
      "Epoch [116/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0839, D_X Fake: 0.1021, D_X Total: 0.0930\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0616, D_Y Total: 0.0428\n",
      "Generator Losses:\n",
      "  G Adv: 0.8811, F Adv: 0.6045\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1517\n",
      "  Total G Loss: 3.5286\n",
      "Epoch [116/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0874, D_X Fake: 0.0664, D_X Total: 0.0769\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0421, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 1.0253, F Adv: 0.5550\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0191\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1197\n",
      "  Total G Loss: 3.4274\n",
      "Epoch [116/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0734, D_X Fake: 0.0795, D_X Total: 0.0765\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0351, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.9617, F Adv: 0.5503\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1023, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.4611\n",
      "Epoch [116/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0624, D_X Fake: 0.1445, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0479, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 1.1727, F Adv: 0.4871\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1885\n",
      "  Total G Loss: 4.1151\n",
      "Epoch [116/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0513, D_X Fake: 0.0657, D_X Total: 0.0585\n",
      "  D_Y Real: 0.0454, D_Y Fake: 0.0902, D_Y Total: 0.0678\n",
      "Generator Losses:\n",
      "  G Adv: 0.7692, F Adv: 0.5880\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.5927\n",
      "Epoch [116/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2784, D_X Fake: 0.0578, D_X Total: 0.1681\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0360, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 1.0698, F Adv: 0.6056\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1270, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.7212\n",
      "Epoch [116/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1626, D_X Fake: 0.1406, D_X Total: 0.1516\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0365, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 1.0035, F Adv: 0.5065\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1981, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.9554\n",
      "Epoch [116/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0722, D_X Fake: 0.0592, D_X Total: 0.0657\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0511, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 1.1520, F Adv: 0.6160\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1653, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 4.1135\n",
      "Epoch [116/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0355, D_X Fake: 0.0745, D_X Total: 0.0550\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0461, D_Y Total: 0.0439\n",
      "Generator Losses:\n",
      "  G Adv: 0.9864, F Adv: 0.6045\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.7701\n",
      "Epoch [116/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0846, D_X Fake: 0.1105, D_X Total: 0.0976\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0348, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 1.0638, F Adv: 0.5037\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0207\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1313\n",
      "  Total G Loss: 3.5077\n",
      "Epoch [116/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0779, D_X Fake: 0.1929, D_X Total: 0.1354\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0818, D_Y Total: 0.0500\n",
      "Generator Losses:\n",
      "  G Adv: 0.8148, F Adv: 0.4500\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1024, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.0098\n",
      "Epoch [116/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1731, D_X Fake: 0.0572, D_X Total: 0.1151\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0319, D_Y Total: 0.0305\n",
      "Generator Losses:\n",
      "  G Adv: 0.9033, F Adv: 0.7258\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1751, Perceptual Monet: 0.1445\n",
      "  Total G Loss: 3.8048\n",
      "Epoch [116/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0929, D_X Fake: 0.0938, D_X Total: 0.0933\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0426, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9593, F Adv: 0.6118\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1682, Perceptual Monet: 0.1440\n",
      "  Total G Loss: 3.7136\n",
      "Epoch [116/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3374, D_X Fake: 0.0974, D_X Total: 0.2174\n",
      "  D_Y Real: 0.0351, D_Y Fake: 0.0336, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.9188, F Adv: 0.5799\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1694\n",
      "  Total G Loss: 3.7314\n",
      "Epoch [117/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0571, D_X Fake: 0.1059, D_X Total: 0.0815\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0448, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 1.0480, F Adv: 0.4738\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1725\n",
      "  Total G Loss: 3.6005\n",
      "Epoch [117/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1847, D_X Fake: 0.1293, D_X Total: 0.1570\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0392, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.8411, F Adv: 0.6379\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1176, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.5326\n",
      "Epoch [117/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1218, D_X Fake: 0.0882, D_X Total: 0.1050\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0376, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 1.0671, F Adv: 0.7020\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1684\n",
      "  Total G Loss: 3.9105\n",
      "Epoch [117/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0654, D_X Fake: 0.1550, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0465, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.7315, F Adv: 0.6615\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1392, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.4526\n",
      "Epoch [117/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1297, D_X Fake: 0.1489, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0338, D_Y Fake: 0.0532, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.9991, F Adv: 0.4477\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 3.4143\n",
      "Epoch [117/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2560, D_X Fake: 0.1429, D_X Total: 0.1994\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0395, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.7919, F Adv: 0.5647\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1316, Perceptual Monet: 0.1965\n",
      "  Total G Loss: 3.6392\n",
      "Epoch [117/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0846, D_X Fake: 0.1068, D_X Total: 0.0957\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0519, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 0.9371, F Adv: 0.5729\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.5793\n",
      "Epoch [117/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1543, D_X Fake: 0.0869, D_X Total: 0.1206\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0351, D_Y Total: 0.0275\n",
      "Generator Losses:\n",
      "  G Adv: 0.9024, F Adv: 0.5492\n",
      "  Cycle Photo: 0.0391, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1844, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.8411\n",
      "Epoch [117/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1213, D_X Fake: 0.0637, D_X Total: 0.0925\n",
      "  D_Y Real: 0.0455, D_Y Fake: 0.0496, D_Y Total: 0.0475\n",
      "Generator Losses:\n",
      "  G Adv: 0.8641, F Adv: 0.6294\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1622, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.9652\n",
      "Epoch [117/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0823, D_X Fake: 0.0971, D_X Total: 0.0897\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.0300, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.8452, F Adv: 0.5946\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1527, Perceptual Monet: 0.1896\n",
      "  Total G Loss: 3.8059\n",
      "Epoch [117/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0706, D_X Fake: 0.0540, D_X Total: 0.0623\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0535, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.8535, F Adv: 0.5867\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1066, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.2618\n",
      "Epoch [117/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1645, D_X Fake: 0.0925, D_X Total: 0.1285\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0306, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.8899, F Adv: 0.6049\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1886\n",
      "  Total G Loss: 3.7562\n",
      "Epoch [117/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1195, D_X Fake: 0.0787, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0542, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.7886, F Adv: 0.5413\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.4908\n",
      "Epoch [117/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0799, D_X Fake: 0.1342, D_X Total: 0.1071\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0607, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.9265, F Adv: 0.4762\n",
      "  Cycle Photo: 0.0389, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1497, Perceptual Monet: 0.1399\n",
      "  Total G Loss: 3.4940\n",
      "Epoch [117/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2338, D_X Fake: 0.0751, D_X Total: 0.1544\n",
      "  D_Y Real: 0.0526, D_Y Fake: 0.0348, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.9939, F Adv: 0.6647\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1579, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.9857\n",
      "Epoch [117/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0626, D_X Fake: 0.1705, D_X Total: 0.1166\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0748, D_Y Total: 0.0494\n",
      "Generator Losses:\n",
      "  G Adv: 0.7218, F Adv: 0.4220\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1111, Perceptual Monet: 0.1505\n",
      "  Total G Loss: 2.9470\n",
      "Epoch [117/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2203, D_X Fake: 0.1368, D_X Total: 0.1785\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0365, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.8981, F Adv: 0.4107\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.5220\n",
      "Epoch [117/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1219, D_X Fake: 0.1121, D_X Total: 0.1170\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0441, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.8457, F Adv: 0.6606\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1050, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.4581\n",
      "Epoch [117/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2210, D_X Fake: 0.0842, D_X Total: 0.1526\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0507, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 1.0194, F Adv: 0.5543\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 3.9527\n",
      "Epoch [117/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0461, D_X Fake: 0.0592, D_X Total: 0.0526\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0347, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.9993, F Adv: 0.6245\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1528, Perceptual Monet: 0.2036\n",
      "  Total G Loss: 4.0987\n",
      "Epoch [117/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1799, D_X Fake: 0.0761, D_X Total: 0.1280\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0617, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.7858, F Adv: 0.4948\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1619, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.5742\n",
      "Epoch [117/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0746, D_X Fake: 0.0624, D_X Total: 0.0685\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0500, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8189, F Adv: 0.6640\n",
      "  Cycle Photo: 0.0453, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1809, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 3.9529\n",
      "Epoch [117/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0827, D_X Fake: 0.1074, D_X Total: 0.0950\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0358, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.9065, F Adv: 0.4918\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1395, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.4630\n",
      "Epoch [117/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1096, D_X Fake: 0.1545, D_X Total: 0.1320\n",
      "  D_Y Real: 0.0255, D_Y Fake: 0.0619, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 1.0281, F Adv: 0.4745\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.4862\n",
      "Epoch [118/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2684, D_X Fake: 0.1415, D_X Total: 0.2049\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0353, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 0.9081, F Adv: 0.4993\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0203\n",
      "  Perceptual Photo: 0.1909, Perceptual Monet: 0.1309\n",
      "  Total G Loss: 3.5697\n",
      "Epoch [118/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1542, D_X Fake: 0.1081, D_X Total: 0.1312\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0543, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.7488, F Adv: 0.5828\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1136, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.2674\n",
      "Epoch [118/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0889, D_X Fake: 0.0926, D_X Total: 0.0907\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0452, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 1.0231, F Adv: 0.6382\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1267, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.6686\n",
      "Epoch [118/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1141, D_X Fake: 0.0889, D_X Total: 0.1015\n",
      "  D_Y Real: 0.0422, D_Y Fake: 0.0485, D_Y Total: 0.0454\n",
      "Generator Losses:\n",
      "  G Adv: 0.7354, F Adv: 0.6586\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1262, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.3619\n",
      "Epoch [118/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1236, D_X Fake: 0.0848, D_X Total: 0.1042\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0513, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.9197, F Adv: 0.7211\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1063, Perceptual Monet: 0.1950\n",
      "  Total G Loss: 3.7981\n",
      "Epoch [118/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1263, D_X Fake: 0.1090, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0580, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.9443, F Adv: 0.5667\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.4587\n",
      "Epoch [118/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1457, D_X Fake: 0.1174, D_X Total: 0.1315\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0725, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 0.5921, F Adv: 0.5562\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1738, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.4190\n",
      "Epoch [118/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0561, D_X Fake: 0.1005, D_X Total: 0.0783\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0719, D_Y Total: 0.0489\n",
      "Generator Losses:\n",
      "  G Adv: 0.8402, F Adv: 0.5914\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.6250\n",
      "Epoch [118/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0632, D_X Fake: 0.1072, D_X Total: 0.0852\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0528, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.8044, F Adv: 0.5056\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1472, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.5135\n",
      "Epoch [118/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1029, D_X Fake: 0.0443, D_X Total: 0.0736\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0613, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.9777, F Adv: 0.6940\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1549, Perceptual Monet: 0.1495\n",
      "  Total G Loss: 3.7572\n",
      "Epoch [118/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1767, D_X Fake: 0.0953, D_X Total: 0.1360\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0293, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.8251, F Adv: 0.6367\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1888, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.8820\n",
      "Epoch [118/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0725, D_X Fake: 0.0821, D_X Total: 0.0773\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0261, D_Y Total: 0.0238\n",
      "Generator Losses:\n",
      "  G Adv: 0.9729, F Adv: 0.6315\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1536, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.8226\n",
      "Epoch [118/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2482, D_X Fake: 0.0727, D_X Total: 0.1605\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0528, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.6917, F Adv: 0.5773\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1400, Perceptual Monet: 0.1979\n",
      "  Total G Loss: 3.5717\n",
      "Epoch [118/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2230, D_X Fake: 0.0727, D_X Total: 0.1478\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0581, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.8765, F Adv: 0.7866\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.7601\n",
      "Epoch [118/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2281, D_X Fake: 0.0829, D_X Total: 0.1555\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0493, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 1.0231, F Adv: 0.5916\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1568, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.7572\n",
      "Epoch [118/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0832, D_X Fake: 0.0821, D_X Total: 0.0827\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.0380, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.8521, F Adv: 0.6772\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1230, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.5315\n",
      "Epoch [118/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1170, D_X Fake: 0.0763, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0344, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8678, F Adv: 0.5985\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1571, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.7146\n",
      "Epoch [118/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0329, D_X Fake: 0.1120, D_X Total: 0.0725\n",
      "  D_Y Real: 0.0321, D_Y Fake: 0.0531, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.8018, F Adv: 0.6477\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1139, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.3874\n",
      "Epoch [118/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2276, D_X Fake: 0.0845, D_X Total: 0.1560\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0433, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.9235, F Adv: 0.6815\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.6828\n",
      "Epoch [118/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1289, D_X Fake: 0.1278, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0572, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.9022, F Adv: 0.5095\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1352\n",
      "  Total G Loss: 3.1660\n",
      "Epoch [118/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1303, D_X Fake: 0.0563, D_X Total: 0.0933\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0384, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.9351, F Adv: 0.6158\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.7703\n",
      "Epoch [118/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0764, D_X Fake: 0.1509, D_X Total: 0.1137\n",
      "  D_Y Real: 0.0466, D_Y Fake: 0.0449, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.8008, F Adv: 0.4802\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1149, Perceptual Monet: 0.1927\n",
      "  Total G Loss: 3.4603\n",
      "Epoch [118/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1483, D_X Fake: 0.0644, D_X Total: 0.1063\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0446, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.7694, F Adv: 0.7212\n",
      "  Cycle Photo: 0.0220, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1071, Perceptual Monet: 0.1870\n",
      "  Total G Loss: 3.4938\n",
      "Epoch [118/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1780, D_X Fake: 0.0976, D_X Total: 0.1378\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0369, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.9825, F Adv: 0.6142\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1701, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 4.0135\n",
      "Epoch [119/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2088, D_X Fake: 0.0887, D_X Total: 0.1487\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0381, D_Y Total: 0.0304\n",
      "Generator Losses:\n",
      "  G Adv: 0.9091, F Adv: 0.5962\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.2014\n",
      "  Total G Loss: 3.8352\n",
      "Epoch [119/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1553, D_X Fake: 0.1643, D_X Total: 0.1598\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0698, D_Y Total: 0.0491\n",
      "Generator Losses:\n",
      "  G Adv: 0.9723, F Adv: 0.4882\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1724, Perceptual Monet: 0.1707\n",
      "  Total G Loss: 3.8312\n",
      "Epoch [119/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1514, D_X Fake: 0.0717, D_X Total: 0.1116\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0347, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.9753, F Adv: 0.8142\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 4.0756\n",
      "Epoch [119/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1718, D_X Fake: 0.0763, D_X Total: 0.1241\n",
      "  D_Y Real: 0.0365, D_Y Fake: 0.0339, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 1.0433, F Adv: 0.6685\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1762, Perceptual Monet: 0.1702\n",
      "  Total G Loss: 4.1057\n",
      "Epoch [119/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1464, D_X Fake: 0.1021, D_X Total: 0.1243\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0688, D_Y Total: 0.0434\n",
      "Generator Losses:\n",
      "  G Adv: 0.8156, F Adv: 0.5760\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1665, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.6364\n",
      "Epoch [119/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0913, D_X Fake: 0.1235, D_X Total: 0.1074\n",
      "  D_Y Real: 0.0357, D_Y Fake: 0.0380, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 1.0034, F Adv: 0.4330\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1384\n",
      "  Total G Loss: 3.3212\n",
      "Epoch [119/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0993, D_X Fake: 0.0565, D_X Total: 0.0779\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0586, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.7963, F Adv: 0.5367\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1395, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.4574\n",
      "Epoch [119/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1442, D_X Fake: 0.1406, D_X Total: 0.1424\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0634, D_Y Total: 0.0434\n",
      "Generator Losses:\n",
      "  G Adv: 0.8032, F Adv: 0.6166\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1549, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.5474\n",
      "Epoch [119/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0608, D_X Fake: 0.0859, D_X Total: 0.0734\n",
      "  D_Y Real: 0.0505, D_Y Fake: 0.0540, D_Y Total: 0.0522\n",
      "Generator Losses:\n",
      "  G Adv: 0.8170, F Adv: 0.6109\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1913\n",
      "  Total G Loss: 3.7756\n",
      "Epoch [119/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0475, D_X Fake: 0.1023, D_X Total: 0.0749\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0357, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 1.0462, F Adv: 0.5559\n",
      "  Cycle Photo: 0.0182, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.0977, Perceptual Monet: 0.1924\n",
      "  Total G Loss: 3.6244\n",
      "Epoch [119/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1337, D_X Fake: 0.0549, D_X Total: 0.0943\n",
      "  D_Y Real: 0.0371, D_Y Fake: 0.0340, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 1.0379, F Adv: 0.6988\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1817\n",
      "  Total G Loss: 4.0026\n",
      "Epoch [119/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1227, D_X Fake: 0.0548, D_X Total: 0.0888\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0395, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.8995, F Adv: 0.5847\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.4214\n",
      "Epoch [119/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1218, D_X Fake: 0.0720, D_X Total: 0.0969\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0754, D_Y Total: 0.0478\n",
      "Generator Losses:\n",
      "  G Adv: 1.0358, F Adv: 0.5159\n",
      "  Cycle Photo: 0.0218, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1012, Perceptual Monet: 0.1423\n",
      "  Total G Loss: 3.2584\n",
      "Epoch [119/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0768, D_X Fake: 0.1026, D_X Total: 0.0897\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.0330, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.8895, F Adv: 0.6524\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.6505\n",
      "Epoch [119/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0504, D_X Fake: 0.1392, D_X Total: 0.0948\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0454, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 0.8196, F Adv: 0.4534\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0200\n",
      "  Perceptual Photo: 0.1052, Perceptual Monet: 0.1201\n",
      "  Total G Loss: 2.8878\n",
      "Epoch [119/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0502, D_X Fake: 0.0997, D_X Total: 0.0750\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0923, D_Y Total: 0.0565\n",
      "Generator Losses:\n",
      "  G Adv: 0.5440, F Adv: 0.6322\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.1535\n",
      "  Total G Loss: 3.0952\n",
      "Epoch [119/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1166, D_X Fake: 0.0621, D_X Total: 0.0894\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0449, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.9543, F Adv: 0.7345\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.7537\n",
      "Epoch [119/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1010, D_X Fake: 0.1458, D_X Total: 0.1234\n",
      "  D_Y Real: 0.0487, D_Y Fake: 0.0430, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.9036, F Adv: 0.5541\n",
      "  Cycle Photo: 0.0209, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1114, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.2640\n",
      "Epoch [119/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0689, D_X Fake: 0.1085, D_X Total: 0.0887\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0376, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.9205, F Adv: 0.4875\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1750\n",
      "  Total G Loss: 3.6039\n",
      "Epoch [119/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0952, D_X Fake: 0.0694, D_X Total: 0.0823\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0673, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 0.7161, F Adv: 0.6553\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1400, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.3388\n",
      "Epoch [119/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1491, D_X Fake: 0.0983, D_X Total: 0.1237\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0626, D_Y Total: 0.0476\n",
      "Generator Losses:\n",
      "  G Adv: 0.6134, F Adv: 0.5611\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 3.3787\n",
      "Epoch [119/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2524, D_X Fake: 0.0900, D_X Total: 0.1712\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0345, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.8752, F Adv: 0.5728\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 3.8451\n",
      "Epoch [119/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2065, D_X Fake: 0.0908, D_X Total: 0.1486\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0415, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9306, F Adv: 0.6368\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.0945, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.4723\n",
      "Epoch [119/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1628, D_X Fake: 0.1287, D_X Total: 0.1457\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0681, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.9034, F Adv: 0.6345\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 3.7062\n",
      "Epoch [120/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1989, D_X Fake: 0.0813, D_X Total: 0.1401\n",
      "  D_Y Real: 0.0378, D_Y Fake: 0.0451, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.8502, F Adv: 0.5918\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.6160\n",
      "Epoch [120/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2312, D_X Fake: 0.0802, D_X Total: 0.1557\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0422, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.9533, F Adv: 0.6083\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1284, Perceptual Monet: 0.1960\n",
      "  Total G Loss: 3.7954\n",
      "Epoch [120/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0534, D_X Fake: 0.1450, D_X Total: 0.0992\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0597, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.8284, F Adv: 0.4887\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.4841\n",
      "Epoch [120/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2350, D_X Fake: 0.1150, D_X Total: 0.1750\n",
      "  D_Y Real: 0.0452, D_Y Fake: 0.0406, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.8386, F Adv: 0.5733\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1400, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.5301\n",
      "Epoch [120/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1337, D_X Fake: 0.1098, D_X Total: 0.1218\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0378, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.8613, F Adv: 0.5674\n",
      "  Cycle Photo: 0.0467, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.2237, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 4.1452\n",
      "Epoch [120/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2127, D_X Fake: 0.1216, D_X Total: 0.1671\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0339, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 1.0332, F Adv: 0.5435\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1658, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.6934\n",
      "Epoch [120/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1014, D_X Fake: 0.1061, D_X Total: 0.1038\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0691, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 0.7481, F Adv: 0.6543\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1318, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.4589\n",
      "Epoch [120/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1682, D_X Fake: 0.0882, D_X Total: 0.1282\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0443, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 0.8712, F Adv: 0.6280\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1418\n",
      "  Total G Loss: 3.3667\n",
      "Epoch [120/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1518, D_X Fake: 0.1159, D_X Total: 0.1338\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.0394, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 1.0708, F Adv: 0.5780\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1592\n",
      "  Total G Loss: 3.9280\n",
      "Epoch [120/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0438, D_X Fake: 0.0950, D_X Total: 0.0694\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0533, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.8466, F Adv: 0.5847\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1157, Perceptual Monet: 0.1346\n",
      "  Total G Loss: 3.1302\n",
      "Epoch [120/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1346, D_X Fake: 0.1068, D_X Total: 0.1207\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.0391, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 1.0425, F Adv: 0.5306\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1405\n",
      "  Total G Loss: 3.5953\n",
      "Epoch [120/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1180, D_X Fake: 0.0785, D_X Total: 0.0982\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0435, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.9735, F Adv: 0.5839\n",
      "  Cycle Photo: 0.0491, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.2132, Perceptual Monet: 0.1328\n",
      "  Total G Loss: 4.0038\n",
      "Epoch [120/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0930, D_X Fake: 0.0994, D_X Total: 0.0962\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0319, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.8852, F Adv: 0.6065\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1655, Perceptual Monet: 0.1708\n",
      "  Total G Loss: 3.7742\n",
      "Epoch [120/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1763, D_X Fake: 0.1367, D_X Total: 0.1565\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0667, D_Y Total: 0.0551\n",
      "Generator Losses:\n",
      "  G Adv: 0.7428, F Adv: 0.5079\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1475, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.2780\n",
      "Epoch [120/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1066, D_X Fake: 0.1296, D_X Total: 0.1181\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0679, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.8128, F Adv: 0.4697\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.1493\n",
      "  Total G Loss: 3.1795\n",
      "Epoch [120/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1675, D_X Fake: 0.1102, D_X Total: 0.1389\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0487, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.9070, F Adv: 0.6304\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1560, Perceptual Monet: 0.1830\n",
      "  Total G Loss: 3.8734\n",
      "Epoch [120/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1617, D_X Fake: 0.1047, D_X Total: 0.1332\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0478, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 1.1254, F Adv: 0.4759\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0206\n",
      "  Perceptual Photo: 0.1176, Perceptual Monet: 0.1329\n",
      "  Total G Loss: 3.2826\n",
      "Epoch [120/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1108, D_X Fake: 0.1590, D_X Total: 0.1349\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0755, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.7357, F Adv: 0.4632\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1221, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.1214\n",
      "Epoch [120/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0599, D_X Fake: 0.0964, D_X Total: 0.0781\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0300, D_Y Total: 0.0251\n",
      "Generator Losses:\n",
      "  G Adv: 0.9068, F Adv: 0.5234\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1621, Perceptual Monet: 0.1785\n",
      "  Total G Loss: 3.9140\n",
      "Epoch [120/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0943, D_X Fake: 0.0671, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0626, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.7637, F Adv: 0.6335\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1303, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.4987\n",
      "Epoch [120/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1783, D_X Fake: 0.1059, D_X Total: 0.1421\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0985, D_Y Total: 0.0643\n",
      "Generator Losses:\n",
      "  G Adv: 0.7375, F Adv: 0.5247\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 3.5340\n",
      "Epoch [120/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1572, D_X Fake: 0.0725, D_X Total: 0.1149\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0526, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.7847, F Adv: 0.8442\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1552, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.8094\n",
      "Epoch [120/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0731, D_X Fake: 0.0792, D_X Total: 0.0762\n",
      "  D_Y Real: 0.0370, D_Y Fake: 0.0357, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 0.8651, F Adv: 0.6928\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1364, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.6044\n",
      "Epoch [120/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1103, D_X Fake: 0.0843, D_X Total: 0.0973\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0405, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.7658, F Adv: 0.6632\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.3981\n",
      "Saved checkpoint at epoch 120\n",
      "Epoch [121/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1420, D_X Fake: 0.0946, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0606, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.7851, F Adv: 0.5888\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1223, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.3039\n",
      "Epoch [121/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2171, D_X Fake: 0.0921, D_X Total: 0.1546\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0354, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.9228, F Adv: 0.7275\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1193, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 3.5273\n",
      "Epoch [121/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1247, D_X Fake: 0.0750, D_X Total: 0.0998\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0348, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.7518, F Adv: 0.5625\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.5101\n",
      "Epoch [121/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0397, D_X Fake: 0.1234, D_X Total: 0.0815\n",
      "  D_Y Real: 0.0439, D_Y Fake: 0.0353, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.9464, F Adv: 0.6041\n",
      "  Cycle Photo: 0.0365, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1402, Perceptual Monet: 0.1877\n",
      "  Total G Loss: 3.8973\n",
      "Epoch [121/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1240, D_X Fake: 0.0875, D_X Total: 0.1057\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0355, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 1.0267, F Adv: 0.6766\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.8231\n",
      "Epoch [121/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0532, D_X Fake: 0.0839, D_X Total: 0.0686\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0336, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 0.8343, F Adv: 0.5980\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1526, Perceptual Monet: 0.1715\n",
      "  Total G Loss: 3.6400\n",
      "Epoch [121/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1210, D_X Fake: 0.0529, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0259, D_Y Fake: 0.0427, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 1.0073, F Adv: 0.5552\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1174, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.3891\n",
      "Epoch [121/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2521, D_X Fake: 0.1163, D_X Total: 0.1842\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0431, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.9358, F Adv: 0.5602\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1572, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.6830\n",
      "Epoch [121/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2078, D_X Fake: 0.0563, D_X Total: 0.1320\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0506, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.9478, F Adv: 0.7259\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1835, Perceptual Monet: 0.1482\n",
      "  Total G Loss: 3.9446\n",
      "Epoch [121/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1505, D_X Fake: 0.0511, D_X Total: 0.1008\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0559, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.9460, F Adv: 0.6630\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.9675\n",
      "Epoch [121/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1022, D_X Fake: 0.1429, D_X Total: 0.1225\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0398, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.8820, F Adv: 0.4885\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1131, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.4774\n",
      "Epoch [121/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1578, D_X Fake: 0.0785, D_X Total: 0.1182\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0415, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8248, F Adv: 0.6730\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1868, Perceptual Monet: 0.1911\n",
      "  Total G Loss: 4.0604\n",
      "Epoch [121/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0678, D_X Fake: 0.1104, D_X Total: 0.0891\n",
      "  D_Y Real: 0.0648, D_Y Fake: 0.0663, D_Y Total: 0.0656\n",
      "Generator Losses:\n",
      "  G Adv: 0.7812, F Adv: 0.5592\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1324, Perceptual Monet: 0.1798\n",
      "  Total G Loss: 3.5459\n",
      "Epoch [121/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0636, D_X Fake: 0.0887, D_X Total: 0.0762\n",
      "  D_Y Real: 0.0512, D_Y Fake: 0.0698, D_Y Total: 0.0605\n",
      "Generator Losses:\n",
      "  G Adv: 0.7736, F Adv: 0.6467\n",
      "  Cycle Photo: 0.0210, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1039, Perceptual Monet: 0.1860\n",
      "  Total G Loss: 3.4316\n",
      "Epoch [121/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2287, D_X Fake: 0.1144, D_X Total: 0.1716\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0406, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.8521, F Adv: 0.6135\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.7776\n",
      "Epoch [121/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1892, D_X Fake: 0.1334, D_X Total: 0.1613\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0482, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.8395, F Adv: 0.4720\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1293, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 3.2626\n",
      "Epoch [121/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0867, D_X Fake: 0.0636, D_X Total: 0.0752\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0617, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.9925, F Adv: 0.7422\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1196, Perceptual Monet: 0.1835\n",
      "  Total G Loss: 3.8049\n",
      "Epoch [121/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.0990, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0442, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 1.0987, F Adv: 0.6129\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.8739\n",
      "Epoch [121/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1447, D_X Fake: 0.1194, D_X Total: 0.1320\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0518, D_Y Total: 0.0420\n",
      "Generator Losses:\n",
      "  G Adv: 0.7768, F Adv: 0.5423\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.0961, Perceptual Monet: 0.1910\n",
      "  Total G Loss: 3.3248\n",
      "Epoch [121/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1958, D_X Fake: 0.0949, D_X Total: 0.1454\n",
      "  D_Y Real: 0.0349, D_Y Fake: 0.0410, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.7215, F Adv: 0.5859\n",
      "  Cycle Photo: 0.0427, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1647\n",
      "  Total G Loss: 3.6669\n",
      "Epoch [121/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0905, D_X Fake: 0.0889, D_X Total: 0.0897\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0499, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.9552, F Adv: 0.5769\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0227\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1339\n",
      "  Total G Loss: 3.3293\n",
      "Epoch [121/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1985, D_X Fake: 0.1153, D_X Total: 0.1569\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0426, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.9268, F Adv: 0.5686\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1579, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.8744\n",
      "Epoch [121/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1184, D_X Fake: 0.0854, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0318, D_Y Fake: 0.0762, D_Y Total: 0.0540\n",
      "Generator Losses:\n",
      "  G Adv: 0.7930, F Adv: 0.6110\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1293, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 3.5789\n",
      "Epoch [121/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2294, D_X Fake: 0.0827, D_X Total: 0.1561\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.1148, D_Y Total: 0.0663\n",
      "Generator Losses:\n",
      "  G Adv: 0.7239, F Adv: 0.6774\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1221, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.4100\n",
      "Epoch [122/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0696, D_X Fake: 0.1267, D_X Total: 0.0982\n",
      "  D_Y Real: 0.0152, D_Y Fake: 0.0414, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.9721, F Adv: 0.5518\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1067, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.4801\n",
      "Epoch [122/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1126, D_X Fake: 0.1109, D_X Total: 0.1118\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0664, D_Y Total: 0.0471\n",
      "Generator Losses:\n",
      "  G Adv: 0.8545, F Adv: 0.5513\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1632, Perceptual Monet: 0.1903\n",
      "  Total G Loss: 3.7673\n",
      "Epoch [122/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2263, D_X Fake: 0.0915, D_X Total: 0.1589\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0326, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9562, F Adv: 0.5420\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1481, Perceptual Monet: 0.1835\n",
      "  Total G Loss: 3.7864\n",
      "Epoch [122/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1864, D_X Fake: 0.0966, D_X Total: 0.1415\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0679, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.7243, F Adv: 0.6060\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 3.3236\n",
      "Epoch [122/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1566, D_X Fake: 0.1290, D_X Total: 0.1428\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.1217, D_Y Total: 0.0828\n",
      "Generator Losses:\n",
      "  G Adv: 0.8280, F Adv: 0.4850\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0205\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1247\n",
      "  Total G Loss: 3.1594\n",
      "Epoch [122/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1260, D_X Fake: 0.0600, D_X Total: 0.0930\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0966, D_Y Total: 0.0608\n",
      "Generator Losses:\n",
      "  G Adv: 0.5758, F Adv: 0.7043\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.3917\n",
      "Epoch [122/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0879, D_X Fake: 0.0694, D_X Total: 0.0786\n",
      "  D_Y Real: 0.0274, D_Y Fake: 0.0409, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.8071, F Adv: 0.6458\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1380, Perceptual Monet: 0.1906\n",
      "  Total G Loss: 3.6955\n",
      "Epoch [122/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0916, D_X Fake: 0.1283, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0554, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.8631, F Adv: 0.5269\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1192, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.4038\n",
      "Epoch [122/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1010, D_X Fake: 0.1078, D_X Total: 0.1044\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0431, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.8571, F Adv: 0.6199\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1256, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.4249\n",
      "Epoch [122/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1169, D_X Fake: 0.0814, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0245, D_Y Fake: 0.0354, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8450, F Adv: 0.5502\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.6988\n",
      "Epoch [122/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0977, D_X Fake: 0.1105, D_X Total: 0.1041\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0606, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 0.7904, F Adv: 0.5743\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 3.4750\n",
      "Epoch [122/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0534, D_X Fake: 0.0877, D_X Total: 0.0706\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0365, D_Y Total: 0.0292\n",
      "Generator Losses:\n",
      "  G Adv: 1.0083, F Adv: 0.5274\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.8169\n",
      "Epoch [122/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2374, D_X Fake: 0.1257, D_X Total: 0.1815\n",
      "  D_Y Real: 0.0352, D_Y Fake: 0.0564, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.8638, F Adv: 0.5404\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1571\n",
      "  Total G Loss: 3.4154\n",
      "Epoch [122/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0762, D_X Fake: 0.0993, D_X Total: 0.0878\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0419, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.7204, F Adv: 0.6491\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.4619\n",
      "Epoch [122/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1667, D_X Fake: 0.0961, D_X Total: 0.1314\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0377, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.7994, F Adv: 0.5759\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1261, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.3199\n",
      "Epoch [122/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0542, D_X Fake: 0.0675, D_X Total: 0.0608\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.1288, D_Y Total: 0.0814\n",
      "Generator Losses:\n",
      "  G Adv: 0.6535, F Adv: 0.7489\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1187, Perceptual Monet: 0.1954\n",
      "  Total G Loss: 3.6496\n",
      "Epoch [122/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0651, D_X Fake: 0.0926, D_X Total: 0.0789\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0426, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.8578, F Adv: 0.6090\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1591, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.5938\n",
      "Epoch [122/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0863, D_X Fake: 0.0701, D_X Total: 0.0782\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0468, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.9573, F Adv: 0.6371\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.7521\n",
      "Epoch [122/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1982, D_X Fake: 0.0883, D_X Total: 0.1433\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0442, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.8503, F Adv: 0.6320\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1231, Perceptual Monet: 0.2157\n",
      "  Total G Loss: 3.8439\n",
      "Epoch [122/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2043, D_X Fake: 0.1172, D_X Total: 0.1608\n",
      "  D_Y Real: 0.0138, D_Y Fake: 0.0583, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8534, F Adv: 0.4391\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1786, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.5866\n",
      "Epoch [122/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1409, D_X Fake: 0.1609, D_X Total: 0.1509\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0673, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 0.9127, F Adv: 0.5956\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1750, Perceptual Monet: 0.1511\n",
      "  Total G Loss: 3.8242\n",
      "Epoch [122/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0818, D_X Fake: 0.0705, D_X Total: 0.0762\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0704, D_Y Total: 0.0466\n",
      "Generator Losses:\n",
      "  G Adv: 0.8602, F Adv: 0.6749\n",
      "  Cycle Photo: 0.0215, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1221, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.4999\n",
      "Epoch [122/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0824, D_X Fake: 0.1514, D_X Total: 0.1169\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0467, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.9553, F Adv: 0.5423\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1285, Perceptual Monet: 0.1514\n",
      "  Total G Loss: 3.4301\n",
      "Epoch [122/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1083, D_X Fake: 0.0735, D_X Total: 0.0909\n",
      "  D_Y Real: 0.0510, D_Y Fake: 0.0437, D_Y Total: 0.0474\n",
      "Generator Losses:\n",
      "  G Adv: 0.8615, F Adv: 0.4738\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.5207\n",
      "Epoch [123/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1398, D_X Fake: 0.0784, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0402, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.8661, F Adv: 0.5439\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.4894\n",
      "Epoch [123/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2579, D_X Fake: 0.1164, D_X Total: 0.1872\n",
      "  D_Y Real: 0.0481, D_Y Fake: 0.0560, D_Y Total: 0.0521\n",
      "Generator Losses:\n",
      "  G Adv: 0.7561, F Adv: 0.6525\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1754\n",
      "  Total G Loss: 3.6799\n",
      "Epoch [123/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1599, D_X Fake: 0.1371, D_X Total: 0.1485\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0390, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.9697, F Adv: 0.4792\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1294, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.4272\n",
      "Epoch [123/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2053, D_X Fake: 0.1253, D_X Total: 0.1653\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0337, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 0.9578, F Adv: 0.5754\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1741, Perceptual Monet: 0.1852\n",
      "  Total G Loss: 3.9309\n",
      "Epoch [123/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0746, D_X Fake: 0.1507, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0500, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9400, F Adv: 0.6713\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1060, Perceptual Monet: 0.1708\n",
      "  Total G Loss: 3.5256\n",
      "Epoch [123/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0411, D_X Fake: 0.1024, D_X Total: 0.0718\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0574, D_Y Total: 0.0428\n",
      "Generator Losses:\n",
      "  G Adv: 0.9154, F Adv: 0.5892\n",
      "  Cycle Photo: 0.0202, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1131, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.5360\n",
      "Epoch [123/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1669, D_X Fake: 0.0924, D_X Total: 0.1297\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0308, D_Y Total: 0.0253\n",
      "Generator Losses:\n",
      "  G Adv: 0.8961, F Adv: 0.6534\n",
      "  Cycle Photo: 0.0224, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1180, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.5106\n",
      "Epoch [123/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1252, D_X Fake: 0.0771, D_X Total: 0.1011\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0474, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.7245, F Adv: 0.6520\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1144, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.3462\n",
      "Epoch [123/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2690, D_X Fake: 0.1314, D_X Total: 0.2002\n",
      "  D_Y Real: 0.0378, D_Y Fake: 0.0358, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.9045, F Adv: 0.5344\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1581, Perceptual Monet: 0.1469\n",
      "  Total G Loss: 3.5729\n",
      "Epoch [123/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1034, D_X Fake: 0.1492, D_X Total: 0.1263\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0590, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.9787, F Adv: 0.4859\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1578\n",
      "  Total G Loss: 3.4950\n",
      "Epoch [123/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1050, D_X Fake: 0.1116, D_X Total: 0.1083\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0475, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 1.0483, F Adv: 0.5149\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1626, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 3.7492\n",
      "Epoch [123/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1573, D_X Fake: 0.0661, D_X Total: 0.1117\n",
      "  D_Y Real: 0.0480, D_Y Fake: 0.0330, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.9926, F Adv: 0.6609\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1400, Perceptual Monet: 0.1832\n",
      "  Total G Loss: 3.8493\n",
      "Epoch [123/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2113, D_X Fake: 0.0782, D_X Total: 0.1447\n",
      "  D_Y Real: 0.0348, D_Y Fake: 0.0393, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.8725, F Adv: 0.6815\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.2008\n",
      "  Total G Loss: 4.1228\n",
      "Epoch [123/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0743, D_X Fake: 0.0820, D_X Total: 0.0781\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0514, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 1.0084, F Adv: 0.6841\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1216, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.8149\n",
      "Epoch [123/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1868, D_X Fake: 0.1129, D_X Total: 0.1499\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0717, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.8483, F Adv: 0.5903\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1301, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.4823\n",
      "Epoch [123/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1011, D_X Fake: 0.1382, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0623, D_Y Fake: 0.0359, D_Y Total: 0.0491\n",
      "Generator Losses:\n",
      "  G Adv: 0.9887, F Adv: 0.4832\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1152, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.4280\n",
      "Epoch [123/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1109, D_X Fake: 0.0922, D_X Total: 0.1016\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0453, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8185, F Adv: 0.5837\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1497, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.4347\n",
      "Epoch [123/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0801, D_X Fake: 0.1646, D_X Total: 0.1224\n",
      "  D_Y Real: 0.0493, D_Y Fake: 0.0325, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.9709, F Adv: 0.4299\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1801, Perceptual Monet: 0.1375\n",
      "  Total G Loss: 3.5625\n",
      "Epoch [123/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1192, D_X Fake: 0.0989, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0378, D_Y Total: 0.0289\n",
      "Generator Losses:\n",
      "  G Adv: 1.0217, F Adv: 0.4705\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.1370\n",
      "  Total G Loss: 3.4108\n",
      "Epoch [123/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1605, D_X Fake: 0.0946, D_X Total: 0.1276\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.0430, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.8841, F Adv: 0.6486\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1487, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.7588\n",
      "Epoch [123/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0854, D_X Fake: 0.1166, D_X Total: 0.1010\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0868, D_Y Total: 0.0571\n",
      "Generator Losses:\n",
      "  G Adv: 0.7735, F Adv: 0.5094\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.4576\n",
      "Epoch [123/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1423, D_X Fake: 0.1131, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0513, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.9199, F Adv: 0.5652\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1273, Perceptual Monet: 0.1579\n",
      "  Total G Loss: 3.4786\n",
      "Epoch [123/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0591, D_X Fake: 0.0981, D_X Total: 0.0786\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0310, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 0.8132, F Adv: 0.6427\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0192\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1294\n",
      "  Total G Loss: 3.3416\n",
      "Epoch [123/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1562, D_X Fake: 0.0879, D_X Total: 0.1220\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0709, D_Y Total: 0.0517\n",
      "Generator Losses:\n",
      "  G Adv: 0.7599, F Adv: 0.4702\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1291, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 3.3791\n",
      "Epoch [124/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1039, D_X Fake: 0.1953, D_X Total: 0.1496\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0520, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 0.9024, F Adv: 0.4666\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0205\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1302\n",
      "  Total G Loss: 3.2776\n",
      "Epoch [124/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0917, D_X Fake: 0.1154, D_X Total: 0.1036\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0371, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.8443, F Adv: 0.5122\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1949\n",
      "  Total G Loss: 3.7091\n",
      "Epoch [124/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1000, D_X Fake: 0.1224, D_X Total: 0.1112\n",
      "  D_Y Real: 0.0450, D_Y Fake: 0.0476, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 1.0531, F Adv: 0.6977\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.9247\n",
      "Epoch [124/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1268, D_X Fake: 0.0847, D_X Total: 0.1057\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0333, D_Y Total: 0.0280\n",
      "Generator Losses:\n",
      "  G Adv: 0.8066, F Adv: 0.7050\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.5480\n",
      "Epoch [124/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0631, D_X Fake: 0.0590, D_X Total: 0.0611\n",
      "  D_Y Real: 0.0570, D_Y Fake: 0.0329, D_Y Total: 0.0450\n",
      "Generator Losses:\n",
      "  G Adv: 1.0029, F Adv: 0.6512\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1282, Perceptual Monet: 0.1915\n",
      "  Total G Loss: 3.9466\n",
      "Epoch [124/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0974, D_X Fake: 0.1311, D_X Total: 0.1142\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0450, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.9582, F Adv: 0.5568\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1162, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.3287\n",
      "Epoch [124/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1115, D_X Fake: 0.0645, D_X Total: 0.0880\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0359, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.8054, F Adv: 0.6746\n",
      "  Cycle Photo: 0.0176, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.0972, Perceptual Monet: 0.2083\n",
      "  Total G Loss: 3.5589\n",
      "Epoch [124/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1382, D_X Fake: 0.1010, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0344, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.9437, F Adv: 0.5028\n",
      "  Cycle Photo: 0.0220, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1071, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.3639\n",
      "Epoch [124/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.0830, D_X Total: 0.0894\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0511, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.9676, F Adv: 0.6600\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1505\n",
      "  Total G Loss: 3.5487\n",
      "Epoch [124/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1653, D_X Fake: 0.2015, D_X Total: 0.1834\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0395, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 1.0050, F Adv: 0.5117\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1615, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.7083\n",
      "Epoch [124/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0790, D_X Fake: 0.0667, D_X Total: 0.0728\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0641, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.8060, F Adv: 0.7119\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1236, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.5990\n",
      "Epoch [124/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1443, D_X Fake: 0.1408, D_X Total: 0.1426\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0460, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.8002, F Adv: 0.5120\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1135, Perceptual Monet: 0.1772\n",
      "  Total G Loss: 3.3108\n",
      "Epoch [124/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1452, D_X Fake: 0.1039, D_X Total: 0.1245\n",
      "  D_Y Real: 0.0432, D_Y Fake: 0.0434, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 1.0138, F Adv: 0.6306\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 3.9065\n",
      "Epoch [124/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1362, D_X Fake: 0.0639, D_X Total: 0.1001\n",
      "  D_Y Real: 0.0388, D_Y Fake: 0.0412, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.9226, F Adv: 0.6593\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.5582\n",
      "Epoch [124/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1161, D_X Fake: 0.0915, D_X Total: 0.1038\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0373, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8037, F Adv: 0.5633\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 3.6119\n",
      "Epoch [124/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1014, D_X Fake: 0.0682, D_X Total: 0.0848\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0358, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 0.9190, F Adv: 0.6511\n",
      "  Cycle Photo: 0.0486, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1524, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.9103\n",
      "Epoch [124/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2264, D_X Fake: 0.0553, D_X Total: 0.1408\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0382, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.8346, F Adv: 0.7247\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1827, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 4.1126\n",
      "Epoch [124/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1754, D_X Fake: 0.0922, D_X Total: 0.1338\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0448, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 1.1075, F Adv: 0.6184\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1494\n",
      "  Total G Loss: 3.7125\n",
      "Epoch [124/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1036, D_X Fake: 0.1250, D_X Total: 0.1143\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0438, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.9797, F Adv: 0.4985\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1412, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.5646\n",
      "Epoch [124/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1500, D_X Fake: 0.0945, D_X Total: 0.1223\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.0540, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.8274, F Adv: 0.5727\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.5703\n",
      "Epoch [124/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0862, D_X Fake: 0.0641, D_X Total: 0.0751\n",
      "  D_Y Real: 0.0440, D_Y Fake: 0.0363, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.8591, F Adv: 0.6888\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0206\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1312\n",
      "  Total G Loss: 3.3937\n",
      "Epoch [124/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1385, D_X Fake: 0.0696, D_X Total: 0.1041\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.1289, D_Y Total: 0.0744\n",
      "Generator Losses:\n",
      "  G Adv: 0.8078, F Adv: 0.7058\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.7766\n",
      "Epoch [124/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1305, D_X Fake: 0.1227, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0248, D_Y Fake: 0.0495, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.9825, F Adv: 0.4830\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 3.4397\n",
      "Epoch [124/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0424, D_X Fake: 0.0577, D_X Total: 0.0501\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0494, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.9114, F Adv: 0.7216\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.7391\n",
      "Epoch [125/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1630, D_X Fake: 0.1009, D_X Total: 0.1319\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.0737, D_Y Total: 0.0579\n",
      "Generator Losses:\n",
      "  G Adv: 0.8064, F Adv: 0.4990\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1776\n",
      "  Total G Loss: 3.6577\n",
      "Epoch [125/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1961, D_X Fake: 0.0591, D_X Total: 0.1276\n",
      "  D_Y Real: 0.0448, D_Y Fake: 0.0477, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 0.7388, F Adv: 0.7797\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1893\n",
      "  Total G Loss: 3.8403\n",
      "Epoch [125/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1636, D_X Fake: 0.1803, D_X Total: 0.1719\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0469, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.8508, F Adv: 0.5524\n",
      "  Cycle Photo: 0.0445, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1901\n",
      "  Total G Loss: 3.9253\n",
      "Epoch [125/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1340, D_X Fake: 0.0750, D_X Total: 0.1045\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0442, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9976, F Adv: 0.7454\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.9272\n",
      "Epoch [125/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1165, D_X Fake: 0.0603, D_X Total: 0.0884\n",
      "  D_Y Real: 0.0501, D_Y Fake: 0.0886, D_Y Total: 0.0693\n",
      "Generator Losses:\n",
      "  G Adv: 0.7347, F Adv: 0.5351\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1323, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.4044\n",
      "Epoch [125/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1278, D_X Fake: 0.1160, D_X Total: 0.1219\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0417, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 1.0116, F Adv: 0.5591\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1554\n",
      "  Total G Loss: 3.7864\n",
      "Epoch [125/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2482, D_X Fake: 0.0810, D_X Total: 0.1646\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0455, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.8576, F Adv: 0.5609\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 3.4512\n",
      "Epoch [125/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0870, D_X Fake: 0.1347, D_X Total: 0.1108\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0491, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 1.0044, F Adv: 0.4656\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1330, Perceptual Monet: 0.1888\n",
      "  Total G Loss: 3.6318\n",
      "Epoch [125/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2655, D_X Fake: 0.0759, D_X Total: 0.1707\n",
      "  D_Y Real: 0.0537, D_Y Fake: 0.0884, D_Y Total: 0.0710\n",
      "Generator Losses:\n",
      "  G Adv: 0.9326, F Adv: 0.6103\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1525, Perceptual Monet: 0.2037\n",
      "  Total G Loss: 4.0573\n",
      "Epoch [125/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1306, D_X Fake: 0.1261, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0868, D_Y Total: 0.0554\n",
      "Generator Losses:\n",
      "  G Adv: 0.8258, F Adv: 0.6906\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.1816\n",
      "  Total G Loss: 3.8799\n",
      "Epoch [125/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1680, D_X Fake: 0.0528, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0221, D_Y Fake: 0.0635, D_Y Total: 0.0428\n",
      "Generator Losses:\n",
      "  G Adv: 0.6893, F Adv: 0.7849\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 3.7952\n",
      "Epoch [125/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0954, D_X Fake: 0.0831, D_X Total: 0.0893\n",
      "  D_Y Real: 0.0248, D_Y Fake: 0.0389, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 1.1042, F Adv: 0.5654\n",
      "  Cycle Photo: 0.0224, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1170, Perceptual Monet: 0.1935\n",
      "  Total G Loss: 3.7762\n",
      "Epoch [125/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0616, D_X Fake: 0.0708, D_X Total: 0.0662\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.0658, D_Y Total: 0.0501\n",
      "Generator Losses:\n",
      "  G Adv: 0.8580, F Adv: 0.6999\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1299, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.4902\n",
      "Epoch [125/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1447, D_X Fake: 0.0787, D_X Total: 0.1117\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.0379, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.7993, F Adv: 0.5513\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.3589\n",
      "Epoch [125/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4113, D_X Fake: 0.0570, D_X Total: 0.2341\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0764, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.7258, F Adv: 0.7210\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1663, Perceptual Monet: 0.1812\n",
      "  Total G Loss: 3.8762\n",
      "Epoch [125/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1168, D_X Fake: 0.1260, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.0475, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.9106, F Adv: 0.5566\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1525, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.5476\n",
      "Epoch [125/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1950, D_X Fake: 0.0952, D_X Total: 0.1451\n",
      "  D_Y Real: 0.0527, D_Y Fake: 0.0546, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.8736, F Adv: 0.5913\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1634, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.8785\n",
      "Epoch [125/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1110, D_X Fake: 0.1310, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0334, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 1.0377, F Adv: 0.4847\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1908\n",
      "  Total G Loss: 3.8306\n",
      "Epoch [125/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0883, D_X Fake: 0.1104, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0408, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.9908, F Adv: 0.5479\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1091, Perceptual Monet: 0.1968\n",
      "  Total G Loss: 3.6696\n",
      "Epoch [125/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1563, D_X Fake: 0.1531, D_X Total: 0.1547\n",
      "  D_Y Real: 0.0425, D_Y Fake: 0.0284, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.8563, F Adv: 0.5735\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.5537\n",
      "Epoch [125/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0870, D_X Fake: 0.0854, D_X Total: 0.0862\n",
      "  D_Y Real: 0.0302, D_Y Fake: 0.0332, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 1.0586, F Adv: 0.6095\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1871\n",
      "  Total G Loss: 3.9192\n",
      "Epoch [125/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0456, D_X Fake: 0.1236, D_X Total: 0.0846\n",
      "  D_Y Real: 0.0392, D_Y Fake: 0.0390, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 1.0344, F Adv: 0.5159\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1346, Perceptual Monet: 0.1970\n",
      "  Total G Loss: 3.8718\n",
      "Epoch [125/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0984, D_X Fake: 0.1195, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0614, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 0.8631, F Adv: 0.6171\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.6169\n",
      "Epoch [125/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3355, D_X Fake: 0.0740, D_X Total: 0.2048\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0522, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.9722, F Adv: 0.5903\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1293, Perceptual Monet: 0.1508\n",
      "  Total G Loss: 3.4460\n",
      "Epoch [126/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1189, D_X Fake: 0.1246, D_X Total: 0.1218\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0508, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 1.0456, F Adv: 0.5189\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1672, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 3.8235\n",
      "Epoch [126/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.0982, D_X Total: 0.0843\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0787, D_Y Total: 0.0524\n",
      "Generator Losses:\n",
      "  G Adv: 0.7996, F Adv: 0.6495\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1151, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 3.5314\n",
      "Epoch [126/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0836, D_X Fake: 0.1301, D_X Total: 0.1069\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0971, D_Y Total: 0.0602\n",
      "Generator Losses:\n",
      "  G Adv: 0.9448, F Adv: 0.4951\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1241, Perceptual Monet: 0.1789\n",
      "  Total G Loss: 3.5228\n",
      "Epoch [126/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.4024, D_X Fake: 0.1221, D_X Total: 0.2623\n",
      "  D_Y Real: 0.0590, D_Y Fake: 0.0542, D_Y Total: 0.0566\n",
      "Generator Losses:\n",
      "  G Adv: 0.7949, F Adv: 0.5406\n",
      "  Cycle Photo: 0.0420, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1783, Perceptual Monet: 0.1839\n",
      "  Total G Loss: 3.8928\n",
      "Epoch [126/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1783, D_X Fake: 0.0552, D_X Total: 0.1167\n",
      "  D_Y Real: 0.0641, D_Y Fake: 0.0548, D_Y Total: 0.0595\n",
      "Generator Losses:\n",
      "  G Adv: 1.0140, F Adv: 0.6691\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1765\n",
      "  Total G Loss: 3.8916\n",
      "Epoch [126/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0525, D_X Fake: 0.0835, D_X Total: 0.0680\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.0502, D_Y Total: 0.0404\n",
      "Generator Losses:\n",
      "  G Adv: 0.9291, F Adv: 0.5505\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1180, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.4387\n",
      "Epoch [126/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0519, D_X Fake: 0.0759, D_X Total: 0.0639\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0410, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.8710, F Adv: 0.6081\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1278, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.5510\n",
      "Epoch [126/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1814, D_X Fake: 0.1127, D_X Total: 0.1471\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0529, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.8253, F Adv: 0.5082\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1362, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.4285\n",
      "Epoch [126/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1171, D_X Fake: 0.0757, D_X Total: 0.0964\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0644, D_Y Total: 0.0502\n",
      "Generator Losses:\n",
      "  G Adv: 0.9352, F Adv: 0.6028\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1248, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.4810\n",
      "Epoch [126/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0602, D_X Fake: 0.1190, D_X Total: 0.0896\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.0327, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 1.0027, F Adv: 0.5351\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1331, Perceptual Monet: 0.1965\n",
      "  Total G Loss: 3.7879\n",
      "Epoch [126/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0971, D_X Fake: 0.1188, D_X Total: 0.1080\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0599, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.7253, F Adv: 0.6804\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1402, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 3.4901\n",
      "Epoch [126/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1360, D_X Fake: 0.0905, D_X Total: 0.1133\n",
      "  D_Y Real: 0.0335, D_Y Fake: 0.0540, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.7964, F Adv: 0.5802\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1715\n",
      "  Total G Loss: 3.4560\n",
      "Epoch [126/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1637, D_X Fake: 0.0836, D_X Total: 0.1237\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0334, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9275, F Adv: 0.8060\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 3.7716\n",
      "Epoch [126/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1519, D_X Fake: 0.1176, D_X Total: 0.1348\n",
      "  D_Y Real: 0.0378, D_Y Fake: 0.0380, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 0.9592, F Adv: 0.5092\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1535, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.7245\n",
      "Epoch [126/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0959, D_X Fake: 0.1029, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0385, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 1.0247, F Adv: 0.5763\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1270, Perceptual Monet: 0.1782\n",
      "  Total G Loss: 3.7021\n",
      "Epoch [126/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1864, D_X Fake: 0.1756, D_X Total: 0.1810\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0261, D_Y Total: 0.0239\n",
      "Generator Losses:\n",
      "  G Adv: 1.0212, F Adv: 0.4330\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1363, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.6758\n",
      "Epoch [126/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1550, D_X Fake: 0.1076, D_X Total: 0.1313\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0733, D_Y Total: 0.0465\n",
      "Generator Losses:\n",
      "  G Adv: 0.9754, F Adv: 0.4711\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1196, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.3974\n",
      "Epoch [126/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1773, D_X Fake: 0.0602, D_X Total: 0.1187\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.0450, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.9296, F Adv: 0.7365\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1303, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.6717\n",
      "Epoch [126/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1146, D_X Fake: 0.0695, D_X Total: 0.0921\n",
      "  D_Y Real: 0.0445, D_Y Fake: 0.0416, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.8450, F Adv: 0.7161\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1787\n",
      "  Total G Loss: 3.9301\n",
      "Epoch [126/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1632, D_X Fake: 0.0557, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0379, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.8546, F Adv: 0.7629\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1889, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 4.0918\n",
      "Epoch [126/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0436, D_X Fake: 0.0727, D_X Total: 0.0582\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0353, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 1.0175, F Adv: 0.7317\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1041, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 3.7276\n",
      "Epoch [126/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1624, D_X Fake: 0.0921, D_X Total: 0.1272\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0316, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.8803, F Adv: 0.6374\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1781, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.9099\n",
      "Epoch [126/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1480, D_X Fake: 0.1176, D_X Total: 0.1328\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0696, D_Y Total: 0.0491\n",
      "Generator Losses:\n",
      "  G Adv: 1.0494, F Adv: 0.6356\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1915, Perceptual Monet: 0.1906\n",
      "  Total G Loss: 4.3445\n",
      "Epoch [126/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1017, D_X Fake: 0.1163, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0145, D_Y Fake: 0.0703, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.8042, F Adv: 0.6179\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1822, Perceptual Monet: 0.1510\n",
      "  Total G Loss: 3.6876\n",
      "Epoch [127/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1286, D_X Fake: 0.1412, D_X Total: 0.1349\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.0378, D_Y Total: 0.0346\n",
      "Generator Losses:\n",
      "  G Adv: 0.9634, F Adv: 0.4920\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1385, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.4892\n",
      "Epoch [127/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0710, D_X Fake: 0.1478, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0426, D_Y Fake: 0.0914, D_Y Total: 0.0670\n",
      "Generator Losses:\n",
      "  G Adv: 0.7338, F Adv: 0.4862\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.3686\n",
      "Epoch [127/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.0880, D_X Total: 0.0836\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0357, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 0.9568, F Adv: 0.6812\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1273, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.5919\n",
      "Epoch [127/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1523, D_X Fake: 0.0862, D_X Total: 0.1193\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0425, D_Y Total: 0.0305\n",
      "Generator Losses:\n",
      "  G Adv: 1.1414, F Adv: 0.6305\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.9953\n",
      "Epoch [127/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1201, D_X Fake: 0.0537, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0124, D_Y Fake: 0.0407, D_Y Total: 0.0266\n",
      "Generator Losses:\n",
      "  G Adv: 1.0046, F Adv: 0.5735\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.5725\n",
      "Epoch [127/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2148, D_X Fake: 0.0860, D_X Total: 0.1504\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0618, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.8042, F Adv: 0.5614\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.4257\n",
      "Epoch [127/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0706, D_X Fake: 0.1514, D_X Total: 0.1110\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0599, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 1.0586, F Adv: 0.4740\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1603, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.7050\n",
      "Epoch [127/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0831, D_X Fake: 0.0918, D_X Total: 0.0874\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0696, D_Y Total: 0.0468\n",
      "Generator Losses:\n",
      "  G Adv: 0.7664, F Adv: 0.5386\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1396, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.3397\n",
      "Epoch [127/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1896, D_X Fake: 0.1327, D_X Total: 0.1612\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0383, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 1.0058, F Adv: 0.5333\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1331, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.4274\n",
      "Epoch [127/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1737, D_X Fake: 0.1472, D_X Total: 0.1604\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0878, D_Y Total: 0.0584\n",
      "Generator Losses:\n",
      "  G Adv: 0.8852, F Adv: 0.4990\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0182\n",
      "  Perceptual Photo: 0.1067, Perceptual Monet: 0.1101\n",
      "  Total G Loss: 2.8672\n",
      "Epoch [127/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0693, D_X Fake: 0.0910, D_X Total: 0.0801\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0823, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.8131, F Adv: 0.5392\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0199\n",
      "  Perceptual Photo: 0.0892, Perceptual Monet: 0.1350\n",
      "  Total G Loss: 2.9742\n",
      "Epoch [127/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1751, D_X Fake: 0.0781, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0489, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.9579, F Adv: 0.5540\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1216, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 3.6092\n",
      "Epoch [127/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1232, D_X Fake: 0.0653, D_X Total: 0.0943\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0457, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.8078, F Adv: 0.6839\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1761, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.7616\n",
      "Epoch [127/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1184, D_X Fake: 0.0907, D_X Total: 0.1045\n",
      "  D_Y Real: 0.0302, D_Y Fake: 0.0371, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.8579, F Adv: 0.5918\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1489, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.5746\n",
      "Epoch [127/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0889, D_X Fake: 0.1037, D_X Total: 0.0963\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0655, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.9337, F Adv: 0.5933\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1044, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.4222\n",
      "Epoch [127/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.1445, D_X Total: 0.1075\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0336, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 1.0328, F Adv: 0.4815\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1337, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.5813\n",
      "Epoch [127/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1536, D_X Fake: 0.0664, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0417, D_Y Fake: 0.0298, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.9044, F Adv: 0.6233\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.7441\n",
      "Epoch [127/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1059, D_X Fake: 0.0925, D_X Total: 0.0992\n",
      "  D_Y Real: 0.0337, D_Y Fake: 0.0643, D_Y Total: 0.0490\n",
      "Generator Losses:\n",
      "  G Adv: 0.7968, F Adv: 0.6354\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1755\n",
      "  Total G Loss: 3.5975\n",
      "Epoch [127/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2168, D_X Fake: 0.0842, D_X Total: 0.1505\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0434, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 0.6390, F Adv: 0.6338\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.5423\n",
      "Epoch [127/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2039, D_X Fake: 0.1666, D_X Total: 0.1852\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0399, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.7964, F Adv: 0.4866\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.4475\n",
      "Epoch [127/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1487, D_X Fake: 0.1042, D_X Total: 0.1265\n",
      "  D_Y Real: 0.0496, D_Y Fake: 0.0382, D_Y Total: 0.0439\n",
      "Generator Losses:\n",
      "  G Adv: 0.8387, F Adv: 0.6169\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.5503\n",
      "Epoch [127/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0766, D_X Fake: 0.0967, D_X Total: 0.0867\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0477, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 1.1132, F Adv: 0.6292\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1682, Perceptual Monet: 0.1400\n",
      "  Total G Loss: 3.8362\n",
      "Epoch [127/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2683, D_X Fake: 0.0796, D_X Total: 0.1739\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0361, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.6248, F Adv: 0.6504\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1464, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.5532\n",
      "Epoch [127/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1007, D_X Fake: 0.1195, D_X Total: 0.1101\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.0443, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.8796, F Adv: 0.4215\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1497, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 3.5787\n",
      "Epoch [128/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1379, D_X Fake: 0.1170, D_X Total: 0.1274\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0355, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.9582, F Adv: 0.5393\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1634, Perceptual Monet: 0.1856\n",
      "  Total G Loss: 3.8893\n",
      "Epoch [128/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1626, D_X Fake: 0.1275, D_X Total: 0.1450\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0743, D_Y Total: 0.0521\n",
      "Generator Losses:\n",
      "  G Adv: 0.7007, F Adv: 0.6433\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1550, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.5458\n",
      "Epoch [128/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1627, D_X Fake: 0.1234, D_X Total: 0.1430\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0429, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 1.0266, F Adv: 0.5175\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1998, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 4.0758\n",
      "Epoch [128/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0444, D_X Fake: 0.1235, D_X Total: 0.0839\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0408, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 1.0679, F Adv: 0.4659\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1583\n",
      "  Total G Loss: 3.5225\n",
      "Epoch [128/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1589, D_X Fake: 0.0702, D_X Total: 0.1146\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0552, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 1.0659, F Adv: 0.6103\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1888\n",
      "  Total G Loss: 3.8908\n",
      "Epoch [128/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2627, D_X Fake: 0.0903, D_X Total: 0.1765\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0427, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9649, F Adv: 0.6566\n",
      "  Cycle Photo: 0.0534, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1702, Perceptual Monet: 0.1752\n",
      "  Total G Loss: 4.2160\n",
      "Epoch [128/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0902, D_X Fake: 0.0817, D_X Total: 0.0859\n",
      "  D_Y Real: 0.0131, D_Y Fake: 0.0389, D_Y Total: 0.0260\n",
      "Generator Losses:\n",
      "  G Adv: 1.0879, F Adv: 0.6381\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1263, Perceptual Monet: 0.1964\n",
      "  Total G Loss: 3.9432\n",
      "Epoch [128/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1178, D_X Fake: 0.0904, D_X Total: 0.1041\n",
      "  D_Y Real: 0.0165, D_Y Fake: 0.0309, D_Y Total: 0.0237\n",
      "Generator Losses:\n",
      "  G Adv: 0.9404, F Adv: 0.5972\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.5871\n",
      "Epoch [128/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2938, D_X Fake: 0.0770, D_X Total: 0.1854\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0414, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8638, F Adv: 0.6009\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1566\n",
      "  Total G Loss: 3.4808\n",
      "Epoch [128/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2093, D_X Fake: 0.0737, D_X Total: 0.1415\n",
      "  D_Y Real: 0.0519, D_Y Fake: 0.0551, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.8701, F Adv: 0.7311\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1742, Perceptual Monet: 0.2117\n",
      "  Total G Loss: 4.2258\n",
      "Epoch [128/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1132, D_X Fake: 0.1143, D_X Total: 0.1137\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0438, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8556, F Adv: 0.4781\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1352, Perceptual Monet: 0.1871\n",
      "  Total G Loss: 3.5689\n",
      "Epoch [128/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2116, D_X Fake: 0.0837, D_X Total: 0.1477\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0228, D_Y Total: 0.0242\n",
      "Generator Losses:\n",
      "  G Adv: 0.9240, F Adv: 0.6695\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 4.0018\n",
      "Epoch [128/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0810, D_X Fake: 0.1122, D_X Total: 0.0966\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.0407, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.8424, F Adv: 0.5326\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1073, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.3352\n",
      "Epoch [128/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1049, D_X Fake: 0.1006, D_X Total: 0.1027\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0610, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 0.7579, F Adv: 0.6744\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1327, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.5450\n",
      "Epoch [128/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0881, D_X Fake: 0.0949, D_X Total: 0.0915\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0419, D_Y Total: 0.0304\n",
      "Generator Losses:\n",
      "  G Adv: 1.0734, F Adv: 0.5397\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1282, Perceptual Monet: 0.1500\n",
      "  Total G Loss: 3.5453\n",
      "Epoch [128/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1574, D_X Fake: 0.0404, D_X Total: 0.0989\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0320, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.9479, F Adv: 0.7948\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.9155\n",
      "Epoch [128/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0799, D_X Fake: 0.0783, D_X Total: 0.0791\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0390, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 1.0536, F Adv: 0.6285\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.6355\n",
      "Epoch [128/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1141, D_X Fake: 0.1043, D_X Total: 0.1092\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0473, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9305, F Adv: 0.5710\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.6099\n",
      "Epoch [128/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1687, D_X Fake: 0.1343, D_X Total: 0.1515\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0478, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.8760, F Adv: 0.5336\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1288, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 3.6352\n",
      "Epoch [128/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1539, D_X Fake: 0.1160, D_X Total: 0.1349\n",
      "  D_Y Real: 0.0140, D_Y Fake: 0.0427, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.9111, F Adv: 0.5752\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.9008\n",
      "Epoch [128/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1957, D_X Fake: 0.1006, D_X Total: 0.1482\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0408, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.9305, F Adv: 0.6315\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1832, Perceptual Monet: 0.1513\n",
      "  Total G Loss: 3.9004\n",
      "Epoch [128/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2655, D_X Fake: 0.1164, D_X Total: 0.1910\n",
      "  D_Y Real: 0.0518, D_Y Fake: 0.0301, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.8588, F Adv: 0.5915\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.1866\n",
      "  Total G Loss: 3.7862\n",
      "Epoch [128/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0984, D_X Fake: 0.1248, D_X Total: 0.1116\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.0371, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.9190, F Adv: 0.5725\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.5344\n",
      "Epoch [128/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2645, D_X Fake: 0.0862, D_X Total: 0.1754\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0443, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8760, F Adv: 0.6092\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 3.6655\n",
      "Epoch [129/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1860, D_X Fake: 0.0900, D_X Total: 0.1380\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0589, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.8287, F Adv: 0.5989\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1246, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.3970\n",
      "Epoch [129/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1056, D_X Fake: 0.1037, D_X Total: 0.1047\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0497, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.9447, F Adv: 0.5697\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1841\n",
      "  Total G Loss: 3.6851\n",
      "Epoch [129/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1089, D_X Fake: 0.0756, D_X Total: 0.0922\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0513, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.8930, F Adv: 0.6326\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1621, Perceptual Monet: 0.1624\n",
      "  Total G Loss: 3.7896\n",
      "Epoch [129/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1433, D_X Fake: 0.0918, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0874, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.7382, F Adv: 0.6503\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.2005\n",
      "  Total G Loss: 3.8535\n",
      "Epoch [129/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0981, D_X Fake: 0.0948, D_X Total: 0.0964\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0671, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 0.7295, F Adv: 0.5948\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1443, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.4851\n",
      "Epoch [129/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1647, D_X Fake: 0.1137, D_X Total: 0.1392\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0551, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.8386, F Adv: 0.5538\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1704, Perceptual Monet: 0.1577\n",
      "  Total G Loss: 3.6039\n",
      "Epoch [129/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2311, D_X Fake: 0.0749, D_X Total: 0.1530\n",
      "  D_Y Real: 0.0164, D_Y Fake: 0.0399, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 0.7822, F Adv: 0.6711\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1479\n",
      "  Total G Loss: 3.4202\n",
      "Epoch [129/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1244, D_X Fake: 0.1254, D_X Total: 0.1249\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0607, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.8147, F Adv: 0.5300\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1967\n",
      "  Total G Loss: 3.6174\n",
      "Epoch [129/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1662, D_X Fake: 0.1291, D_X Total: 0.1477\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0350, D_Y Total: 0.0266\n",
      "Generator Losses:\n",
      "  G Adv: 1.0449, F Adv: 0.4898\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1698\n",
      "  Total G Loss: 3.9300\n",
      "Epoch [129/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1262, D_X Fake: 0.1870, D_X Total: 0.1566\n",
      "  D_Y Real: 0.0286, D_Y Fake: 0.0435, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.8562, F Adv: 0.4344\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1334, Perceptual Monet: 0.1551\n",
      "  Total G Loss: 3.2669\n",
      "Epoch [129/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2669, D_X Fake: 0.0915, D_X Total: 0.1792\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.1092, D_Y Total: 0.0667\n",
      "Generator Losses:\n",
      "  G Adv: 0.8561, F Adv: 0.5901\n",
      "  Cycle Photo: 0.0441, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1924, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 4.0293\n",
      "Epoch [129/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0898, D_X Fake: 0.1722, D_X Total: 0.1310\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0507, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8050, F Adv: 0.4893\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1129, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.2209\n",
      "Epoch [129/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0870, D_X Fake: 0.1387, D_X Total: 0.1129\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0316, D_Y Total: 0.0254\n",
      "Generator Losses:\n",
      "  G Adv: 0.9811, F Adv: 0.4896\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1731\n",
      "  Total G Loss: 3.6907\n",
      "Epoch [129/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3096, D_X Fake: 0.1080, D_X Total: 0.2088\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.0252, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.9847, F Adv: 0.6517\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.6173\n",
      "Epoch [129/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1276, D_X Fake: 0.0922, D_X Total: 0.1099\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0611, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 0.8524, F Adv: 0.6120\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.7109\n",
      "Epoch [129/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0573, D_X Fake: 0.1815, D_X Total: 0.1194\n",
      "  D_Y Real: 0.0524, D_Y Fake: 0.0499, D_Y Total: 0.0511\n",
      "Generator Losses:\n",
      "  G Adv: 0.9024, F Adv: 0.5378\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.4933\n",
      "Epoch [129/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1732, D_X Fake: 0.1035, D_X Total: 0.1384\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0295, D_Y Total: 0.0257\n",
      "Generator Losses:\n",
      "  G Adv: 0.7155, F Adv: 0.6660\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1428, Perceptual Monet: 0.1847\n",
      "  Total G Loss: 3.7391\n",
      "Epoch [129/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1097, D_X Fake: 0.1050, D_X Total: 0.1073\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0496, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.8030, F Adv: 0.5090\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.3018\n",
      "Epoch [129/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1225, D_X Fake: 0.1019, D_X Total: 0.1122\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0436, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 1.0901, F Adv: 0.6320\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1357, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.9364\n",
      "Epoch [129/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2163, D_X Fake: 0.1401, D_X Total: 0.1782\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0269, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.8617, F Adv: 0.4433\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.4851\n",
      "Epoch [129/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2190, D_X Fake: 0.1020, D_X Total: 0.1605\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0508, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.8911, F Adv: 0.5814\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1795\n",
      "  Total G Loss: 3.6424\n",
      "Epoch [129/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0873, D_X Fake: 0.1293, D_X Total: 0.1083\n",
      "  D_Y Real: 0.0705, D_Y Fake: 0.0272, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 1.0061, F Adv: 0.4846\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1884\n",
      "  Total G Loss: 3.8040\n",
      "Epoch [129/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1435, D_X Fake: 0.0651, D_X Total: 0.1043\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0438, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 0.8336, F Adv: 0.7358\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0396\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 3.9575\n",
      "Epoch [129/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1705, D_X Fake: 0.0804, D_X Total: 0.1254\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0411, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.8744, F Adv: 0.5723\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1937, Perceptual Monet: 0.1504\n",
      "  Total G Loss: 3.7862\n",
      "Epoch [130/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1731, D_X Fake: 0.0775, D_X Total: 0.1253\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0540, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.5820, F Adv: 0.7687\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1619, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.5751\n",
      "Epoch [130/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0666, D_X Fake: 0.1237, D_X Total: 0.0952\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0490, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 1.0790, F Adv: 0.5354\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1408, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.7701\n",
      "Epoch [130/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1846, D_X Fake: 0.1118, D_X Total: 0.1482\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0772, D_Y Total: 0.0542\n",
      "Generator Losses:\n",
      "  G Adv: 0.8566, F Adv: 0.5450\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1308, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 3.5051\n",
      "Epoch [130/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0948, D_X Fake: 0.1222, D_X Total: 0.1085\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0295, D_Y Total: 0.0235\n",
      "Generator Losses:\n",
      "  G Adv: 0.8724, F Adv: 0.5721\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1527\n",
      "  Total G Loss: 3.5167\n",
      "Epoch [130/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1830, D_X Fake: 0.0519, D_X Total: 0.1174\n",
      "  D_Y Real: 0.0359, D_Y Fake: 0.0481, D_Y Total: 0.0420\n",
      "Generator Losses:\n",
      "  G Adv: 1.1295, F Adv: 0.7405\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1836, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 4.1729\n",
      "Epoch [130/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1960, D_X Fake: 0.0962, D_X Total: 0.1461\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0546, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.7705, F Adv: 0.6654\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1097, Perceptual Monet: 0.1686\n",
      "  Total G Loss: 3.2806\n",
      "Epoch [130/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1816, D_X Fake: 0.0698, D_X Total: 0.1257\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0750, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.9996, F Adv: 0.5471\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1561, Perceptual Monet: 0.1523\n",
      "  Total G Loss: 3.6373\n",
      "Epoch [130/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1010, D_X Fake: 0.0858, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0300, D_Y Fake: 0.0565, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.9218, F Adv: 0.6817\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1366, Perceptual Monet: 0.1420\n",
      "  Total G Loss: 3.5328\n",
      "Epoch [130/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3030, D_X Fake: 0.1022, D_X Total: 0.2026\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0263, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.9927, F Adv: 0.5723\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1616, Perceptual Monet: 0.1949\n",
      "  Total G Loss: 4.0142\n",
      "Epoch [130/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1709, D_X Fake: 0.2335, D_X Total: 0.2022\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0392, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9730, F Adv: 0.4372\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0205\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1239\n",
      "  Total G Loss: 3.3810\n",
      "Epoch [130/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0634, D_X Fake: 0.1222, D_X Total: 0.0928\n",
      "  D_Y Real: 0.0625, D_Y Fake: 0.0528, D_Y Total: 0.0576\n",
      "Generator Losses:\n",
      "  G Adv: 0.9616, F Adv: 0.4955\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0429\n",
      "  Perceptual Photo: 0.1211, Perceptual Monet: 0.2095\n",
      "  Total G Loss: 3.8080\n",
      "Epoch [130/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3081, D_X Fake: 0.1287, D_X Total: 0.2184\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0440, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.9090, F Adv: 0.5369\n",
      "  Cycle Photo: 0.0465, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1855, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.8184\n",
      "Epoch [130/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0866, D_X Fake: 0.1637, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0869, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 1.0167, F Adv: 0.5329\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.8445\n",
      "Epoch [130/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1472, D_X Fake: 0.1249, D_X Total: 0.1360\n",
      "  D_Y Real: 0.0466, D_Y Fake: 0.0395, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.8800, F Adv: 0.4924\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1166, Perceptual Monet: 0.1929\n",
      "  Total G Loss: 3.6187\n",
      "Epoch [130/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1471, D_X Fake: 0.0968, D_X Total: 0.1219\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0359, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.9340, F Adv: 0.5006\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.4796\n",
      "Epoch [130/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2188, D_X Fake: 0.1069, D_X Total: 0.1629\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0566, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.6793, F Adv: 0.5963\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.5787\n",
      "Epoch [130/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0859, D_X Fake: 0.0520, D_X Total: 0.0690\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0616, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.8407, F Adv: 0.8127\n",
      "  Cycle Photo: 0.0202, Cycle Monet: 0.0218\n",
      "  Perceptual Photo: 0.0975, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.2860\n",
      "Epoch [130/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1807, D_X Fake: 0.0909, D_X Total: 0.1358\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0559, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.8520, F Adv: 0.7699\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1799\n",
      "  Total G Loss: 3.8692\n",
      "Epoch [130/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0332, D_X Fake: 0.0703, D_X Total: 0.0518\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0930, D_Y Total: 0.0614\n",
      "Generator Losses:\n",
      "  G Adv: 0.6857, F Adv: 0.6458\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1113, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.1872\n",
      "Epoch [130/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0887, D_X Fake: 0.0899, D_X Total: 0.0893\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.0896, D_Y Total: 0.0612\n",
      "Generator Losses:\n",
      "  G Adv: 0.7679, F Adv: 0.7647\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1598, Perceptual Monet: 0.1931\n",
      "  Total G Loss: 3.9832\n",
      "Epoch [130/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2559, D_X Fake: 0.1144, D_X Total: 0.1852\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0477, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8968, F Adv: 0.5399\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1573, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.7184\n",
      "Epoch [130/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0676, D_X Fake: 0.0702, D_X Total: 0.0689\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0826, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.7589, F Adv: 0.5806\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 3.4937\n",
      "Epoch [130/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1684, D_X Fake: 0.0927, D_X Total: 0.1306\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0353, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 1.0177, F Adv: 0.5995\n",
      "  Cycle Photo: 0.0198, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.0979, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.4119\n",
      "Epoch [130/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1172, D_X Fake: 0.1074, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0446, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.8798, F Adv: 0.4592\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1898, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.9599\n",
      "Epoch [131/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2032, D_X Fake: 0.0908, D_X Total: 0.1470\n",
      "  D_Y Real: 0.0218, D_Y Fake: 0.0431, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8664, F Adv: 0.6078\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1145, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.4267\n",
      "Epoch [131/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3160, D_X Fake: 0.0857, D_X Total: 0.2008\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.0487, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 1.0651, F Adv: 0.5846\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1344, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.7125\n",
      "Epoch [131/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1521, D_X Fake: 0.0772, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0411, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.8592, F Adv: 0.7162\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1517\n",
      "  Total G Loss: 3.6631\n",
      "Epoch [131/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1063, D_X Fake: 0.1098, D_X Total: 0.1081\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0569, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.9969, F Adv: 0.5244\n",
      "  Cycle Photo: 0.0376, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.1468\n",
      "  Total G Loss: 3.7004\n",
      "Epoch [131/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0653, D_X Fake: 0.0975, D_X Total: 0.0814\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.0496, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8987, F Adv: 0.4570\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1113, Perceptual Monet: 0.1981\n",
      "  Total G Loss: 3.5253\n",
      "Epoch [131/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.0852, D_X Total: 0.0792\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0403, D_Y Total: 0.0305\n",
      "Generator Losses:\n",
      "  G Adv: 0.9474, F Adv: 0.5057\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0188\n",
      "  Perceptual Photo: 0.1262, Perceptual Monet: 0.1240\n",
      "  Total G Loss: 3.1658\n",
      "Epoch [131/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.1009, D_X Total: 0.1069\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0729, D_Y Total: 0.0499\n",
      "Generator Losses:\n",
      "  G Adv: 0.8310, F Adv: 0.6257\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1449, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.6620\n",
      "Epoch [131/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1216, D_X Fake: 0.0601, D_X Total: 0.0909\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.0411, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.8300, F Adv: 0.6829\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1277, Perceptual Monet: 0.1916\n",
      "  Total G Loss: 3.6829\n",
      "Epoch [131/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0725, D_X Fake: 0.0795, D_X Total: 0.0760\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0551, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.8584, F Adv: 0.5734\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.3611\n",
      "Epoch [131/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0845, D_X Fake: 0.0962, D_X Total: 0.0904\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0313, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 1.0473, F Adv: 0.6286\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1829\n",
      "  Total G Loss: 3.8843\n",
      "Epoch [131/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1113, D_X Fake: 0.0970, D_X Total: 0.1042\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0459, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.7168, F Adv: 0.7296\n",
      "  Cycle Photo: 0.0204, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1085, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 3.3375\n",
      "Epoch [131/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1408, D_X Fake: 0.0847, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.0316, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.9228, F Adv: 0.7259\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1560\n",
      "  Total G Loss: 3.8059\n",
      "Epoch [131/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1702, D_X Fake: 0.0798, D_X Total: 0.1250\n",
      "  D_Y Real: 0.0528, D_Y Fake: 0.0624, D_Y Total: 0.0576\n",
      "Generator Losses:\n",
      "  G Adv: 0.7006, F Adv: 0.6219\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1569, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.5745\n",
      "Epoch [131/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1169, D_X Fake: 0.0903, D_X Total: 0.1036\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0576, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.7037, F Adv: 0.7953\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1685, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.6864\n",
      "Epoch [131/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0401, D_X Fake: 0.0674, D_X Total: 0.0537\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.0786, D_Y Total: 0.0581\n",
      "Generator Losses:\n",
      "  G Adv: 0.7593, F Adv: 0.8182\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1910\n",
      "  Total G Loss: 3.8878\n",
      "Epoch [131/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0907, D_X Fake: 0.1301, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0669, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.7543, F Adv: 0.5330\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.2862\n",
      "Epoch [131/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1359, D_X Fake: 0.1126, D_X Total: 0.1242\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.1690, D_Y Total: 0.0923\n",
      "Generator Losses:\n",
      "  G Adv: 0.7637, F Adv: 0.5861\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1194, Perceptual Monet: 0.1647\n",
      "  Total G Loss: 3.2766\n",
      "Epoch [131/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2083, D_X Fake: 0.0889, D_X Total: 0.1486\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0520, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 0.8974, F Adv: 0.6435\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1870\n",
      "  Total G Loss: 3.8942\n",
      "Epoch [131/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1340, D_X Fake: 0.1564, D_X Total: 0.1452\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0478, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.8845, F Adv: 0.5851\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.7126\n",
      "Epoch [131/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0706, D_X Fake: 0.0579, D_X Total: 0.0642\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0308, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.9845, F Adv: 0.5388\n",
      "  Cycle Photo: 0.0720, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1788, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 4.2407\n",
      "Epoch [131/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0761, D_X Fake: 0.1490, D_X Total: 0.1126\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0405, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.8699, F Adv: 0.5322\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1443\n",
      "  Total G Loss: 3.5159\n",
      "Epoch [131/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1790, D_X Fake: 0.0716, D_X Total: 0.1253\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0399, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.8613, F Adv: 0.7167\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1466, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 3.8308\n",
      "Epoch [131/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1306, D_X Fake: 0.0830, D_X Total: 0.1068\n",
      "  D_Y Real: 0.0475, D_Y Fake: 0.0339, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 1.0734, F Adv: 0.6033\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0189\n",
      "  Perceptual Photo: 0.1513, Perceptual Monet: 0.1282\n",
      "  Total G Loss: 3.5497\n",
      "Epoch [131/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2366, D_X Fake: 0.1171, D_X Total: 0.1768\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0676, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.7577, F Adv: 0.7390\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.9264\n",
      "Epoch [132/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1045, D_X Fake: 0.1813, D_X Total: 0.1429\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.1244, D_Y Total: 0.0751\n",
      "Generator Losses:\n",
      "  G Adv: 0.7419, F Adv: 0.4693\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 3.1083\n",
      "Epoch [132/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1188, D_X Fake: 0.0911, D_X Total: 0.1050\n",
      "  D_Y Real: 0.0272, D_Y Fake: 0.0488, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.7558, F Adv: 0.5469\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 3.4515\n",
      "Epoch [132/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1589, D_X Fake: 0.0700, D_X Total: 0.1145\n",
      "  D_Y Real: 0.0561, D_Y Fake: 0.0570, D_Y Total: 0.0565\n",
      "Generator Losses:\n",
      "  G Adv: 0.9646, F Adv: 0.7621\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.8593\n",
      "Epoch [132/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3170, D_X Fake: 0.0561, D_X Total: 0.1866\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0437, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.9397, F Adv: 0.7179\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.7900\n",
      "Epoch [132/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0840, D_X Fake: 0.1081, D_X Total: 0.0960\n",
      "  D_Y Real: 0.0133, D_Y Fake: 0.0891, D_Y Total: 0.0512\n",
      "Generator Losses:\n",
      "  G Adv: 0.6639, F Adv: 0.5816\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1537\n",
      "  Total G Loss: 3.1747\n",
      "Epoch [132/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1769, D_X Fake: 0.0836, D_X Total: 0.1302\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0369, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.9921, F Adv: 0.5876\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1621, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.8497\n",
      "Epoch [132/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0654, D_X Fake: 0.1040, D_X Total: 0.0847\n",
      "  D_Y Real: 0.0463, D_Y Fake: 0.0379, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.7799, F Adv: 0.5791\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1221, Perceptual Monet: 0.1902\n",
      "  Total G Loss: 3.5531\n",
      "Epoch [132/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0471, D_X Fake: 0.1198, D_X Total: 0.0834\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0612, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.8058, F Adv: 0.5139\n",
      "  Cycle Photo: 0.0218, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.0988, Perceptual Monet: 0.1497\n",
      "  Total G Loss: 3.0259\n",
      "Epoch [132/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1534, D_X Fake: 0.1035, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0343, D_Y Fake: 0.0585, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.8365, F Adv: 0.5544\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1810, Perceptual Monet: 0.2070\n",
      "  Total G Loss: 4.0605\n",
      "Epoch [132/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3187, D_X Fake: 0.0741, D_X Total: 0.1964\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0403, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 1.0672, F Adv: 0.7202\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1559, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 4.0462\n",
      "Epoch [132/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1339, D_X Fake: 0.0960, D_X Total: 0.1149\n",
      "  D_Y Real: 0.0573, D_Y Fake: 0.0379, D_Y Total: 0.0476\n",
      "Generator Losses:\n",
      "  G Adv: 0.8808, F Adv: 0.5653\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1833\n",
      "  Total G Loss: 3.6952\n",
      "Epoch [132/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0672, D_X Fake: 0.1032, D_X Total: 0.0852\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0372, D_Y Total: 0.0346\n",
      "Generator Losses:\n",
      "  G Adv: 0.9307, F Adv: 0.4997\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1377, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.4041\n",
      "Epoch [132/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1450, D_X Fake: 0.0786, D_X Total: 0.1118\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0698, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.9127, F Adv: 0.6233\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1040, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 3.2897\n",
      "Epoch [132/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0446, D_X Fake: 0.0962, D_X Total: 0.0704\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0454, D_Y Total: 0.0301\n",
      "Generator Losses:\n",
      "  G Adv: 0.9216, F Adv: 0.4791\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.4919\n",
      "Epoch [132/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1948, D_X Fake: 0.0682, D_X Total: 0.1315\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0789, D_Y Total: 0.0502\n",
      "Generator Losses:\n",
      "  G Adv: 1.0391, F Adv: 0.6032\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1569\n",
      "  Total G Loss: 3.5582\n",
      "Epoch [132/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2244, D_X Fake: 0.0631, D_X Total: 0.1438\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0413, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8439, F Adv: 0.7081\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.5780\n",
      "Epoch [132/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1235, D_X Fake: 0.0789, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0576, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.7054, F Adv: 0.7170\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1860\n",
      "  Total G Loss: 3.7003\n",
      "Epoch [132/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1936, D_X Fake: 0.1080, D_X Total: 0.1508\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0383, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.8739, F Adv: 0.6088\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.5175\n",
      "Epoch [132/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1379, D_X Fake: 0.0937, D_X Total: 0.1158\n",
      "  D_Y Real: 0.0509, D_Y Fake: 0.0350, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.9188, F Adv: 0.6623\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1817\n",
      "  Total G Loss: 3.8764\n",
      "Epoch [132/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2009, D_X Fake: 0.0573, D_X Total: 0.1291\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0712, D_Y Total: 0.0500\n",
      "Generator Losses:\n",
      "  G Adv: 0.6752, F Adv: 0.6693\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 3.6391\n",
      "Epoch [132/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.1056, D_X Total: 0.0984\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0592, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.8700, F Adv: 0.6290\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1277, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5760\n",
      "Epoch [132/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0497, D_X Fake: 0.2117, D_X Total: 0.1307\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0383, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.9554, F Adv: 0.3930\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1324, Perceptual Monet: 0.1551\n",
      "  Total G Loss: 3.3250\n",
      "Epoch [132/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0622, D_X Fake: 0.0791, D_X Total: 0.0707\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0656, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.7627, F Adv: 0.6758\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1260, Perceptual Monet: 0.1711\n",
      "  Total G Loss: 3.5261\n",
      "Epoch [132/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.0795, D_X Total: 0.1132\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0365, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.9288, F Adv: 0.6529\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1575, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.8907\n",
      "Epoch [133/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1704, D_X Fake: 0.1252, D_X Total: 0.1478\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0441, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.9632, F Adv: 0.7479\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0443\n",
      "  Perceptual Photo: 0.1898, Perceptual Monet: 0.2145\n",
      "  Total G Loss: 4.5423\n",
      "Epoch [133/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2726, D_X Fake: 0.0386, D_X Total: 0.1556\n",
      "  D_Y Real: 0.0334, D_Y Fake: 0.0496, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.8366, F Adv: 0.7128\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1650, Perceptual Monet: 0.1831\n",
      "  Total G Loss: 3.9479\n",
      "Epoch [133/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2040, D_X Fake: 0.0926, D_X Total: 0.1483\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0490, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 1.0014, F Adv: 0.6347\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1880\n",
      "  Total G Loss: 3.9448\n",
      "Epoch [133/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1560, D_X Fake: 0.1415, D_X Total: 0.1488\n",
      "  D_Y Real: 0.0355, D_Y Fake: 0.0490, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.8626, F Adv: 0.4645\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1421, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.4971\n",
      "Epoch [133/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2194, D_X Fake: 0.0456, D_X Total: 0.1325\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0313, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9650, F Adv: 0.8323\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 3.7854\n",
      "Epoch [133/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1647, D_X Fake: 0.1270, D_X Total: 0.1459\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0303, D_Y Total: 0.0252\n",
      "Generator Losses:\n",
      "  G Adv: 1.0107, F Adv: 0.4397\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.6821\n",
      "Epoch [133/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1591, D_X Fake: 0.0716, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0435, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.8333, F Adv: 0.7250\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1993\n",
      "  Total G Loss: 3.7839\n",
      "Epoch [133/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0424, D_X Fake: 0.1275, D_X Total: 0.0849\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0391, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.9317, F Adv: 0.4495\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1051, Perceptual Monet: 0.1441\n",
      "  Total G Loss: 3.1067\n",
      "Epoch [133/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0945, D_X Fake: 0.1352, D_X Total: 0.1148\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0489, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.9133, F Adv: 0.4544\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.4347\n",
      "Epoch [133/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2304, D_X Fake: 0.1251, D_X Total: 0.1778\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0340, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8972, F Adv: 0.5258\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1625, Perceptual Monet: 0.1366\n",
      "  Total G Loss: 3.4747\n",
      "Epoch [133/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1745, D_X Fake: 0.1390, D_X Total: 0.1567\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0454, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.8234, F Adv: 0.4840\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1520\n",
      "  Total G Loss: 3.2845\n",
      "Epoch [133/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3096, D_X Fake: 0.0708, D_X Total: 0.1902\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.1193, D_Y Total: 0.0696\n",
      "Generator Losses:\n",
      "  G Adv: 0.7237, F Adv: 0.6840\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1460, Perceptual Monet: 0.1839\n",
      "  Total G Loss: 3.7410\n",
      "Epoch [133/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0712, D_X Fake: 0.1484, D_X Total: 0.1098\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0674, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.7203, F Adv: 0.4472\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1490, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.2567\n",
      "Epoch [133/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0482, D_X Fake: 0.0910, D_X Total: 0.0696\n",
      "  D_Y Real: 0.0474, D_Y Fake: 0.0597, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.7509, F Adv: 0.5564\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1038, Perceptual Monet: 0.1336\n",
      "  Total G Loss: 2.9927\n",
      "Epoch [133/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3090, D_X Fake: 0.0654, D_X Total: 0.1872\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.1059, D_Y Total: 0.0610\n",
      "Generator Losses:\n",
      "  G Adv: 0.6583, F Adv: 0.7291\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1443, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 3.4309\n",
      "Epoch [133/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0662, D_X Fake: 0.0471, D_X Total: 0.0566\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0596, D_Y Total: 0.0478\n",
      "Generator Losses:\n",
      "  G Adv: 0.8853, F Adv: 0.5516\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.6981\n",
      "Epoch [133/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1690, D_X Fake: 0.2053, D_X Total: 0.1872\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0509, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.6892, F Adv: 0.3571\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0217\n",
      "  Perceptual Photo: 0.1027, Perceptual Monet: 0.1425\n",
      "  Total G Loss: 2.7272\n",
      "Epoch [133/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2158, D_X Fake: 0.1056, D_X Total: 0.1607\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0303, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.9713, F Adv: 0.5296\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.2063, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.9499\n",
      "Epoch [133/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1708, D_X Fake: 0.0779, D_X Total: 0.1243\n",
      "  D_Y Real: 0.0417, D_Y Fake: 0.0521, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 0.9662, F Adv: 0.4423\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1302, Perceptual Monet: 0.1945\n",
      "  Total G Loss: 3.6097\n",
      "Epoch [133/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0777, D_X Fake: 0.1324, D_X Total: 0.1051\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0477, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 0.9538, F Adv: 0.4778\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1487, Perceptual Monet: 0.1958\n",
      "  Total G Loss: 3.8276\n",
      "Epoch [133/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0852, D_X Fake: 0.0837, D_X Total: 0.0844\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0522, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.8958, F Adv: 0.5714\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1419, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.6311\n",
      "Epoch [133/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1422, D_X Fake: 0.0719, D_X Total: 0.1071\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0446, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.9944, F Adv: 0.6856\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1343, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 3.6214\n",
      "Epoch [133/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0544, D_X Fake: 0.0876, D_X Total: 0.0710\n",
      "  D_Y Real: 0.0430, D_Y Fake: 0.0475, D_Y Total: 0.0452\n",
      "Generator Losses:\n",
      "  G Adv: 0.8856, F Adv: 0.6335\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1136, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 3.6308\n",
      "Epoch [133/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1110, D_X Fake: 0.1066, D_X Total: 0.1088\n",
      "  D_Y Real: 0.0471, D_Y Fake: 0.0350, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 0.8984, F Adv: 0.6491\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1520, Perceptual Monet: 0.1912\n",
      "  Total G Loss: 3.9349\n",
      "Epoch [134/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1639, D_X Fake: 0.0607, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0311, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9539, F Adv: 0.6753\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1334, Perceptual Monet: 0.1830\n",
      "  Total G Loss: 3.7318\n",
      "Epoch [134/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1609, D_X Fake: 0.1242, D_X Total: 0.1425\n",
      "  D_Y Real: 0.0370, D_Y Fake: 0.0317, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.9281, F Adv: 0.5012\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.4526\n",
      "Epoch [134/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0790, D_X Fake: 0.0992, D_X Total: 0.0891\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0436, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8551, F Adv: 0.4910\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1387\n",
      "  Total G Loss: 3.2047\n",
      "Epoch [134/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2498, D_X Fake: 0.0940, D_X Total: 0.1719\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0270, D_Y Total: 0.0229\n",
      "Generator Losses:\n",
      "  G Adv: 0.8989, F Adv: 0.6113\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.6195\n",
      "Epoch [134/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1955, D_X Fake: 0.0549, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0499, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.8797, F Adv: 0.6095\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1274, Perceptual Monet: 0.1776\n",
      "  Total G Loss: 3.5961\n",
      "Epoch [134/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0802, D_X Fake: 0.1141, D_X Total: 0.0972\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0596, D_Y Total: 0.0461\n",
      "Generator Losses:\n",
      "  G Adv: 0.8607, F Adv: 0.5382\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1648\n",
      "  Total G Loss: 3.3435\n",
      "Epoch [134/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1480, D_X Fake: 0.1177, D_X Total: 0.1329\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0539, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 1.0260, F Adv: 0.5507\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1384\n",
      "  Total G Loss: 3.5645\n",
      "Epoch [134/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1915, D_X Fake: 0.0708, D_X Total: 0.1312\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0498, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.7745, F Adv: 0.6901\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1527, Perceptual Monet: 0.1693\n",
      "  Total G Loss: 3.6870\n",
      "Epoch [134/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2719, D_X Fake: 0.0814, D_X Total: 0.1766\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0527, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.8873, F Adv: 0.5312\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1293, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 3.3511\n",
      "Epoch [134/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0706, D_X Fake: 0.0723, D_X Total: 0.0714\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0275, D_Y Total: 0.0248\n",
      "Generator Losses:\n",
      "  G Adv: 1.0688, F Adv: 0.6047\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1929\n",
      "  Total G Loss: 3.9981\n",
      "Epoch [134/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0461, D_X Fake: 0.1019, D_X Total: 0.0740\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0491, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8776, F Adv: 0.5070\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1218, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 3.4014\n",
      "Epoch [134/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0832, D_X Fake: 0.1207, D_X Total: 0.1020\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0475, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.9896, F Adv: 0.6385\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.2051\n",
      "  Total G Loss: 3.9535\n",
      "Epoch [134/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1589, D_X Fake: 0.0741, D_X Total: 0.1165\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0823, D_Y Total: 0.0544\n",
      "Generator Losses:\n",
      "  G Adv: 0.7459, F Adv: 0.6633\n",
      "  Cycle Photo: 0.0391, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.7577\n",
      "Epoch [134/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0829, D_X Fake: 0.1768, D_X Total: 0.1298\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0397, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.8994, F Adv: 0.4412\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1257, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 3.2682\n",
      "Epoch [134/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0709, D_X Fake: 0.0776, D_X Total: 0.0743\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0501, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.8114, F Adv: 0.5632\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.5558\n",
      "Epoch [134/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1172, D_X Fake: 0.0693, D_X Total: 0.0933\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0371, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.8267, F Adv: 0.6182\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.4912\n",
      "Epoch [134/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1322, D_X Fake: 0.1017, D_X Total: 0.1170\n",
      "  D_Y Real: 0.0164, D_Y Fake: 0.0311, D_Y Total: 0.0238\n",
      "Generator Losses:\n",
      "  G Adv: 1.0408, F Adv: 0.6290\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 3.6476\n",
      "Epoch [134/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1519, D_X Fake: 0.1366, D_X Total: 0.1443\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.0465, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 0.8272, F Adv: 0.4831\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 3.3065\n",
      "Epoch [134/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1322, D_X Fake: 0.0502, D_X Total: 0.0912\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0599, D_Y Total: 0.0461\n",
      "Generator Losses:\n",
      "  G Adv: 0.7377, F Adv: 0.7939\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1283, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 3.7167\n",
      "Epoch [134/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0838, D_X Fake: 0.0905, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0820, D_Y Total: 0.0564\n",
      "Generator Losses:\n",
      "  G Adv: 0.6104, F Adv: 0.5169\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1666\n",
      "  Total G Loss: 3.2809\n",
      "Epoch [134/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0680, D_X Fake: 0.1425, D_X Total: 0.1052\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0508, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.7531, F Adv: 0.4510\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.0992, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.1727\n",
      "Epoch [134/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1113, D_X Fake: 0.0874, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0480, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 1.1187, F Adv: 0.5789\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1184, Perceptual Monet: 0.1496\n",
      "  Total G Loss: 3.5139\n",
      "Epoch [134/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0790, D_X Fake: 0.1274, D_X Total: 0.1032\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0468, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.8953, F Adv: 0.5094\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1408, Perceptual Monet: 0.1984\n",
      "  Total G Loss: 3.7574\n",
      "Epoch [134/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0399, D_X Fake: 0.1674, D_X Total: 0.1037\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0546, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.9384, F Adv: 0.5264\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.4789\n",
      "Epoch [135/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1072, D_X Fake: 0.1698, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0919, D_Y Total: 0.0558\n",
      "Generator Losses:\n",
      "  G Adv: 0.6715, F Adv: 0.4851\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1118, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.0451\n",
      "Epoch [135/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1480, D_X Fake: 0.1012, D_X Total: 0.1246\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0423, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.9981, F Adv: 0.6030\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.2019\n",
      "  Total G Loss: 4.0717\n",
      "Epoch [135/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0465, D_X Fake: 0.1503, D_X Total: 0.0984\n",
      "  D_Y Real: 0.0375, D_Y Fake: 0.0359, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 1.0145, F Adv: 0.4966\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1373, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.6839\n",
      "Epoch [135/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1885, D_X Fake: 0.1236, D_X Total: 0.1560\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0400, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.8499, F Adv: 0.6311\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1160, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.3501\n",
      "Epoch [135/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.1159, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0360, D_Y Fake: 0.0363, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8727, F Adv: 0.5592\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1193, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 3.3520\n",
      "Epoch [135/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0985, D_X Fake: 0.0794, D_X Total: 0.0889\n",
      "  D_Y Real: 0.0430, D_Y Fake: 0.0547, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 1.0216, F Adv: 0.6274\n",
      "  Cycle Photo: 0.0412, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 4.0257\n",
      "Epoch [135/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2223, D_X Fake: 0.1242, D_X Total: 0.1733\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0433, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.9458, F Adv: 0.4809\n",
      "  Cycle Photo: 0.0365, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1914, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.9382\n",
      "Epoch [135/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0591, D_X Fake: 0.0752, D_X Total: 0.0672\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0364, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9606, F Adv: 0.6645\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1747, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 4.0939\n",
      "Epoch [135/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1756, D_X Fake: 0.1452, D_X Total: 0.1604\n",
      "  D_Y Real: 0.0146, D_Y Fake: 0.0607, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.9026, F Adv: 0.5013\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1228, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.2499\n",
      "Epoch [135/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1378, D_X Fake: 0.0994, D_X Total: 0.1186\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.0642, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.8580, F Adv: 0.6391\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1023, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 3.4635\n",
      "Epoch [135/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0880, D_X Fake: 0.1342, D_X Total: 0.1111\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0645, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.9167, F Adv: 0.5137\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1514, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.6757\n",
      "Epoch [135/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2131, D_X Fake: 0.0672, D_X Total: 0.1401\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0551, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 0.8545, F Adv: 0.6818\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1868\n",
      "  Total G Loss: 3.6612\n",
      "Epoch [135/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1918, D_X Fake: 0.0638, D_X Total: 0.1278\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0423, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8592, F Adv: 0.7472\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1258, Perceptual Monet: 0.2099\n",
      "  Total G Loss: 3.9001\n",
      "Epoch [135/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1749, D_X Fake: 0.1340, D_X Total: 0.1545\n",
      "  D_Y Real: 0.0348, D_Y Fake: 0.0433, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.9360, F Adv: 0.4823\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1584, Perceptual Monet: 0.1453\n",
      "  Total G Loss: 3.5402\n",
      "Epoch [135/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0673, D_X Fake: 0.1054, D_X Total: 0.0863\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0400, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 1.1119, F Adv: 0.7238\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1119, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.7389\n",
      "Epoch [135/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0933, D_X Fake: 0.0776, D_X Total: 0.0854\n",
      "  D_Y Real: 0.0421, D_Y Fake: 0.0394, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.9545, F Adv: 0.6640\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.1969\n",
      "  Total G Loss: 3.8195\n",
      "Epoch [135/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0883, D_X Fake: 0.1076, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0262, D_Y Fake: 0.0553, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.7859, F Adv: 0.6891\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0213\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1336\n",
      "  Total G Loss: 3.3778\n",
      "Epoch [135/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1391, D_X Fake: 0.1164, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.1062, D_Y Total: 0.0630\n",
      "Generator Losses:\n",
      "  G Adv: 0.8352, F Adv: 0.5678\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1806\n",
      "  Total G Loss: 3.7134\n",
      "Epoch [135/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0390, D_X Fake: 0.1215, D_X Total: 0.0802\n",
      "  D_Y Real: 0.0314, D_Y Fake: 0.0518, D_Y Total: 0.0416\n",
      "Generator Losses:\n",
      "  G Adv: 0.8030, F Adv: 0.5943\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.5850\n",
      "Epoch [135/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1181, D_X Fake: 0.1200, D_X Total: 0.1190\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0540, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.8337, F Adv: 0.5339\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.5962\n",
      "Epoch [135/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0621, D_X Fake: 0.0648, D_X Total: 0.0634\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0429, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.9003, F Adv: 0.7086\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1215, Perceptual Monet: 0.2052\n",
      "  Total G Loss: 3.8766\n",
      "Epoch [135/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1741, D_X Fake: 0.1392, D_X Total: 0.1566\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0497, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.8850, F Adv: 0.4811\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1217, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.4074\n",
      "Epoch [135/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1950, D_X Fake: 0.0872, D_X Total: 0.1411\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0503, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.7744, F Adv: 0.6310\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1567, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 3.7215\n",
      "Epoch [135/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1109, D_X Fake: 0.0938, D_X Total: 0.1023\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0966, D_Y Total: 0.0580\n",
      "Generator Losses:\n",
      "  G Adv: 0.7445, F Adv: 0.5666\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1373, Perceptual Monet: 0.1688\n",
      "  Total G Loss: 3.4736\n",
      "Epoch [136/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0922, D_X Fake: 0.0827, D_X Total: 0.0875\n",
      "  D_Y Real: 0.0462, D_Y Fake: 0.0532, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.9065, F Adv: 0.6285\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0186\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1306\n",
      "  Total G Loss: 3.2993\n",
      "Epoch [136/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1695, D_X Fake: 0.0870, D_X Total: 0.1282\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0475, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.7959, F Adv: 0.4773\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1541, Perceptual Monet: 0.1479\n",
      "  Total G Loss: 3.3300\n",
      "Epoch [136/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1624, D_X Fake: 0.0936, D_X Total: 0.1280\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0341, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 1.0594, F Adv: 0.6536\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.7252\n",
      "Epoch [136/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1666, D_X Fake: 0.0836, D_X Total: 0.1251\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0472, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.9235, F Adv: 0.5319\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1641, Perceptual Monet: 0.1350\n",
      "  Total G Loss: 3.5043\n",
      "Epoch [136/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1621, D_X Fake: 0.0490, D_X Total: 0.1056\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0318, D_Y Total: 0.0236\n",
      "Generator Losses:\n",
      "  G Adv: 0.9533, F Adv: 0.6106\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.1422\n",
      "  Total G Loss: 3.3707\n",
      "Epoch [136/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1137, D_X Fake: 0.0909, D_X Total: 0.1023\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0395, D_Y Total: 0.0292\n",
      "Generator Losses:\n",
      "  G Adv: 0.8511, F Adv: 0.5585\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1284, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.4631\n",
      "Epoch [136/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1821, D_X Fake: 0.1127, D_X Total: 0.1474\n",
      "  D_Y Real: 0.0520, D_Y Fake: 0.0410, D_Y Total: 0.0465\n",
      "Generator Losses:\n",
      "  G Adv: 0.9068, F Adv: 0.6105\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1322, Perceptual Monet: 0.1963\n",
      "  Total G Loss: 3.7906\n",
      "Epoch [136/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0928, D_X Fake: 0.1704, D_X Total: 0.1316\n",
      "  D_Y Real: 0.0362, D_Y Fake: 0.0430, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.7757, F Adv: 0.4628\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1458, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.4184\n",
      "Epoch [136/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0676, D_X Fake: 0.1869, D_X Total: 0.1272\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0613, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.8003, F Adv: 0.4630\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1578\n",
      "  Total G Loss: 3.2789\n",
      "Epoch [136/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1146, D_X Fake: 0.1217, D_X Total: 0.1182\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0434, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.9089, F Adv: 0.5358\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1606, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.7968\n",
      "Epoch [136/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1683, D_X Fake: 0.0596, D_X Total: 0.1139\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0716, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.6874, F Adv: 0.7220\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1780\n",
      "  Total G Loss: 3.5370\n",
      "Epoch [136/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2517, D_X Fake: 0.0936, D_X Total: 0.1727\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0532, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.7717, F Adv: 0.6070\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.5405\n",
      "Epoch [136/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2474, D_X Fake: 0.0554, D_X Total: 0.1514\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0562, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.6824, F Adv: 0.5663\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.5558\n",
      "Epoch [136/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1131, D_X Fake: 0.1202, D_X Total: 0.1166\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0346, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.8996, F Adv: 0.4731\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1649, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.5561\n",
      "Epoch [136/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1349, D_X Fake: 0.1051, D_X Total: 0.1200\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.0565, D_Y Total: 0.0489\n",
      "Generator Losses:\n",
      "  G Adv: 0.8425, F Adv: 0.5563\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.4151\n",
      "Epoch [136/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0609, D_X Fake: 0.0758, D_X Total: 0.0684\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0708, D_Y Total: 0.0553\n",
      "Generator Losses:\n",
      "  G Adv: 1.0967, F Adv: 0.6238\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1249, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.7648\n",
      "Epoch [136/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0826, D_X Fake: 0.1080, D_X Total: 0.0953\n",
      "  D_Y Real: 0.0330, D_Y Fake: 0.0643, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.8353, F Adv: 0.5551\n",
      "  Cycle Photo: 0.0227, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1236, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.1841\n",
      "Epoch [136/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1269, D_X Fake: 0.0969, D_X Total: 0.1119\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0507, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.9137, F Adv: 0.5874\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.6632\n",
      "Epoch [136/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1731, D_X Fake: 0.1073, D_X Total: 0.1402\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0583, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 1.0257, F Adv: 0.4951\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.5568\n",
      "Epoch [136/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1177, D_X Fake: 0.1289, D_X Total: 0.1233\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0351, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.8766, F Adv: 0.5261\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1188, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.3746\n",
      "Epoch [136/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1542, D_X Fake: 0.0878, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0490, D_Y Fake: 0.0471, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.9978, F Adv: 0.5321\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1416, Perceptual Monet: 0.2107\n",
      "  Total G Loss: 4.0331\n",
      "Epoch [136/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1261, D_X Fake: 0.1516, D_X Total: 0.1389\n",
      "  D_Y Real: 0.0289, D_Y Fake: 0.0384, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 1.0424, F Adv: 0.6561\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1558, Perceptual Monet: 0.1764\n",
      "  Total G Loss: 3.9837\n",
      "Epoch [136/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2039, D_X Fake: 0.0639, D_X Total: 0.1339\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0369, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.9723, F Adv: 0.7580\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1288, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.7917\n",
      "Epoch [136/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1050, D_X Fake: 0.1602, D_X Total: 0.1326\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0516, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.8798, F Adv: 0.5134\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1276, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.3218\n",
      "Epoch [137/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0748, D_X Fake: 0.1207, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0454, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 1.2345, F Adv: 0.5451\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1892\n",
      "  Total G Loss: 3.9751\n",
      "Epoch [137/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1389, D_X Fake: 0.1171, D_X Total: 0.1280\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0404, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.6768, F Adv: 0.6269\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1142, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.1627\n",
      "Epoch [137/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1386, D_X Fake: 0.0633, D_X Total: 0.1010\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0356, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.9013, F Adv: 0.6929\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1839\n",
      "  Total G Loss: 3.9606\n",
      "Epoch [137/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3237, D_X Fake: 0.0853, D_X Total: 0.2045\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0438, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.8403, F Adv: 0.5047\n",
      "  Cycle Photo: 0.0210, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.2121\n",
      "Epoch [137/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0770, D_X Fake: 0.1196, D_X Total: 0.0983\n",
      "  D_Y Real: 0.0586, D_Y Fake: 0.0654, D_Y Total: 0.0620\n",
      "Generator Losses:\n",
      "  G Adv: 0.7116, F Adv: 0.4598\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.3395\n",
      "Epoch [137/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0319, D_X Fake: 0.1625, D_X Total: 0.0972\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0379, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.7934, F Adv: 0.4901\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1025, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 3.2985\n",
      "Epoch [137/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1805, D_X Fake: 0.1370, D_X Total: 0.1588\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0348, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.8982, F Adv: 0.5710\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0178\n",
      "  Perceptual Photo: 0.1687, Perceptual Monet: 0.1173\n",
      "  Total G Loss: 3.4357\n",
      "Epoch [137/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1788, D_X Fake: 0.0535, D_X Total: 0.1162\n",
      "  D_Y Real: 0.0165, D_Y Fake: 0.0559, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.7589, F Adv: 0.7107\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1772\n",
      "  Total G Loss: 3.7907\n",
      "Epoch [137/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0793, D_X Fake: 0.1294, D_X Total: 0.1044\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0503, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.8458, F Adv: 0.4566\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1330, Perceptual Monet: 0.1465\n",
      "  Total G Loss: 3.2349\n",
      "Epoch [137/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1685, D_X Fake: 0.0513, D_X Total: 0.1099\n",
      "  D_Y Real: 0.0318, D_Y Fake: 0.0520, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.8121, F Adv: 0.6517\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1155, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.4996\n",
      "Epoch [137/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1510, D_X Fake: 0.0631, D_X Total: 0.1071\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0518, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.8177, F Adv: 0.7283\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1468, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.6705\n",
      "Epoch [137/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1112, D_X Fake: 0.1137, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0441, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.9415, F Adv: 0.6023\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1612\n",
      "  Total G Loss: 3.5446\n",
      "Epoch [137/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1580, D_X Fake: 0.0923, D_X Total: 0.1251\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0371, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.8625, F Adv: 0.6580\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1886\n",
      "  Total G Loss: 3.7339\n",
      "Epoch [137/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1680, D_X Fake: 0.1219, D_X Total: 0.1449\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0548, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.8306, F Adv: 0.5733\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.2114\n",
      "  Total G Loss: 3.8684\n",
      "Epoch [137/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1338, D_X Fake: 0.0685, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0482, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.8417, F Adv: 0.6306\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1510\n",
      "  Total G Loss: 3.5377\n",
      "Epoch [137/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1781, D_X Fake: 0.1237, D_X Total: 0.1509\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0500, D_Y Total: 0.0485\n",
      "Generator Losses:\n",
      "  G Adv: 0.8269, F Adv: 0.6229\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1914, Perceptual Monet: 0.1731\n",
      "  Total G Loss: 3.9489\n",
      "Epoch [137/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1435, D_X Fake: 0.1378, D_X Total: 0.1406\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0411, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.7647, F Adv: 0.5167\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.4702\n",
      "Epoch [137/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0509, D_X Fake: 0.0763, D_X Total: 0.0636\n",
      "  D_Y Real: 0.0532, D_Y Fake: 0.0302, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.8352, F Adv: 0.6724\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0411\n",
      "  Perceptual Photo: 0.1198, Perceptual Monet: 0.1984\n",
      "  Total G Loss: 3.8260\n",
      "Epoch [137/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1514, D_X Fake: 0.0929, D_X Total: 0.1221\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.0471, D_Y Total: 0.0454\n",
      "Generator Losses:\n",
      "  G Adv: 0.8843, F Adv: 0.7040\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 3.7289\n",
      "Epoch [137/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1256, D_X Fake: 0.0772, D_X Total: 0.1014\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0490, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.9499, F Adv: 0.6189\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1308, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.5433\n",
      "Epoch [137/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1053, D_X Fake: 0.0901, D_X Total: 0.0977\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0342, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.8897, F Adv: 0.7227\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.9113\n",
      "Epoch [137/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1415, D_X Fake: 0.1094, D_X Total: 0.1255\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0457, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.9104, F Adv: 0.4948\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1113, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.4347\n",
      "Epoch [137/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1751, D_X Fake: 0.0555, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0410, D_Y Fake: 0.0370, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.8208, F Adv: 0.7352\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1489\n",
      "  Total G Loss: 3.5023\n",
      "Epoch [137/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1377, D_X Fake: 0.1429, D_X Total: 0.1403\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0412, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 1.1150, F Adv: 0.6339\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.8358\n",
      "Epoch [138/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0755, D_X Fake: 0.1168, D_X Total: 0.0962\n",
      "  D_Y Real: 0.0371, D_Y Fake: 0.0305, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.8993, F Adv: 0.5461\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1191, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.4900\n",
      "Epoch [138/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1074, D_X Fake: 0.0649, D_X Total: 0.0862\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0586, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.9358, F Adv: 0.6821\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.6739\n",
      "Epoch [138/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1756, D_X Fake: 0.0778, D_X Total: 0.1267\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0619, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.8674, F Adv: 0.6337\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1551, Perceptual Monet: 0.1908\n",
      "  Total G Loss: 3.8398\n",
      "Epoch [138/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0896, D_X Fake: 0.0633, D_X Total: 0.0765\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0596, D_Y Total: 0.0516\n",
      "Generator Losses:\n",
      "  G Adv: 0.8552, F Adv: 0.6845\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1109, Perceptual Monet: 0.1922\n",
      "  Total G Loss: 3.6774\n",
      "Epoch [138/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1145, D_X Fake: 0.0803, D_X Total: 0.0974\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0321, D_Y Total: 0.0275\n",
      "Generator Losses:\n",
      "  G Adv: 1.0986, F Adv: 0.6503\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1794\n",
      "  Total G Loss: 3.9517\n",
      "Epoch [138/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1183, D_X Fake: 0.1281, D_X Total: 0.1232\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0496, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.8075, F Adv: 0.6140\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1262, Perceptual Monet: 0.1620\n",
      "  Total G Loss: 3.4311\n",
      "Epoch [138/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1133, D_X Fake: 0.0650, D_X Total: 0.0892\n",
      "  D_Y Real: 0.0487, D_Y Fake: 0.0872, D_Y Total: 0.0680\n",
      "Generator Losses:\n",
      "  G Adv: 0.7805, F Adv: 0.6492\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1195, Perceptual Monet: 0.1378\n",
      "  Total G Loss: 3.2091\n",
      "Epoch [138/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1809, D_X Fake: 0.1586, D_X Total: 0.1697\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0470, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.9907, F Adv: 0.5101\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0216\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1421\n",
      "  Total G Loss: 3.3896\n",
      "Epoch [138/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0681, D_X Fake: 0.1539, D_X Total: 0.1110\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0320, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9866, F Adv: 0.4610\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1196, Perceptual Monet: 0.1546\n",
      "  Total G Loss: 3.3302\n",
      "Epoch [138/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1048, D_X Fake: 0.1537, D_X Total: 0.1293\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0389, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.8865, F Adv: 0.5323\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1449, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.5442\n",
      "Epoch [138/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0920, D_X Fake: 0.0680, D_X Total: 0.0800\n",
      "  D_Y Real: 0.0277, D_Y Fake: 0.0318, D_Y Total: 0.0297\n",
      "Generator Losses:\n",
      "  G Adv: 0.9167, F Adv: 0.5916\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1146, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.4767\n",
      "Epoch [138/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0849, D_X Fake: 0.1207, D_X Total: 0.1028\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0508, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.7433, F Adv: 0.5414\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.3534\n",
      "Epoch [138/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1047, D_X Fake: 0.0734, D_X Total: 0.0891\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0357, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 1.0863, F Adv: 0.5509\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1145, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.4618\n",
      "Epoch [138/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0900, D_X Fake: 0.1548, D_X Total: 0.1224\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0490, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.9570, F Adv: 0.4706\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.4836\n",
      "Epoch [138/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1526, D_X Fake: 0.0994, D_X Total: 0.1260\n",
      "  D_Y Real: 0.0314, D_Y Fake: 0.0484, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.9024, F Adv: 0.5644\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0208\n",
      "  Perceptual Photo: 0.1011, Perceptual Monet: 0.1318\n",
      "  Total G Loss: 3.1784\n",
      "Epoch [138/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2275, D_X Fake: 0.1109, D_X Total: 0.1692\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0365, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.7126, F Adv: 0.5552\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.3025\n",
      "Epoch [138/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.0600, D_X Total: 0.0779\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0288, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.9025, F Adv: 0.7146\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 3.8023\n",
      "Epoch [138/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1616, D_X Fake: 0.0844, D_X Total: 0.1230\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0737, D_Y Total: 0.0492\n",
      "Generator Losses:\n",
      "  G Adv: 0.6872, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1757, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.5488\n",
      "Epoch [138/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2053, D_X Fake: 0.1166, D_X Total: 0.1610\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0635, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.9501, F Adv: 0.6028\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1326, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.5876\n",
      "Epoch [138/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1142, D_X Fake: 0.0858, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0472, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.8689, F Adv: 0.5438\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1612\n",
      "  Total G Loss: 3.3777\n",
      "Epoch [138/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0656, D_X Fake: 0.1784, D_X Total: 0.1220\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0437, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.7449, F Adv: 0.4237\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1862\n",
      "  Total G Loss: 3.4475\n",
      "Epoch [138/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0680, D_X Fake: 0.0583, D_X Total: 0.0632\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0355, D_Y Total: 0.0252\n",
      "Generator Losses:\n",
      "  G Adv: 0.6605, F Adv: 0.6801\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1252, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.6498\n",
      "Epoch [138/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1855, D_X Fake: 0.0439, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0539, D_Y Fake: 0.0408, D_Y Total: 0.0473\n",
      "Generator Losses:\n",
      "  G Adv: 0.8563, F Adv: 0.6868\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1419, Perceptual Monet: 0.1513\n",
      "  Total G Loss: 3.5591\n",
      "Epoch [138/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1536, D_X Fake: 0.0715, D_X Total: 0.1126\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0668, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.7531, F Adv: 0.5833\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 3.4538\n",
      "Epoch [139/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1525, D_X Fake: 0.0986, D_X Total: 0.1256\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0529, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.8219, F Adv: 0.5565\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1818, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.8173\n",
      "Epoch [139/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1086, D_X Fake: 0.1414, D_X Total: 0.1250\n",
      "  D_Y Real: 0.0449, D_Y Fake: 0.0413, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.9557, F Adv: 0.4769\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1381, Perceptual Monet: 0.1559\n",
      "  Total G Loss: 3.4038\n",
      "Epoch [139/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1582, D_X Fake: 0.0959, D_X Total: 0.1270\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0465, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.7509, F Adv: 0.5497\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1330, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.3400\n",
      "Epoch [139/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1583, D_X Fake: 0.0882, D_X Total: 0.1233\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0471, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 1.2011, F Adv: 0.5513\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1547\n",
      "  Total G Loss: 3.7904\n",
      "Epoch [139/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.1062, D_X Total: 0.1096\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0336, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9522, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1466\n",
      "  Total G Loss: 3.3957\n",
      "Epoch [139/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1419, D_X Fake: 0.0835, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0245, D_Y Fake: 0.0404, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.9170, F Adv: 0.6128\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.5498\n",
      "Epoch [139/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0892, D_X Fake: 0.0510, D_X Total: 0.0701\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0516, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.7680, F Adv: 0.7788\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1682, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 4.0244\n",
      "Epoch [139/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2008, D_X Fake: 0.1079, D_X Total: 0.1543\n",
      "  D_Y Real: 0.0272, D_Y Fake: 0.0430, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.9431, F Adv: 0.4684\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1487\n",
      "  Total G Loss: 3.4021\n",
      "Epoch [139/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1466, D_X Fake: 0.0916, D_X Total: 0.1191\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0579, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.8892, F Adv: 0.6220\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.8475\n",
      "Epoch [139/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0957, D_X Fake: 0.1000, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0341, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 0.9494, F Adv: 0.4946\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1156, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.4497\n",
      "Epoch [139/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1638, D_X Fake: 0.1103, D_X Total: 0.1371\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0553, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.9196, F Adv: 0.5976\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1131, Perceptual Monet: 0.1753\n",
      "  Total G Loss: 3.4921\n",
      "Epoch [139/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1262, D_X Fake: 0.1257, D_X Total: 0.1260\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.1039, D_Y Total: 0.0610\n",
      "Generator Losses:\n",
      "  G Adv: 0.6333, F Adv: 0.5257\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1287, Perceptual Monet: 0.1584\n",
      "  Total G Loss: 3.1580\n",
      "Epoch [139/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0787, D_X Fake: 0.0794, D_X Total: 0.0791\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0446, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 1.1301, F Adv: 0.6768\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1569, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 4.0237\n",
      "Epoch [139/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1281, D_X Fake: 0.1410, D_X Total: 0.1346\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0583, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.9263, F Adv: 0.4621\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1488\n",
      "  Total G Loss: 3.5118\n",
      "Epoch [139/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0910, D_X Fake: 0.1065, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0363, D_Y Fake: 0.0728, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.8690, F Adv: 0.5906\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1194, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.3891\n",
      "Epoch [139/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2420, D_X Fake: 0.1034, D_X Total: 0.1727\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0309, D_Y Total: 0.0255\n",
      "Generator Losses:\n",
      "  G Adv: 0.9216, F Adv: 0.5268\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1709, Perceptual Monet: 0.1550\n",
      "  Total G Loss: 3.6504\n",
      "Epoch [139/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0747, D_X Fake: 0.0713, D_X Total: 0.0730\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0388, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.9986, F Adv: 0.5674\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.8802\n",
      "Epoch [139/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0748, D_X Fake: 0.1072, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0366, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8018, F Adv: 0.6116\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1817\n",
      "  Total G Loss: 3.7681\n",
      "Epoch [139/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1354, D_X Fake: 0.0850, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0381, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 0.7685, F Adv: 0.6161\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1161, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.3989\n",
      "Epoch [139/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1094, D_X Fake: 0.0804, D_X Total: 0.0949\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0385, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 1.0316, F Adv: 0.6359\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1234, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.7349\n",
      "Epoch [139/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1227, D_X Fake: 0.0454, D_X Total: 0.0841\n",
      "  D_Y Real: 0.0385, D_Y Fake: 0.0328, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.9486, F Adv: 0.6814\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1490, Perceptual Monet: 0.1715\n",
      "  Total G Loss: 3.8679\n",
      "Epoch [139/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1912, D_X Fake: 0.0949, D_X Total: 0.1431\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.0573, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.7424, F Adv: 0.5687\n",
      "  Cycle Photo: 0.0406, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1788, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.6935\n",
      "Epoch [139/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0875, D_X Fake: 0.0871, D_X Total: 0.0873\n",
      "  D_Y Real: 0.0326, D_Y Fake: 0.0480, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.7881, F Adv: 0.6781\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1524, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 3.8055\n",
      "Epoch [139/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0931, D_X Fake: 0.1235, D_X Total: 0.1083\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0458, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.9073, F Adv: 0.3389\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.5051\n",
      "Epoch [140/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0797, D_X Fake: 0.1322, D_X Total: 0.1060\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.0361, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.9611, F Adv: 0.4925\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1197, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.3639\n",
      "Epoch [140/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1177, D_X Fake: 0.0643, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0147, D_Y Fake: 0.0901, D_Y Total: 0.0524\n",
      "Generator Losses:\n",
      "  G Adv: 0.6348, F Adv: 0.6497\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1718\n",
      "  Total G Loss: 3.3057\n",
      "Epoch [140/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1596, D_X Fake: 0.0921, D_X Total: 0.1259\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0274, D_Y Total: 0.0233\n",
      "Generator Losses:\n",
      "  G Adv: 1.0166, F Adv: 0.6196\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1704, Perceptual Monet: 0.1697\n",
      "  Total G Loss: 3.9812\n",
      "Epoch [140/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0407, D_X Fake: 0.0749, D_X Total: 0.0578\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.1123, D_Y Total: 0.0645\n",
      "Generator Losses:\n",
      "  G Adv: 0.8630, F Adv: 0.6749\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1318, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.7033\n",
      "Epoch [140/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0928, D_X Fake: 0.0972, D_X Total: 0.0950\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0349, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9988, F Adv: 0.5961\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1664\n",
      "  Total G Loss: 3.6636\n",
      "Epoch [140/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1753, D_X Fake: 0.0730, D_X Total: 0.1242\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0474, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.8514, F Adv: 0.5903\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.6265\n",
      "Epoch [140/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.0569, D_X Total: 0.0659\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0432, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.8961, F Adv: 0.6901\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1161, Perceptual Monet: 0.1521\n",
      "  Total G Loss: 3.4032\n",
      "Epoch [140/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1793, D_X Fake: 0.1407, D_X Total: 0.1600\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0385, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9278, F Adv: 0.5050\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1514, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.7027\n",
      "Epoch [140/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1913, D_X Fake: 0.0866, D_X Total: 0.1390\n",
      "  D_Y Real: 0.0391, D_Y Fake: 0.0399, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8195, F Adv: 0.5730\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.4247\n",
      "Epoch [140/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0536, D_X Fake: 0.1404, D_X Total: 0.0970\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0396, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9637, F Adv: 0.4719\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1400, Perceptual Monet: 0.1371\n",
      "  Total G Loss: 3.3260\n",
      "Epoch [140/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1042, D_X Fake: 0.1098, D_X Total: 0.1070\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0932, D_Y Total: 0.0568\n",
      "Generator Losses:\n",
      "  G Adv: 0.7298, F Adv: 0.5433\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.2134\n",
      "  Total G Loss: 3.7535\n",
      "Epoch [140/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1045, D_X Fake: 0.1374, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0534, D_Y Total: 0.0465\n",
      "Generator Losses:\n",
      "  G Adv: 0.8298, F Adv: 0.5415\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1426, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.5756\n",
      "Epoch [140/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2204, D_X Fake: 0.1208, D_X Total: 0.1706\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0453, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.9353, F Adv: 0.5102\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1979, Perceptual Monet: 0.1918\n",
      "  Total G Loss: 4.0667\n",
      "Epoch [140/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0462, D_X Fake: 0.0987, D_X Total: 0.0725\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0420, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8634, F Adv: 0.6219\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.5862\n",
      "Epoch [140/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2271, D_X Fake: 0.0429, D_X Total: 0.1350\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.0508, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.8201, F Adv: 0.7455\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.6319\n",
      "Epoch [140/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0494, D_X Fake: 0.1400, D_X Total: 0.0947\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0266, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.9121, F Adv: 0.5334\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1922\n",
      "  Total G Loss: 3.7017\n",
      "Epoch [140/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1345, D_X Fake: 0.0841, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0580, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.8273, F Adv: 0.6659\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1504\n",
      "  Total G Loss: 3.5489\n",
      "Epoch [140/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1625, D_X Fake: 0.0656, D_X Total: 0.1141\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0756, D_Y Total: 0.0494\n",
      "Generator Losses:\n",
      "  G Adv: 0.6826, F Adv: 0.7391\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1424\n",
      "  Total G Loss: 3.4491\n",
      "Epoch [140/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0549, D_X Fake: 0.2403, D_X Total: 0.1476\n",
      "  D_Y Real: 0.0153, D_Y Fake: 0.0549, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.8107, F Adv: 0.3225\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1267, Perceptual Monet: 0.1569\n",
      "  Total G Loss: 3.1823\n",
      "Epoch [140/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1829, D_X Fake: 0.0608, D_X Total: 0.1218\n",
      "  D_Y Real: 0.0475, D_Y Fake: 0.0402, D_Y Total: 0.0439\n",
      "Generator Losses:\n",
      "  G Adv: 0.8377, F Adv: 0.5541\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1255, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.2820\n",
      "Epoch [140/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2243, D_X Fake: 0.0762, D_X Total: 0.1503\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0886, D_Y Total: 0.0569\n",
      "Generator Losses:\n",
      "  G Adv: 0.7803, F Adv: 0.5682\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1287, Perceptual Monet: 0.1560\n",
      "  Total G Loss: 3.2907\n",
      "Epoch [140/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0625, D_X Fake: 0.0817, D_X Total: 0.0721\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0411, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.8379, F Adv: 0.6228\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1410, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.5719\n",
      "Epoch [140/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1632, D_X Fake: 0.1299, D_X Total: 0.1466\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0332, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.9223, F Adv: 0.4185\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.1905\n",
      "  Total G Loss: 3.9093\n",
      "Epoch [140/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.1361, D_X Total: 0.1415\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0372, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 1.0055, F Adv: 0.5380\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.6249\n",
      "Saved checkpoint at epoch 140\n",
      "Epoch [141/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2009, D_X Fake: 0.1245, D_X Total: 0.1627\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.1288, D_Y Total: 0.0792\n",
      "Generator Losses:\n",
      "  G Adv: 0.8841, F Adv: 0.5380\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 3.5324\n",
      "Epoch [141/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1066, D_X Fake: 0.0932, D_X Total: 0.0999\n",
      "  D_Y Real: 0.0255, D_Y Fake: 0.0452, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.8911, F Adv: 0.6379\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.5920\n",
      "Epoch [141/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1488, D_X Fake: 0.0904, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0367, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 1.1258, F Adv: 0.6491\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1556, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 4.0970\n",
      "Epoch [141/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1165, D_X Fake: 0.1644, D_X Total: 0.1404\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0384, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.8861, F Adv: 0.4292\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1482, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.4942\n",
      "Epoch [141/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2565, D_X Fake: 0.0969, D_X Total: 0.1767\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0300, D_Y Total: 0.0253\n",
      "Generator Losses:\n",
      "  G Adv: 1.0305, F Adv: 0.5309\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1886, Perceptual Monet: 0.1914\n",
      "  Total G Loss: 4.1511\n",
      "Epoch [141/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1847, D_X Fake: 0.1017, D_X Total: 0.1432\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0373, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.8903, F Adv: 0.5925\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1440\n",
      "  Total G Loss: 3.4902\n",
      "Epoch [141/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0571, D_X Fake: 0.1211, D_X Total: 0.0891\n",
      "  D_Y Real: 0.0407, D_Y Fake: 0.0806, D_Y Total: 0.0606\n",
      "Generator Losses:\n",
      "  G Adv: 0.8700, F Adv: 0.5110\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1167, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.2651\n",
      "Epoch [141/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1751, D_X Fake: 0.0677, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0655, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.9342, F Adv: 0.7245\n",
      "  Cycle Photo: 0.0413, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1681, Perceptual Monet: 0.1740\n",
      "  Total G Loss: 4.0754\n",
      "Epoch [141/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2757, D_X Fake: 0.1216, D_X Total: 0.1986\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0454, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.8306, F Adv: 0.6334\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0207\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1281\n",
      "  Total G Loss: 3.4890\n",
      "Epoch [141/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0414, D_X Fake: 0.1300, D_X Total: 0.0857\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.0452, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.7441, F Adv: 0.5473\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.4401\n",
      "Epoch [141/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0855, D_X Fake: 0.0984, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0476, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 1.0050, F Adv: 0.7494\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 4.1932\n",
      "Epoch [141/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1780, D_X Fake: 0.0596, D_X Total: 0.1188\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0531, D_Y Total: 0.0468\n",
      "Generator Losses:\n",
      "  G Adv: 0.9400, F Adv: 0.7014\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.7342\n",
      "Epoch [141/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1382, D_X Fake: 0.1545, D_X Total: 0.1463\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0640, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.9310, F Adv: 0.4917\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1202, Perceptual Monet: 0.1628\n",
      "  Total G Loss: 3.4092\n",
      "Epoch [141/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3882, D_X Fake: 0.1652, D_X Total: 0.2767\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0374, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9694, F Adv: 0.4573\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1830\n",
      "  Total G Loss: 3.6540\n",
      "Epoch [141/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1187, D_X Fake: 0.0781, D_X Total: 0.0984\n",
      "  D_Y Real: 0.0606, D_Y Fake: 0.0453, D_Y Total: 0.0529\n",
      "Generator Losses:\n",
      "  G Adv: 0.9701, F Adv: 0.6454\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1560, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.9625\n",
      "Epoch [141/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0751, D_X Fake: 0.0739, D_X Total: 0.0745\n",
      "  D_Y Real: 0.0667, D_Y Fake: 0.0697, D_Y Total: 0.0682\n",
      "Generator Losses:\n",
      "  G Adv: 0.9705, F Adv: 0.6881\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1837\n",
      "  Total G Loss: 3.8227\n",
      "Epoch [141/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1996, D_X Fake: 0.0938, D_X Total: 0.1467\n",
      "  D_Y Real: 0.0277, D_Y Fake: 0.0629, D_Y Total: 0.0453\n",
      "Generator Losses:\n",
      "  G Adv: 0.8473, F Adv: 0.6507\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1751, Perceptual Monet: 0.1725\n",
      "  Total G Loss: 3.9129\n",
      "Epoch [141/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0719, D_X Fake: 0.1160, D_X Total: 0.0939\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0926, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.8873, F Adv: 0.5525\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1288, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.4526\n",
      "Epoch [141/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.1607, D_X Total: 0.1209\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0442, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.8752, F Adv: 0.4526\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1469, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.4583\n",
      "Epoch [141/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1099, D_X Fake: 0.0799, D_X Total: 0.0949\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0314, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 0.9454, F Adv: 0.6487\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.5950\n",
      "Epoch [141/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3175, D_X Fake: 0.1137, D_X Total: 0.2156\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0410, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8458, F Adv: 0.5787\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1263, Perceptual Monet: 0.1752\n",
      "  Total G Loss: 3.4708\n",
      "Epoch [141/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0995, D_X Fake: 0.0944, D_X Total: 0.0970\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0788, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.8642, F Adv: 0.5521\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.4143\n",
      "Epoch [141/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0400, D_X Fake: 0.0830, D_X Total: 0.0615\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0421, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.8602, F Adv: 0.6494\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.6408\n",
      "Epoch [141/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0659, D_X Fake: 0.0872, D_X Total: 0.0765\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0496, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.9258, F Adv: 0.6789\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.7349\n",
      "Epoch [142/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1335, D_X Fake: 0.1344, D_X Total: 0.1339\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0349, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9902, F Adv: 0.4591\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1081, Perceptual Monet: 0.1708\n",
      "  Total G Loss: 3.3292\n",
      "Epoch [142/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0888, D_X Fake: 0.0902, D_X Total: 0.0895\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0650, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.9325, F Adv: 0.6331\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.6837\n",
      "Epoch [142/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0928, D_X Fake: 0.1600, D_X Total: 0.1264\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0364, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.9616, F Adv: 0.5306\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.6149\n",
      "Epoch [142/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1039, D_X Fake: 0.1397, D_X Total: 0.1218\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0750, D_Y Total: 0.0508\n",
      "Generator Losses:\n",
      "  G Adv: 0.8535, F Adv: 0.4749\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1841\n",
      "  Total G Loss: 3.6095\n",
      "Epoch [142/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3842, D_X Fake: 0.1517, D_X Total: 0.2679\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0324, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 0.9301, F Adv: 0.4803\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1695, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.6879\n",
      "Epoch [142/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2037, D_X Fake: 0.0936, D_X Total: 0.1486\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0504, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.7528, F Adv: 0.6266\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1248, Perceptual Monet: 0.2127\n",
      "  Total G Loss: 3.7097\n",
      "Epoch [142/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0937, D_X Fake: 0.0839, D_X Total: 0.0888\n",
      "  D_Y Real: 0.0351, D_Y Fake: 0.0350, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.8804, F Adv: 0.6527\n",
      "  Cycle Photo: 0.0493, Cycle Monet: 0.0227\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1397\n",
      "  Total G Loss: 3.7650\n",
      "Epoch [142/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0862, D_X Fake: 0.0731, D_X Total: 0.0796\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0616, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.7337, F Adv: 0.6014\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1655\n",
      "  Total G Loss: 3.5390\n",
      "Epoch [142/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2600, D_X Fake: 0.0661, D_X Total: 0.1630\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0505, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.8292, F Adv: 0.5300\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1559, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.5994\n",
      "Epoch [142/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1303, D_X Fake: 0.1049, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0780, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 0.7457, F Adv: 0.6673\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1438\n",
      "  Total G Loss: 3.5769\n",
      "Epoch [142/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1299, D_X Fake: 0.0698, D_X Total: 0.0999\n",
      "  D_Y Real: 0.0497, D_Y Fake: 0.0620, D_Y Total: 0.0558\n",
      "Generator Losses:\n",
      "  G Adv: 0.6749, F Adv: 0.7164\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1280, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.4424\n",
      "Epoch [142/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0659, D_X Fake: 0.0727, D_X Total: 0.0693\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0528, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8527, F Adv: 0.7357\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1262, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.5981\n",
      "Epoch [142/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0872, D_X Fake: 0.1012, D_X Total: 0.0942\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0523, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 1.0735, F Adv: 0.5903\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1715, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 3.9445\n",
      "Epoch [142/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1777, D_X Fake: 0.0642, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0424, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.9044, F Adv: 0.6535\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1344, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.5602\n",
      "Epoch [142/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2079, D_X Fake: 0.0429, D_X Total: 0.1254\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0422, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.7975, F Adv: 0.6321\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1047, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.4270\n",
      "Epoch [142/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1351, D_X Fake: 0.1058, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0439, D_Y Fake: 0.0537, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 0.7853, F Adv: 0.6250\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.2030\n",
      "  Total G Loss: 3.7289\n",
      "Epoch [142/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1611, D_X Fake: 0.1122, D_X Total: 0.1366\n",
      "  D_Y Real: 0.0392, D_Y Fake: 0.0576, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.8857, F Adv: 0.6104\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1346, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 3.7028\n",
      "Epoch [142/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1401, D_X Fake: 0.0824, D_X Total: 0.1113\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0396, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.7860, F Adv: 0.5416\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1316, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.3201\n",
      "Epoch [142/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1776, D_X Fake: 0.0847, D_X Total: 0.1312\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0552, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.7602, F Adv: 0.5441\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.3827\n",
      "Epoch [142/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0917, D_X Fake: 0.0874, D_X Total: 0.0895\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0470, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8400, F Adv: 0.6218\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.4554\n",
      "Epoch [142/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1475, D_X Fake: 0.1072, D_X Total: 0.1273\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.1015, D_Y Total: 0.0615\n",
      "Generator Losses:\n",
      "  G Adv: 0.7621, F Adv: 0.4989\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.1925\n",
      "Epoch [142/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1573, D_X Fake: 0.1101, D_X Total: 0.1337\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0386, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8521, F Adv: 0.6049\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1762, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.8031\n",
      "Epoch [142/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0630, D_X Fake: 0.0847, D_X Total: 0.0739\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0581, D_Y Total: 0.0430\n",
      "Generator Losses:\n",
      "  G Adv: 0.7696, F Adv: 0.7438\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1504, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.6118\n",
      "Epoch [142/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2464, D_X Fake: 0.0910, D_X Total: 0.1687\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0515, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9538, F Adv: 0.6674\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1940, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 4.0876\n",
      "Epoch [143/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0625, D_X Fake: 0.1104, D_X Total: 0.0864\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0375, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8403, F Adv: 0.5149\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1141, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 3.3545\n",
      "Epoch [143/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0729, D_X Fake: 0.1026, D_X Total: 0.0878\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0364, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.7647, F Adv: 0.6163\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.2076\n",
      "  Total G Loss: 3.8935\n",
      "Epoch [143/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2140, D_X Fake: 0.0721, D_X Total: 0.1431\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0351, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 0.9214, F Adv: 0.5591\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1755\n",
      "  Total G Loss: 3.7858\n",
      "Epoch [143/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1613, D_X Fake: 0.0596, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0335, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.9410, F Adv: 0.6212\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1954, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 4.1317\n",
      "Epoch [143/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1367, D_X Fake: 0.2010, D_X Total: 0.1689\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0762, D_Y Total: 0.0541\n",
      "Generator Losses:\n",
      "  G Adv: 0.5712, F Adv: 0.5593\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.2976\n",
      "Epoch [143/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0973, D_X Fake: 0.1569, D_X Total: 0.1271\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0621, D_Y Total: 0.0412\n",
      "Generator Losses:\n",
      "  G Adv: 0.9987, F Adv: 0.4458\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1711\n",
      "  Total G Loss: 3.4989\n",
      "Epoch [143/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2081, D_X Fake: 0.0940, D_X Total: 0.1510\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.0372, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.9864, F Adv: 0.5474\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1363, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.5408\n",
      "Epoch [143/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1145, D_X Fake: 0.1239, D_X Total: 0.1192\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0794, D_Y Total: 0.0525\n",
      "Generator Losses:\n",
      "  G Adv: 0.6678, F Adv: 0.5191\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.5319\n",
      "Epoch [143/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2431, D_X Fake: 0.0770, D_X Total: 0.1600\n",
      "  D_Y Real: 0.0577, D_Y Fake: 0.0423, D_Y Total: 0.0500\n",
      "Generator Losses:\n",
      "  G Adv: 1.0888, F Adv: 0.6380\n",
      "  Cycle Photo: 0.0442, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1594, Perceptual Monet: 0.1543\n",
      "  Total G Loss: 3.9789\n",
      "Epoch [143/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1690, D_X Fake: 0.1195, D_X Total: 0.1443\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0452, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9246, F Adv: 0.6107\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0227\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.4835\n",
      "Epoch [143/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1605, D_X Fake: 0.1492, D_X Total: 0.1549\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0461, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.7722, F Adv: 0.5212\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.5365\n",
      "Epoch [143/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2262, D_X Fake: 0.0924, D_X Total: 0.1593\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0718, D_Y Total: 0.0448\n",
      "Generator Losses:\n",
      "  G Adv: 0.8467, F Adv: 0.6451\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1760\n",
      "  Total G Loss: 3.7242\n",
      "Epoch [143/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1877, D_X Fake: 0.0909, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0374, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.8498, F Adv: 0.6343\n",
      "  Cycle Photo: 0.0183, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.0968, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.1628\n",
      "Epoch [143/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1860, D_X Fake: 0.1541, D_X Total: 0.1700\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0643, D_Y Total: 0.0498\n",
      "Generator Losses:\n",
      "  G Adv: 0.6935, F Adv: 0.5335\n",
      "  Cycle Photo: 0.0396, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1816, Perceptual Monet: 0.1936\n",
      "  Total G Loss: 3.8291\n",
      "Epoch [143/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2473, D_X Fake: 0.1056, D_X Total: 0.1765\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0532, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.6679, F Adv: 0.6027\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1731\n",
      "  Total G Loss: 3.5427\n",
      "Epoch [143/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0760, D_X Fake: 0.0931, D_X Total: 0.0845\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0499, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.8829, F Adv: 0.6002\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.6048\n",
      "Epoch [143/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0974, D_X Fake: 0.1535, D_X Total: 0.1254\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0418, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.7352, F Adv: 0.4850\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1380, Perceptual Monet: 0.1702\n",
      "  Total G Loss: 3.3619\n",
      "Epoch [143/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1590, D_X Fake: 0.1023, D_X Total: 0.1307\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.0724, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.7945, F Adv: 0.5551\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1812\n",
      "  Total G Loss: 3.5445\n",
      "Epoch [143/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1970, D_X Fake: 0.0961, D_X Total: 0.1466\n",
      "  D_Y Real: 0.0381, D_Y Fake: 0.0572, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.8319, F Adv: 0.5199\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1948\n",
      "  Total G Loss: 3.5941\n",
      "Epoch [143/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1752, D_X Fake: 0.0895, D_X Total: 0.1324\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0463, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9280, F Adv: 0.5851\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1765\n",
      "  Total G Loss: 3.7497\n",
      "Epoch [143/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1476, D_X Fake: 0.1299, D_X Total: 0.1388\n",
      "  D_Y Real: 0.0680, D_Y Fake: 0.0443, D_Y Total: 0.0562\n",
      "Generator Losses:\n",
      "  G Adv: 0.8715, F Adv: 0.5510\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1070, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.3609\n",
      "Epoch [143/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2432, D_X Fake: 0.1052, D_X Total: 0.1742\n",
      "  D_Y Real: 0.0360, D_Y Fake: 0.0589, D_Y Total: 0.0474\n",
      "Generator Losses:\n",
      "  G Adv: 0.8379, F Adv: 0.3891\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1931\n",
      "  Total G Loss: 3.5041\n",
      "Epoch [143/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0614, D_X Fake: 0.0745, D_X Total: 0.0679\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0379, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.8381, F Adv: 0.4841\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.4508\n",
      "Epoch [143/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1108, D_X Fake: 0.0977, D_X Total: 0.1042\n",
      "  D_Y Real: 0.0333, D_Y Fake: 0.0395, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 1.0180, F Adv: 0.5984\n",
      "  Cycle Photo: 0.0215, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1071, Perceptual Monet: 0.1929\n",
      "  Total G Loss: 3.6658\n",
      "Epoch [144/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1443, D_X Fake: 0.1366, D_X Total: 0.1404\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0447, D_Y Total: 0.0304\n",
      "Generator Losses:\n",
      "  G Adv: 0.9090, F Adv: 0.5777\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1758, Perceptual Monet: 0.1512\n",
      "  Total G Loss: 3.6668\n",
      "Epoch [144/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0892, D_X Fake: 0.0979, D_X Total: 0.0936\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0347, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.9353, F Adv: 0.6487\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.6303\n",
      "Epoch [144/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3033, D_X Fake: 0.1469, D_X Total: 0.2251\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.1319, D_Y Total: 0.0762\n",
      "Generator Losses:\n",
      "  G Adv: 0.6816, F Adv: 0.4756\n",
      "  Cycle Photo: 0.0384, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1385, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.2945\n",
      "Epoch [144/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1114, D_X Fake: 0.1197, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0536, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.9553, F Adv: 0.5672\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1232, Perceptual Monet: 0.1901\n",
      "  Total G Loss: 3.6637\n",
      "Epoch [144/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1110, D_X Fake: 0.1052, D_X Total: 0.1081\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0346, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.9504, F Adv: 0.5939\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.7771\n",
      "Epoch [144/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1616, D_X Fake: 0.1317, D_X Total: 0.1467\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0582, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.9164, F Adv: 0.6952\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1968\n",
      "  Total G Loss: 3.8591\n",
      "Epoch [144/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2371, D_X Fake: 0.0939, D_X Total: 0.1655\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0853, D_Y Total: 0.0597\n",
      "Generator Losses:\n",
      "  G Adv: 0.7572, F Adv: 0.4840\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1358, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.2897\n",
      "Epoch [144/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0759, D_X Fake: 0.1025, D_X Total: 0.0892\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0400, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 1.0709, F Adv: 0.6494\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.8931\n",
      "Epoch [144/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1534, D_X Fake: 0.1091, D_X Total: 0.1313\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0566, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8257, F Adv: 0.5274\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1175, Perceptual Monet: 0.1833\n",
      "  Total G Loss: 3.4462\n",
      "Epoch [144/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0947, D_X Fake: 0.0844, D_X Total: 0.0896\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0914, D_Y Total: 0.0583\n",
      "Generator Losses:\n",
      "  G Adv: 0.9311, F Adv: 0.5682\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1101, Perceptual Monet: 0.1432\n",
      "  Total G Loss: 3.2576\n",
      "Epoch [144/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2502, D_X Fake: 0.0659, D_X Total: 0.1581\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0881, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.8348, F Adv: 0.8102\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1291, Perceptual Monet: 0.1517\n",
      "  Total G Loss: 3.5580\n",
      "Epoch [144/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0768, D_X Fake: 0.1191, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0398, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8105, F Adv: 0.5534\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1331, Perceptual Monet: 0.1628\n",
      "  Total G Loss: 3.4170\n",
      "Epoch [144/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1602, D_X Fake: 0.1366, D_X Total: 0.1484\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0367, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.9477, F Adv: 0.4650\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.2177, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 4.0228\n",
      "Epoch [144/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1277, D_X Fake: 0.1187, D_X Total: 0.1232\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0604, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.7661, F Adv: 0.6516\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1395, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.5979\n",
      "Epoch [144/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2184, D_X Fake: 0.0890, D_X Total: 0.1537\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0444, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.8984, F Adv: 0.6722\n",
      "  Cycle Photo: 0.0469, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1769, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 4.0645\n",
      "Epoch [144/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0646, D_X Fake: 0.1192, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0336, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 1.0746, F Adv: 0.5267\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.8343\n",
      "Epoch [144/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1214, D_X Fake: 0.0968, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0710, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.7114, F Adv: 0.5786\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1248, Perceptual Monet: 0.1725\n",
      "  Total G Loss: 3.2939\n",
      "Epoch [144/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0813, D_X Fake: 0.0671, D_X Total: 0.0742\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0510, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.6235, F Adv: 0.6375\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1806, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 3.7460\n",
      "Epoch [144/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0971, D_X Fake: 0.1098, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0656, D_Y Total: 0.0473\n",
      "Generator Losses:\n",
      "  G Adv: 0.7311, F Adv: 0.5219\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1882\n",
      "  Total G Loss: 3.5674\n",
      "Epoch [144/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1881, D_X Fake: 0.1029, D_X Total: 0.1455\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0473, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9987, F Adv: 0.5530\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1707, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 4.0015\n",
      "Epoch [144/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1173, D_X Fake: 0.0611, D_X Total: 0.0892\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0326, D_Y Total: 0.0244\n",
      "Generator Losses:\n",
      "  G Adv: 0.9700, F Adv: 0.5976\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.6516\n",
      "Epoch [144/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1200, D_X Fake: 0.1075, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0724, D_Y Total: 0.0461\n",
      "Generator Losses:\n",
      "  G Adv: 0.7370, F Adv: 0.5551\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.3178\n",
      "Epoch [144/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1119, D_X Fake: 0.0741, D_X Total: 0.0930\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0416, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.8994, F Adv: 0.5820\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1727, Perceptual Monet: 0.1472\n",
      "  Total G Loss: 3.7233\n",
      "Epoch [144/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1418, D_X Fake: 0.1262, D_X Total: 0.1340\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0371, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 1.0386, F Adv: 0.4925\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1650, Perceptual Monet: 0.1508\n",
      "  Total G Loss: 3.7260\n",
      "Epoch [145/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1937, D_X Fake: 0.1691, D_X Total: 0.1814\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0341, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9368, F Adv: 0.6513\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.7273\n",
      "Epoch [145/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1311, D_X Fake: 0.0901, D_X Total: 0.1106\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0715, D_Y Total: 0.0506\n",
      "Generator Losses:\n",
      "  G Adv: 0.7794, F Adv: 0.7279\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1173, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 3.3917\n",
      "Epoch [145/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0953, D_X Fake: 0.2040, D_X Total: 0.1496\n",
      "  D_Y Real: 0.0385, D_Y Fake: 0.0363, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 1.2137, F Adv: 0.4374\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1463\n",
      "  Total G Loss: 3.7614\n",
      "Epoch [145/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0951, D_X Fake: 0.0795, D_X Total: 0.0873\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0577, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.9651, F Adv: 0.6757\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.7115\n",
      "Epoch [145/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1229, D_X Fake: 0.0944, D_X Total: 0.1086\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.1042, D_Y Total: 0.0714\n",
      "Generator Losses:\n",
      "  G Adv: 0.9840, F Adv: 0.5847\n",
      "  Cycle Photo: 0.0580, Cycle Monet: 0.0218\n",
      "  Perceptual Photo: 0.1970, Perceptual Monet: 0.1427\n",
      "  Total G Loss: 4.0652\n",
      "Epoch [145/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.1442, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0389, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.8589, F Adv: 0.5529\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1477, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.4883\n",
      "Epoch [145/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1091, D_X Fake: 0.1534, D_X Total: 0.1312\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0457, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.9594, F Adv: 0.5038\n",
      "  Cycle Photo: 0.0205, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1129, Perceptual Monet: 0.1896\n",
      "  Total G Loss: 3.5207\n",
      "Epoch [145/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1391, D_X Fake: 0.1130, D_X Total: 0.1260\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0468, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.8111, F Adv: 0.5440\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1449, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.5503\n",
      "Epoch [145/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1645, D_X Fake: 0.0673, D_X Total: 0.1159\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.0431, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.9612, F Adv: 0.5133\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.5594\n",
      "Epoch [145/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1693, D_X Fake: 0.0486, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0417, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.5964, F Adv: 0.6921\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1787\n",
      "  Total G Loss: 3.5934\n",
      "Epoch [145/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1000, D_X Fake: 0.1145, D_X Total: 0.1073\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.1032, D_Y Total: 0.0608\n",
      "Generator Losses:\n",
      "  G Adv: 0.5913, F Adv: 0.6025\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1520\n",
      "  Total G Loss: 3.0668\n",
      "Epoch [145/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1354, D_X Fake: 0.0659, D_X Total: 0.1007\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0343, D_Y Total: 0.0267\n",
      "Generator Losses:\n",
      "  G Adv: 1.0464, F Adv: 0.6811\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.9278\n",
      "Epoch [145/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1327, D_X Fake: 0.1153, D_X Total: 0.1240\n",
      "  D_Y Real: 0.0466, D_Y Fake: 0.0334, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.9963, F Adv: 0.5808\n",
      "  Cycle Photo: 0.0417, Cycle Monet: 0.0471\n",
      "  Perceptual Photo: 0.1607, Perceptual Monet: 0.2469\n",
      "  Total G Loss: 4.5031\n",
      "Epoch [145/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0871, D_X Fake: 0.1847, D_X Total: 0.1359\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0607, D_Y Total: 0.0503\n",
      "Generator Losses:\n",
      "  G Adv: 1.1557, F Adv: 0.4794\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1578\n",
      "  Total G Loss: 3.7716\n",
      "Epoch [145/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0672, D_X Fake: 0.1759, D_X Total: 0.1215\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0378, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.9318, F Adv: 0.3793\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1091, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.1089\n",
      "Epoch [145/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0955, D_X Fake: 0.1632, D_X Total: 0.1294\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0402, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8804, F Adv: 0.6662\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.7428\n",
      "Epoch [145/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2389, D_X Fake: 0.0735, D_X Total: 0.1562\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.1067, D_Y Total: 0.0641\n",
      "Generator Losses:\n",
      "  G Adv: 0.8523, F Adv: 0.6707\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.7919\n",
      "Epoch [145/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1018, D_X Fake: 0.1185, D_X Total: 0.1101\n",
      "  D_Y Real: 0.0730, D_Y Fake: 0.0362, D_Y Total: 0.0546\n",
      "Generator Losses:\n",
      "  G Adv: 0.9273, F Adv: 0.5899\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1864\n",
      "  Total G Loss: 3.7316\n",
      "Epoch [145/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0714, D_X Fake: 0.1031, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0404, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 0.8398, F Adv: 0.5762\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1468\n",
      "  Total G Loss: 3.3407\n",
      "Epoch [145/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0602, D_X Fake: 0.0487, D_X Total: 0.0544\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0391, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.9405, F Adv: 0.7349\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1365, Perceptual Monet: 0.1941\n",
      "  Total G Loss: 3.9553\n",
      "Epoch [145/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1551, D_X Fake: 0.1461, D_X Total: 0.1506\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0305, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.9158, F Adv: 0.4740\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.2064\n",
      "  Total G Loss: 3.7125\n",
      "Epoch [145/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1259, D_X Fake: 0.0874, D_X Total: 0.1067\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0450, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 1.0679, F Adv: 0.5911\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1306, Perceptual Monet: 0.1595\n",
      "  Total G Loss: 3.6606\n",
      "Epoch [145/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1022, D_X Fake: 0.1156, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0352, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 1.0044, F Adv: 0.4669\n",
      "  Cycle Photo: 0.0205, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1011, Perceptual Monet: 0.1371\n",
      "  Total G Loss: 3.1049\n",
      "Epoch [145/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0699, D_X Fake: 0.0587, D_X Total: 0.0643\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0387, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.8494, F Adv: 0.6608\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1725\n",
      "  Total G Loss: 3.5311\n",
      "Epoch [146/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1519, D_X Fake: 0.0918, D_X Total: 0.1218\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0418, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.7016, F Adv: 0.6352\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.3831\n",
      "Epoch [146/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1348, D_X Fake: 0.1002, D_X Total: 0.1175\n",
      "  D_Y Real: 0.0389, D_Y Fake: 0.0346, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 1.0697, F Adv: 0.5874\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.8620\n",
      "Epoch [146/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1421, D_X Fake: 0.1741, D_X Total: 0.1581\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0640, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.8810, F Adv: 0.4810\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1528, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 3.4894\n",
      "Epoch [146/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1540, D_X Fake: 0.0552, D_X Total: 0.1046\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.0475, D_Y Total: 0.0420\n",
      "Generator Losses:\n",
      "  G Adv: 0.9118, F Adv: 0.6794\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1171, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.6007\n",
      "Epoch [146/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1204, D_X Fake: 0.0906, D_X Total: 0.1055\n",
      "  D_Y Real: 0.0470, D_Y Fake: 0.0576, D_Y Total: 0.0523\n",
      "Generator Losses:\n",
      "  G Adv: 0.8758, F Adv: 0.5550\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.1903\n",
      "  Total G Loss: 3.6440\n",
      "Epoch [146/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1704, D_X Fake: 0.0735, D_X Total: 0.1219\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0299, D_Y Total: 0.0234\n",
      "Generator Losses:\n",
      "  G Adv: 0.9404, F Adv: 0.5706\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.4804\n",
      "Epoch [146/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1426, D_X Fake: 0.0871, D_X Total: 0.1149\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0813, D_Y Total: 0.0497\n",
      "Generator Losses:\n",
      "  G Adv: 0.7901, F Adv: 0.7564\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.6320\n",
      "Epoch [146/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2354, D_X Fake: 0.1066, D_X Total: 0.1710\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0686, D_Y Total: 0.0508\n",
      "Generator Losses:\n",
      "  G Adv: 0.7450, F Adv: 0.7146\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1712\n",
      "  Total G Loss: 3.7093\n",
      "Epoch [146/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3089, D_X Fake: 0.0787, D_X Total: 0.1938\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0609, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.7946, F Adv: 0.5290\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1583\n",
      "  Total G Loss: 3.4649\n",
      "Epoch [146/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0696, D_X Fake: 0.0944, D_X Total: 0.0820\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0402, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 1.0622, F Adv: 0.6757\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1310, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.7313\n",
      "Epoch [146/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1338, D_X Fake: 0.1557, D_X Total: 0.1448\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0552, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.7784, F Adv: 0.5105\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1521, Perceptual Monet: 0.1902\n",
      "  Total G Loss: 3.5944\n",
      "Epoch [146/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0529, D_X Fake: 0.0738, D_X Total: 0.0634\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0314, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.7873, F Adv: 0.7057\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.6469\n",
      "Epoch [146/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1696, D_X Fake: 0.0697, D_X Total: 0.1197\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0574, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.7957, F Adv: 0.6154\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1818, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.7542\n",
      "Epoch [146/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1890, D_X Fake: 0.0331, D_X Total: 0.1110\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0398, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 1.0049, F Adv: 0.6852\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1349, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.6567\n",
      "Epoch [146/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1523, D_X Fake: 0.1008, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0688, D_Y Total: 0.0485\n",
      "Generator Losses:\n",
      "  G Adv: 0.9365, F Adv: 0.6139\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1227, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.6478\n",
      "Epoch [146/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1062, D_X Fake: 0.1113, D_X Total: 0.1087\n",
      "  D_Y Real: 0.0424, D_Y Fake: 0.0469, D_Y Total: 0.0446\n",
      "Generator Losses:\n",
      "  G Adv: 0.9513, F Adv: 0.6158\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1787\n",
      "  Total G Loss: 3.8082\n",
      "Epoch [146/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1090, D_X Fake: 0.1509, D_X Total: 0.1300\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0552, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 1.1144, F Adv: 0.5636\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1914\n",
      "  Total G Loss: 3.9778\n",
      "Epoch [146/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1956, D_X Fake: 0.0796, D_X Total: 0.1376\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0594, D_Y Total: 0.0445\n",
      "Generator Losses:\n",
      "  G Adv: 0.7740, F Adv: 0.6469\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.6857\n",
      "Epoch [146/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1565, D_X Fake: 0.1268, D_X Total: 0.1416\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0801, D_Y Total: 0.0599\n",
      "Generator Losses:\n",
      "  G Adv: 0.7524, F Adv: 0.5851\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1761, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.5737\n",
      "Epoch [146/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3437, D_X Fake: 0.0468, D_X Total: 0.1953\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0605, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.8137, F Adv: 0.7761\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1614, Perceptual Monet: 0.1924\n",
      "  Total G Loss: 3.9891\n",
      "Epoch [146/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1101, D_X Fake: 0.1085, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0465, D_Y Total: 0.0439\n",
      "Generator Losses:\n",
      "  G Adv: 0.9191, F Adv: 0.5571\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1481, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.7237\n",
      "Epoch [146/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1042, D_X Fake: 0.1020, D_X Total: 0.1031\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0532, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.7771, F Adv: 0.5303\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1267, Perceptual Monet: 0.1441\n",
      "  Total G Loss: 3.1376\n",
      "Epoch [146/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1488, D_X Fake: 0.0846, D_X Total: 0.1167\n",
      "  D_Y Real: 0.0496, D_Y Fake: 0.0385, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 0.7796, F Adv: 0.6286\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0362\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1849\n",
      "  Total G Loss: 3.5911\n",
      "Epoch [146/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1990, D_X Fake: 0.0813, D_X Total: 0.1402\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0573, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.9209, F Adv: 0.6280\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1713, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.7865\n",
      "Epoch [147/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0700, D_X Fake: 0.1683, D_X Total: 0.1191\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0654, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.7133, F Adv: 0.4670\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.3508\n",
      "Epoch [147/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2381, D_X Fake: 0.1122, D_X Total: 0.1752\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0654, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.8701, F Adv: 0.4207\n",
      "  Cycle Photo: 0.0424, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.2003, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.9924\n",
      "Epoch [147/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0935, D_X Fake: 0.0781, D_X Total: 0.0858\n",
      "  D_Y Real: 0.0425, D_Y Fake: 0.0454, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 0.9000, F Adv: 0.6359\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1557, Perceptual Monet: 0.1855\n",
      "  Total G Loss: 3.9138\n",
      "Epoch [147/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0901, D_X Fake: 0.0701, D_X Total: 0.0801\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0434, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8485, F Adv: 0.6999\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1416, Perceptual Monet: 0.1538\n",
      "  Total G Loss: 3.5160\n",
      "Epoch [147/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0990, D_X Fake: 0.0775, D_X Total: 0.0882\n",
      "  D_Y Real: 0.0631, D_Y Fake: 0.0561, D_Y Total: 0.0596\n",
      "Generator Losses:\n",
      "  G Adv: 0.7801, F Adv: 0.6833\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1279, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.5565\n",
      "Epoch [147/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1646, D_X Fake: 0.0682, D_X Total: 0.1164\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.0313, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 1.0682, F Adv: 0.5303\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1203, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.5120\n",
      "Epoch [147/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2969, D_X Fake: 0.1054, D_X Total: 0.2011\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.1003, D_Y Total: 0.0626\n",
      "Generator Losses:\n",
      "  G Adv: 0.7760, F Adv: 0.4951\n",
      "  Cycle Photo: 0.0438, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1515\n",
      "  Total G Loss: 3.3685\n",
      "Epoch [147/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0977, D_X Fake: 0.0930, D_X Total: 0.0954\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0549, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.9330, F Adv: 0.6499\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1191, Perceptual Monet: 0.1628\n",
      "  Total G Loss: 3.6011\n",
      "Epoch [147/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1848, D_X Fake: 0.0951, D_X Total: 0.1399\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0429, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.9440, F Adv: 0.5914\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1735, Perceptual Monet: 0.1856\n",
      "  Total G Loss: 3.9455\n",
      "Epoch [147/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0742, D_X Fake: 0.1000, D_X Total: 0.0871\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.1421, D_Y Total: 0.0858\n",
      "Generator Losses:\n",
      "  G Adv: 0.8416, F Adv: 0.6508\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1594, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.7400\n",
      "Epoch [147/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1330, D_X Fake: 0.1455, D_X Total: 0.1392\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0508, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.8810, F Adv: 0.5655\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1316, Perceptual Monet: 0.1835\n",
      "  Total G Loss: 3.6386\n",
      "Epoch [147/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0889, D_X Fake: 0.0697, D_X Total: 0.0793\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0533, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 0.7259, F Adv: 0.7102\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1230, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.5092\n",
      "Epoch [147/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2491, D_X Fake: 0.1142, D_X Total: 0.1816\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0361, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 0.8196, F Adv: 0.4878\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1500, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.6122\n",
      "Epoch [147/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2136, D_X Fake: 0.0981, D_X Total: 0.1559\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0373, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.9597, F Adv: 0.5753\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1578\n",
      "  Total G Loss: 3.5955\n",
      "Epoch [147/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2327, D_X Fake: 0.1297, D_X Total: 0.1812\n",
      "  D_Y Real: 0.0218, D_Y Fake: 0.0318, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 0.9265, F Adv: 0.5096\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.6135\n",
      "Epoch [147/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1558, D_X Fake: 0.1089, D_X Total: 0.1324\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0558, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.7925, F Adv: 0.5185\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.4437\n",
      "Epoch [147/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1133, D_X Fake: 0.1277, D_X Total: 0.1205\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0414, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 1.0102, F Adv: 0.6233\n",
      "  Cycle Photo: 0.0219, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1164, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.5524\n",
      "Epoch [147/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0734, D_X Fake: 0.1336, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0513, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.9401, F Adv: 0.4931\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1697\n",
      "  Total G Loss: 3.7954\n",
      "Epoch [147/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2749, D_X Fake: 0.0891, D_X Total: 0.1820\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0360, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.9762, F Adv: 0.6367\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.5789\n",
      "Epoch [147/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1313, D_X Fake: 0.1092, D_X Total: 0.1202\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0387, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9893, F Adv: 0.4392\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1437, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 3.8333\n",
      "Epoch [147/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1429, D_X Fake: 0.0784, D_X Total: 0.1106\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0374, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9756, F Adv: 0.6244\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1322, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.6784\n",
      "Epoch [147/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2891, D_X Fake: 0.1458, D_X Total: 0.2174\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0657, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.8220, F Adv: 0.4611\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0205\n",
      "  Perceptual Photo: 0.1429, Perceptual Monet: 0.1268\n",
      "  Total G Loss: 3.0920\n",
      "Epoch [147/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1525, D_X Fake: 0.0563, D_X Total: 0.1044\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0366, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.9083, F Adv: 0.7662\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1939\n",
      "  Total G Loss: 3.8763\n",
      "Epoch [147/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2093, D_X Fake: 0.1056, D_X Total: 0.1575\n",
      "  D_Y Real: 0.0406, D_Y Fake: 0.0365, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.9313, F Adv: 0.5417\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.5968\n",
      "Epoch [148/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1638, D_X Fake: 0.1106, D_X Total: 0.1372\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0374, D_Y Total: 0.0291\n",
      "Generator Losses:\n",
      "  G Adv: 0.8224, F Adv: 0.6293\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0212\n",
      "  Perceptual Photo: 0.1084, Perceptual Monet: 0.1297\n",
      "  Total G Loss: 3.0903\n",
      "Epoch [148/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1310, D_X Fake: 0.0748, D_X Total: 0.1029\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0486, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 1.0185, F Adv: 0.5936\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1395, Perceptual Monet: 0.1731\n",
      "  Total G Loss: 3.7251\n",
      "Epoch [148/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1505, D_X Fake: 0.0941, D_X Total: 0.1223\n",
      "  D_Y Real: 0.0739, D_Y Fake: 0.0444, D_Y Total: 0.0592\n",
      "Generator Losses:\n",
      "  G Adv: 0.7667, F Adv: 0.5972\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1061, Perceptual Monet: 0.1697\n",
      "  Total G Loss: 3.2861\n",
      "Epoch [148/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1350, D_X Fake: 0.0797, D_X Total: 0.1073\n",
      "  D_Y Real: 0.0600, D_Y Fake: 0.0937, D_Y Total: 0.0768\n",
      "Generator Losses:\n",
      "  G Adv: 0.8528, F Adv: 0.7620\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 4.0022\n",
      "Epoch [148/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0420, D_X Fake: 0.0869, D_X Total: 0.0645\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.0393, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8697, F Adv: 0.5494\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1300, Perceptual Monet: 0.1887\n",
      "  Total G Loss: 3.6304\n",
      "Epoch [148/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0984, D_X Fake: 0.1215, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0381, D_Y Fake: 0.0303, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.9898, F Adv: 0.4933\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0417\n",
      "  Perceptual Photo: 0.1656, Perceptual Monet: 0.2101\n",
      "  Total G Loss: 4.1369\n",
      "Epoch [148/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0986, D_X Fake: 0.1108, D_X Total: 0.1047\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0764, D_Y Total: 0.0480\n",
      "Generator Losses:\n",
      "  G Adv: 0.9610, F Adv: 0.4976\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.6927\n",
      "Epoch [148/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1203, D_X Fake: 0.1051, D_X Total: 0.1127\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0438, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.9208, F Adv: 0.5976\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1568, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 3.8590\n",
      "Epoch [148/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1246, D_X Fake: 0.1570, D_X Total: 0.1408\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0484, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8545, F Adv: 0.4999\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1969\n",
      "  Total G Loss: 3.8475\n",
      "Epoch [148/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0841, D_X Fake: 0.0488, D_X Total: 0.0664\n",
      "  D_Y Real: 0.0143, D_Y Fake: 0.0561, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 0.7737, F Adv: 0.7826\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1482, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.6726\n",
      "Epoch [148/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1407, D_X Fake: 0.0481, D_X Total: 0.0944\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0406, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.9760, F Adv: 0.6839\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.1535\n",
      "  Total G Loss: 3.7905\n",
      "Epoch [148/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0471, D_X Fake: 0.0813, D_X Total: 0.0642\n",
      "  D_Y Real: 0.0159, D_Y Fake: 0.0392, D_Y Total: 0.0275\n",
      "Generator Losses:\n",
      "  G Adv: 0.9700, F Adv: 0.5528\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1346, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.5035\n",
      "Epoch [148/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0749, D_X Fake: 0.0775, D_X Total: 0.0762\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0431, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 1.0360, F Adv: 0.6059\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.0895, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.5100\n",
      "Epoch [148/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1271, D_X Fake: 0.0577, D_X Total: 0.0924\n",
      "  D_Y Real: 0.0393, D_Y Fake: 0.0321, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 1.0327, F Adv: 0.6035\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.7222\n",
      "Epoch [148/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0857, D_X Fake: 0.1135, D_X Total: 0.0996\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0405, D_Y Total: 0.0319\n",
      "Generator Losses:\n",
      "  G Adv: 0.7909, F Adv: 0.5364\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.5952\n",
      "Epoch [148/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2820, D_X Fake: 0.1218, D_X Total: 0.2019\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0755, D_Y Total: 0.0492\n",
      "Generator Losses:\n",
      "  G Adv: 0.7375, F Adv: 0.5134\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0226\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1491\n",
      "  Total G Loss: 3.3112\n",
      "Epoch [148/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1500, D_X Fake: 0.0810, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0383, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.9511, F Adv: 0.5210\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1916, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.9737\n",
      "Epoch [148/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1227, D_X Fake: 0.1570, D_X Total: 0.1398\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0632, D_Y Total: 0.0470\n",
      "Generator Losses:\n",
      "  G Adv: 0.8571, F Adv: 0.4939\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.6284\n",
      "Epoch [148/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1814, D_X Fake: 0.0483, D_X Total: 0.1148\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0374, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9374, F Adv: 0.6882\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1379, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.7557\n",
      "Epoch [148/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1499, D_X Fake: 0.0582, D_X Total: 0.1040\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0509, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8076, F Adv: 0.6481\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1756, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 3.8660\n",
      "Epoch [148/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1709, D_X Fake: 0.0795, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0614, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.9222, F Adv: 0.5743\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1467\n",
      "  Total G Loss: 3.4191\n",
      "Epoch [148/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1593, D_X Fake: 0.1614, D_X Total: 0.1603\n",
      "  D_Y Real: 0.0518, D_Y Fake: 0.0433, D_Y Total: 0.0476\n",
      "Generator Losses:\n",
      "  G Adv: 0.9417, F Adv: 0.4867\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1757, Perceptual Monet: 0.1663\n",
      "  Total G Loss: 3.8064\n",
      "Epoch [148/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0529, D_X Fake: 0.1593, D_X Total: 0.1061\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0518, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.7282, F Adv: 0.5714\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1183, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.3563\n",
      "Epoch [148/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1260, D_X Fake: 0.1356, D_X Total: 0.1308\n",
      "  D_Y Real: 0.0321, D_Y Fake: 0.0426, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8965, F Adv: 0.5218\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1622, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.7670\n",
      "Epoch [149/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1901, D_X Fake: 0.1008, D_X Total: 0.1455\n",
      "  D_Y Real: 0.0331, D_Y Fake: 0.0333, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 1.0214, F Adv: 0.6411\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1189, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.6096\n",
      "Epoch [149/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1010, D_X Fake: 0.0993, D_X Total: 0.1002\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0405, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.9064, F Adv: 0.4888\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1269, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 3.3479\n",
      "Epoch [149/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0903, D_X Fake: 0.0752, D_X Total: 0.0827\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0375, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8347, F Adv: 0.7499\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1012, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.4613\n",
      "Epoch [149/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1153, D_X Fake: 0.1367, D_X Total: 0.1260\n",
      "  D_Y Real: 0.0483, D_Y Fake: 0.0342, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 1.0410, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1924, Perceptual Monet: 0.1557\n",
      "  Total G Loss: 3.9361\n",
      "Epoch [149/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1477, D_X Fake: 0.0647, D_X Total: 0.1062\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0436, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9051, F Adv: 0.5794\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1282, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.5918\n",
      "Epoch [149/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1186, D_X Fake: 0.1162, D_X Total: 0.1174\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0387, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 1.2565, F Adv: 0.6299\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1962\n",
      "  Total G Loss: 4.4354\n",
      "Epoch [149/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2622, D_X Fake: 0.0786, D_X Total: 0.1704\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0444, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.8199, F Adv: 0.7430\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1024, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 3.4073\n",
      "Epoch [149/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.0833, D_X Total: 0.1013\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0441, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.8428, F Adv: 0.5822\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 3.7237\n",
      "Epoch [149/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1191, D_X Fake: 0.0407, D_X Total: 0.0799\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0580, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8200, F Adv: 0.8835\n",
      "  Cycle Photo: 0.0220, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1274, Perceptual Monet: 0.1993\n",
      "  Total G Loss: 3.9150\n",
      "Epoch [149/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1265, D_X Fake: 0.1181, D_X Total: 0.1223\n",
      "  D_Y Real: 0.0152, D_Y Fake: 0.0509, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.8507, F Adv: 0.5555\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1117, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.2832\n",
      "Epoch [149/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0795, D_X Fake: 0.1101, D_X Total: 0.0948\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0348, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9894, F Adv: 0.6061\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1171, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.5346\n",
      "Epoch [149/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0819, D_X Fake: 0.1044, D_X Total: 0.0931\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0494, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.9062, F Adv: 0.5986\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.2118\n",
      "  Total G Loss: 3.9259\n",
      "Epoch [149/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2126, D_X Fake: 0.0694, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0496, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8036, F Adv: 0.6618\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1450, Perceptual Monet: 0.1721\n",
      "  Total G Loss: 3.5647\n",
      "Epoch [149/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0991, D_X Fake: 0.0623, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0640, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.6477, F Adv: 0.7313\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0471\n",
      "  Perceptual Photo: 0.1206, Perceptual Monet: 0.2130\n",
      "  Total G Loss: 3.7674\n",
      "Epoch [149/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1452, D_X Fake: 0.1013, D_X Total: 0.1233\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0373, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.7588, F Adv: 0.5973\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1845\n",
      "  Total G Loss: 3.5641\n",
      "Epoch [149/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1715, D_X Fake: 0.0942, D_X Total: 0.1329\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0560, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 1.0789, F Adv: 0.5829\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.8051\n",
      "Epoch [149/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1879, D_X Fake: 0.1156, D_X Total: 0.1518\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0421, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.9262, F Adv: 0.5324\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1380, Perceptual Monet: 0.1400\n",
      "  Total G Loss: 3.3386\n",
      "Epoch [149/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0650, D_X Fake: 0.1317, D_X Total: 0.0983\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0466, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.8518, F Adv: 0.5771\n",
      "  Cycle Photo: 0.0326, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1180, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.5533\n",
      "Epoch [149/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1369, D_X Fake: 0.1139, D_X Total: 0.1254\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0398, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.7748, F Adv: 0.6444\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1961\n",
      "  Total G Loss: 3.8239\n",
      "Epoch [149/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1774, D_X Fake: 0.1082, D_X Total: 0.1428\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0571, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.7163, F Adv: 0.5021\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1707\n",
      "  Total G Loss: 3.3948\n",
      "Epoch [149/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.1555, D_X Total: 0.1435\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0331, D_Y Total: 0.0289\n",
      "Generator Losses:\n",
      "  G Adv: 0.9284, F Adv: 0.4440\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1343, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.4955\n",
      "Epoch [149/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1532, D_X Fake: 0.1079, D_X Total: 0.1306\n",
      "  D_Y Real: 0.0462, D_Y Fake: 0.0364, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.9940, F Adv: 0.5956\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1712, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 3.9476\n",
      "Epoch [149/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2062, D_X Fake: 0.0435, D_X Total: 0.1248\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0794, D_Y Total: 0.0493\n",
      "Generator Losses:\n",
      "  G Adv: 0.7540, F Adv: 0.7946\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.1666\n",
      "  Total G Loss: 3.7998\n",
      "Epoch [149/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2242, D_X Fake: 0.1043, D_X Total: 0.1642\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0378, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.9901, F Adv: 0.5970\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1584, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 3.8957\n",
      "Epoch [150/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0628, D_X Fake: 0.1009, D_X Total: 0.0818\n",
      "  D_Y Real: 0.0406, D_Y Fake: 0.0351, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 0.8936, F Adv: 0.6203\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1750\n",
      "  Total G Loss: 3.7181\n",
      "Epoch [150/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1803, D_X Fake: 0.0872, D_X Total: 0.1337\n",
      "  D_Y Real: 0.0445, D_Y Fake: 0.0358, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.9670, F Adv: 0.5533\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1396, Perceptual Monet: 0.1888\n",
      "  Total G Loss: 3.7982\n",
      "Epoch [150/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1629, D_X Fake: 0.1370, D_X Total: 0.1499\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0956, D_Y Total: 0.0600\n",
      "Generator Losses:\n",
      "  G Adv: 0.9717, F Adv: 0.4116\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1317, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.3727\n",
      "Epoch [150/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0573, D_X Fake: 0.0540, D_X Total: 0.0556\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0867, D_Y Total: 0.0561\n",
      "Generator Losses:\n",
      "  G Adv: 0.8567, F Adv: 0.6361\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1181, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.4228\n",
      "Epoch [150/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1531, D_X Fake: 0.1161, D_X Total: 0.1346\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0489, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.8196, F Adv: 0.4929\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.5517\n",
      "Epoch [150/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1106, D_X Fake: 0.1140, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0422, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 1.1055, F Adv: 0.5376\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1705, Perceptual Monet: 0.1789\n",
      "  Total G Loss: 4.0351\n",
      "Epoch [150/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0646, D_X Fake: 0.0969, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0691, D_Y Total: 0.0493\n",
      "Generator Losses:\n",
      "  G Adv: 0.8614, F Adv: 0.5385\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1460, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.4787\n",
      "Epoch [150/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1382, D_X Fake: 0.0925, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.1037, D_Y Total: 0.0652\n",
      "Generator Losses:\n",
      "  G Adv: 0.9957, F Adv: 0.6118\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 3.7426\n",
      "Epoch [150/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2833, D_X Fake: 0.0865, D_X Total: 0.1849\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0533, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.9240, F Adv: 0.4612\n",
      "  Cycle Photo: 0.0218, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 3.2949\n",
      "Epoch [150/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1299, D_X Fake: 0.0775, D_X Total: 0.1037\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0764, D_Y Total: 0.0489\n",
      "Generator Losses:\n",
      "  G Adv: 0.8685, F Adv: 0.5516\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1217, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.3334\n",
      "Epoch [150/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1659, D_X Fake: 0.0585, D_X Total: 0.1122\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0423, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.7975, F Adv: 0.6390\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.5902\n",
      "Epoch [150/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.0970, D_X Total: 0.0963\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0680, D_Y Total: 0.0502\n",
      "Generator Losses:\n",
      "  G Adv: 0.8111, F Adv: 0.5990\n",
      "  Cycle Photo: 0.0384, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1610, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.6640\n",
      "Epoch [150/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2668, D_X Fake: 0.1531, D_X Total: 0.2099\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0478, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.9235, F Adv: 0.5036\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.5006\n",
      "Epoch [150/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1994, D_X Fake: 0.0978, D_X Total: 0.1486\n",
      "  D_Y Real: 0.0435, D_Y Fake: 0.0508, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.7627, F Adv: 0.5702\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1120, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.3061\n",
      "Epoch [150/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0717, D_X Fake: 0.1028, D_X Total: 0.0872\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.0321, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.8705, F Adv: 0.4982\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0180\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1159\n",
      "  Total G Loss: 3.0740\n",
      "Epoch [150/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1567, D_X Fake: 0.1255, D_X Total: 0.1411\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0402, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 1.0825, F Adv: 0.4773\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.6601\n",
      "Epoch [150/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1237, D_X Fake: 0.1051, D_X Total: 0.1144\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0404, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8148, F Adv: 0.5544\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1187, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.1633\n",
      "Epoch [150/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1234, D_X Fake: 0.2172, D_X Total: 0.1703\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0482, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 1.0703, F Adv: 0.4170\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1284, Perceptual Monet: 0.1586\n",
      "  Total G Loss: 3.3975\n",
      "Epoch [150/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1425, D_X Fake: 0.0797, D_X Total: 0.1111\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0346, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.8911, F Adv: 0.6334\n",
      "  Cycle Photo: 0.0213, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1220, Perceptual Monet: 0.1949\n",
      "  Total G Loss: 3.6715\n",
      "Epoch [150/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0854, D_X Fake: 0.1369, D_X Total: 0.1112\n",
      "  D_Y Real: 0.0436, D_Y Fake: 0.0443, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 0.9767, F Adv: 0.4315\n",
      "  Cycle Photo: 0.0219, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1513\n",
      "  Total G Loss: 3.2413\n",
      "Epoch [150/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1608, D_X Fake: 0.0807, D_X Total: 0.1208\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0770, D_Y Total: 0.0580\n",
      "Generator Losses:\n",
      "  G Adv: 0.8503, F Adv: 0.5441\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.5701\n",
      "Epoch [150/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0905, D_X Fake: 0.1497, D_X Total: 0.1201\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0413, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 1.0040, F Adv: 0.4983\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.6810\n",
      "Epoch [150/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.1057, D_X Total: 0.1186\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0549, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 0.9453, F Adv: 0.4381\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1670, Perceptual Monet: 0.1363\n",
      "  Total G Loss: 3.4851\n",
      "Epoch [150/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1306, D_X Fake: 0.0764, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0337, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.9786, F Adv: 0.6509\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0412\n",
      "  Perceptual Photo: 0.1634, Perceptual Monet: 0.2008\n",
      "  Total G Loss: 4.1864\n",
      "Epoch [151/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1238, D_X Fake: 0.1027, D_X Total: 0.1133\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0349, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.9937, F Adv: 0.5754\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.6956\n",
      "Epoch [151/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1143, D_X Fake: 0.1065, D_X Total: 0.1104\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0307, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 1.1539, F Adv: 0.6523\n",
      "  Cycle Photo: 0.0199, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1179, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 3.8080\n",
      "Epoch [151/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1166, D_X Fake: 0.0866, D_X Total: 0.1016\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.0368, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 1.0204, F Adv: 0.7144\n",
      "  Cycle Photo: 0.0215, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.0997, Perceptual Monet: 0.1495\n",
      "  Total G Loss: 3.4490\n",
      "Epoch [151/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1286, D_X Fake: 0.1111, D_X Total: 0.1198\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.0378, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 1.0405, F Adv: 0.6314\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 3.9862\n",
      "Epoch [151/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0500, D_X Fake: 0.1381, D_X Total: 0.0940\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0345, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 1.1327, F Adv: 0.5580\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1592\n",
      "  Total G Loss: 3.7144\n",
      "Epoch [151/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0615, D_X Fake: 0.1206, D_X Total: 0.0911\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0378, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.9550, F Adv: 0.4721\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1531, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.5856\n",
      "Epoch [151/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2228, D_X Fake: 0.0812, D_X Total: 0.1520\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0504, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 1.0202, F Adv: 0.6316\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 3.8931\n",
      "Epoch [151/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3422, D_X Fake: 0.0794, D_X Total: 0.2108\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0318, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.8318, F Adv: 0.6147\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1575\n",
      "  Total G Loss: 3.5207\n",
      "Epoch [151/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1474, D_X Fake: 0.0718, D_X Total: 0.1096\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0458, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.8813, F Adv: 0.8348\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1745\n",
      "  Total G Loss: 3.9981\n",
      "Epoch [151/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.1322, D_X Total: 0.1239\n",
      "  D_Y Real: 0.0583, D_Y Fake: 0.0551, D_Y Total: 0.0567\n",
      "Generator Losses:\n",
      "  G Adv: 0.7444, F Adv: 0.5526\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1706, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.7047\n",
      "Epoch [151/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1891, D_X Fake: 0.1026, D_X Total: 0.1458\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0334, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8579, F Adv: 0.5337\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0202\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1344\n",
      "  Total G Loss: 3.3915\n",
      "Epoch [151/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2888, D_X Fake: 0.0994, D_X Total: 0.1941\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0401, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.8356, F Adv: 0.6732\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1805, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.9079\n",
      "Epoch [151/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0980, D_X Fake: 0.0842, D_X Total: 0.0911\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0380, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 1.0095, F Adv: 0.5090\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1638\n",
      "  Total G Loss: 3.6181\n",
      "Epoch [151/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1158, D_X Fake: 0.1367, D_X Total: 0.1262\n",
      "  D_Y Real: 0.0658, D_Y Fake: 0.0411, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.9935, F Adv: 0.5919\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1890\n",
      "  Total G Loss: 3.8895\n",
      "Epoch [151/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0885, D_X Fake: 0.1035, D_X Total: 0.0960\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0368, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.8057, F Adv: 0.5665\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1206, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 3.4851\n",
      "Epoch [151/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2148, D_X Fake: 0.1687, D_X Total: 0.1917\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0424, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.7804, F Adv: 0.4692\n",
      "  Cycle Photo: 0.0376, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.5685\n",
      "Epoch [151/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0638, D_X Fake: 0.1247, D_X Total: 0.0942\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0634, D_Y Total: 0.0450\n",
      "Generator Losses:\n",
      "  G Adv: 0.8124, F Adv: 0.5493\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1349, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.5935\n",
      "Epoch [151/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2180, D_X Fake: 0.0513, D_X Total: 0.1347\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0833, D_Y Total: 0.0510\n",
      "Generator Losses:\n",
      "  G Adv: 0.6418, F Adv: 0.7317\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.3473\n",
      "Epoch [151/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1320, D_X Fake: 0.1467, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0835, D_Y Total: 0.0520\n",
      "Generator Losses:\n",
      "  G Adv: 0.8058, F Adv: 0.5323\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.3567\n",
      "Epoch [151/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2677, D_X Fake: 0.0783, D_X Total: 0.1730\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0418, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.8513, F Adv: 0.6079\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1219, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.4660\n",
      "Epoch [151/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0466, D_X Fake: 0.1020, D_X Total: 0.0743\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0592, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.7389, F Adv: 0.6551\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.6362\n",
      "Epoch [151/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0546, D_X Fake: 0.0924, D_X Total: 0.0735\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.0382, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.9428, F Adv: 0.5734\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1287, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 3.5048\n",
      "Epoch [151/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1333, D_X Fake: 0.0945, D_X Total: 0.1139\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0451, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 1.0288, F Adv: 0.6524\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1463, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 3.7430\n",
      "Epoch [151/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1324, D_X Fake: 0.1343, D_X Total: 0.1334\n",
      "  D_Y Real: 0.0432, D_Y Fake: 0.0282, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.9202, F Adv: 0.5191\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1275\n",
      "  Total G Loss: 3.2172\n",
      "Epoch [152/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1608, D_X Fake: 0.1145, D_X Total: 0.1376\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0377, D_Y Total: 0.0264\n",
      "Generator Losses:\n",
      "  G Adv: 0.8931, F Adv: 0.6161\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1730, Perceptual Monet: 0.1867\n",
      "  Total G Loss: 3.9357\n",
      "Epoch [152/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1989, D_X Fake: 0.0979, D_X Total: 0.1484\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.0351, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 1.0987, F Adv: 0.6313\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1380, Perceptual Monet: 0.1959\n",
      "  Total G Loss: 3.9912\n",
      "Epoch [152/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1752, D_X Fake: 0.0877, D_X Total: 0.1314\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0344, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.8991, F Adv: 0.6176\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0418\n",
      "  Perceptual Photo: 0.1352, Perceptual Monet: 0.2043\n",
      "  Total G Loss: 3.8870\n",
      "Epoch [152/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0631, D_X Fake: 0.1571, D_X Total: 0.1101\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.0849, D_Y Total: 0.0580\n",
      "Generator Losses:\n",
      "  G Adv: 0.7911, F Adv: 0.4599\n",
      "  Cycle Photo: 0.0194, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1013, Perceptual Monet: 0.1893\n",
      "  Total G Loss: 3.2544\n",
      "Epoch [152/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0474, D_X Fake: 0.0702, D_X Total: 0.0588\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0360, D_Y Total: 0.0264\n",
      "Generator Losses:\n",
      "  G Adv: 0.8430, F Adv: 0.6470\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1057, Perceptual Monet: 0.1457\n",
      "  Total G Loss: 3.2227\n",
      "Epoch [152/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1147, D_X Fake: 0.0716, D_X Total: 0.0931\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0380, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.9301, F Adv: 0.6076\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.6280\n",
      "Epoch [152/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1147, D_X Fake: 0.1147, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0425, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.8154, F Adv: 0.5482\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1417, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.4874\n",
      "Epoch [152/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1601, D_X Fake: 0.1118, D_X Total: 0.1359\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0431, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.8017, F Adv: 0.5514\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1600\n",
      "  Total G Loss: 3.2952\n",
      "Epoch [152/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0628, D_X Fake: 0.0643, D_X Total: 0.0636\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0366, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.9522, F Adv: 0.6892\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1059, Perceptual Monet: 0.1795\n",
      "  Total G Loss: 3.6289\n",
      "Epoch [152/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1595, D_X Fake: 0.1692, D_X Total: 0.1643\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0383, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 1.1291, F Adv: 0.4291\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1944, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 4.0392\n",
      "Epoch [152/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2635, D_X Fake: 0.1318, D_X Total: 0.1977\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0489, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 0.9514, F Adv: 0.7018\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1570, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.7934\n",
      "Epoch [152/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1701, D_X Fake: 0.0964, D_X Total: 0.1332\n",
      "  D_Y Real: 0.0488, D_Y Fake: 0.0689, D_Y Total: 0.0588\n",
      "Generator Losses:\n",
      "  G Adv: 0.6941, F Adv: 0.5949\n",
      "  Cycle Photo: 0.0210, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1068, Perceptual Monet: 0.1480\n",
      "  Total G Loss: 3.0123\n",
      "Epoch [152/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2021, D_X Fake: 0.0643, D_X Total: 0.1332\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0741, D_Y Total: 0.0532\n",
      "Generator Losses:\n",
      "  G Adv: 0.7964, F Adv: 0.6826\n",
      "  Cycle Photo: 0.0490, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.2435, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 4.3151\n",
      "Epoch [152/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0935, D_X Fake: 0.0679, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0463, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.9196, F Adv: 0.6924\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1680, Perceptual Monet: 0.1430\n",
      "  Total G Loss: 3.7403\n",
      "Epoch [152/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1816, D_X Fake: 0.0902, D_X Total: 0.1359\n",
      "  D_Y Real: 0.0164, D_Y Fake: 0.0484, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.8041, F Adv: 0.6016\n",
      "  Cycle Photo: 0.0407, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.7121\n",
      "Epoch [152/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1730, D_X Fake: 0.0668, D_X Total: 0.1199\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0452, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.7975, F Adv: 0.6690\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1609, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.6400\n",
      "Epoch [152/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1054, D_X Fake: 0.0684, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0366, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 1.0523, F Adv: 0.6970\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1238, Perceptual Monet: 0.2009\n",
      "  Total G Loss: 3.9935\n",
      "Epoch [152/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1263, D_X Fake: 0.0686, D_X Total: 0.0974\n",
      "  D_Y Real: 0.0517, D_Y Fake: 0.0909, D_Y Total: 0.0713\n",
      "Generator Losses:\n",
      "  G Adv: 0.6193, F Adv: 0.5760\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1199, Perceptual Monet: 0.1429\n",
      "  Total G Loss: 3.0293\n",
      "Epoch [152/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0901, D_X Fake: 0.1002, D_X Total: 0.0951\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0495, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.9818, F Adv: 0.5930\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1464, Perceptual Monet: 0.1920\n",
      "  Total G Loss: 3.8995\n",
      "Epoch [152/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1799, D_X Fake: 0.0909, D_X Total: 0.1354\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0300, D_Y Total: 0.0251\n",
      "Generator Losses:\n",
      "  G Adv: 0.9044, F Adv: 0.5994\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1794\n",
      "  Total G Loss: 3.7523\n",
      "Epoch [152/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2027, D_X Fake: 0.0814, D_X Total: 0.1420\n",
      "  D_Y Real: 0.0392, D_Y Fake: 0.0433, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.9491, F Adv: 0.6780\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1832, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 4.1286\n",
      "Epoch [152/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0950, D_X Fake: 0.1270, D_X Total: 0.1110\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0460, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 1.0350, F Adv: 0.4692\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1107, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.4055\n",
      "Epoch [152/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1770, D_X Fake: 0.0552, D_X Total: 0.1161\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0598, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.8008, F Adv: 0.7464\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.6637\n",
      "Epoch [152/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2333, D_X Fake: 0.1150, D_X Total: 0.1741\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0962, D_Y Total: 0.0572\n",
      "Generator Losses:\n",
      "  G Adv: 0.7189, F Adv: 0.3923\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1272, Perceptual Monet: 0.1499\n",
      "  Total G Loss: 3.0100\n",
      "Epoch [153/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2297, D_X Fake: 0.1377, D_X Total: 0.1837\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0567, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.7640, F Adv: 0.4208\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1565, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.4040\n",
      "Epoch [153/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0801, D_X Fake: 0.1046, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0145, D_Y Fake: 0.0423, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 1.0471, F Adv: 0.5804\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1102, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.5813\n",
      "Epoch [153/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0581, D_X Fake: 0.0967, D_X Total: 0.0774\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0422, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.9383, F Adv: 0.7085\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.9643\n",
      "Epoch [153/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0869, D_X Fake: 0.1090, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0538, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9478, F Adv: 0.5355\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.5731\n",
      "Epoch [153/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0512, D_X Fake: 0.1182, D_X Total: 0.0847\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.1146, D_Y Total: 0.0690\n",
      "Generator Losses:\n",
      "  G Adv: 0.7032, F Adv: 0.4618\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1189, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.2451\n",
      "Epoch [153/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0594, D_X Fake: 0.1135, D_X Total: 0.0865\n",
      "  D_Y Real: 0.0447, D_Y Fake: 0.0521, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.9013, F Adv: 0.5409\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1643, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.7449\n",
      "Epoch [153/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3006, D_X Fake: 0.0996, D_X Total: 0.2001\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0418, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.7785, F Adv: 0.5948\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1759\n",
      "  Total G Loss: 3.6032\n",
      "Epoch [153/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0940, D_X Fake: 0.1099, D_X Total: 0.1020\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0476, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.9369, F Adv: 0.5142\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1883\n",
      "  Total G Loss: 3.8094\n",
      "Epoch [153/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1695, D_X Fake: 0.1361, D_X Total: 0.1528\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0590, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.8166, F Adv: 0.4863\n",
      "  Cycle Photo: 0.0373, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1691, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.7458\n",
      "Epoch [153/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.1508, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0751, D_Y Total: 0.0566\n",
      "Generator Losses:\n",
      "  G Adv: 0.8926, F Adv: 0.5417\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.5244\n",
      "Epoch [153/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1432, D_X Fake: 0.0976, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0429, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.9447, F Adv: 0.5507\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1466, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.5895\n",
      "Epoch [153/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1683, D_X Fake: 0.0623, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0444, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.8467, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0200, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1163, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.1940\n",
      "Epoch [153/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1880, D_X Fake: 0.1256, D_X Total: 0.1568\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0504, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.6572, F Adv: 0.5730\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.5061\n",
      "Epoch [153/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1074, D_X Fake: 0.0967, D_X Total: 0.1020\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.0546, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.8783, F Adv: 0.6756\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1962, Perceptual Monet: 0.1877\n",
      "  Total G Loss: 4.1647\n",
      "Epoch [153/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2537, D_X Fake: 0.0463, D_X Total: 0.1500\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0352, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9078, F Adv: 0.6318\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1724, Perceptual Monet: 0.1382\n",
      "  Total G Loss: 3.6626\n",
      "Epoch [153/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0556, D_X Fake: 0.1058, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0382, D_Y Fake: 0.0338, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.8040, F Adv: 0.6007\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1592\n",
      "  Total G Loss: 3.3444\n",
      "Epoch [153/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1333, D_X Fake: 0.1031, D_X Total: 0.1182\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0629, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.7311, F Adv: 0.4981\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1640\n",
      "  Total G Loss: 3.3926\n",
      "Epoch [153/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2461, D_X Fake: 0.0655, D_X Total: 0.1558\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0407, D_Y Total: 0.0301\n",
      "Generator Losses:\n",
      "  G Adv: 0.8164, F Adv: 0.7275\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.7169\n",
      "Epoch [153/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2786, D_X Fake: 0.0565, D_X Total: 0.1675\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0382, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.9078, F Adv: 0.7383\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.7310\n",
      "Epoch [153/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1608, D_X Fake: 0.1584, D_X Total: 0.1596\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0509, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.9134, F Adv: 0.4534\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.3584\n",
      "Epoch [153/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1373, D_X Fake: 0.1149, D_X Total: 0.1261\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0314, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.8164, F Adv: 0.7308\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.7467\n",
      "Epoch [153/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1224, D_X Fake: 0.1016, D_X Total: 0.1120\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0759, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.8335, F Adv: 0.5835\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1177, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.4806\n",
      "Epoch [153/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1407, D_X Fake: 0.0755, D_X Total: 0.1081\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0645, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 1.1021, F Adv: 0.7496\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1626, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 4.1788\n",
      "Epoch [153/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.0911, D_X Total: 0.1052\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0572, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.8811, F Adv: 0.5899\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1590, Perceptual Monet: 0.1887\n",
      "  Total G Loss: 3.8221\n",
      "Epoch [154/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1029, D_X Fake: 0.0912, D_X Total: 0.0971\n",
      "  D_Y Real: 0.0347, D_Y Fake: 0.0623, D_Y Total: 0.0485\n",
      "Generator Losses:\n",
      "  G Adv: 0.9257, F Adv: 0.6521\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.5986\n",
      "Epoch [154/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1145, D_X Fake: 0.1463, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0328, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.9605, F Adv: 0.4589\n",
      "  Cycle Photo: 0.0365, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1475, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.5907\n",
      "Epoch [154/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1637, D_X Fake: 0.0814, D_X Total: 0.1226\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0378, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9467, F Adv: 0.5374\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.7287\n",
      "Epoch [154/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1567, D_X Fake: 0.1250, D_X Total: 0.1408\n",
      "  D_Y Real: 0.0635, D_Y Fake: 0.0337, D_Y Total: 0.0486\n",
      "Generator Losses:\n",
      "  G Adv: 0.9553, F Adv: 0.4738\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1895\n",
      "  Total G Loss: 3.7144\n",
      "Epoch [154/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0358, D_X Fake: 0.1412, D_X Total: 0.0885\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0420, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 1.0897, F Adv: 0.5112\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1071, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.3520\n",
      "Epoch [154/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1628, D_X Fake: 0.0826, D_X Total: 0.1227\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0375, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 1.0928, F Adv: 0.5116\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1871, Perceptual Monet: 0.1550\n",
      "  Total G Loss: 3.9341\n",
      "Epoch [154/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1174, D_X Fake: 0.1795, D_X Total: 0.1485\n",
      "  D_Y Real: 0.0413, D_Y Fake: 0.0392, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 1.1045, F Adv: 0.4825\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1258, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.6431\n",
      "Epoch [154/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0723, D_X Fake: 0.1459, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0527, D_Y Fake: 0.0647, D_Y Total: 0.0587\n",
      "Generator Losses:\n",
      "  G Adv: 0.8414, F Adv: 0.4980\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1374\n",
      "  Total G Loss: 3.1066\n",
      "Epoch [154/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1166, D_X Fake: 0.1096, D_X Total: 0.1131\n",
      "  D_Y Real: 0.0277, D_Y Fake: 0.0559, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.8849, F Adv: 0.6092\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0379\n",
      "  Perceptual Photo: 0.1227, Perceptual Monet: 0.1942\n",
      "  Total G Loss: 3.7158\n",
      "Epoch [154/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2242, D_X Fake: 0.1185, D_X Total: 0.1713\n",
      "  D_Y Real: 0.0277, D_Y Fake: 0.0469, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.8067, F Adv: 0.5373\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1457, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.5387\n",
      "Epoch [154/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1602, D_X Fake: 0.0971, D_X Total: 0.1286\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0388, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.8867, F Adv: 0.5478\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0216\n",
      "  Perceptual Photo: 0.1212, Perceptual Monet: 0.1346\n",
      "  Total G Loss: 3.2001\n",
      "Epoch [154/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1385, D_X Fake: 0.0845, D_X Total: 0.1115\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0407, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.9431, F Adv: 0.6461\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1819\n",
      "  Total G Loss: 3.7527\n",
      "Epoch [154/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1100, D_X Fake: 0.1333, D_X Total: 0.1217\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0493, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.6652, F Adv: 0.4599\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1421, Perceptual Monet: 0.1555\n",
      "  Total G Loss: 3.2055\n",
      "Epoch [154/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0927, D_X Fake: 0.1078, D_X Total: 0.1002\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0367, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.9001, F Adv: 0.6053\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1795\n",
      "  Total G Loss: 3.6358\n",
      "Epoch [154/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1070, D_X Fake: 0.1473, D_X Total: 0.1271\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0436, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.9374, F Adv: 0.6025\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.1621\n",
      "  Total G Loss: 3.4804\n",
      "Epoch [154/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1229, D_X Fake: 0.1184, D_X Total: 0.1206\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0411, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.9799, F Adv: 0.6464\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1842\n",
      "  Total G Loss: 3.8715\n",
      "Epoch [154/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2015, D_X Fake: 0.0755, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0537, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.9798, F Adv: 0.5112\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1838\n",
      "  Total G Loss: 3.7549\n",
      "Epoch [154/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1045, D_X Fake: 0.1552, D_X Total: 0.1298\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0541, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 1.0079, F Adv: 0.5102\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1681, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.7388\n",
      "Epoch [154/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1880, D_X Fake: 0.0914, D_X Total: 0.1397\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0850, D_Y Total: 0.0520\n",
      "Generator Losses:\n",
      "  G Adv: 0.8513, F Adv: 0.5881\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1903, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.8198\n",
      "Epoch [154/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2750, D_X Fake: 0.0769, D_X Total: 0.1760\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0314, D_Y Total: 0.0267\n",
      "Generator Losses:\n",
      "  G Adv: 0.9347, F Adv: 0.6882\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1603, Perceptual Monet: 0.1910\n",
      "  Total G Loss: 4.0378\n",
      "Epoch [154/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0503, D_X Fake: 0.1235, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0349, D_Y Total: 0.0257\n",
      "Generator Losses:\n",
      "  G Adv: 0.9120, F Adv: 0.5288\n",
      "  Cycle Photo: 0.0389, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1109, Perceptual Monet: 0.1498\n",
      "  Total G Loss: 3.3676\n",
      "Epoch [154/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2868, D_X Fake: 0.0763, D_X Total: 0.1816\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0483, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.7621, F Adv: 0.6448\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1409, Perceptual Monet: 0.1920\n",
      "  Total G Loss: 3.7109\n",
      "Epoch [154/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1034, D_X Fake: 0.0948, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0370, D_Y Total: 0.0289\n",
      "Generator Losses:\n",
      "  G Adv: 1.0817, F Adv: 0.5872\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1428, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.8195\n",
      "Epoch [154/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2806, D_X Fake: 0.0861, D_X Total: 0.1833\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0443, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.7765, F Adv: 0.6081\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1715\n",
      "  Total G Loss: 3.4331\n",
      "Epoch [155/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2051, D_X Fake: 0.0663, D_X Total: 0.1357\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0470, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.8247, F Adv: 0.6773\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1416, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.5740\n",
      "Epoch [155/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0911, D_X Fake: 0.1281, D_X Total: 0.1096\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0646, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.7761, F Adv: 0.4643\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.2855\n",
      "Epoch [155/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1556, D_X Fake: 0.1021, D_X Total: 0.1288\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0623, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.8539, F Adv: 0.6589\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1496\n",
      "  Total G Loss: 3.5586\n",
      "Epoch [155/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0415, D_X Fake: 0.0794, D_X Total: 0.0605\n",
      "  D_Y Real: 0.0476, D_Y Fake: 0.1306, D_Y Total: 0.0891\n",
      "Generator Losses:\n",
      "  G Adv: 1.0495, F Adv: 0.4465\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1412, Perceptual Monet: 0.1477\n",
      "  Total G Loss: 3.4784\n",
      "Epoch [155/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1618, D_X Fake: 0.0744, D_X Total: 0.1181\n",
      "  D_Y Real: 0.0639, D_Y Fake: 0.0487, D_Y Total: 0.0563\n",
      "Generator Losses:\n",
      "  G Adv: 1.0054, F Adv: 0.6731\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1816, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 4.0962\n",
      "Epoch [155/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1255, D_X Fake: 0.1002, D_X Total: 0.1128\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0463, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8157, F Adv: 0.4773\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1684, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.6076\n",
      "Epoch [155/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0940, D_X Fake: 0.0662, D_X Total: 0.0801\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0432, D_Y Total: 0.0311\n",
      "Generator Losses:\n",
      "  G Adv: 0.8672, F Adv: 0.6296\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 3.8472\n",
      "Epoch [155/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1737, D_X Fake: 0.1235, D_X Total: 0.1486\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0423, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.9216, F Adv: 0.4941\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1579\n",
      "  Total G Loss: 3.4307\n",
      "Epoch [155/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2315, D_X Fake: 0.0952, D_X Total: 0.1634\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0881, D_Y Total: 0.0557\n",
      "Generator Losses:\n",
      "  G Adv: 1.0808, F Adv: 0.4543\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0185\n",
      "  Perceptual Photo: 0.1517, Perceptual Monet: 0.1216\n",
      "  Total G Loss: 3.4230\n",
      "Epoch [155/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0581, D_X Fake: 0.0798, D_X Total: 0.0690\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0563, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8934, F Adv: 0.6668\n",
      "  Cycle Photo: 0.0182, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.0905, Perceptual Monet: 0.1626\n",
      "  Total G Loss: 3.2471\n",
      "Epoch [155/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2006, D_X Fake: 0.0814, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0463, D_Y Fake: 0.0355, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.8952, F Adv: 0.6885\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0424\n",
      "  Perceptual Photo: 0.1718, Perceptual Monet: 0.2124\n",
      "  Total G Loss: 4.2481\n",
      "Epoch [155/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1728, D_X Fake: 0.0884, D_X Total: 0.1306\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0534, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.8126, F Adv: 0.7248\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1435, Perceptual Monet: 0.1958\n",
      "  Total G Loss: 3.8612\n",
      "Epoch [155/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1856, D_X Fake: 0.0631, D_X Total: 0.1243\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0359, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.7944, F Adv: 0.6622\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1718\n",
      "  Total G Loss: 3.5286\n",
      "Epoch [155/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0737, D_X Fake: 0.1581, D_X Total: 0.1159\n",
      "  D_Y Real: 0.0532, D_Y Fake: 0.0550, D_Y Total: 0.0541\n",
      "Generator Losses:\n",
      "  G Adv: 0.9094, F Adv: 0.3655\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1062, Perceptual Monet: 0.1610\n",
      "  Total G Loss: 3.1734\n",
      "Epoch [155/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1246, D_X Fake: 0.1366, D_X Total: 0.1306\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0457, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 1.0928, F Adv: 0.5100\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1157, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.5715\n",
      "Epoch [155/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2137, D_X Fake: 0.0798, D_X Total: 0.1467\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0508, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.9171, F Adv: 0.6494\n",
      "  Cycle Photo: 0.0391, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1126, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 3.5944\n",
      "Epoch [155/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1527, D_X Fake: 0.0714, D_X Total: 0.1121\n",
      "  D_Y Real: 0.0277, D_Y Fake: 0.0365, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.7561, F Adv: 0.6355\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1870, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.9661\n",
      "Epoch [155/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0625, D_X Fake: 0.1167, D_X Total: 0.0896\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0349, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.8715, F Adv: 0.6182\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1115, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.3146\n",
      "Epoch [155/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1927, D_X Fake: 0.0734, D_X Total: 0.1330\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0428, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 1.0257, F Adv: 0.5608\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1893\n",
      "  Total G Loss: 3.8971\n",
      "Epoch [155/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0602, D_X Fake: 0.1586, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0289, D_Y Fake: 0.0407, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9350, F Adv: 0.4350\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0214\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1294\n",
      "  Total G Loss: 3.3010\n",
      "Epoch [155/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1490, D_X Fake: 0.1042, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0679, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.8001, F Adv: 0.5093\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.5189\n",
      "Epoch [155/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1713, D_X Fake: 0.1192, D_X Total: 0.1453\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0572, D_Y Total: 0.0422\n",
      "Generator Losses:\n",
      "  G Adv: 0.7980, F Adv: 0.5633\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.2901\n",
      "Epoch [155/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1051, D_X Fake: 0.0642, D_X Total: 0.0846\n",
      "  D_Y Real: 0.0403, D_Y Fake: 0.0439, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.6785, F Adv: 0.6641\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.5998\n",
      "Epoch [155/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0968, D_X Fake: 0.0740, D_X Total: 0.0854\n",
      "  D_Y Real: 0.0522, D_Y Fake: 0.1078, D_Y Total: 0.0800\n",
      "Generator Losses:\n",
      "  G Adv: 0.7892, F Adv: 0.7257\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1496, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.7036\n",
      "Epoch [156/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1557, D_X Fake: 0.1114, D_X Total: 0.1335\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0380, D_Y Total: 0.0304\n",
      "Generator Losses:\n",
      "  G Adv: 0.8372, F Adv: 0.5794\n",
      "  Cycle Photo: 0.0495, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.2239, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 4.0523\n",
      "Epoch [156/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1416, D_X Fake: 0.0804, D_X Total: 0.1110\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0875, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.7809, F Adv: 0.5850\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1300, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.3688\n",
      "Epoch [156/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0996, D_X Fake: 0.0979, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0425, D_Y Total: 0.0297\n",
      "Generator Losses:\n",
      "  G Adv: 0.8118, F Adv: 0.5324\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 3.3755\n",
      "Epoch [156/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2199, D_X Fake: 0.0626, D_X Total: 0.1412\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0440, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 1.1557, F Adv: 0.7542\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1496, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 4.1317\n",
      "Epoch [156/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1625, D_X Fake: 0.1003, D_X Total: 0.1314\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0422, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8070, F Adv: 0.5717\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1496\n",
      "  Total G Loss: 3.5068\n",
      "Epoch [156/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1023, D_X Fake: 0.1236, D_X Total: 0.1129\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0510, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.8830, F Adv: 0.4925\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1194, Perceptual Monet: 0.1977\n",
      "  Total G Loss: 3.5729\n",
      "Epoch [156/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0679, D_X Fake: 0.1487, D_X Total: 0.1083\n",
      "  D_Y Real: 0.0152, D_Y Fake: 0.0684, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.9531, F Adv: 0.4658\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 3.6758\n",
      "Epoch [156/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3553, D_X Fake: 0.0800, D_X Total: 0.2176\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0599, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.7692, F Adv: 0.6966\n",
      "  Cycle Photo: 0.0378, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1668, Perceptual Monet: 0.1886\n",
      "  Total G Loss: 3.9384\n",
      "Epoch [156/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1031, D_X Fake: 0.2047, D_X Total: 0.1539\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0387, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.8020, F Adv: 0.4472\n",
      "  Cycle Photo: 0.0218, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.0964, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.0765\n",
      "Epoch [156/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0807, D_X Fake: 0.1674, D_X Total: 0.1241\n",
      "  D_Y Real: 0.0334, D_Y Fake: 0.0457, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 1.1276, F Adv: 0.4824\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1306, Perceptual Monet: 0.1454\n",
      "  Total G Loss: 3.5055\n",
      "Epoch [156/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0596, D_X Fake: 0.1076, D_X Total: 0.0836\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0620, D_Y Total: 0.0422\n",
      "Generator Losses:\n",
      "  G Adv: 0.9033, F Adv: 0.4363\n",
      "  Cycle Photo: 0.0204, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1023, Perceptual Monet: 0.1909\n",
      "  Total G Loss: 3.3653\n",
      "Epoch [156/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2181, D_X Fake: 0.0662, D_X Total: 0.1421\n",
      "  D_Y Real: 0.0442, D_Y Fake: 0.0385, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 1.0452, F Adv: 0.7072\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1674, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 4.0081\n",
      "Epoch [156/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2662, D_X Fake: 0.0688, D_X Total: 0.1675\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0506, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.9831, F Adv: 0.7502\n",
      "  Cycle Photo: 0.0443, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.2166, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 4.2782\n",
      "Epoch [156/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1265, D_X Fake: 0.0885, D_X Total: 0.1075\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0347, D_Y Total: 0.0292\n",
      "Generator Losses:\n",
      "  G Adv: 0.8640, F Adv: 0.6867\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1444, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.6726\n",
      "Epoch [156/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1636, D_X Fake: 0.1761, D_X Total: 0.1699\n",
      "  D_Y Real: 0.0156, D_Y Fake: 0.0502, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.9675, F Adv: 0.4328\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.2856\n",
      "Epoch [156/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.0952, D_X Total: 0.0722\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0385, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 0.9858, F Adv: 0.6692\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.2012\n",
      "  Total G Loss: 3.9351\n",
      "Epoch [156/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2328, D_X Fake: 0.0692, D_X Total: 0.1510\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0464, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8467, F Adv: 0.6550\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 3.6404\n",
      "Epoch [156/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0693, D_X Fake: 0.0825, D_X Total: 0.0759\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0397, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 1.0403, F Adv: 0.6650\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1228, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.8335\n",
      "Epoch [156/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1835, D_X Fake: 0.0851, D_X Total: 0.1343\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0399, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8509, F Adv: 0.5477\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1399, Perceptual Monet: 0.1521\n",
      "  Total G Loss: 3.4379\n",
      "Epoch [156/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2136, D_X Fake: 0.0575, D_X Total: 0.1356\n",
      "  D_Y Real: 0.0745, D_Y Fake: 0.0395, D_Y Total: 0.0570\n",
      "Generator Losses:\n",
      "  G Adv: 1.1590, F Adv: 0.7032\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1507, Perceptual Monet: 0.1766\n",
      "  Total G Loss: 4.1223\n",
      "Epoch [156/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1264, D_X Fake: 0.1667, D_X Total: 0.1466\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0933, D_Y Total: 0.0624\n",
      "Generator Losses:\n",
      "  G Adv: 1.0033, F Adv: 0.4805\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.7334\n",
      "Epoch [156/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2095, D_X Fake: 0.0775, D_X Total: 0.1435\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.0437, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.9252, F Adv: 0.6532\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1035, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.5785\n",
      "Epoch [156/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2078, D_X Fake: 0.0842, D_X Total: 0.1460\n",
      "  D_Y Real: 0.0289, D_Y Fake: 0.0382, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.9673, F Adv: 0.6625\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1484, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.8528\n",
      "Epoch [156/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0745, D_X Fake: 0.1125, D_X Total: 0.0935\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0411, D_Y Total: 0.0311\n",
      "Generator Losses:\n",
      "  G Adv: 1.0301, F Adv: 0.5393\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1968\n",
      "  Total G Loss: 3.9168\n",
      "Epoch [157/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1959, D_X Fake: 0.1473, D_X Total: 0.1716\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0395, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.9564, F Adv: 0.5031\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1465\n",
      "  Total G Loss: 3.5192\n",
      "Epoch [157/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0925, D_X Fake: 0.1226, D_X Total: 0.1075\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0710, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.6881, F Adv: 0.6497\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1650\n",
      "  Total G Loss: 3.3896\n",
      "Epoch [157/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0839, D_X Fake: 0.0895, D_X Total: 0.0867\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0451, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.9154, F Adv: 0.6047\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1255, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.5502\n",
      "Epoch [157/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1772, D_X Fake: 0.0705, D_X Total: 0.1238\n",
      "  D_Y Real: 0.0352, D_Y Fake: 0.0331, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.9723, F Adv: 0.7688\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1880, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 4.2109\n",
      "Epoch [157/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2376, D_X Fake: 0.1227, D_X Total: 0.1801\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0390, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 0.8822, F Adv: 0.5063\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1644, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.5918\n",
      "Epoch [157/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1104, D_X Fake: 0.1409, D_X Total: 0.1257\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0555, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.8357, F Adv: 0.4855\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1410, Perceptual Monet: 0.1974\n",
      "  Total G Loss: 3.6813\n",
      "Epoch [157/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0637, D_X Fake: 0.1280, D_X Total: 0.0958\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0617, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.8199, F Adv: 0.5496\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 3.3385\n",
      "Epoch [157/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0945, D_X Fake: 0.0775, D_X Total: 0.0860\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0473, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.8493, F Adv: 0.6266\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1553\n",
      "  Total G Loss: 3.4025\n",
      "Epoch [157/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1375, D_X Fake: 0.1582, D_X Total: 0.1478\n",
      "  D_Y Real: 0.0392, D_Y Fake: 0.0261, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.9035, F Adv: 0.5866\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1348, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.3643\n",
      "Epoch [157/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1496, D_X Fake: 0.0578, D_X Total: 0.1037\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0393, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 1.1544, F Adv: 0.7572\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 4.1449\n",
      "Epoch [157/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0671, D_X Fake: 0.1362, D_X Total: 0.1016\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0498, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.6672, F Adv: 0.5313\n",
      "  Cycle Photo: 0.0215, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.0927, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 2.8883\n",
      "Epoch [157/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1840, D_X Fake: 0.0734, D_X Total: 0.1287\n",
      "  D_Y Real: 0.0137, D_Y Fake: 0.0491, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.7975, F Adv: 0.6216\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1507, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.5323\n",
      "Epoch [157/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3195, D_X Fake: 0.0965, D_X Total: 0.2080\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0468, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.8533, F Adv: 0.5869\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1765, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.6806\n",
      "Epoch [157/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0698, D_X Fake: 0.0890, D_X Total: 0.0794\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0585, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 1.0078, F Adv: 0.5459\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1249, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.6109\n",
      "Epoch [157/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0747, D_X Fake: 0.1391, D_X Total: 0.1069\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0432, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8464, F Adv: 0.5977\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1283, Perceptual Monet: 0.1541\n",
      "  Total G Loss: 3.4207\n",
      "Epoch [157/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1194, D_X Fake: 0.0893, D_X Total: 0.1044\n",
      "  D_Y Real: 0.0539, D_Y Fake: 0.0400, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 1.0259, F Adv: 0.6092\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1489, Perceptual Monet: 0.1478\n",
      "  Total G Loss: 3.6686\n",
      "Epoch [157/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0840, D_X Fake: 0.1301, D_X Total: 0.1071\n",
      "  D_Y Real: 0.0145, D_Y Fake: 0.0863, D_Y Total: 0.0504\n",
      "Generator Losses:\n",
      "  G Adv: 0.6266, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1080, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.1496\n",
      "Epoch [157/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1981, D_X Fake: 0.0628, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0565, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 1.0100, F Adv: 0.7561\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.9558\n",
      "Epoch [157/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0739, D_X Fake: 0.1095, D_X Total: 0.0917\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0364, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 1.0161, F Adv: 0.4838\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1208, Perceptual Monet: 0.1495\n",
      "  Total G Loss: 3.4302\n",
      "Epoch [157/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3227, D_X Fake: 0.0523, D_X Total: 0.1875\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0279, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.9327, F Adv: 0.7440\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1650, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 4.0693\n",
      "Epoch [157/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0637, D_X Fake: 0.1541, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0407, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 1.1707, F Adv: 0.4815\n",
      "  Cycle Photo: 0.0403, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1862, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 4.1814\n",
      "Epoch [157/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1260, D_X Fake: 0.1151, D_X Total: 0.1205\n",
      "  D_Y Real: 0.0543, D_Y Fake: 0.0387, D_Y Total: 0.0465\n",
      "Generator Losses:\n",
      "  G Adv: 0.9392, F Adv: 0.4540\n",
      "  Cycle Photo: 0.0214, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1157, Perceptual Monet: 0.1804\n",
      "  Total G Loss: 3.4217\n",
      "Epoch [157/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1184, D_X Fake: 0.0616, D_X Total: 0.0900\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0629, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.8298, F Adv: 0.7304\n",
      "  Cycle Photo: 0.0462, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.7227\n",
      "Epoch [157/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1125, D_X Fake: 0.0972, D_X Total: 0.1049\n",
      "  D_Y Real: 0.0372, D_Y Fake: 0.0603, D_Y Total: 0.0488\n",
      "Generator Losses:\n",
      "  G Adv: 0.9702, F Adv: 0.6796\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.2052\n",
      "  Total G Loss: 4.1090\n",
      "Epoch [158/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1628, D_X Fake: 0.0877, D_X Total: 0.1253\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0673, D_Y Total: 0.0521\n",
      "Generator Losses:\n",
      "  G Adv: 0.9321, F Adv: 0.6214\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1145, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 3.6385\n",
      "Epoch [158/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2567, D_X Fake: 0.0640, D_X Total: 0.1604\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0430, D_Y Total: 0.0319\n",
      "Generator Losses:\n",
      "  G Adv: 0.6757, F Adv: 0.7072\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1409\n",
      "  Total G Loss: 3.2474\n",
      "Epoch [158/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1276, D_X Fake: 0.0753, D_X Total: 0.1015\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0422, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8710, F Adv: 0.6681\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0205\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1327\n",
      "  Total G Loss: 3.5461\n",
      "Epoch [158/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1524, D_X Fake: 0.0788, D_X Total: 0.1156\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0373, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.9422, F Adv: 0.6588\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1898\n",
      "  Total G Loss: 3.7975\n",
      "Epoch [158/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1114, D_X Fake: 0.0953, D_X Total: 0.1033\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0363, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.9675, F Adv: 0.5784\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1422, Perceptual Monet: 0.1712\n",
      "  Total G Loss: 3.6744\n",
      "Epoch [158/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1361, D_X Fake: 0.0871, D_X Total: 0.1116\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0357, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9462, F Adv: 0.6167\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1680, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.7556\n",
      "Epoch [158/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1856, D_X Fake: 0.0644, D_X Total: 0.1250\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0354, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9994, F Adv: 0.6635\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1259, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.6948\n",
      "Epoch [158/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0748, D_X Fake: 0.1002, D_X Total: 0.0875\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0389, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 0.8142, F Adv: 0.6061\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1554\n",
      "  Total G Loss: 3.5358\n",
      "Epoch [158/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0719, D_X Fake: 0.0888, D_X Total: 0.0804\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0351, D_Y Total: 0.0260\n",
      "Generator Losses:\n",
      "  G Adv: 1.0558, F Adv: 0.5955\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1520, Perceptual Monet: 0.1832\n",
      "  Total G Loss: 3.9830\n",
      "Epoch [158/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2025, D_X Fake: 0.1430, D_X Total: 0.1728\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0467, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.9009, F Adv: 0.4735\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1720, Perceptual Monet: 0.1901\n",
      "  Total G Loss: 3.8506\n",
      "Epoch [158/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1937, D_X Fake: 0.1862, D_X Total: 0.1899\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0356, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.8769, F Adv: 0.3933\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1362, Perceptual Monet: 0.1444\n",
      "  Total G Loss: 3.2062\n",
      "Epoch [158/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1707, D_X Fake: 0.1177, D_X Total: 0.1442\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0283, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 0.9933, F Adv: 0.7550\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1475, Perceptual Monet: 0.1897\n",
      "  Total G Loss: 4.0428\n",
      "Epoch [158/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1613, D_X Fake: 0.0988, D_X Total: 0.1300\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0493, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.8596, F Adv: 0.6399\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1992\n",
      "  Total G Loss: 3.7935\n",
      "Epoch [158/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0928, D_X Fake: 0.1002, D_X Total: 0.0965\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.0383, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.9172, F Adv: 0.6189\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1448\n",
      "  Total G Loss: 3.4352\n",
      "Epoch [158/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1181, D_X Fake: 0.0815, D_X Total: 0.0998\n",
      "  D_Y Real: 0.0384, D_Y Fake: 0.0534, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.7400, F Adv: 0.6048\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0197\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1221\n",
      "  Total G Loss: 3.1259\n",
      "Epoch [158/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0941, D_X Fake: 0.0616, D_X Total: 0.0779\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0409, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 1.0055, F Adv: 0.6661\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1777\n",
      "  Total G Loss: 3.7344\n",
      "Epoch [158/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1341, D_X Fake: 0.1267, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0446, D_Y Fake: 0.0359, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 1.0297, F Adv: 0.5096\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1392, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.7316\n",
      "Epoch [158/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2491, D_X Fake: 0.0747, D_X Total: 0.1619\n",
      "  D_Y Real: 0.0370, D_Y Fake: 0.0472, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.8684, F Adv: 0.7509\n",
      "  Cycle Photo: 0.0512, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.2035, Perceptual Monet: 0.1486\n",
      "  Total G Loss: 4.1325\n",
      "Epoch [158/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0437, D_X Fake: 0.0834, D_X Total: 0.0636\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.1178, D_Y Total: 0.0697\n",
      "Generator Losses:\n",
      "  G Adv: 0.5749, F Adv: 0.5168\n",
      "  Cycle Photo: 0.0196, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.0903, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 2.8620\n",
      "Epoch [158/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.1887, D_X Total: 0.1601\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0581, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.9810, F Adv: 0.5658\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.1377\n",
      "  Total G Loss: 3.5583\n",
      "Epoch [158/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1413, D_X Fake: 0.0625, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0718, D_Y Total: 0.0457\n",
      "Generator Losses:\n",
      "  G Adv: 0.8913, F Adv: 0.7081\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0447\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.2109\n",
      "  Total G Loss: 4.1614\n",
      "Epoch [158/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1169, D_X Fake: 0.0888, D_X Total: 0.1028\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0450, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.7477, F Adv: 0.4813\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0210\n",
      "  Perceptual Photo: 0.1647, Perceptual Monet: 0.1337\n",
      "  Total G Loss: 3.2785\n",
      "Epoch [158/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0800, D_X Fake: 0.1148, D_X Total: 0.0974\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0471, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.6853, F Adv: 0.4599\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.2505\n",
      "Epoch [158/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1116, D_X Fake: 0.0908, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0393, D_Y Total: 0.0271\n",
      "Generator Losses:\n",
      "  G Adv: 0.8422, F Adv: 0.5314\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0218\n",
      "  Perceptual Photo: 0.1666, Perceptual Monet: 0.1384\n",
      "  Total G Loss: 3.4408\n",
      "Epoch [159/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0664, D_X Fake: 0.1369, D_X Total: 0.1017\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0551, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 0.9946, F Adv: 0.5290\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1701, Perceptual Monet: 0.1372\n",
      "  Total G Loss: 3.6087\n",
      "Epoch [159/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1707, D_X Fake: 0.0939, D_X Total: 0.1323\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0607, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.7968, F Adv: 0.5280\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1324, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.3235\n",
      "Epoch [159/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2018, D_X Fake: 0.0855, D_X Total: 0.1437\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0968, D_Y Total: 0.0562\n",
      "Generator Losses:\n",
      "  G Adv: 1.2448, F Adv: 0.7271\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 4.1859\n",
      "Epoch [159/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2592, D_X Fake: 0.0972, D_X Total: 0.1782\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0500, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.6454, F Adv: 0.5681\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.3889\n",
      "Epoch [159/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0605, D_X Fake: 0.0899, D_X Total: 0.0752\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0745, D_Y Total: 0.0474\n",
      "Generator Losses:\n",
      "  G Adv: 0.7256, F Adv: 0.6369\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.4582\n",
      "Epoch [159/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2519, D_X Fake: 0.1062, D_X Total: 0.1790\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0490, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.7915, F Adv: 0.5957\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0227\n",
      "  Perceptual Photo: 0.1580, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.4811\n",
      "Epoch [159/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1743, D_X Fake: 0.1260, D_X Total: 0.1501\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0414, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.9552, F Adv: 0.5283\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1505, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.6821\n",
      "Epoch [159/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1711, D_X Fake: 0.0887, D_X Total: 0.1299\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0487, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.9747, F Adv: 0.5831\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 3.5598\n",
      "Epoch [159/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1190, D_X Fake: 0.1443, D_X Total: 0.1316\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0379, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.8803, F Adv: 0.5872\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1227, Perceptual Monet: 0.1345\n",
      "  Total G Loss: 3.2034\n",
      "Epoch [159/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1020, D_X Fake: 0.1113, D_X Total: 0.1066\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0612, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 1.1361, F Adv: 0.5476\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.7217\n",
      "Epoch [159/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1324, D_X Fake: 0.1344, D_X Total: 0.1334\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0445, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.7368, F Adv: 0.5192\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1197, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.1902\n",
      "Epoch [159/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1548, D_X Fake: 0.1120, D_X Total: 0.1334\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0383, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.8812, F Adv: 0.5892\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1831\n",
      "  Total G Loss: 3.6781\n",
      "Epoch [159/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1486, D_X Fake: 0.0745, D_X Total: 0.1115\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0383, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.9743, F Adv: 0.5989\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.7213\n",
      "Epoch [159/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1532, D_X Fake: 0.1491, D_X Total: 0.1512\n",
      "  D_Y Real: 0.0426, D_Y Fake: 0.0324, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.9547, F Adv: 0.5795\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1444, Perceptual Monet: 0.1678\n",
      "  Total G Loss: 3.6799\n",
      "Epoch [159/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0592, D_X Fake: 0.0826, D_X Total: 0.0709\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0364, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.9059, F Adv: 0.5627\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1725\n",
      "  Total G Loss: 3.6056\n",
      "Epoch [159/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1956, D_X Fake: 0.1317, D_X Total: 0.1637\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0407, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.9485, F Adv: 0.5482\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0419\n",
      "  Perceptual Photo: 0.1856, Perceptual Monet: 0.1969\n",
      "  Total G Loss: 4.1900\n",
      "Epoch [159/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1129, D_X Fake: 0.1407, D_X Total: 0.1268\n",
      "  D_Y Real: 0.0589, D_Y Fake: 0.0567, D_Y Total: 0.0578\n",
      "Generator Losses:\n",
      "  G Adv: 0.9479, F Adv: 0.5402\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1544, Perceptual Monet: 0.1711\n",
      "  Total G Loss: 3.7084\n",
      "Epoch [159/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.1470, D_X Total: 0.1101\n",
      "  D_Y Real: 0.0542, D_Y Fake: 0.0519, D_Y Total: 0.0530\n",
      "Generator Losses:\n",
      "  G Adv: 0.8702, F Adv: 0.4470\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1819\n",
      "  Total G Loss: 3.7046\n",
      "Epoch [159/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1341, D_X Fake: 0.0905, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0392, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.8677, F Adv: 0.4090\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1389, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.4525\n",
      "Epoch [159/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1705, D_X Fake: 0.1026, D_X Total: 0.1366\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0387, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9099, F Adv: 0.6183\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1527, Perceptual Monet: 0.1815\n",
      "  Total G Loss: 3.8181\n",
      "Epoch [159/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1038, D_X Fake: 0.1264, D_X Total: 0.1151\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0435, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.9856, F Adv: 0.5409\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.7741\n",
      "Epoch [159/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2071, D_X Fake: 0.0814, D_X Total: 0.1442\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0387, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.9471, F Adv: 0.5341\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1799, Perceptual Monet: 0.1414\n",
      "  Total G Loss: 3.6739\n",
      "Epoch [159/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1603, D_X Fake: 0.0591, D_X Total: 0.1097\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0851, D_Y Total: 0.0547\n",
      "Generator Losses:\n",
      "  G Adv: 0.8791, F Adv: 0.6999\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1673, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.8541\n",
      "Epoch [159/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1622, D_X Fake: 0.0995, D_X Total: 0.1308\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0838, D_Y Total: 0.0574\n",
      "Generator Losses:\n",
      "  G Adv: 0.8931, F Adv: 0.5427\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1304, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.5040\n",
      "Epoch [160/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0472, D_X Fake: 0.0909, D_X Total: 0.0690\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0374, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.9407, F Adv: 0.4043\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1114, Perceptual Monet: 0.1559\n",
      "  Total G Loss: 3.2250\n",
      "Epoch [160/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1734, D_X Fake: 0.0901, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0355, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.8380, F Adv: 0.6474\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0378\n",
      "  Perceptual Photo: 0.1080, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.5991\n",
      "Epoch [160/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2612, D_X Fake: 0.0786, D_X Total: 0.1699\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0555, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.8610, F Adv: 0.7609\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1245, Perceptual Monet: 0.1509\n",
      "  Total G Loss: 3.5529\n",
      "Epoch [160/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1023, D_X Fake: 0.0819, D_X Total: 0.0921\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0461, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9815, F Adv: 0.5944\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.7334\n",
      "Epoch [160/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2892, D_X Fake: 0.0818, D_X Total: 0.1855\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0463, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.8578, F Adv: 0.7435\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1232, Perceptual Monet: 0.1817\n",
      "  Total G Loss: 3.6997\n",
      "Epoch [160/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1797, D_X Fake: 0.1488, D_X Total: 0.1643\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0384, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 0.8770, F Adv: 0.5131\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.5763\n",
      "Epoch [160/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1376, D_X Fake: 0.0868, D_X Total: 0.1122\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0632, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 0.8751, F Adv: 0.5615\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1750\n",
      "  Total G Loss: 3.6268\n",
      "Epoch [160/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1339, D_X Fake: 0.1430, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0484, D_Y Fake: 0.0382, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 1.1155, F Adv: 0.4698\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0381\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1932\n",
      "  Total G Loss: 3.9068\n",
      "Epoch [160/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0412, D_X Fake: 0.0695, D_X Total: 0.0553\n",
      "  D_Y Real: 0.0140, D_Y Fake: 0.0474, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.8757, F Adv: 0.6547\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1280, Perceptual Monet: 0.1710\n",
      "  Total G Loss: 3.6486\n",
      "Epoch [160/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0433, D_X Fake: 0.1269, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0648, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.8480, F Adv: 0.4396\n",
      "  Cycle Photo: 0.0187, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.0830, Perceptual Monet: 0.1521\n",
      "  Total G Loss: 2.8779\n",
      "Epoch [160/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2455, D_X Fake: 0.0636, D_X Total: 0.1546\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.0469, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.8869, F Adv: 0.6516\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.8793\n",
      "Epoch [160/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1595, D_X Fake: 0.0726, D_X Total: 0.1161\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.0429, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 1.0392, F Adv: 0.5726\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.7747\n",
      "Epoch [160/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1618, D_X Fake: 0.1558, D_X Total: 0.1588\n",
      "  D_Y Real: 0.0164, D_Y Fake: 0.0429, D_Y Total: 0.0297\n",
      "Generator Losses:\n",
      "  G Adv: 0.7193, F Adv: 0.4527\n",
      "  Cycle Photo: 0.0384, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.3854\n",
      "Epoch [160/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0900, D_X Fake: 0.1171, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0592, D_Y Fake: 0.0437, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 0.9812, F Adv: 0.5478\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1307, Perceptual Monet: 0.1909\n",
      "  Total G Loss: 3.7141\n",
      "Epoch [160/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0926, D_X Fake: 0.1154, D_X Total: 0.1040\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0526, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.8039, F Adv: 0.6495\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.7715\n",
      "Epoch [160/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1375, D_X Fake: 0.1038, D_X Total: 0.1207\n",
      "  D_Y Real: 0.0518, D_Y Fake: 0.0431, D_Y Total: 0.0475\n",
      "Generator Losses:\n",
      "  G Adv: 1.1048, F Adv: 0.5327\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1270, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.8125\n",
      "Epoch [160/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1927, D_X Fake: 0.1434, D_X Total: 0.1681\n",
      "  D_Y Real: 0.0349, D_Y Fake: 0.0540, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.7599, F Adv: 0.5553\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1587, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.4977\n",
      "Epoch [160/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1986, D_X Fake: 0.0775, D_X Total: 0.1380\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.1152, D_Y Total: 0.0753\n",
      "Generator Losses:\n",
      "  G Adv: 0.7586, F Adv: 0.6124\n",
      "  Cycle Photo: 0.0440, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.8184\n",
      "Epoch [160/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1336, D_X Fake: 0.1651, D_X Total: 0.1494\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0517, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 0.9201, F Adv: 0.4197\n",
      "  Cycle Photo: 0.0192, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.0976, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 3.1882\n",
      "Epoch [160/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1240, D_X Fake: 0.0930, D_X Total: 0.1085\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0572, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 0.8700, F Adv: 0.6044\n",
      "  Cycle Photo: 0.0200, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1252, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.5426\n",
      "Epoch [160/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2642, D_X Fake: 0.0714, D_X Total: 0.1678\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0530, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.7380, F Adv: 0.6623\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1531, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.5795\n",
      "Epoch [160/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2982, D_X Fake: 0.1386, D_X Total: 0.2184\n",
      "  D_Y Real: 0.0410, D_Y Fake: 0.0304, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 1.0158, F Adv: 0.5497\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0208\n",
      "  Perceptual Photo: 0.1965, Perceptual Monet: 0.1379\n",
      "  Total G Loss: 3.8227\n",
      "Epoch [160/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1749, D_X Fake: 0.0744, D_X Total: 0.1247\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0404, D_Y Total: 0.0281\n",
      "Generator Losses:\n",
      "  G Adv: 0.7749, F Adv: 0.6563\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.5427\n",
      "Epoch [160/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1291, D_X Fake: 0.0938, D_X Total: 0.1114\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0476, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.7817, F Adv: 0.6689\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1517, Perceptual Monet: 0.1815\n",
      "  Total G Loss: 3.8386\n",
      "Saved checkpoint at epoch 160\n",
      "Epoch [161/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2330, D_X Fake: 0.0735, D_X Total: 0.1533\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0592, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.7149, F Adv: 0.7238\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0201\n",
      "  Perceptual Photo: 0.1171, Perceptual Monet: 0.1389\n",
      "  Total G Loss: 3.1712\n",
      "Epoch [161/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1879, D_X Fake: 0.1199, D_X Total: 0.1539\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0377, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.9422, F Adv: 0.5365\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.3238\n",
      "Epoch [161/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0586, D_X Fake: 0.1042, D_X Total: 0.0814\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0444, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.9909, F Adv: 0.5965\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1310, Perceptual Monet: 0.1852\n",
      "  Total G Loss: 3.8781\n",
      "Epoch [161/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1475, D_X Fake: 0.1398, D_X Total: 0.1437\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0632, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.7448, F Adv: 0.5697\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1428, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 3.5269\n",
      "Epoch [161/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1331, D_X Fake: 0.1355, D_X Total: 0.1343\n",
      "  D_Y Real: 0.0422, D_Y Fake: 0.0562, D_Y Total: 0.0492\n",
      "Generator Losses:\n",
      "  G Adv: 0.7988, F Adv: 0.4788\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1750, Perceptual Monet: 0.1779\n",
      "  Total G Loss: 3.7034\n",
      "Epoch [161/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1134, D_X Fake: 0.1281, D_X Total: 0.1207\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0796, D_Y Total: 0.0519\n",
      "Generator Losses:\n",
      "  G Adv: 0.9592, F Adv: 0.6131\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.2061\n",
      "  Total G Loss: 3.8762\n",
      "Epoch [161/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0521, D_X Fake: 0.1076, D_X Total: 0.0799\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0602, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.7113, F Adv: 0.6188\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0182\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.1333\n",
      "  Total G Loss: 3.0476\n",
      "Epoch [161/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2420, D_X Fake: 0.0935, D_X Total: 0.1677\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0514, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.8529, F Adv: 0.6049\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1282, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.5626\n",
      "Epoch [161/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1239, D_X Fake: 0.0914, D_X Total: 0.1076\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0418, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 1.0417, F Adv: 0.7411\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.9173\n",
      "Epoch [161/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1992, D_X Fake: 0.0640, D_X Total: 0.1316\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0375, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.8922, F Adv: 0.8989\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1416, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 4.0225\n",
      "Epoch [161/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0667, D_X Fake: 0.0684, D_X Total: 0.0676\n",
      "  D_Y Real: 0.0585, D_Y Fake: 0.0464, D_Y Total: 0.0525\n",
      "Generator Losses:\n",
      "  G Adv: 0.8010, F Adv: 0.6650\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1191, Perceptual Monet: 0.1605\n",
      "  Total G Loss: 3.4065\n",
      "Epoch [161/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1579, D_X Fake: 0.1151, D_X Total: 0.1365\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0623, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.8731, F Adv: 0.5304\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1831, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.8385\n",
      "Epoch [161/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0704, D_X Fake: 0.0711, D_X Total: 0.0708\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0551, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8240, F Adv: 0.7290\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1007, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.4037\n",
      "Epoch [161/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2007, D_X Fake: 0.0471, D_X Total: 0.1239\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0427, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.9403, F Adv: 0.7163\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1612\n",
      "  Total G Loss: 3.6744\n",
      "Epoch [161/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1108, D_X Fake: 0.1279, D_X Total: 0.1193\n",
      "  D_Y Real: 0.0455, D_Y Fake: 0.0473, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.8378, F Adv: 0.5127\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1548, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 3.6824\n",
      "Epoch [161/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2787, D_X Fake: 0.0694, D_X Total: 0.1741\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0480, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.7074, F Adv: 0.7446\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1794, Perceptual Monet: 0.1906\n",
      "  Total G Loss: 3.9771\n",
      "Epoch [161/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0489, D_X Fake: 0.1520, D_X Total: 0.1005\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.0314, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.9592, F Adv: 0.5256\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1654, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.6804\n",
      "Epoch [161/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1032, D_X Fake: 0.0855, D_X Total: 0.0944\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0312, D_Y Total: 0.0248\n",
      "Generator Losses:\n",
      "  G Adv: 1.0041, F Adv: 0.5402\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1154, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.5761\n",
      "Epoch [161/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0964, D_X Fake: 0.0859, D_X Total: 0.0911\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0428, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.9462, F Adv: 0.6523\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1344, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.6550\n",
      "Epoch [161/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1252, D_X Fake: 0.0616, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0380, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 1.0733, F Adv: 0.7055\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1372, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.8809\n",
      "Epoch [161/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.1208, D_X Total: 0.0947\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.0293, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.8622, F Adv: 0.5196\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.4138\n",
      "Epoch [161/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1000, D_X Fake: 0.1518, D_X Total: 0.1259\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0366, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 0.9289, F Adv: 0.5135\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1527, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 3.5655\n",
      "Epoch [161/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1700, D_X Fake: 0.1226, D_X Total: 0.1463\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0337, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.9334, F Adv: 0.4605\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1836, Perceptual Monet: 0.1428\n",
      "  Total G Loss: 3.5855\n",
      "Epoch [161/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1426, D_X Fake: 0.1151, D_X Total: 0.1289\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0493, D_Y Total: 0.0344\n",
      "Generator Losses:\n",
      "  G Adv: 1.0605, F Adv: 0.5686\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1159, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.5302\n",
      "Epoch [162/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2410, D_X Fake: 0.0781, D_X Total: 0.1596\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0351, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 0.8513, F Adv: 0.6415\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.6640\n",
      "Epoch [162/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2810, D_X Fake: 0.1178, D_X Total: 0.1994\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0523, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.8505, F Adv: 0.5432\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 3.4021\n",
      "Epoch [162/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1961, D_X Fake: 0.0809, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0363, D_Y Fake: 0.0825, D_Y Total: 0.0594\n",
      "Generator Losses:\n",
      "  G Adv: 0.8174, F Adv: 0.6384\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1804, Perceptual Monet: 0.1533\n",
      "  Total G Loss: 3.7232\n",
      "Epoch [162/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1969, D_X Fake: 0.0972, D_X Total: 0.1470\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0305, D_Y Total: 0.0256\n",
      "Generator Losses:\n",
      "  G Adv: 0.8701, F Adv: 0.5264\n",
      "  Cycle Photo: 0.0224, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1131, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.3334\n",
      "Epoch [162/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1667, D_X Fake: 0.1153, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0325, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 1.0088, F Adv: 0.4782\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1840\n",
      "  Total G Loss: 3.7854\n",
      "Epoch [162/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1109, D_X Fake: 0.1379, D_X Total: 0.1244\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0387, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.9345, F Adv: 0.5518\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1616, Perceptual Monet: 0.1924\n",
      "  Total G Loss: 3.9034\n",
      "Epoch [162/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1448, D_X Fake: 0.0960, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0578, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.9958, F Adv: 0.5396\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1227, Perceptual Monet: 0.1633\n",
      "  Total G Loss: 3.4748\n",
      "Epoch [162/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1443, D_X Fake: 0.0823, D_X Total: 0.1133\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0382, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.9017, F Adv: 0.5757\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1522\n",
      "  Total G Loss: 3.5691\n",
      "Epoch [162/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2786, D_X Fake: 0.0881, D_X Total: 0.1834\n",
      "  D_Y Real: 0.0141, D_Y Fake: 0.0325, D_Y Total: 0.0233\n",
      "Generator Losses:\n",
      "  G Adv: 1.0767, F Adv: 0.6151\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1568, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.8122\n",
      "Epoch [162/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2730, D_X Fake: 0.0739, D_X Total: 0.1735\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0312, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.8881, F Adv: 0.5539\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1745\n",
      "  Total G Loss: 3.5399\n",
      "Epoch [162/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0456, D_X Fake: 0.0746, D_X Total: 0.0601\n",
      "  D_Y Real: 0.0532, D_Y Fake: 0.0526, D_Y Total: 0.0529\n",
      "Generator Losses:\n",
      "  G Adv: 0.9605, F Adv: 0.6183\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 3.8375\n",
      "Epoch [162/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.0795, D_X Total: 0.0975\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0577, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 0.8653, F Adv: 0.5968\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1359, Perceptual Monet: 0.1553\n",
      "  Total G Loss: 3.4653\n",
      "Epoch [162/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1532, D_X Fake: 0.1147, D_X Total: 0.1339\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0826, D_Y Total: 0.0503\n",
      "Generator Losses:\n",
      "  G Adv: 1.0080, F Adv: 0.5114\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1138, Perceptual Monet: 0.1484\n",
      "  Total G Loss: 3.3576\n",
      "Epoch [162/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1155, D_X Fake: 0.0798, D_X Total: 0.0976\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0469, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8598, F Adv: 0.6267\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1288, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.5257\n",
      "Epoch [162/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0522, D_X Fake: 0.1014, D_X Total: 0.0768\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0471, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.8141, F Adv: 0.5858\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1245, Perceptual Monet: 0.1811\n",
      "  Total G Loss: 3.4939\n",
      "Epoch [162/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0591, D_X Fake: 0.1023, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0569, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.7856, F Adv: 0.5360\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1569\n",
      "  Total G Loss: 3.2125\n",
      "Epoch [162/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1124, D_X Fake: 0.1286, D_X Total: 0.1205\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0429, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.8220, F Adv: 0.6153\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1671\n",
      "  Total G Loss: 3.5157\n",
      "Epoch [162/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0780, D_X Fake: 0.0977, D_X Total: 0.0879\n",
      "  D_Y Real: 0.0433, D_Y Fake: 0.0443, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.8414, F Adv: 0.5527\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1481, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.7382\n",
      "Epoch [162/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2863, D_X Fake: 0.2140, D_X Total: 0.2502\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0452, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.7375, F Adv: 0.3847\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0191\n",
      "  Perceptual Photo: 0.1364, Perceptual Monet: 0.1169\n",
      "  Total G Loss: 2.8583\n",
      "Epoch [162/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0538, D_X Fake: 0.1385, D_X Total: 0.0961\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0589, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.9138, F Adv: 0.5107\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.5066\n",
      "Epoch [162/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2230, D_X Fake: 0.0820, D_X Total: 0.1525\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0631, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.8454, F Adv: 0.5430\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.5827\n",
      "Epoch [162/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0528, D_X Fake: 0.0948, D_X Total: 0.0738\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0460, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.7926, F Adv: 0.5574\n",
      "  Cycle Photo: 0.0224, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1257, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.2488\n",
      "Epoch [162/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0919, D_X Fake: 0.0733, D_X Total: 0.0826\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0548, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.9328, F Adv: 0.6486\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1838\n",
      "  Total G Loss: 3.8134\n",
      "Epoch [162/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1859, D_X Fake: 0.0739, D_X Total: 0.1299\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0720, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.9180, F Adv: 0.5242\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1378\n",
      "  Total G Loss: 3.3422\n",
      "Epoch [163/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3068, D_X Fake: 0.0887, D_X Total: 0.1978\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0359, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.8298, F Adv: 0.6560\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1189, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 3.6568\n",
      "Epoch [163/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1485, D_X Fake: 0.0599, D_X Total: 0.1042\n",
      "  D_Y Real: 0.0652, D_Y Fake: 0.0305, D_Y Total: 0.0479\n",
      "Generator Losses:\n",
      "  G Adv: 1.0450, F Adv: 0.5897\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.1438\n",
      "  Total G Loss: 3.7444\n",
      "Epoch [163/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1175, D_X Fake: 0.1251, D_X Total: 0.1213\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0529, D_Y Total: 0.0346\n",
      "Generator Losses:\n",
      "  G Adv: 0.8635, F Adv: 0.5225\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1303, Perceptual Monet: 0.1820\n",
      "  Total G Loss: 3.5231\n",
      "Epoch [163/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1317, D_X Fake: 0.1046, D_X Total: 0.1182\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0474, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.7877, F Adv: 0.7112\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1337, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.5781\n",
      "Epoch [163/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0895, D_X Fake: 0.1422, D_X Total: 0.1159\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0569, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8434, F Adv: 0.5637\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1120, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.4404\n",
      "Epoch [163/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2040, D_X Fake: 0.0557, D_X Total: 0.1299\n",
      "  D_Y Real: 0.0136, D_Y Fake: 0.0432, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.9711, F Adv: 0.6811\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1565, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.8368\n",
      "Epoch [163/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1262, D_X Fake: 0.0960, D_X Total: 0.1111\n",
      "  D_Y Real: 0.0628, D_Y Fake: 0.0381, D_Y Total: 0.0505\n",
      "Generator Losses:\n",
      "  G Adv: 0.8591, F Adv: 0.5950\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1317, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.5404\n",
      "Epoch [163/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2307, D_X Fake: 0.0520, D_X Total: 0.1414\n",
      "  D_Y Real: 0.0146, D_Y Fake: 0.0325, D_Y Total: 0.0235\n",
      "Generator Losses:\n",
      "  G Adv: 1.0754, F Adv: 0.7387\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1698\n",
      "  Total G Loss: 4.0027\n",
      "Epoch [163/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1206, D_X Fake: 0.1252, D_X Total: 0.1229\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.0791, D_Y Total: 0.0605\n",
      "Generator Losses:\n",
      "  G Adv: 0.8653, F Adv: 0.5558\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1780\n",
      "  Total G Loss: 3.5988\n",
      "Epoch [163/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1355, D_X Fake: 0.1159, D_X Total: 0.1257\n",
      "  D_Y Real: 0.0472, D_Y Fake: 0.0385, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.6861, F Adv: 0.6020\n",
      "  Cycle Photo: 0.0215, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1001, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.1621\n",
      "Epoch [163/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0676, D_X Fake: 0.1222, D_X Total: 0.0949\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0852, D_Y Total: 0.0520\n",
      "Generator Losses:\n",
      "  G Adv: 0.9077, F Adv: 0.5545\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1536, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 3.7616\n",
      "Epoch [163/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1113, D_X Fake: 0.1056, D_X Total: 0.1084\n",
      "  D_Y Real: 0.0447, D_Y Fake: 0.0416, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.9528, F Adv: 0.6134\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1693\n",
      "  Total G Loss: 3.6172\n",
      "Epoch [163/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1542, D_X Fake: 0.1936, D_X Total: 0.1739\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0479, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.8427, F Adv: 0.3618\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.3324\n",
      "Epoch [163/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2084, D_X Fake: 0.1292, D_X Total: 0.1688\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.0531, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.8371, F Adv: 0.6244\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.5869\n",
      "Epoch [163/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.1347, D_X Total: 0.1122\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0509, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8967, F Adv: 0.5256\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1470\n",
      "  Total G Loss: 3.3822\n",
      "Epoch [163/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0807, D_X Fake: 0.1232, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0342, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9398, F Adv: 0.5595\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1875\n",
      "  Total G Loss: 3.8542\n",
      "Epoch [163/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1940, D_X Fake: 0.0429, D_X Total: 0.1185\n",
      "  D_Y Real: 0.0415, D_Y Fake: 0.0741, D_Y Total: 0.0578\n",
      "Generator Losses:\n",
      "  G Adv: 1.0116, F Adv: 0.7162\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0404\n",
      "  Perceptual Photo: 0.1563, Perceptual Monet: 0.2075\n",
      "  Total G Loss: 4.2420\n",
      "Epoch [163/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1660, D_X Fake: 0.1451, D_X Total: 0.1556\n",
      "  D_Y Real: 0.0442, D_Y Fake: 0.0409, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.9094, F Adv: 0.5319\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.6783\n",
      "Epoch [163/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2244, D_X Fake: 0.0993, D_X Total: 0.1619\n",
      "  D_Y Real: 0.0396, D_Y Fake: 0.0538, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.9953, F Adv: 0.6087\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1684\n",
      "  Total G Loss: 3.6424\n",
      "Epoch [163/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0955, D_X Fake: 0.1328, D_X Total: 0.1142\n",
      "  D_Y Real: 0.0357, D_Y Fake: 0.0763, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.9398, F Adv: 0.5425\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1235, Perceptual Monet: 0.1354\n",
      "  Total G Loss: 3.2832\n",
      "Epoch [163/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0857, D_X Fake: 0.1453, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0503, D_Y Total: 0.0409\n",
      "Generator Losses:\n",
      "  G Adv: 0.7870, F Adv: 0.4780\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1280, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 3.3584\n",
      "Epoch [163/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1573, D_X Fake: 0.0551, D_X Total: 0.1062\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0402, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.7773, F Adv: 0.7384\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1656\n",
      "  Total G Loss: 3.5465\n",
      "Epoch [163/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1024, D_X Fake: 0.1222, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0447, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8443, F Adv: 0.5301\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0206\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1312\n",
      "  Total G Loss: 3.2055\n",
      "Epoch [163/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1073, D_X Fake: 0.0882, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0439, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.9757, F Adv: 0.6678\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1210, Perceptual Monet: 0.1918\n",
      "  Total G Loss: 3.7900\n",
      "Epoch [164/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1444, D_X Fake: 0.0480, D_X Total: 0.0962\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0537, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.7325, F Adv: 0.6806\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1458, Perceptual Monet: 0.1479\n",
      "  Total G Loss: 3.4137\n",
      "Epoch [164/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1864, D_X Fake: 0.0863, D_X Total: 0.1363\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.0336, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 0.9017, F Adv: 0.7015\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.9587\n",
      "Epoch [164/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0493, D_X Fake: 0.1183, D_X Total: 0.0838\n",
      "  D_Y Real: 0.0418, D_Y Fake: 0.0386, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.8241, F Adv: 0.5349\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1534, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.4572\n",
      "Epoch [164/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1099, D_X Fake: 0.1079, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0876, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.5632, F Adv: 0.5406\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1994\n",
      "  Total G Loss: 3.4415\n",
      "Epoch [164/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2194, D_X Fake: 0.1141, D_X Total: 0.1667\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.1151, D_Y Total: 0.0671\n",
      "Generator Losses:\n",
      "  G Adv: 0.6204, F Adv: 0.4863\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1376\n",
      "  Total G Loss: 3.0852\n",
      "Epoch [164/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.0745, D_X Total: 0.0829\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0413, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.7895, F Adv: 0.5363\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1415\n",
      "  Total G Loss: 3.1984\n",
      "Epoch [164/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1000, D_X Fake: 0.0820, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0607, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.8643, F Adv: 0.6154\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1649, Perceptual Monet: 0.1621\n",
      "  Total G Loss: 3.7177\n",
      "Epoch [164/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0920, D_X Fake: 0.0982, D_X Total: 0.0951\n",
      "  D_Y Real: 0.0248, D_Y Fake: 0.0319, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 1.1244, F Adv: 0.6747\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1483\n",
      "  Total G Loss: 3.9031\n",
      "Epoch [164/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1697, D_X Fake: 0.0826, D_X Total: 0.1262\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0346, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8925, F Adv: 0.7383\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0389\n",
      "  Perceptual Photo: 0.1745, Perceptual Monet: 0.1977\n",
      "  Total G Loss: 4.2116\n",
      "Epoch [164/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1692, D_X Fake: 0.1337, D_X Total: 0.1515\n",
      "  D_Y Real: 0.0286, D_Y Fake: 0.0349, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.8548, F Adv: 0.5609\n",
      "  Cycle Photo: 0.0208, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1051, Perceptual Monet: 0.1945\n",
      "  Total G Loss: 3.4644\n",
      "Epoch [164/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1286, D_X Fake: 0.1432, D_X Total: 0.1359\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0500, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 1.1109, F Adv: 0.5735\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1523, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.8180\n",
      "Epoch [164/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1201, D_X Fake: 0.1156, D_X Total: 0.1179\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.0354, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8937, F Adv: 0.5521\n",
      "  Cycle Photo: 0.0198, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1001, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.2568\n",
      "Epoch [164/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0622, D_X Fake: 0.0819, D_X Total: 0.0721\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0677, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.8502, F Adv: 0.5416\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1516\n",
      "  Total G Loss: 3.2747\n",
      "Epoch [164/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2298, D_X Fake: 0.1164, D_X Total: 0.1731\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0541, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.7433, F Adv: 0.5509\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1628, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 3.6620\n",
      "Epoch [164/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2287, D_X Fake: 0.0974, D_X Total: 0.1630\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0447, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.9381, F Adv: 0.4710\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.4433\n",
      "Epoch [164/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0865, D_X Fake: 0.0667, D_X Total: 0.0766\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0668, D_Y Total: 0.0446\n",
      "Generator Losses:\n",
      "  G Adv: 0.8846, F Adv: 0.7335\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1198, Perceptual Monet: 0.1575\n",
      "  Total G Loss: 3.5418\n",
      "Epoch [164/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1287, D_X Fake: 0.0668, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0425, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.9048, F Adv: 0.7843\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1400\n",
      "  Total G Loss: 3.4934\n",
      "Epoch [164/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1933, D_X Fake: 0.0608, D_X Total: 0.1270\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0599, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.6721, F Adv: 0.7316\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.1745\n",
      "  Total G Loss: 3.5501\n",
      "Epoch [164/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1056, D_X Fake: 0.1709, D_X Total: 0.1383\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0578, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.8262, F Adv: 0.4367\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.6707\n",
      "Epoch [164/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1700, D_X Fake: 0.0973, D_X Total: 0.1337\n",
      "  D_Y Real: 0.0407, D_Y Fake: 0.0422, D_Y Total: 0.0415\n",
      "Generator Losses:\n",
      "  G Adv: 0.9066, F Adv: 0.7584\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1237, Perceptual Monet: 0.1903\n",
      "  Total G Loss: 3.8623\n",
      "Epoch [164/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1285, D_X Fake: 0.0795, D_X Total: 0.1040\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0346, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.9671, F Adv: 0.5892\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1385, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.5216\n",
      "Epoch [164/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1600, D_X Fake: 0.1248, D_X Total: 0.1424\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0676, D_Y Total: 0.0465\n",
      "Generator Losses:\n",
      "  G Adv: 0.8985, F Adv: 0.4416\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.5107\n",
      "Epoch [164/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2600, D_X Fake: 0.0557, D_X Total: 0.1578\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0535, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.7559, F Adv: 0.7293\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0358\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1816\n",
      "  Total G Loss: 3.8116\n",
      "Epoch [164/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1119, D_X Fake: 0.2201, D_X Total: 0.1660\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0540, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.7812, F Adv: 0.3625\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1311\n",
      "  Total G Loss: 2.9943\n",
      "Epoch [165/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0694, D_X Fake: 0.1648, D_X Total: 0.1171\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0712, D_Y Total: 0.0541\n",
      "Generator Losses:\n",
      "  G Adv: 0.7055, F Adv: 0.4738\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1070, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.0258\n",
      "Epoch [165/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2222, D_X Fake: 0.0993, D_X Total: 0.1607\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0532, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.8733, F Adv: 0.5002\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1433\n",
      "  Total G Loss: 3.2355\n",
      "Epoch [165/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1353, D_X Fake: 0.0823, D_X Total: 0.1088\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0501, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8664, F Adv: 0.5116\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.5558\n",
      "Epoch [165/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0998, D_X Fake: 0.0371, D_X Total: 0.0685\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.0609, D_Y Total: 0.0498\n",
      "Generator Losses:\n",
      "  G Adv: 0.9577, F Adv: 0.6728\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0254\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1509\n",
      "  Total G Loss: 3.6643\n",
      "Epoch [165/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2979, D_X Fake: 0.0850, D_X Total: 0.1915\n",
      "  D_Y Real: 0.0145, D_Y Fake: 0.0383, D_Y Total: 0.0264\n",
      "Generator Losses:\n",
      "  G Adv: 0.8526, F Adv: 0.6305\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.3880\n",
      "Epoch [165/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1735, D_X Fake: 0.1426, D_X Total: 0.1581\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0483, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.8812, F Adv: 0.6205\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1337, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.5306\n",
      "Epoch [165/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1095, D_X Fake: 0.1175, D_X Total: 0.1135\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0577, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 1.0292, F Adv: 0.5925\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1684, Perceptual Monet: 0.1557\n",
      "  Total G Loss: 3.8200\n",
      "Epoch [165/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1551, D_X Fake: 0.1367, D_X Total: 0.1459\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0324, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.9566, F Adv: 0.5878\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1781, Perceptual Monet: 0.1753\n",
      "  Total G Loss: 4.0291\n",
      "Epoch [165/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1326, D_X Fake: 0.0837, D_X Total: 0.1082\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0471, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.9075, F Adv: 0.6587\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1417, Perceptual Monet: 0.2002\n",
      "  Total G Loss: 3.9577\n",
      "Epoch [165/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1858, D_X Fake: 0.0866, D_X Total: 0.1362\n",
      "  D_Y Real: 0.0405, D_Y Fake: 0.0393, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.9332, F Adv: 0.6206\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1677, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.8045\n",
      "Epoch [165/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0630, D_X Fake: 0.1327, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0378, D_Y Fake: 0.0492, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.9383, F Adv: 0.6035\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1276, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.5935\n",
      "Epoch [165/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2334, D_X Fake: 0.1117, D_X Total: 0.1726\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0845, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 0.8305, F Adv: 0.6435\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.5941\n",
      "Epoch [165/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0791, D_X Fake: 0.1373, D_X Total: 0.1082\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0366, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8583, F Adv: 0.5446\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1174, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 3.3505\n",
      "Epoch [165/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2053, D_X Fake: 0.1167, D_X Total: 0.1610\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0382, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.9928, F Adv: 0.4426\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1568, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.5338\n",
      "Epoch [165/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1153, D_X Fake: 0.1176, D_X Total: 0.1164\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0457, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9937, F Adv: 0.5257\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0349\n",
      "  Perceptual Photo: 0.1148, Perceptual Monet: 0.1823\n",
      "  Total G Loss: 3.6342\n",
      "Epoch [165/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0692, D_X Fake: 0.1115, D_X Total: 0.0903\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0376, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 1.0298, F Adv: 0.6475\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1364, Perceptual Monet: 0.1833\n",
      "  Total G Loss: 3.9188\n",
      "Epoch [165/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0668, D_X Fake: 0.0592, D_X Total: 0.0630\n",
      "  D_Y Real: 0.0585, D_Y Fake: 0.0430, D_Y Total: 0.0507\n",
      "Generator Losses:\n",
      "  G Adv: 0.9343, F Adv: 0.6189\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1042, Perceptual Monet: 0.1436\n",
      "  Total G Loss: 3.3233\n",
      "Epoch [165/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1631, D_X Fake: 0.0672, D_X Total: 0.1152\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.0459, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.8370, F Adv: 0.5921\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.2057\n",
      "  Total G Loss: 4.0155\n",
      "Epoch [165/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0874, D_X Fake: 0.1530, D_X Total: 0.1202\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0499, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.8570, F Adv: 0.4563\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1247, Perceptual Monet: 0.1929\n",
      "  Total G Loss: 3.5570\n",
      "Epoch [165/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0982, D_X Fake: 0.1567, D_X Total: 0.1275\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0407, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8823, F Adv: 0.4710\n",
      "  Cycle Photo: 0.0405, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.2139, Perceptual Monet: 0.1997\n",
      "  Total G Loss: 4.1810\n",
      "Epoch [165/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1329, D_X Fake: 0.1063, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0286, D_Y Fake: 0.0377, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9881, F Adv: 0.5685\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 3.6912\n",
      "Epoch [165/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1349, D_X Fake: 0.1083, D_X Total: 0.1216\n",
      "  D_Y Real: 0.0286, D_Y Fake: 0.0342, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.8566, F Adv: 0.6256\n",
      "  Cycle Photo: 0.0205, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1032, Perceptual Monet: 0.1501\n",
      "  Total G Loss: 3.2220\n",
      "Epoch [165/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2729, D_X Fake: 0.0868, D_X Total: 0.1799\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0494, D_Y Total: 0.0393\n",
      "Generator Losses:\n",
      "  G Adv: 0.8794, F Adv: 0.5555\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.6214\n",
      "Epoch [165/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0664, D_X Fake: 0.1140, D_X Total: 0.0902\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0514, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.7646, F Adv: 0.5523\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1323, Perceptual Monet: 0.1455\n",
      "  Total G Loss: 3.2953\n",
      "Epoch [166/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1725, D_X Fake: 0.0662, D_X Total: 0.1193\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0390, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.8976, F Adv: 0.7165\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1273, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.5968\n",
      "Epoch [166/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1428, D_X Fake: 0.0658, D_X Total: 0.1043\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0444, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.8517, F Adv: 0.6785\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.2012, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 4.0890\n",
      "Epoch [166/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1042, D_X Fake: 0.0895, D_X Total: 0.0968\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0528, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 0.7876, F Adv: 0.5788\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1390\n",
      "  Total G Loss: 3.4135\n",
      "Epoch [166/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0898, D_X Fake: 0.0781, D_X Total: 0.0840\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0399, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.8437, F Adv: 0.5263\n",
      "  Cycle Photo: 0.0338, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.6537\n",
      "Epoch [166/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1038, D_X Fake: 0.1544, D_X Total: 0.1291\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0413, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.9438, F Adv: 0.4581\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.2045, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.8744\n",
      "Epoch [166/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0789, D_X Fake: 0.0800, D_X Total: 0.0794\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0666, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.9378, F Adv: 0.6116\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1811\n",
      "  Total G Loss: 3.8346\n",
      "Epoch [166/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1297, D_X Fake: 0.0930, D_X Total: 0.1114\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0693, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 0.9302, F Adv: 0.6183\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.0999, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.5283\n",
      "Epoch [166/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0760, D_X Fake: 0.0942, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0774, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.7914, F Adv: 0.5379\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.1678\n",
      "  Total G Loss: 3.6087\n",
      "Epoch [166/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0917, D_X Fake: 0.1263, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0316, D_Y Total: 0.0264\n",
      "Generator Losses:\n",
      "  G Adv: 1.0440, F Adv: 0.4212\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1719, Perceptual Monet: 0.1618\n",
      "  Total G Loss: 3.7078\n",
      "Epoch [166/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2765, D_X Fake: 0.0857, D_X Total: 0.1811\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0406, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.9313, F Adv: 0.6487\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1431, Perceptual Monet: 0.1763\n",
      "  Total G Loss: 3.7648\n",
      "Epoch [166/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2439, D_X Fake: 0.1058, D_X Total: 0.1749\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0814, D_Y Total: 0.0549\n",
      "Generator Losses:\n",
      "  G Adv: 0.8633, F Adv: 0.5303\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1482, Perceptual Monet: 0.1431\n",
      "  Total G Loss: 3.3572\n",
      "Epoch [166/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0708, D_X Fake: 0.1457, D_X Total: 0.1082\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0410, D_Y Total: 0.0292\n",
      "Generator Losses:\n",
      "  G Adv: 0.9608, F Adv: 0.4961\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1153, Perceptual Monet: 0.1389\n",
      "  Total G Loss: 3.2496\n",
      "Epoch [166/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1911, D_X Fake: 0.0506, D_X Total: 0.1208\n",
      "  D_Y Real: 0.0302, D_Y Fake: 0.0340, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8317, F Adv: 0.7951\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1283, Perceptual Monet: 0.1886\n",
      "  Total G Loss: 3.9052\n",
      "Epoch [166/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2169, D_X Fake: 0.1066, D_X Total: 0.1618\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0285, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.7736, F Adv: 0.5584\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.3635\n",
      "Epoch [166/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2003, D_X Fake: 0.1211, D_X Total: 0.1607\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0646, D_Y Total: 0.0471\n",
      "Generator Losses:\n",
      "  G Adv: 0.9892, F Adv: 0.5359\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1733, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.8542\n",
      "Epoch [166/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1172, D_X Fake: 0.0748, D_X Total: 0.0960\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0335, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.8915, F Adv: 0.6265\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1192, Perceptual Monet: 0.1846\n",
      "  Total G Loss: 3.6728\n",
      "Epoch [166/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0676, D_X Fake: 0.1366, D_X Total: 0.1021\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0359, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.9046, F Adv: 0.5615\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.6445\n",
      "Epoch [166/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1703, D_X Fake: 0.0905, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0463, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8836, F Adv: 0.6446\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1653, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.7971\n",
      "Epoch [166/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2182, D_X Fake: 0.1067, D_X Total: 0.1625\n",
      "  D_Y Real: 0.0508, D_Y Fake: 0.0361, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 1.1285, F Adv: 0.6798\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.9924\n",
      "Epoch [166/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1529, D_X Fake: 0.1025, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0799, D_Y Total: 0.0504\n",
      "Generator Losses:\n",
      "  G Adv: 0.7697, F Adv: 0.5720\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1397, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.4028\n",
      "Epoch [166/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2270, D_X Fake: 0.0929, D_X Total: 0.1599\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0423, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.7968, F Adv: 0.6906\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0224\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1390\n",
      "  Total G Loss: 3.5283\n",
      "Epoch [166/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0530, D_X Fake: 0.0880, D_X Total: 0.0705\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0432, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 1.0344, F Adv: 0.5074\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1198, Perceptual Monet: 0.1882\n",
      "  Total G Loss: 3.6879\n",
      "Epoch [166/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0586, D_X Fake: 0.1273, D_X Total: 0.0929\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0376, D_Y Total: 0.0330\n",
      "Generator Losses:\n",
      "  G Adv: 0.8405, F Adv: 0.4785\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1188, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.3832\n",
      "Epoch [166/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1673, D_X Fake: 0.0801, D_X Total: 0.1237\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0405, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.9712, F Adv: 0.5082\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1196, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.3503\n",
      "Epoch [167/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0665, D_X Fake: 0.0862, D_X Total: 0.0763\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0794, D_Y Total: 0.0496\n",
      "Generator Losses:\n",
      "  G Adv: 0.8603, F Adv: 0.6267\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1199, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.4134\n",
      "Epoch [167/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0864, D_X Fake: 0.1352, D_X Total: 0.1108\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0445, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.9463, F Adv: 0.4559\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1298, Perceptual Monet: 0.1836\n",
      "  Total G Loss: 3.6330\n",
      "Epoch [167/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0554, D_X Fake: 0.1424, D_X Total: 0.0989\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0354, D_Y Total: 0.0252\n",
      "Generator Losses:\n",
      "  G Adv: 0.9180, F Adv: 0.6111\n",
      "  Cycle Photo: 0.0208, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1009, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 3.4861\n",
      "Epoch [167/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1951, D_X Fake: 0.0777, D_X Total: 0.1364\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0339, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.9973, F Adv: 0.6956\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.9620\n",
      "Epoch [167/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2079, D_X Fake: 0.1737, D_X Total: 0.1908\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0513, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.9727, F Adv: 0.6269\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.7600\n",
      "Epoch [167/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1056, D_X Fake: 0.1016, D_X Total: 0.1036\n",
      "  D_Y Real: 0.0393, D_Y Fake: 0.0543, D_Y Total: 0.0468\n",
      "Generator Losses:\n",
      "  G Adv: 0.7805, F Adv: 0.5991\n",
      "  Cycle Photo: 0.0178, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.0963, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.2545\n",
      "Epoch [167/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1200, D_X Fake: 0.0994, D_X Total: 0.1097\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.0320, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 1.0189, F Adv: 0.5776\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1853\n",
      "  Total G Loss: 3.7804\n",
      "Epoch [167/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1417, D_X Fake: 0.1625, D_X Total: 0.1521\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0473, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.8974, F Adv: 0.4485\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1916, Perceptual Monet: 0.1450\n",
      "  Total G Loss: 3.6234\n",
      "Epoch [167/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0426, D_X Fake: 0.0878, D_X Total: 0.0652\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0686, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.8165, F Adv: 0.5345\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1210, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.3393\n",
      "Epoch [167/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1070, D_X Fake: 0.0642, D_X Total: 0.0856\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0604, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.7962, F Adv: 0.6463\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.5959\n",
      "Epoch [167/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2101, D_X Fake: 0.0908, D_X Total: 0.1504\n",
      "  D_Y Real: 0.0467, D_Y Fake: 0.0645, D_Y Total: 0.0556\n",
      "Generator Losses:\n",
      "  G Adv: 0.8676, F Adv: 0.6866\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1754\n",
      "  Total G Loss: 3.7787\n",
      "Epoch [167/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3285, D_X Fake: 0.0751, D_X Total: 0.2018\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0746, D_Y Total: 0.0490\n",
      "Generator Losses:\n",
      "  G Adv: 0.7666, F Adv: 0.6476\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0398\n",
      "  Perceptual Photo: 0.1862, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.9880\n",
      "Epoch [167/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0738, D_X Fake: 0.0756, D_X Total: 0.0747\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.0306, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.7701, F Adv: 0.7408\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0404\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.2070\n",
      "  Total G Loss: 3.8382\n",
      "Epoch [167/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1348, D_X Fake: 0.0628, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0387, D_Y Fake: 0.0402, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8885, F Adv: 0.7384\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1953\n",
      "  Total G Loss: 3.8986\n",
      "Epoch [167/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0545, D_X Fake: 0.1092, D_X Total: 0.0819\n",
      "  D_Y Real: 0.0334, D_Y Fake: 0.0329, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.6599, F Adv: 0.5505\n",
      "  Cycle Photo: 0.0197, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.0934, Perceptual Monet: 0.2096\n",
      "  Total G Loss: 3.3078\n",
      "Epoch [167/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1320, D_X Fake: 0.1191, D_X Total: 0.1256\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0365, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 1.0015, F Adv: 0.5308\n",
      "  Cycle Photo: 0.0351, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1768, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.9799\n",
      "Epoch [167/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1514, D_X Fake: 0.1197, D_X Total: 0.1356\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.0379, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.8709, F Adv: 0.5421\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.4938\n",
      "Epoch [167/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0832, D_X Fake: 0.1414, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0325, D_Y Total: 0.0237\n",
      "Generator Losses:\n",
      "  G Adv: 1.0481, F Adv: 0.4013\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.3508\n",
      "Epoch [167/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1678, D_X Fake: 0.1050, D_X Total: 0.1364\n",
      "  D_Y Real: 0.0313, D_Y Fake: 0.0309, D_Y Total: 0.0311\n",
      "Generator Losses:\n",
      "  G Adv: 0.8243, F Adv: 0.5589\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.4794\n",
      "Epoch [167/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1895, D_X Fake: 0.1554, D_X Total: 0.1724\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0386, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8848, F Adv: 0.5004\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1481, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.7171\n",
      "Epoch [167/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1185, D_X Fake: 0.0868, D_X Total: 0.1027\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0609, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 1.0419, F Adv: 0.5784\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1359, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 3.6604\n",
      "Epoch [167/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2046, D_X Fake: 0.1045, D_X Total: 0.1546\n",
      "  D_Y Real: 0.0513, D_Y Fake: 0.0371, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.9857, F Adv: 0.6754\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1906\n",
      "  Total G Loss: 3.8780\n",
      "Epoch [167/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0989, D_X Fake: 0.1234, D_X Total: 0.1112\n",
      "  D_Y Real: 0.0519, D_Y Fake: 0.0721, D_Y Total: 0.0620\n",
      "Generator Losses:\n",
      "  G Adv: 1.0365, F Adv: 0.5075\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0204\n",
      "  Perceptual Photo: 0.1643, Perceptual Monet: 0.1320\n",
      "  Total G Loss: 3.5768\n",
      "Epoch [167/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0735, D_X Fake: 0.1185, D_X Total: 0.0960\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0594, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.8631, F Adv: 0.5715\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0377\n",
      "  Perceptual Photo: 0.1133, Perceptual Monet: 0.1861\n",
      "  Total G Loss: 3.5474\n",
      "Epoch [168/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0657, D_X Fake: 0.1166, D_X Total: 0.0912\n",
      "  D_Y Real: 0.0408, D_Y Fake: 0.0710, D_Y Total: 0.0559\n",
      "Generator Losses:\n",
      "  G Adv: 0.7439, F Adv: 0.5439\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1165, Perceptual Monet: 0.1867\n",
      "  Total G Loss: 3.4390\n",
      "Epoch [168/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1883, D_X Fake: 0.1006, D_X Total: 0.1444\n",
      "  D_Y Real: 0.0263, D_Y Fake: 0.0367, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8551, F Adv: 0.6758\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0430\n",
      "  Perceptual Photo: 0.1326, Perceptual Monet: 0.2180\n",
      "  Total G Loss: 3.9929\n",
      "Epoch [168/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1639, D_X Fake: 0.0892, D_X Total: 0.1265\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0523, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.7205, F Adv: 0.5487\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.3992\n",
      "Epoch [168/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1452, D_X Fake: 0.1136, D_X Total: 0.1294\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0331, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9112, F Adv: 0.5863\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1494\n",
      "  Total G Loss: 3.4007\n",
      "Epoch [168/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2137, D_X Fake: 0.0824, D_X Total: 0.1480\n",
      "  D_Y Real: 0.0519, D_Y Fake: 0.0837, D_Y Total: 0.0678\n",
      "Generator Losses:\n",
      "  G Adv: 0.8968, F Adv: 0.6199\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0213\n",
      "  Perceptual Photo: 0.1700, Perceptual Monet: 0.1442\n",
      "  Total G Loss: 3.6374\n",
      "Epoch [168/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1059, D_X Fake: 0.0929, D_X Total: 0.0994\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0495, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8475, F Adv: 0.7249\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1307, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.7893\n",
      "Epoch [168/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0557, D_X Fake: 0.1279, D_X Total: 0.0918\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0331, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9442, F Adv: 0.5224\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1269, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.4815\n",
      "Epoch [168/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1010, D_X Fake: 0.1417, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0502, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.9669, F Adv: 0.5636\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1237, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.5994\n",
      "Epoch [168/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0600, D_X Fake: 0.0912, D_X Total: 0.0756\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0363, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.8096, F Adv: 0.5133\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1107, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.3404\n",
      "Epoch [168/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2367, D_X Fake: 0.0735, D_X Total: 0.1551\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0370, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.9828, F Adv: 0.7083\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1697, Perceptual Monet: 0.2054\n",
      "  Total G Loss: 4.2950\n",
      "Epoch [168/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0565, D_X Fake: 0.1137, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0463, D_Y Fake: 0.0396, D_Y Total: 0.0430\n",
      "Generator Losses:\n",
      "  G Adv: 0.7542, F Adv: 0.5700\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.4751\n",
      "Epoch [168/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0702, D_X Fake: 0.1994, D_X Total: 0.1348\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0481, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8601, F Adv: 0.4015\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1552, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.3978\n",
      "Epoch [168/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2192, D_X Fake: 0.0635, D_X Total: 0.1413\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0504, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.6926, F Adv: 0.6948\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1435, Perceptual Monet: 0.1449\n",
      "  Total G Loss: 3.3534\n",
      "Epoch [168/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1425, D_X Fake: 0.0934, D_X Total: 0.1180\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0496, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.8484, F Adv: 0.6747\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1777\n",
      "  Total G Loss: 3.7544\n",
      "Epoch [168/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1327, D_X Fake: 0.1375, D_X Total: 0.1351\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0307, D_Y Total: 0.0261\n",
      "Generator Losses:\n",
      "  G Adv: 1.0008, F Adv: 0.5180\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1477, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.7039\n",
      "Epoch [168/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1863, D_X Fake: 0.1449, D_X Total: 0.1656\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0549, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.8971, F Adv: 0.5375\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.2008\n",
      "  Total G Loss: 3.9691\n",
      "Epoch [168/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1262, D_X Fake: 0.1122, D_X Total: 0.1192\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0338, D_Y Total: 0.0254\n",
      "Generator Losses:\n",
      "  G Adv: 0.9186, F Adv: 0.5354\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1417, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.5059\n",
      "Epoch [168/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1026, D_X Fake: 0.0891, D_X Total: 0.0958\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0651, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.9786, F Adv: 0.5946\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1469, Perceptual Monet: 0.1510\n",
      "  Total G Loss: 3.5940\n",
      "Epoch [168/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3008, D_X Fake: 0.0693, D_X Total: 0.1851\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0456, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8793, F Adv: 0.6168\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1738\n",
      "  Total G Loss: 3.5653\n",
      "Epoch [168/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0837, D_X Fake: 0.0758, D_X Total: 0.0797\n",
      "  D_Y Real: 0.0368, D_Y Fake: 0.0313, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.9317, F Adv: 0.5450\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0354\n",
      "  Perceptual Photo: 0.1091, Perceptual Monet: 0.1958\n",
      "  Total G Loss: 3.5864\n",
      "Epoch [168/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2072, D_X Fake: 0.0677, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0504, D_Y Total: 0.0452\n",
      "Generator Losses:\n",
      "  G Adv: 0.9987, F Adv: 0.6099\n",
      "  Cycle Photo: 0.0371, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1801, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 4.0498\n",
      "Epoch [168/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1464, D_X Fake: 0.1176, D_X Total: 0.1320\n",
      "  D_Y Real: 0.0149, D_Y Fake: 0.0578, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 0.7955, F Adv: 0.6790\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.6299\n",
      "Epoch [168/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1549, D_X Fake: 0.1127, D_X Total: 0.1338\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0609, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.8009, F Adv: 0.5335\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1279, Perceptual Monet: 0.1945\n",
      "  Total G Loss: 3.5446\n",
      "Epoch [168/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1512, D_X Fake: 0.0904, D_X Total: 0.1208\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0357, D_Y Total: 0.0301\n",
      "Generator Losses:\n",
      "  G Adv: 1.0216, F Adv: 0.5624\n",
      "  Cycle Photo: 0.0214, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.4209\n",
      "Epoch [169/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1793, D_X Fake: 0.0769, D_X Total: 0.1281\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0351, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9505, F Adv: 0.7351\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1450, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.8311\n",
      "Epoch [169/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1836, D_X Fake: 0.0673, D_X Total: 0.1254\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.0305, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 1.0942, F Adv: 0.8069\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1829, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 4.4037\n",
      "Epoch [169/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2264, D_X Fake: 0.0907, D_X Total: 0.1585\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0668, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.7599, F Adv: 0.5712\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1714, Perceptual Monet: 0.1953\n",
      "  Total G Loss: 3.8728\n",
      "Epoch [169/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1885, D_X Fake: 0.0683, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0428, D_Y Fake: 0.0376, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.7544, F Adv: 0.5930\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1824\n",
      "  Total G Loss: 3.4961\n",
      "Epoch [169/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1213, D_X Fake: 0.1079, D_X Total: 0.1146\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0593, D_Y Total: 0.0373\n",
      "Generator Losses:\n",
      "  G Adv: 0.9698, F Adv: 0.5435\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1349, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.5221\n",
      "Epoch [169/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0765, D_X Fake: 0.0490, D_X Total: 0.0627\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0368, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.9850, F Adv: 0.7519\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1710\n",
      "  Total G Loss: 3.8858\n",
      "Epoch [169/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2719, D_X Fake: 0.0980, D_X Total: 0.1849\n",
      "  D_Y Real: 0.0538, D_Y Fake: 0.0810, D_Y Total: 0.0674\n",
      "Generator Losses:\n",
      "  G Adv: 0.7352, F Adv: 0.6605\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.0949, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 3.3849\n",
      "Epoch [169/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0979, D_X Fake: 0.0994, D_X Total: 0.0987\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0418, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.9758, F Adv: 0.5381\n",
      "  Cycle Photo: 0.0377, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1872, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.9015\n",
      "Epoch [169/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3288, D_X Fake: 0.1234, D_X Total: 0.2261\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0492, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.7017, F Adv: 0.4658\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1343, Perceptual Monet: 0.1365\n",
      "  Total G Loss: 3.0602\n",
      "Epoch [169/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2495, D_X Fake: 0.0876, D_X Total: 0.1686\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0666, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 0.8403, F Adv: 0.4566\n",
      "  Cycle Photo: 0.0398, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1917, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.6665\n",
      "Epoch [169/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0556, D_X Fake: 0.0851, D_X Total: 0.0703\n",
      "  D_Y Real: 0.0257, D_Y Fake: 0.0349, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8908, F Adv: 0.5715\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1307, Perceptual Monet: 0.1685\n",
      "  Total G Loss: 3.5904\n",
      "Epoch [169/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.1209, D_X Total: 0.1339\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0400, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.9379, F Adv: 0.5452\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1798\n",
      "  Total G Loss: 3.7222\n",
      "Epoch [169/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1586, D_X Fake: 0.1061, D_X Total: 0.1324\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0453, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.7669, F Adv: 0.5655\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1608, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.5968\n",
      "Epoch [169/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2384, D_X Fake: 0.0998, D_X Total: 0.1691\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0486, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.9669, F Adv: 0.7011\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1824, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 4.1534\n",
      "Epoch [169/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2325, D_X Fake: 0.0781, D_X Total: 0.1553\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0637, D_Y Total: 0.0466\n",
      "Generator Losses:\n",
      "  G Adv: 0.7406, F Adv: 0.7884\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 3.8408\n",
      "Epoch [169/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1554, D_X Fake: 0.1159, D_X Total: 0.1357\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0425, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.9640, F Adv: 0.5011\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1352, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.5653\n",
      "Epoch [169/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1164, D_X Fake: 0.1194, D_X Total: 0.1179\n",
      "  D_Y Real: 0.0447, D_Y Fake: 0.0934, D_Y Total: 0.0691\n",
      "Generator Losses:\n",
      "  G Adv: 0.8912, F Adv: 0.6499\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1510, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.6157\n",
      "Epoch [169/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0652, D_X Fake: 0.0732, D_X Total: 0.0692\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0313, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 1.0518, F Adv: 0.6614\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1566, Perceptual Monet: 0.1907\n",
      "  Total G Loss: 4.0933\n",
      "Epoch [169/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1356, D_X Fake: 0.0944, D_X Total: 0.1150\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0515, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.8651, F Adv: 0.6548\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.8734\n",
      "Epoch [169/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2178, D_X Fake: 0.0925, D_X Total: 0.1551\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0421, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.9579, F Adv: 0.5872\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1440\n",
      "  Total G Loss: 3.4906\n",
      "Epoch [169/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0674, D_X Fake: 0.0885, D_X Total: 0.0779\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0386, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 1.0102, F Adv: 0.6412\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0403\n",
      "  Perceptual Photo: 0.1555, Perceptual Monet: 0.2299\n",
      "  Total G Loss: 4.2917\n",
      "Epoch [169/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2264, D_X Fake: 0.1218, D_X Total: 0.1741\n",
      "  D_Y Real: 0.0330, D_Y Fake: 0.0354, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.8617, F Adv: 0.5143\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1679, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.6950\n",
      "Epoch [169/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1523, D_X Fake: 0.0681, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0384, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.8824, F Adv: 0.7077\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1793\n",
      "  Total G Loss: 3.8295\n",
      "Epoch [169/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0355, D_X Fake: 0.0962, D_X Total: 0.0658\n",
      "  D_Y Real: 0.0374, D_Y Fake: 0.0601, D_Y Total: 0.0487\n",
      "Generator Losses:\n",
      "  G Adv: 0.8318, F Adv: 0.6329\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1124, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.4650\n",
      "Epoch [170/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1327, D_X Fake: 0.0478, D_X Total: 0.0903\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0754, D_Y Total: 0.0478\n",
      "Generator Losses:\n",
      "  G Adv: 0.8408, F Adv: 0.6505\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1435\n",
      "  Total G Loss: 3.3446\n",
      "Epoch [170/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1519, D_X Fake: 0.1395, D_X Total: 0.1457\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0681, D_Y Total: 0.0494\n",
      "Generator Losses:\n",
      "  G Adv: 1.0561, F Adv: 0.4672\n",
      "  Cycle Photo: 0.0321, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1546\n",
      "  Total G Loss: 3.6808\n",
      "Epoch [170/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0548, D_X Fake: 0.1425, D_X Total: 0.0987\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0500, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 1.0612, F Adv: 0.4881\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0410\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.2047\n",
      "  Total G Loss: 3.8997\n",
      "Epoch [170/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1210, D_X Fake: 0.0726, D_X Total: 0.0968\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0563, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.9684, F Adv: 0.6669\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1783, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 4.0193\n",
      "Epoch [170/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1773, D_X Fake: 0.0670, D_X Total: 0.1222\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0611, D_Y Total: 0.0445\n",
      "Generator Losses:\n",
      "  G Adv: 0.8153, F Adv: 0.7149\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1175, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.5521\n",
      "Epoch [170/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1943, D_X Fake: 0.0683, D_X Total: 0.1313\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0352, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.9098, F Adv: 0.6987\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1625, Perceptual Monet: 0.1373\n",
      "  Total G Loss: 3.6308\n",
      "Epoch [170/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1422, D_X Fake: 0.1311, D_X Total: 0.1366\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0304, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 1.0879, F Adv: 0.4777\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1481\n",
      "  Total G Loss: 3.5838\n",
      "Epoch [170/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1462, D_X Fake: 0.1363, D_X Total: 0.1412\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0744, D_Y Total: 0.0509\n",
      "Generator Losses:\n",
      "  G Adv: 0.7932, F Adv: 0.6521\n",
      "  Cycle Photo: 0.0213, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1135, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.3716\n",
      "Epoch [170/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0823, D_X Fake: 0.0640, D_X Total: 0.0732\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0572, D_Y Total: 0.0457\n",
      "Generator Losses:\n",
      "  G Adv: 0.7480, F Adv: 0.7220\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1189, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.3924\n",
      "Epoch [170/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1078, D_X Fake: 0.1306, D_X Total: 0.1192\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0362, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 1.0861, F Adv: 0.4153\n",
      "  Cycle Photo: 0.0392, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1552, Perceptual Monet: 0.1566\n",
      "  Total G Loss: 3.6924\n",
      "Epoch [170/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1453, D_X Fake: 0.1340, D_X Total: 0.1396\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0932, D_Y Total: 0.0614\n",
      "Generator Losses:\n",
      "  G Adv: 0.7728, F Adv: 0.4887\n",
      "  Cycle Photo: 0.0369, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1679, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.5390\n",
      "Epoch [170/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1394, D_X Fake: 0.1040, D_X Total: 0.1217\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0653, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.9321, F Adv: 0.5713\n",
      "  Cycle Photo: 0.0429, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1182, Perceptual Monet: 0.1570\n",
      "  Total G Loss: 3.5667\n",
      "Epoch [170/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1333, D_X Fake: 0.0813, D_X Total: 0.1073\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.0517, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.9122, F Adv: 0.6046\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0200\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1424\n",
      "  Total G Loss: 3.2258\n",
      "Epoch [170/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1390, D_X Fake: 0.1516, D_X Total: 0.1453\n",
      "  D_Y Real: 0.0449, D_Y Fake: 0.0516, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 1.0405, F Adv: 0.6273\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1346, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.6723\n",
      "Epoch [170/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2006, D_X Fake: 0.0749, D_X Total: 0.1377\n",
      "  D_Y Real: 0.0370, D_Y Fake: 0.0447, D_Y Total: 0.0408\n",
      "Generator Losses:\n",
      "  G Adv: 0.8624, F Adv: 0.6402\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1346, Perceptual Monet: 0.1497\n",
      "  Total G Loss: 3.4114\n",
      "Epoch [170/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1078, D_X Fake: 0.0732, D_X Total: 0.0905\n",
      "  D_Y Real: 0.0448, D_Y Fake: 0.0439, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.7285, F Adv: 0.6752\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1380, Perceptual Monet: 0.1931\n",
      "  Total G Loss: 3.6796\n",
      "Epoch [170/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1489, D_X Fake: 0.0838, D_X Total: 0.1163\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0663, D_Y Total: 0.0472\n",
      "Generator Losses:\n",
      "  G Adv: 0.9017, F Adv: 0.5523\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1632, Perceptual Monet: 0.1661\n",
      "  Total G Loss: 3.7870\n",
      "Epoch [170/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1201, D_X Fake: 0.1165, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0557, D_Y Total: 0.0428\n",
      "Generator Losses:\n",
      "  G Adv: 0.8979, F Adv: 0.4543\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1574, Perceptual Monet: 0.1472\n",
      "  Total G Loss: 3.4134\n",
      "Epoch [170/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1475, D_X Fake: 0.1001, D_X Total: 0.1238\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0447, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.9407, F Adv: 0.5708\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1656, Perceptual Monet: 0.1316\n",
      "  Total G Loss: 3.5127\n",
      "Epoch [170/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1317, D_X Fake: 0.1638, D_X Total: 0.1477\n",
      "  D_Y Real: 0.0391, D_Y Fake: 0.0459, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.9311, F Adv: 0.4456\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1292, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.2758\n",
      "Epoch [170/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1722, D_X Fake: 0.1301, D_X Total: 0.1512\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.0385, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.8214, F Adv: 0.6329\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.9442\n",
      "Epoch [170/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1207, D_X Fake: 0.1167, D_X Total: 0.1187\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0464, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.7784, F Adv: 0.5708\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1647, Perceptual Monet: 0.1825\n",
      "  Total G Loss: 3.6967\n",
      "Epoch [170/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2084, D_X Fake: 0.1463, D_X Total: 0.1773\n",
      "  D_Y Real: 0.0274, D_Y Fake: 0.0536, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.9078, F Adv: 0.4539\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1339, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.4973\n",
      "Epoch [170/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0682, D_X Fake: 0.1439, D_X Total: 0.1061\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0589, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.9040, F Adv: 0.5493\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.4062\n",
      "Epoch [171/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0976, D_X Fake: 0.1087, D_X Total: 0.1032\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0409, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.8493, F Adv: 0.5065\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1280, Perceptual Monet: 0.1671\n",
      "  Total G Loss: 3.3417\n",
      "Epoch [171/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2829, D_X Fake: 0.0665, D_X Total: 0.1747\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0476, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.9971, F Adv: 0.8095\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1765\n",
      "  Total G Loss: 3.9200\n",
      "Epoch [171/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0618, D_X Fake: 0.1029, D_X Total: 0.0823\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0363, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.9601, F Adv: 0.5827\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0239\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.4058\n",
      "Epoch [171/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2105, D_X Fake: 0.1267, D_X Total: 0.1686\n",
      "  D_Y Real: 0.0380, D_Y Fake: 0.0466, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.8391, F Adv: 0.4545\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1657, Perceptual Monet: 0.1791\n",
      "  Total G Loss: 3.6970\n",
      "Epoch [171/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2933, D_X Fake: 0.1004, D_X Total: 0.1969\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0378, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.9247, F Adv: 0.5653\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1577\n",
      "  Total G Loss: 3.5916\n",
      "Epoch [171/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1508, D_X Fake: 0.0649, D_X Total: 0.1079\n",
      "  D_Y Real: 0.0348, D_Y Fake: 0.0336, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.9850, F Adv: 0.6406\n",
      "  Cycle Photo: 0.0269, Cycle Monet: 0.0222\n",
      "  Perceptual Photo: 0.1429, Perceptual Monet: 0.1371\n",
      "  Total G Loss: 3.5170\n",
      "Epoch [171/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1189, D_X Fake: 0.0646, D_X Total: 0.0918\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0606, D_Y Total: 0.0455\n",
      "Generator Losses:\n",
      "  G Adv: 0.9572, F Adv: 0.6682\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1690, Perceptual Monet: 0.1539\n",
      "  Total G Loss: 3.8500\n",
      "Epoch [171/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1867, D_X Fake: 0.0899, D_X Total: 0.1383\n",
      "  D_Y Real: 0.0383, D_Y Fake: 0.0338, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 1.0235, F Adv: 0.6219\n",
      "  Cycle Photo: 0.0454, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1666\n",
      "  Total G Loss: 4.0224\n",
      "Epoch [171/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1770, D_X Fake: 0.0896, D_X Total: 0.1333\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0327, D_Y Total: 0.0291\n",
      "Generator Losses:\n",
      "  G Adv: 0.9929, F Adv: 0.6030\n",
      "  Cycle Photo: 0.0397, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.2196, Perceptual Monet: 0.1446\n",
      "  Total G Loss: 4.0368\n",
      "Epoch [171/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1917, D_X Fake: 0.0983, D_X Total: 0.1450\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0388, D_Y Total: 0.0319\n",
      "Generator Losses:\n",
      "  G Adv: 0.9333, F Adv: 0.6221\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1360, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.5893\n",
      "Epoch [171/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1486, D_X Fake: 0.1235, D_X Total: 0.1360\n",
      "  D_Y Real: 0.0350, D_Y Fake: 0.0351, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.8891, F Adv: 0.5301\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1169, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.3037\n",
      "Epoch [171/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0834, D_X Fake: 0.0592, D_X Total: 0.0713\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.1117, D_Y Total: 0.0655\n",
      "Generator Losses:\n",
      "  G Adv: 0.9359, F Adv: 0.6693\n",
      "  Cycle Photo: 0.0374, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1740, Perceptual Monet: 0.1681\n",
      "  Total G Loss: 3.9607\n",
      "Epoch [171/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2469, D_X Fake: 0.0895, D_X Total: 0.1682\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0527, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.8936, F Adv: 0.6115\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.6824\n",
      "Epoch [171/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0852, D_X Fake: 0.1106, D_X Total: 0.0979\n",
      "  D_Y Real: 0.0484, D_Y Fake: 0.0457, D_Y Total: 0.0470\n",
      "Generator Losses:\n",
      "  G Adv: 0.9803, F Adv: 0.5718\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1619\n",
      "  Total G Loss: 3.5646\n",
      "Epoch [171/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0528, D_X Fake: 0.0672, D_X Total: 0.0600\n",
      "  D_Y Real: 0.0492, D_Y Fake: 0.0388, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 0.9123, F Adv: 0.6001\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0405\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1965\n",
      "  Total G Loss: 3.8420\n",
      "Epoch [171/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1653, D_X Fake: 0.0986, D_X Total: 0.1320\n",
      "  D_Y Real: 0.0354, D_Y Fake: 0.0581, D_Y Total: 0.0467\n",
      "Generator Losses:\n",
      "  G Adv: 0.8748, F Adv: 0.6775\n",
      "  Cycle Photo: 0.0229, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1229, Perceptual Monet: 0.2086\n",
      "  Total G Loss: 3.7875\n",
      "Epoch [171/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2119, D_X Fake: 0.1155, D_X Total: 0.1637\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0387, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.9123, F Adv: 0.4892\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1684\n",
      "  Total G Loss: 3.5630\n",
      "Epoch [171/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1628, D_X Fake: 0.0898, D_X Total: 0.1263\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.0310, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.8782, F Adv: 0.6177\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1323, Perceptual Monet: 0.1844\n",
      "  Total G Loss: 3.6514\n",
      "Epoch [171/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1531, D_X Fake: 0.0737, D_X Total: 0.1134\n",
      "  D_Y Real: 0.0183, D_Y Fake: 0.0619, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.8275, F Adv: 0.5182\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.4773\n",
      "Epoch [171/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1061, D_X Fake: 0.1224, D_X Total: 0.1143\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0322, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 0.9178, F Adv: 0.4600\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1256, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.3479\n",
      "Epoch [171/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0911, D_X Fake: 0.0857, D_X Total: 0.0884\n",
      "  D_Y Real: 0.0457, D_Y Fake: 0.0599, D_Y Total: 0.0528\n",
      "Generator Losses:\n",
      "  G Adv: 1.2295, F Adv: 0.6365\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.9987\n",
      "Epoch [171/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1901, D_X Fake: 0.0893, D_X Total: 0.1397\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0364, D_Y Total: 0.0261\n",
      "Generator Losses:\n",
      "  G Adv: 0.9301, F Adv: 0.5566\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 3.7183\n",
      "Epoch [171/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2600, D_X Fake: 0.0950, D_X Total: 0.1775\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0486, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.8200, F Adv: 0.7483\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1876\n",
      "  Total G Loss: 3.8196\n",
      "Epoch [171/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1613, D_X Fake: 0.1168, D_X Total: 0.1390\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0571, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.9092, F Adv: 0.5095\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0201\n",
      "  Perceptual Photo: 0.1539, Perceptual Monet: 0.1297\n",
      "  Total G Loss: 3.3352\n",
      "Epoch [172/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1516, D_X Fake: 0.0861, D_X Total: 0.1188\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0534, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 1.0428, F Adv: 0.6932\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1733\n",
      "  Total G Loss: 3.8936\n",
      "Epoch [172/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1559, D_X Fake: 0.0788, D_X Total: 0.1174\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.1189, D_Y Total: 0.0681\n",
      "Generator Losses:\n",
      "  G Adv: 0.6148, F Adv: 0.7107\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0383\n",
      "  Perceptual Photo: 0.1405, Perceptual Monet: 0.1970\n",
      "  Total G Loss: 3.6632\n",
      "Epoch [172/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.1032, D_X Total: 0.0995\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0351, D_Y Total: 0.0280\n",
      "Generator Losses:\n",
      "  G Adv: 0.6748, F Adv: 0.5698\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1390, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.3016\n",
      "Epoch [172/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0480, D_X Fake: 0.0749, D_X Total: 0.0614\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0358, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.9321, F Adv: 0.5127\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1482, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.6147\n",
      "Epoch [172/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0724, D_X Fake: 0.0979, D_X Total: 0.0851\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0452, D_Y Total: 0.0311\n",
      "Generator Losses:\n",
      "  G Adv: 1.0409, F Adv: 0.5286\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.7735\n",
      "Epoch [172/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1626, D_X Fake: 0.1265, D_X Total: 0.1446\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0614, D_Y Total: 0.0422\n",
      "Generator Losses:\n",
      "  G Adv: 0.7318, F Adv: 0.6146\n",
      "  Cycle Photo: 0.0360, Cycle Monet: 0.0168\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1216\n",
      "  Total G Loss: 3.2763\n",
      "Epoch [172/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0691, D_X Fake: 0.1176, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0660, D_Y Total: 0.0447\n",
      "Generator Losses:\n",
      "  G Adv: 0.7100, F Adv: 0.5014\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1960\n",
      "  Total G Loss: 3.4709\n",
      "Epoch [172/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3702, D_X Fake: 0.0857, D_X Total: 0.2279\n",
      "  D_Y Real: 0.0449, D_Y Fake: 0.0327, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.9040, F Adv: 0.6066\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1450, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.7285\n",
      "Epoch [172/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1618, D_X Fake: 0.0972, D_X Total: 0.1295\n",
      "  D_Y Real: 0.0373, D_Y Fake: 0.0358, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.8731, F Adv: 0.6441\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0235\n",
      "  Perceptual Photo: 0.1592, Perceptual Monet: 0.1454\n",
      "  Total G Loss: 3.5859\n",
      "Epoch [172/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0549, D_X Fake: 0.0829, D_X Total: 0.0689\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0501, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.8551, F Adv: 0.5972\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.4845\n",
      "Epoch [172/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1815, D_X Fake: 0.0656, D_X Total: 0.1236\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0400, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.9200, F Adv: 0.6997\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1623\n",
      "  Total G Loss: 3.7029\n",
      "Epoch [172/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2217, D_X Fake: 0.0600, D_X Total: 0.1408\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0335, D_Y Total: 0.0270\n",
      "Generator Losses:\n",
      "  G Adv: 0.9469, F Adv: 0.7207\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.7724\n",
      "Epoch [172/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1572, D_X Fake: 0.1606, D_X Total: 0.1589\n",
      "  D_Y Real: 0.0259, D_Y Fake: 0.0518, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.8890, F Adv: 0.4304\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.1284, Perceptual Monet: 0.1827\n",
      "  Total G Loss: 3.4803\n",
      "Epoch [172/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0744, D_X Fake: 0.1152, D_X Total: 0.0948\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0484, D_Y Total: 0.0346\n",
      "Generator Losses:\n",
      "  G Adv: 0.8571, F Adv: 0.5442\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1470, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.5949\n",
      "Epoch [172/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2355, D_X Fake: 0.0804, D_X Total: 0.1580\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0599, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.7482, F Adv: 0.6058\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1398, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.4116\n",
      "Epoch [172/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1355, D_X Fake: 0.0770, D_X Total: 0.1063\n",
      "  D_Y Real: 0.0317, D_Y Fake: 0.0400, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.9184, F Adv: 0.5982\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0348\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1849\n",
      "  Total G Loss: 3.6858\n",
      "Epoch [172/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0712, D_X Fake: 0.0863, D_X Total: 0.0788\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0538, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.8941, F Adv: 0.6363\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1215, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.6335\n",
      "Epoch [172/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1995, D_X Fake: 0.1917, D_X Total: 0.1956\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0449, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.7807, F Adv: 0.4783\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1460, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.2928\n",
      "Epoch [172/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2284, D_X Fake: 0.0593, D_X Total: 0.1438\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0376, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.8738, F Adv: 0.6783\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1395\n",
      "  Total G Loss: 3.4785\n",
      "Epoch [172/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1842, D_X Fake: 0.0825, D_X Total: 0.1333\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0343, D_Y Total: 0.0252\n",
      "Generator Losses:\n",
      "  G Adv: 0.8564, F Adv: 0.7035\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1519, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.8780\n",
      "Epoch [172/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0545, D_X Fake: 0.0883, D_X Total: 0.0714\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0530, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8728, F Adv: 0.5295\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1131, Perceptual Monet: 0.1494\n",
      "  Total G Loss: 3.2146\n",
      "Epoch [172/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0432, D_X Fake: 0.1214, D_X Total: 0.0823\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0340, D_Y Total: 0.0271\n",
      "Generator Losses:\n",
      "  G Adv: 0.9082, F Adv: 0.6956\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.1759\n",
      "  Total G Loss: 3.9811\n",
      "Epoch [172/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1264, D_X Fake: 0.1125, D_X Total: 0.1195\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0553, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.9938, F Adv: 0.3359\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1437, Perceptual Monet: 0.1868\n",
      "  Total G Loss: 3.5673\n",
      "Epoch [172/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1458, D_X Fake: 0.0710, D_X Total: 0.1084\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0428, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.9028, F Adv: 0.6349\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.6264\n",
      "Epoch [173/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1880, D_X Fake: 0.1291, D_X Total: 0.1585\n",
      "  D_Y Real: 0.0300, D_Y Fake: 0.0309, D_Y Total: 0.0304\n",
      "Generator Losses:\n",
      "  G Adv: 1.0500, F Adv: 0.5110\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.7344\n",
      "Epoch [173/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2128, D_X Fake: 0.1502, D_X Total: 0.1815\n",
      "  D_Y Real: 0.0309, D_Y Fake: 0.0450, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 0.9611, F Adv: 0.4889\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1611, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.7307\n",
      "Epoch [173/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2408, D_X Fake: 0.0832, D_X Total: 0.1620\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0556, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.9204, F Adv: 0.5328\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.5544\n",
      "Epoch [173/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0893, D_X Fake: 0.0779, D_X Total: 0.0836\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0355, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8694, F Adv: 0.5539\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.4763\n",
      "Epoch [173/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3263, D_X Fake: 0.0617, D_X Total: 0.1940\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.0275, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.9185, F Adv: 0.7032\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1823\n",
      "  Total G Loss: 3.8610\n",
      "Epoch [173/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0872, D_X Fake: 0.0901, D_X Total: 0.0886\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0363, D_Y Total: 0.0272\n",
      "Generator Losses:\n",
      "  G Adv: 0.9125, F Adv: 0.6502\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1297, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.6694\n",
      "Epoch [173/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1117, D_X Fake: 0.1447, D_X Total: 0.1282\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0591, D_Y Total: 0.0422\n",
      "Generator Losses:\n",
      "  G Adv: 0.7950, F Adv: 0.4277\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1138, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.2583\n",
      "Epoch [173/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1104, D_X Fake: 0.1245, D_X Total: 0.1174\n",
      "  D_Y Real: 0.0147, D_Y Fake: 0.0337, D_Y Total: 0.0242\n",
      "Generator Losses:\n",
      "  G Adv: 0.7203, F Adv: 0.3829\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0217\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.0280\n",
      "Epoch [173/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2682, D_X Fake: 0.0754, D_X Total: 0.1718\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0480, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8275, F Adv: 0.5902\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1712\n",
      "  Total G Loss: 3.5339\n",
      "Epoch [173/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0796, D_X Fake: 0.1216, D_X Total: 0.1006\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0566, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 0.7048, F Adv: 0.5425\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.1469\n",
      "  Total G Loss: 3.1174\n",
      "Epoch [173/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1950, D_X Fake: 0.0766, D_X Total: 0.1358\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0548, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.7855, F Adv: 0.6664\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1683, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.7399\n",
      "Epoch [173/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1441, D_X Fake: 0.0698, D_X Total: 0.1069\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0508, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.9670, F Adv: 0.5961\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 3.8278\n",
      "Epoch [173/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1851, D_X Fake: 0.0328, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0367, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9281, F Adv: 0.7371\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1622\n",
      "  Total G Loss: 3.6220\n",
      "Epoch [173/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1218, D_X Fake: 0.0590, D_X Total: 0.0904\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0291, D_Y Total: 0.0230\n",
      "Generator Losses:\n",
      "  G Adv: 1.1047, F Adv: 0.6191\n",
      "  Cycle Photo: 0.0220, Cycle Monet: 0.0214\n",
      "  Perceptual Photo: 0.1057, Perceptual Monet: 0.1357\n",
      "  Total G Loss: 3.3647\n",
      "Epoch [173/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1062, D_X Fake: 0.1399, D_X Total: 0.1230\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0585, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.9023, F Adv: 0.5202\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1540, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.5644\n",
      "Epoch [173/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1621, D_X Fake: 0.0907, D_X Total: 0.1264\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0304, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.8971, F Adv: 0.5890\n",
      "  Cycle Photo: 0.0193, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1089, Perceptual Monet: 0.1749\n",
      "  Total G Loss: 3.3978\n",
      "Epoch [173/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1436, D_X Fake: 0.0985, D_X Total: 0.1211\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0495, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.7309, F Adv: 0.5857\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0337\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.5824\n",
      "Epoch [173/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1085, D_X Fake: 0.1118, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0490, D_Y Fake: 0.0594, D_Y Total: 0.0542\n",
      "Generator Losses:\n",
      "  G Adv: 0.8561, F Adv: 0.5935\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0427\n",
      "  Perceptual Photo: 0.1199, Perceptual Monet: 0.2119\n",
      "  Total G Loss: 3.7674\n",
      "Epoch [173/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0765, D_X Fake: 0.0859, D_X Total: 0.0812\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0330, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.8735, F Adv: 0.6311\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0385\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 3.8069\n",
      "Epoch [173/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1448, D_X Fake: 0.1351, D_X Total: 0.1399\n",
      "  D_Y Real: 0.0450, D_Y Fake: 0.0458, D_Y Total: 0.0454\n",
      "Generator Losses:\n",
      "  G Adv: 1.0228, F Adv: 0.4776\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.6377\n",
      "Epoch [173/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1446, D_X Fake: 0.1090, D_X Total: 0.1268\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0506, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 1.0775, F Adv: 0.5241\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1508\n",
      "  Total G Loss: 3.5568\n",
      "Epoch [173/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0504, D_X Fake: 0.1719, D_X Total: 0.1112\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0343, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.8856, F Adv: 0.5620\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.3451\n",
      "Epoch [173/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0483, D_X Fake: 0.1390, D_X Total: 0.0936\n",
      "  D_Y Real: 0.0274, D_Y Fake: 0.0756, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 1.0336, F Adv: 0.5638\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1359, Perceptual Monet: 0.1800\n",
      "  Total G Loss: 3.7786\n",
      "Epoch [173/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1771, D_X Fake: 0.0783, D_X Total: 0.1277\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0354, D_Y Total: 0.0254\n",
      "Generator Losses:\n",
      "  G Adv: 0.9306, F Adv: 0.5848\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1886, Perceptual Monet: 0.1683\n",
      "  Total G Loss: 3.9217\n",
      "Epoch [174/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1711, D_X Fake: 0.0596, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0275, D_Y Total: 0.0216\n",
      "Generator Losses:\n",
      "  G Adv: 1.0251, F Adv: 0.7882\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1783, Perceptual Monet: 0.1894\n",
      "  Total G Loss: 4.2995\n",
      "Epoch [174/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1567, D_X Fake: 0.1269, D_X Total: 0.1418\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0335, D_Y Total: 0.0254\n",
      "Generator Losses:\n",
      "  G Adv: 0.9377, F Adv: 0.4696\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1632, Perceptual Monet: 0.1859\n",
      "  Total G Loss: 3.7638\n",
      "Epoch [174/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0807, D_X Fake: 0.0933, D_X Total: 0.0870\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0470, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.8081, F Adv: 0.5494\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0380\n",
      "  Perceptual Photo: 0.1188, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.5192\n",
      "Epoch [174/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0507, D_X Fake: 0.1136, D_X Total: 0.0821\n",
      "  D_Y Real: 0.0369, D_Y Fake: 0.0512, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 0.7736, F Adv: 0.5992\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.1859\n",
      "  Total G Loss: 3.4671\n",
      "Epoch [174/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1383, D_X Fake: 0.0929, D_X Total: 0.1156\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0420, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.8153, F Adv: 0.5581\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.4436\n",
      "Epoch [174/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0638, D_X Fake: 0.1416, D_X Total: 0.1027\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0445, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.8172, F Adv: 0.3962\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1089, Perceptual Monet: 0.1398\n",
      "  Total G Loss: 2.9750\n",
      "Epoch [174/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2743, D_X Fake: 0.0786, D_X Total: 0.1765\n",
      "  D_Y Real: 0.0338, D_Y Fake: 0.0316, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 1.0042, F Adv: 0.6693\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1509, Perceptual Monet: 0.2012\n",
      "  Total G Loss: 4.0798\n",
      "Epoch [174/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2094, D_X Fake: 0.0924, D_X Total: 0.1509\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0457, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.8554, F Adv: 0.6677\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1841\n",
      "  Total G Loss: 3.6602\n",
      "Epoch [174/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1818, D_X Fake: 0.0703, D_X Total: 0.1261\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0371, D_Y Total: 0.0270\n",
      "Generator Losses:\n",
      "  G Adv: 0.9101, F Adv: 0.7065\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.2152\n",
      "  Total G Loss: 3.9915\n",
      "Epoch [174/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1382, D_X Fake: 0.1481, D_X Total: 0.1431\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0473, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.7507, F Adv: 0.4722\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1613\n",
      "  Total G Loss: 3.3986\n",
      "Epoch [174/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2086, D_X Fake: 0.0446, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0509, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.7871, F Adv: 0.6117\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1547, Perceptual Monet: 0.1620\n",
      "  Total G Loss: 3.5551\n",
      "Epoch [174/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0683, D_X Fake: 0.0784, D_X Total: 0.0734\n",
      "  D_Y Real: 0.0272, D_Y Fake: 0.0402, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.7690, F Adv: 0.5700\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1492, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5881\n",
      "Epoch [174/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1890, D_X Fake: 0.0999, D_X Total: 0.1444\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0370, D_Y Total: 0.0297\n",
      "Generator Losses:\n",
      "  G Adv: 0.9969, F Adv: 0.6912\n",
      "  Cycle Photo: 0.0349, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1772, Perceptual Monet: 0.1612\n",
      "  Total G Loss: 4.0136\n",
      "Epoch [174/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0798, D_X Fake: 0.1275, D_X Total: 0.1036\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0410, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8483, F Adv: 0.3929\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1248, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.5292\n",
      "Epoch [174/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0917, D_X Fake: 0.0600, D_X Total: 0.0759\n",
      "  D_Y Real: 0.0473, D_Y Fake: 0.0386, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.6503, F Adv: 0.6735\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 3.5800\n",
      "Epoch [174/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1722, D_X Fake: 0.0943, D_X Total: 0.1332\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0517, D_Y Total: 0.0412\n",
      "Generator Losses:\n",
      "  G Adv: 0.8392, F Adv: 0.6038\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1757, Perceptual Monet: 0.1654\n",
      "  Total G Loss: 3.7959\n",
      "Epoch [174/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0510, D_X Fake: 0.1278, D_X Total: 0.0894\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0475, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.8737, F Adv: 0.5741\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1300, Perceptual Monet: 0.1893\n",
      "  Total G Loss: 3.6507\n",
      "Epoch [174/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0716, D_X Fake: 0.0727, D_X Total: 0.0722\n",
      "  D_Y Real: 0.0420, D_Y Fake: 0.0418, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.8641, F Adv: 0.6397\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1450, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.6262\n",
      "Epoch [174/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1045, D_X Fake: 0.1160, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0545, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.9598, F Adv: 0.5305\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.6782\n",
      "Epoch [174/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1273, D_X Fake: 0.0687, D_X Total: 0.0980\n",
      "  D_Y Real: 0.0407, D_Y Fake: 0.0334, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.6248, F Adv: 0.5901\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1124, Perceptual Monet: 0.1569\n",
      "  Total G Loss: 3.0455\n",
      "Epoch [174/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1652, D_X Fake: 0.0917, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0386, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.9482, F Adv: 0.6179\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1268, Perceptual Monet: 0.2170\n",
      "  Total G Loss: 3.9326\n",
      "Epoch [174/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0463, D_X Fake: 0.0522, D_X Total: 0.0492\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0382, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.7832, F Adv: 0.7611\n",
      "  Cycle Photo: 0.0219, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.0982, Perceptual Monet: 0.1797\n",
      "  Total G Loss: 3.4316\n",
      "Epoch [174/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0378, D_X Fake: 0.1148, D_X Total: 0.0763\n",
      "  D_Y Real: 0.0338, D_Y Fake: 0.0514, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.8324, F Adv: 0.4317\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.3609\n",
      "Epoch [174/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1176, D_X Fake: 0.0965, D_X Total: 0.1070\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.0722, D_Y Total: 0.0543\n",
      "Generator Losses:\n",
      "  G Adv: 1.0234, F Adv: 0.4927\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1825\n",
      "  Total G Loss: 3.9057\n",
      "Epoch [175/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.1417, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0358, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8845, F Adv: 0.5028\n",
      "  Cycle Photo: 0.0581, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1776, Perceptual Monet: 0.1649\n",
      "  Total G Loss: 3.9541\n",
      "Epoch [175/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0642, D_X Fake: 0.0675, D_X Total: 0.0658\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0799, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.7595, F Adv: 0.8090\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1728\n",
      "  Total G Loss: 3.5805\n",
      "Epoch [175/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2188, D_X Fake: 0.0755, D_X Total: 0.1471\n",
      "  D_Y Real: 0.0377, D_Y Fake: 0.0470, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.8060, F Adv: 0.6500\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1853, Perceptual Monet: 0.1875\n",
      "  Total G Loss: 4.0748\n",
      "Epoch [175/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1643, D_X Fake: 0.1120, D_X Total: 0.1381\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0338, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.9428, F Adv: 0.6007\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0316\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1770\n",
      "  Total G Loss: 3.8129\n",
      "Epoch [175/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0758, D_X Fake: 0.1341, D_X Total: 0.1049\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0468, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8675, F Adv: 0.4748\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1358, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.3163\n",
      "Epoch [175/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0873, D_X Fake: 0.0873, D_X Total: 0.0873\n",
      "  D_Y Real: 0.0185, D_Y Fake: 0.0667, D_Y Total: 0.0426\n",
      "Generator Losses:\n",
      "  G Adv: 0.8736, F Adv: 0.6604\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1101, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 3.3846\n",
      "Epoch [175/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1299, D_X Fake: 0.1594, D_X Total: 0.1447\n",
      "  D_Y Real: 0.0340, D_Y Fake: 0.0261, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8647, F Adv: 0.5978\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1499, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.7445\n",
      "Epoch [175/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1083, D_X Fake: 0.0750, D_X Total: 0.0917\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.0450, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.8983, F Adv: 0.6627\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1647, Perceptual Monet: 0.1943\n",
      "  Total G Loss: 4.0589\n",
      "Epoch [175/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1503, D_X Fake: 0.0724, D_X Total: 0.1113\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0602, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.7718, F Adv: 0.5662\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1617, Perceptual Monet: 0.1769\n",
      "  Total G Loss: 3.6192\n",
      "Epoch [175/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1390, D_X Fake: 0.0583, D_X Total: 0.0986\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0617, D_Y Total: 0.0424\n",
      "Generator Losses:\n",
      "  G Adv: 0.7422, F Adv: 0.6459\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1504, Perceptual Monet: 0.1917\n",
      "  Total G Loss: 3.7164\n",
      "Epoch [175/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.1065, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0341, D_Y Fake: 0.0389, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 1.1803, F Adv: 0.5823\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.2085\n",
      "  Total G Loss: 4.0849\n",
      "Epoch [175/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0996, D_X Fake: 0.1022, D_X Total: 0.1009\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0490, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.8470, F Adv: 0.5903\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1328, Perceptual Monet: 0.1822\n",
      "  Total G Loss: 3.6418\n",
      "Epoch [175/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1815, D_X Fake: 0.1130, D_X Total: 0.1473\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0599, D_Y Total: 0.0464\n",
      "Generator Losses:\n",
      "  G Adv: 0.9576, F Adv: 0.5665\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1525, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.7434\n",
      "Epoch [175/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0729, D_X Fake: 0.2421, D_X Total: 0.1575\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0375, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.8970, F Adv: 0.3746\n",
      "  Cycle Photo: 0.0217, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1082, Perceptual Monet: 0.1405\n",
      "  Total G Loss: 2.9436\n",
      "Epoch [175/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0930, D_X Fake: 0.1099, D_X Total: 0.1015\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0455, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 1.1860, F Adv: 0.5638\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.1819\n",
      "  Total G Loss: 3.8938\n",
      "Epoch [175/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2521, D_X Fake: 0.0958, D_X Total: 0.1740\n",
      "  D_Y Real: 0.0460, D_Y Fake: 0.0549, D_Y Total: 0.0504\n",
      "Generator Losses:\n",
      "  G Adv: 0.6638, F Adv: 0.5368\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1590, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.5347\n",
      "Epoch [175/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2113, D_X Fake: 0.1227, D_X Total: 0.1670\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0371, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9940, F Adv: 0.5515\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1176, Perceptual Monet: 0.1845\n",
      "  Total G Loss: 3.5996\n",
      "Epoch [175/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1397, D_X Fake: 0.1123, D_X Total: 0.1260\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0554, D_Y Total: 0.0404\n",
      "Generator Losses:\n",
      "  G Adv: 1.1140, F Adv: 0.6657\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.2192, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 4.4605\n",
      "Epoch [175/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1976, D_X Fake: 0.0556, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0799, D_Y Total: 0.0545\n",
      "Generator Losses:\n",
      "  G Adv: 0.7755, F Adv: 0.6790\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.8519\n",
      "Epoch [175/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1674, D_X Fake: 0.0857, D_X Total: 0.1265\n",
      "  D_Y Real: 0.0223, D_Y Fake: 0.0518, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.7481, F Adv: 0.6449\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1490, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.5221\n",
      "Epoch [175/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1761, D_X Fake: 0.0608, D_X Total: 0.1184\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0376, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.7453, F Adv: 0.5861\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1574\n",
      "  Total G Loss: 3.3690\n",
      "Epoch [175/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0817, D_X Fake: 0.1028, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0400, D_Y Fake: 0.0353, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 1.0263, F Adv: 0.5620\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1464\n",
      "  Total G Loss: 3.6351\n",
      "Epoch [175/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1239, D_X Fake: 0.1216, D_X Total: 0.1228\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0425, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9313, F Adv: 0.6090\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1827, Perceptual Monet: 0.1568\n",
      "  Total G Loss: 3.8517\n",
      "Epoch [175/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1121, D_X Fake: 0.0521, D_X Total: 0.0821\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0320, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.8458, F Adv: 0.6311\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1660, Perceptual Monet: 0.1708\n",
      "  Total G Loss: 3.8437\n",
      "Epoch [176/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1273, D_X Fake: 0.0818, D_X Total: 0.1045\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0681, D_Y Total: 0.0476\n",
      "Generator Losses:\n",
      "  G Adv: 0.8779, F Adv: 0.6258\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1500, Perceptual Monet: 0.1855\n",
      "  Total G Loss: 3.9400\n",
      "Epoch [176/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3567, D_X Fake: 0.0602, D_X Total: 0.2085\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0519, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.7795, F Adv: 0.6131\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.4552\n",
      "Epoch [176/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2186, D_X Fake: 0.0953, D_X Total: 0.1570\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0433, D_Y Total: 0.0301\n",
      "Generator Losses:\n",
      "  G Adv: 0.9835, F Adv: 0.6083\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1852\n",
      "  Total G Loss: 3.9139\n",
      "Epoch [176/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2314, D_X Fake: 0.0878, D_X Total: 0.1596\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0564, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.8014, F Adv: 0.5265\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1767, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.6979\n",
      "Epoch [176/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1198, D_X Fake: 0.1109, D_X Total: 0.1153\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0255, D_Y Total: 0.0269\n",
      "Generator Losses:\n",
      "  G Adv: 0.8776, F Adv: 0.7164\n",
      "  Cycle Photo: 0.0227, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1244, Perceptual Monet: 0.1678\n",
      "  Total G Loss: 3.5633\n",
      "Epoch [176/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1525, D_X Fake: 0.0895, D_X Total: 0.1210\n",
      "  D_Y Real: 0.0699, D_Y Fake: 0.0437, D_Y Total: 0.0568\n",
      "Generator Losses:\n",
      "  G Adv: 1.1330, F Adv: 0.6354\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1377, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.9127\n",
      "Epoch [176/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1806, D_X Fake: 0.1199, D_X Total: 0.1503\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0448, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 1.0341, F Adv: 0.5420\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1974\n",
      "  Total G Loss: 3.8891\n",
      "Epoch [176/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2034, D_X Fake: 0.0400, D_X Total: 0.1217\n",
      "  D_Y Real: 0.0221, D_Y Fake: 0.0443, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.8368, F Adv: 0.7748\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1869, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.8604\n",
      "Epoch [176/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2144, D_X Fake: 0.0564, D_X Total: 0.1354\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0709, D_Y Total: 0.0479\n",
      "Generator Losses:\n",
      "  G Adv: 0.7842, F Adv: 0.6955\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1215, Perceptual Monet: 0.1838\n",
      "  Total G Loss: 3.6090\n",
      "Epoch [176/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1426, D_X Fake: 0.0934, D_X Total: 0.1180\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0296, D_Y Total: 0.0248\n",
      "Generator Losses:\n",
      "  G Adv: 1.0201, F Adv: 0.6434\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1754, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.9264\n",
      "Epoch [176/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1857, D_X Fake: 0.1304, D_X Total: 0.1581\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0306, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.9669, F Adv: 0.4850\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1656, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.7898\n",
      "Epoch [176/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1263, D_X Fake: 0.1029, D_X Total: 0.1146\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0383, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.9851, F Adv: 0.5452\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1280, Perceptual Monet: 0.1608\n",
      "  Total G Loss: 3.4670\n",
      "Epoch [176/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1924, D_X Fake: 0.0850, D_X Total: 0.1387\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0329, D_Y Total: 0.0261\n",
      "Generator Losses:\n",
      "  G Adv: 0.8249, F Adv: 0.6098\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1209, Perceptual Monet: 0.1977\n",
      "  Total G Loss: 3.5965\n",
      "Epoch [176/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0587, D_X Fake: 0.1037, D_X Total: 0.0812\n",
      "  D_Y Real: 0.0156, D_Y Fake: 0.0304, D_Y Total: 0.0230\n",
      "Generator Losses:\n",
      "  G Adv: 0.9721, F Adv: 0.5704\n",
      "  Cycle Photo: 0.0219, Cycle Monet: 0.0208\n",
      "  Perceptual Photo: 0.1206, Perceptual Monet: 0.1399\n",
      "  Total G Loss: 3.2717\n",
      "Epoch [176/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0918, D_X Fake: 0.1296, D_X Total: 0.1107\n",
      "  D_Y Real: 0.0147, D_Y Fake: 0.0463, D_Y Total: 0.0305\n",
      "Generator Losses:\n",
      "  G Adv: 0.8171, F Adv: 0.5235\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.5071\n",
      "Epoch [176/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1226, D_X Fake: 0.0923, D_X Total: 0.1075\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0573, D_Y Total: 0.0444\n",
      "Generator Losses:\n",
      "  G Adv: 0.8386, F Adv: 0.6014\n",
      "  Cycle Photo: 0.0352, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1457, Perceptual Monet: 0.1855\n",
      "  Total G Loss: 3.8157\n",
      "Epoch [176/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1840, D_X Fake: 0.0819, D_X Total: 0.1329\n",
      "  D_Y Real: 0.0297, D_Y Fake: 0.0525, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.9438, F Adv: 0.6381\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.6694\n",
      "Epoch [176/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0783, D_X Fake: 0.0782, D_X Total: 0.0783\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0333, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 0.9689, F Adv: 0.7103\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1433, Perceptual Monet: 0.1594\n",
      "  Total G Loss: 3.7359\n",
      "Epoch [176/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1637, D_X Fake: 0.1015, D_X Total: 0.1326\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0578, D_Y Total: 0.0447\n",
      "Generator Losses:\n",
      "  G Adv: 0.9141, F Adv: 0.5487\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1289, Perceptual Monet: 0.1862\n",
      "  Total G Loss: 3.6261\n",
      "Epoch [176/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1203, D_X Fake: 0.1008, D_X Total: 0.1106\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0281, D_Y Total: 0.0226\n",
      "Generator Losses:\n",
      "  G Adv: 0.7944, F Adv: 0.6165\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1557, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 3.6186\n",
      "Epoch [176/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2443, D_X Fake: 0.0772, D_X Total: 0.1608\n",
      "  D_Y Real: 0.0246, D_Y Fake: 0.0300, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.8559, F Adv: 0.7671\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1637\n",
      "  Total G Loss: 3.6846\n",
      "Epoch [176/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0468, D_X Fake: 0.0624, D_X Total: 0.0546\n",
      "  D_Y Real: 0.0282, D_Y Fake: 0.0359, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 1.1302, F Adv: 0.6065\n",
      "  Cycle Photo: 0.0555, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1419, Perceptual Monet: 0.1525\n",
      "  Total G Loss: 4.0184\n",
      "Epoch [176/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1335, D_X Fake: 0.1092, D_X Total: 0.1213\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0455, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 1.0627, F Adv: 0.6941\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0409\n",
      "  Perceptual Photo: 0.1580, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 4.1719\n",
      "Epoch [176/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1497, D_X Fake: 0.0873, D_X Total: 0.1185\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0290, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 1.0305, F Adv: 0.4067\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0209\n",
      "  Perceptual Photo: 0.1653, Perceptual Monet: 0.1313\n",
      "  Total G Loss: 3.4620\n",
      "Epoch [177/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0612, D_X Fake: 0.1199, D_X Total: 0.0906\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0414, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.9419, F Adv: 0.4916\n",
      "  Cycle Photo: 0.0449, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1633, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.7976\n",
      "Epoch [177/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0872, D_X Fake: 0.0975, D_X Total: 0.0923\n",
      "  D_Y Real: 0.0491, D_Y Fake: 0.0489, D_Y Total: 0.0490\n",
      "Generator Losses:\n",
      "  G Adv: 0.8310, F Adv: 0.5605\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.5320\n",
      "Epoch [177/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0830, D_X Fake: 0.0798, D_X Total: 0.0814\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0418, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.8768, F Adv: 0.6023\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1408, Perceptual Monet: 0.1579\n",
      "  Total G Loss: 3.5339\n",
      "Epoch [177/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1926, D_X Fake: 0.1101, D_X Total: 0.1514\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.0306, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9136, F Adv: 0.6429\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1669, Perceptual Monet: 0.1489\n",
      "  Total G Loss: 3.7232\n",
      "Epoch [177/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1835, D_X Fake: 0.0772, D_X Total: 0.1303\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0587, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.8812, F Adv: 0.7078\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.7514\n",
      "Epoch [177/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1343, D_X Fake: 0.0968, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0516, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 0.9288, F Adv: 0.5955\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0328\n",
      "  Perceptual Photo: 0.1361, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.6557\n",
      "Epoch [177/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2236, D_X Fake: 0.0657, D_X Total: 0.1447\n",
      "  D_Y Real: 0.0355, D_Y Fake: 0.0401, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 0.8588, F Adv: 0.7852\n",
      "  Cycle Photo: 0.0411, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1846, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 4.1995\n",
      "Epoch [177/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1398, D_X Fake: 0.0849, D_X Total: 0.1123\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0374, D_Y Total: 0.0416\n",
      "Generator Losses:\n",
      "  G Adv: 0.8106, F Adv: 0.6334\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1663, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.7488\n",
      "Epoch [177/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1546, D_X Fake: 0.1025, D_X Total: 0.1286\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0603, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.7358, F Adv: 0.5875\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1737\n",
      "  Total G Loss: 3.4281\n",
      "Epoch [177/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1287, D_X Fake: 0.0699, D_X Total: 0.0993\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0493, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8084, F Adv: 0.4330\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1213, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.1296\n",
      "Epoch [177/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1335, D_X Fake: 0.1209, D_X Total: 0.1272\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0592, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.7764, F Adv: 0.5723\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.1458\n",
      "  Total G Loss: 3.3912\n",
      "Epoch [177/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0966, D_X Fake: 0.1787, D_X Total: 0.1376\n",
      "  D_Y Real: 0.0426, D_Y Fake: 0.0405, D_Y Total: 0.0416\n",
      "Generator Losses:\n",
      "  G Adv: 0.9242, F Adv: 0.4248\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0227\n",
      "  Perceptual Photo: 0.1219, Perceptual Monet: 0.1344\n",
      "  Total G Loss: 3.0737\n",
      "Epoch [177/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1080, D_X Fake: 0.0972, D_X Total: 0.1026\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0392, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.8099, F Adv: 0.6561\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1096, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.3412\n",
      "Epoch [177/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1465, D_X Fake: 0.0988, D_X Total: 0.1227\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.0466, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 0.9427, F Adv: 0.5447\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1647, Perceptual Monet: 0.1534\n",
      "  Total G Loss: 3.6435\n",
      "Epoch [177/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1505, D_X Fake: 0.1278, D_X Total: 0.1392\n",
      "  D_Y Real: 0.0537, D_Y Fake: 0.0434, D_Y Total: 0.0485\n",
      "Generator Losses:\n",
      "  G Adv: 0.9716, F Adv: 0.5394\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1063, Perceptual Monet: 0.1759\n",
      "  Total G Loss: 3.4050\n",
      "Epoch [177/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1281, D_X Fake: 0.0715, D_X Total: 0.0998\n",
      "  D_Y Real: 0.0180, D_Y Fake: 0.0831, D_Y Total: 0.0505\n",
      "Generator Losses:\n",
      "  G Adv: 0.7661, F Adv: 0.5165\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1635, Perceptual Monet: 0.1523\n",
      "  Total G Loss: 3.4352\n",
      "Epoch [177/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0899, D_X Fake: 0.1003, D_X Total: 0.0951\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.0406, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.9088, F Adv: 0.7073\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1673\n",
      "  Total G Loss: 3.8114\n",
      "Epoch [177/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1044, D_X Fake: 0.1498, D_X Total: 0.1271\n",
      "  D_Y Real: 0.0458, D_Y Fake: 0.0629, D_Y Total: 0.0544\n",
      "Generator Losses:\n",
      "  G Adv: 0.9762, F Adv: 0.4701\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0435\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1900\n",
      "  Total G Loss: 3.8656\n",
      "Epoch [177/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.0835, D_X Total: 0.0823\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0523, D_Y Total: 0.0368\n",
      "Generator Losses:\n",
      "  G Adv: 0.7595, F Adv: 0.6800\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1319, Perceptual Monet: 0.1581\n",
      "  Total G Loss: 3.4152\n",
      "Epoch [177/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0984, D_X Fake: 0.0807, D_X Total: 0.0895\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0768, D_Y Total: 0.0477\n",
      "Generator Losses:\n",
      "  G Adv: 0.8081, F Adv: 0.4772\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1274, Perceptual Monet: 0.1506\n",
      "  Total G Loss: 3.2544\n",
      "Epoch [177/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1237, D_X Fake: 0.1040, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0512, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 0.8598, F Adv: 0.5475\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1171, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.4409\n",
      "Epoch [177/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0588, D_X Fake: 0.1287, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0507, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8559, F Adv: 0.4996\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1602\n",
      "  Total G Loss: 3.5094\n",
      "Epoch [177/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1905, D_X Fake: 0.0806, D_X Total: 0.1356\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0572, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.7719, F Adv: 0.5864\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1335, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.4582\n",
      "Epoch [177/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1323, D_X Fake: 0.0464, D_X Total: 0.0893\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0566, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.8850, F Adv: 0.8062\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1192, Perceptual Monet: 0.1461\n",
      "  Total G Loss: 3.4863\n",
      "Epoch [178/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0655, D_X Fake: 0.0908, D_X Total: 0.0782\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0520, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.9759, F Adv: 0.5809\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1553\n",
      "  Total G Loss: 3.6964\n",
      "Epoch [178/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1423, D_X Fake: 0.0755, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0507, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.8415, F Adv: 0.6793\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1362, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.5924\n",
      "Epoch [178/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1561, D_X Fake: 0.1171, D_X Total: 0.1366\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0563, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.7492, F Adv: 0.5926\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.5388\n",
      "Epoch [178/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1242, D_X Fake: 0.1148, D_X Total: 0.1195\n",
      "  D_Y Real: 0.0266, D_Y Fake: 0.0326, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 1.0435, F Adv: 0.4798\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0194\n",
      "  Perceptual Photo: 0.1384, Perceptual Monet: 0.1311\n",
      "  Total G Loss: 3.3039\n",
      "Epoch [178/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2894, D_X Fake: 0.0575, D_X Total: 0.1735\n",
      "  D_Y Real: 0.0280, D_Y Fake: 0.0548, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8742, F Adv: 0.8164\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.9572\n",
      "Epoch [178/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2752, D_X Fake: 0.0670, D_X Total: 0.1711\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0357, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.7966, F Adv: 0.6871\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1654, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.7852\n",
      "Epoch [178/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1299, D_X Fake: 0.1089, D_X Total: 0.1194\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0562, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.8041, F Adv: 0.5828\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1328, Perceptual Monet: 0.1560\n",
      "  Total G Loss: 3.2974\n",
      "Epoch [178/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2406, D_X Fake: 0.0602, D_X Total: 0.1504\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0362, D_Y Total: 0.0286\n",
      "Generator Losses:\n",
      "  G Adv: 0.9371, F Adv: 0.7836\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1216, Perceptual Monet: 0.1804\n",
      "  Total G Loss: 3.7582\n",
      "Epoch [178/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1331, D_X Fake: 0.0651, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0475, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.8729, F Adv: 0.5758\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1191, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.6050\n",
      "Epoch [178/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2309, D_X Fake: 0.0714, D_X Total: 0.1512\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0346, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.9303, F Adv: 0.7162\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1593, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.8289\n",
      "Epoch [178/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1119, D_X Fake: 0.1066, D_X Total: 0.1092\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0506, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.9189, F Adv: 0.5548\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1666, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.6961\n",
      "Epoch [178/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1390, D_X Fake: 0.0670, D_X Total: 0.1030\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0463, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 1.0646, F Adv: 0.7042\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1425\n",
      "  Total G Loss: 3.7030\n",
      "Epoch [178/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1086, D_X Fake: 0.0823, D_X Total: 0.0955\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0467, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.7903, F Adv: 0.7565\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1881, Perceptual Monet: 0.1528\n",
      "  Total G Loss: 3.8940\n",
      "Epoch [178/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0614, D_X Fake: 0.1125, D_X Total: 0.0870\n",
      "  D_Y Real: 0.0213, D_Y Fake: 0.0540, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.7718, F Adv: 0.5453\n",
      "  Cycle Photo: 0.0207, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1039, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.1353\n",
      "Epoch [178/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1452, D_X Fake: 0.0713, D_X Total: 0.1083\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0390, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.8270, F Adv: 0.8168\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1548\n",
      "  Total G Loss: 3.7036\n",
      "Epoch [178/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1036, D_X Fake: 0.1761, D_X Total: 0.1399\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0412, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.7716, F Adv: 0.4626\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1173, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.1652\n",
      "Epoch [178/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1369, D_X Fake: 0.0647, D_X Total: 0.1008\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0413, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.8439, F Adv: 0.7062\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1565\n",
      "  Total G Loss: 3.6727\n",
      "Epoch [178/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2365, D_X Fake: 0.1370, D_X Total: 0.1867\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0388, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 1.1518, F Adv: 0.5313\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0355\n",
      "  Perceptual Photo: 0.1670, Perceptual Monet: 0.2069\n",
      "  Total G Loss: 4.2257\n",
      "Epoch [178/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0472, D_X Fake: 0.0626, D_X Total: 0.0549\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0437, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.7599, F Adv: 0.5925\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1262, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.3829\n",
      "Epoch [178/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1894, D_X Fake: 0.0703, D_X Total: 0.1298\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0321, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.9867, F Adv: 0.7023\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1290, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 3.8558\n",
      "Epoch [178/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1589, D_X Fake: 0.1272, D_X Total: 0.1430\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.0404, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.9343, F Adv: 0.4019\n",
      "  Cycle Photo: 0.0345, Cycle Monet: 0.0218\n",
      "  Perceptual Photo: 0.1923, Perceptual Monet: 0.1440\n",
      "  Total G Loss: 3.5812\n",
      "Epoch [178/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1458, D_X Fake: 0.1317, D_X Total: 0.1387\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0461, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.8922, F Adv: 0.4968\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1826\n",
      "  Total G Loss: 3.6509\n",
      "Epoch [178/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2793, D_X Fake: 0.0874, D_X Total: 0.1833\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0498, D_Y Total: 0.0352\n",
      "Generator Losses:\n",
      "  G Adv: 0.8640, F Adv: 0.6933\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1924, Perceptual Monet: 0.2072\n",
      "  Total G Loss: 4.2989\n",
      "Epoch [178/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0751, D_X Fake: 0.1164, D_X Total: 0.0958\n",
      "  D_Y Real: 0.0502, D_Y Fake: 0.0444, D_Y Total: 0.0473\n",
      "Generator Losses:\n",
      "  G Adv: 0.8651, F Adv: 0.5807\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1134, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.5092\n",
      "Epoch [179/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2585, D_X Fake: 0.0554, D_X Total: 0.1569\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0406, D_Y Total: 0.0301\n",
      "Generator Losses:\n",
      "  G Adv: 1.1043, F Adv: 0.7369\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1678, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 4.0520\n",
      "Epoch [179/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1215, D_X Fake: 0.0913, D_X Total: 0.1064\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0616, D_Y Total: 0.0429\n",
      "Generator Losses:\n",
      "  G Adv: 0.7377, F Adv: 0.6065\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1308, Perceptual Monet: 0.1914\n",
      "  Total G Loss: 3.6090\n",
      "Epoch [179/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0898, D_X Fake: 0.1189, D_X Total: 0.1044\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0468, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.8655, F Adv: 0.4795\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.4150\n",
      "Epoch [179/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0802, D_X Fake: 0.1098, D_X Total: 0.0950\n",
      "  D_Y Real: 0.0391, D_Y Fake: 0.0503, D_Y Total: 0.0447\n",
      "Generator Losses:\n",
      "  G Adv: 0.9843, F Adv: 0.6728\n",
      "  Cycle Photo: 0.0234, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1167, Perceptual Monet: 0.1850\n",
      "  Total G Loss: 3.6773\n",
      "Epoch [179/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1917, D_X Fake: 0.1286, D_X Total: 0.1601\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0492, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8867, F Adv: 0.4899\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1742, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.6510\n",
      "Epoch [179/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0677, D_X Fake: 0.0849, D_X Total: 0.0763\n",
      "  D_Y Real: 0.0211, D_Y Fake: 0.0450, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 1.0183, F Adv: 0.6361\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1236, Perceptual Monet: 0.1918\n",
      "  Total G Loss: 3.9332\n",
      "Epoch [179/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0926, D_X Fake: 0.0978, D_X Total: 0.0952\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0267, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 1.0117, F Adv: 0.5840\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0217\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1349\n",
      "  Total G Loss: 3.4171\n",
      "Epoch [179/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1096, D_X Fake: 0.1143, D_X Total: 0.1120\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0465, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.9510, F Adv: 0.5454\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.5463\n",
      "Epoch [179/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1150, D_X Fake: 0.1176, D_X Total: 0.1163\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0540, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.8544, F Adv: 0.5263\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1651\n",
      "  Total G Loss: 3.5319\n",
      "Epoch [179/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1024, D_X Fake: 0.1252, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0383, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.9643, F Adv: 0.5107\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1286, Perceptual Monet: 0.1898\n",
      "  Total G Loss: 3.6992\n",
      "Epoch [179/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1065, D_X Fake: 0.1340, D_X Total: 0.1203\n",
      "  D_Y Real: 0.0142, D_Y Fake: 0.0777, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.7381, F Adv: 0.6571\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0255\n",
      "  Perceptual Photo: 0.1319, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.4217\n",
      "Epoch [179/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1515, D_X Fake: 0.0666, D_X Total: 0.1091\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0279, D_Y Total: 0.0273\n",
      "Generator Losses:\n",
      "  G Adv: 0.9212, F Adv: 0.6900\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1526, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.7229\n",
      "Epoch [179/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0771, D_X Fake: 0.1220, D_X Total: 0.0995\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0529, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 1.0273, F Adv: 0.5290\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1589, Perceptual Monet: 0.1474\n",
      "  Total G Loss: 3.6547\n",
      "Epoch [179/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1452, D_X Fake: 0.0903, D_X Total: 0.1177\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0716, D_Y Total: 0.0566\n",
      "Generator Losses:\n",
      "  G Adv: 0.7620, F Adv: 0.6538\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1424, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.5807\n",
      "Epoch [179/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0871, D_X Fake: 0.0478, D_X Total: 0.0674\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0440, D_Y Total: 0.0317\n",
      "Generator Losses:\n",
      "  G Adv: 0.9037, F Adv: 0.6934\n",
      "  Cycle Photo: 0.0207, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1141, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.4707\n",
      "Epoch [179/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2417, D_X Fake: 0.1397, D_X Total: 0.1907\n",
      "  D_Y Real: 0.0333, D_Y Fake: 0.0460, D_Y Total: 0.0397\n",
      "Generator Losses:\n",
      "  G Adv: 1.0254, F Adv: 0.4699\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1142, Perceptual Monet: 0.1845\n",
      "  Total G Loss: 3.5618\n",
      "Epoch [179/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1106, D_X Fake: 0.1621, D_X Total: 0.1364\n",
      "  D_Y Real: 0.0531, D_Y Fake: 0.0278, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.9099, F Adv: 0.4594\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0376\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.2127\n",
      "  Total G Loss: 3.7918\n",
      "Epoch [179/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1488, D_X Fake: 0.1121, D_X Total: 0.1304\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0717, D_Y Total: 0.0492\n",
      "Generator Losses:\n",
      "  G Adv: 0.8651, F Adv: 0.4486\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1711, Perceptual Monet: 0.1408\n",
      "  Total G Loss: 3.4461\n",
      "Epoch [179/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1408, D_X Fake: 0.0929, D_X Total: 0.1169\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0635, D_Y Total: 0.0430\n",
      "Generator Losses:\n",
      "  G Adv: 0.9482, F Adv: 0.5452\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1332, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 3.6430\n",
      "Epoch [179/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1007, D_X Fake: 0.1054, D_X Total: 0.1031\n",
      "  D_Y Real: 0.0328, D_Y Fake: 0.0670, D_Y Total: 0.0499\n",
      "Generator Losses:\n",
      "  G Adv: 0.7533, F Adv: 0.5121\n",
      "  Cycle Photo: 0.0211, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1072, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.0935\n",
      "Epoch [179/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0773, D_X Fake: 0.1677, D_X Total: 0.1225\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0620, D_Y Total: 0.0448\n",
      "Generator Losses:\n",
      "  G Adv: 1.1432, F Adv: 0.5531\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1382, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.8324\n",
      "Epoch [179/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1750, D_X Fake: 0.1404, D_X Total: 0.1577\n",
      "  D_Y Real: 0.0389, D_Y Fake: 0.0425, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.9036, F Adv: 0.4672\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.4563\n",
      "Epoch [179/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0923, D_X Fake: 0.1101, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0486, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 1.2073, F Adv: 0.5913\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1345, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.7317\n",
      "Epoch [179/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0972, D_X Fake: 0.0958, D_X Total: 0.0965\n",
      "  D_Y Real: 0.0336, D_Y Fake: 0.0497, D_Y Total: 0.0417\n",
      "Generator Losses:\n",
      "  G Adv: 1.0826, F Adv: 0.5603\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1217, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.6521\n",
      "Epoch [180/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0756, D_X Fake: 0.1095, D_X Total: 0.0925\n",
      "  D_Y Real: 0.0235, D_Y Fake: 0.0347, D_Y Total: 0.0291\n",
      "Generator Losses:\n",
      "  G Adv: 0.9786, F Adv: 0.6334\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1119, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.4423\n",
      "Epoch [180/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1067, D_X Fake: 0.1092, D_X Total: 0.1080\n",
      "  D_Y Real: 0.0493, D_Y Fake: 0.0544, D_Y Total: 0.0518\n",
      "Generator Losses:\n",
      "  G Adv: 0.8218, F Adv: 0.5197\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1520, Perceptual Monet: 0.1755\n",
      "  Total G Loss: 3.5941\n",
      "Epoch [180/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0675, D_X Fake: 0.0933, D_X Total: 0.0804\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0471, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.8748, F Adv: 0.6670\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1771\n",
      "  Total G Loss: 3.6812\n",
      "Epoch [180/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2802, D_X Fake: 0.0877, D_X Total: 0.1840\n",
      "  D_Y Real: 0.0398, D_Y Fake: 0.0440, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 0.8306, F Adv: 0.5906\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.2041\n",
      "  Total G Loss: 3.9171\n",
      "Epoch [180/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1306, D_X Fake: 0.1210, D_X Total: 0.1258\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0430, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9105, F Adv: 0.5077\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1513, Perceptual Monet: 0.1815\n",
      "  Total G Loss: 3.6912\n",
      "Epoch [180/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0569, D_X Fake: 0.0939, D_X Total: 0.0754\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0302, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.9501, F Adv: 0.6897\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1203, Perceptual Monet: 0.1671\n",
      "  Total G Loss: 3.6129\n",
      "Epoch [180/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1104, D_X Fake: 0.0857, D_X Total: 0.0981\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.0518, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.9798, F Adv: 0.5428\n",
      "  Cycle Photo: 0.0247, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1312, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.4775\n",
      "Epoch [180/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0399, D_X Fake: 0.1230, D_X Total: 0.0814\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0344, D_Y Total: 0.0310\n",
      "Generator Losses:\n",
      "  G Adv: 0.9796, F Adv: 0.4652\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1220, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.5946\n",
      "Epoch [180/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1980, D_X Fake: 0.0588, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0371, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.8792, F Adv: 0.8321\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0364\n",
      "  Perceptual Photo: 0.1515, Perceptual Monet: 0.1883\n",
      "  Total G Loss: 4.0805\n",
      "Epoch [180/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0922, D_X Fake: 0.1430, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0336, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9557, F Adv: 0.4155\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1474, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 3.6757\n",
      "Epoch [180/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1273, D_X Fake: 0.1290, D_X Total: 0.1282\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0606, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.7812, F Adv: 0.6596\n",
      "  Cycle Photo: 0.0368, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.1865\n",
      "  Total G Loss: 3.8019\n",
      "Epoch [180/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0597, D_X Fake: 0.0853, D_X Total: 0.0725\n",
      "  D_Y Real: 0.0165, D_Y Fake: 0.0312, D_Y Total: 0.0239\n",
      "Generator Losses:\n",
      "  G Adv: 1.0059, F Adv: 0.6560\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1411, Perceptual Monet: 0.1880\n",
      "  Total G Loss: 3.8799\n",
      "Epoch [180/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2451, D_X Fake: 0.0549, D_X Total: 0.1500\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0330, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 0.8978, F Adv: 0.6953\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1538, Perceptual Monet: 0.1635\n",
      "  Total G Loss: 3.7491\n",
      "Epoch [180/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1233, D_X Fake: 0.0947, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0280, D_Y Total: 0.0237\n",
      "Generator Losses:\n",
      "  G Adv: 0.9550, F Adv: 0.6030\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1247, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.6047\n",
      "Epoch [180/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1449, D_X Fake: 0.1392, D_X Total: 0.1420\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0309, D_Y Total: 0.0240\n",
      "Generator Losses:\n",
      "  G Adv: 0.9561, F Adv: 0.4718\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.4620\n",
      "Epoch [180/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0527, D_X Fake: 0.1931, D_X Total: 0.1229\n",
      "  D_Y Real: 0.0459, D_Y Fake: 0.0377, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 1.1002, F Adv: 0.4230\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1487, Perceptual Monet: 0.1492\n",
      "  Total G Loss: 3.5933\n",
      "Epoch [180/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1799, D_X Fake: 0.0595, D_X Total: 0.1197\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0379, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 1.1562, F Adv: 0.6749\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1754\n",
      "  Total G Loss: 3.9432\n",
      "Epoch [180/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.0525, D_X Total: 0.0997\n",
      "  D_Y Real: 0.0160, D_Y Fake: 0.0640, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.8232, F Adv: 0.8169\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1477, Perceptual Monet: 0.1667\n",
      "  Total G Loss: 3.7811\n",
      "Epoch [180/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1185, D_X Fake: 0.1415, D_X Total: 0.1300\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0323, D_Y Total: 0.0247\n",
      "Generator Losses:\n",
      "  G Adv: 0.7561, F Adv: 0.4834\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1215, Perceptual Monet: 0.1265\n",
      "  Total G Loss: 2.9388\n",
      "Epoch [180/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1622, D_X Fake: 0.0558, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0564, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.7292, F Adv: 0.6807\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0342\n",
      "  Perceptual Photo: 0.1508, Perceptual Monet: 0.1798\n",
      "  Total G Loss: 3.6856\n",
      "Epoch [180/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1992, D_X Fake: 0.0676, D_X Total: 0.1334\n",
      "  D_Y Real: 0.0144, D_Y Fake: 0.0623, D_Y Total: 0.0383\n",
      "Generator Losses:\n",
      "  G Adv: 0.7962, F Adv: 0.6140\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1419, Perceptual Monet: 0.1532\n",
      "  Total G Loss: 3.4021\n",
      "Epoch [180/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3499, D_X Fake: 0.0493, D_X Total: 0.1996\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0602, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 0.8674, F Adv: 0.6165\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0345\n",
      "  Perceptual Photo: 0.2058, Perceptual Monet: 0.1925\n",
      "  Total G Loss: 4.2294\n",
      "Epoch [180/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1069, D_X Fake: 0.1378, D_X Total: 0.1224\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0403, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.9391, F Adv: 0.5609\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1338, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.6251\n",
      "Epoch [180/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1248, D_X Fake: 0.1061, D_X Total: 0.1155\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0637, D_Y Total: 0.0406\n",
      "Generator Losses:\n",
      "  G Adv: 0.8695, F Adv: 0.6089\n",
      "  Cycle Photo: 0.0356, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1833, Perceptual Monet: 0.1833\n",
      "  Total G Loss: 3.9891\n",
      "Saved checkpoint at epoch 180\n",
      "Epoch [181/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0971, D_X Fake: 0.1175, D_X Total: 0.1073\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0758, D_Y Total: 0.0469\n",
      "Generator Losses:\n",
      "  G Adv: 1.0207, F Adv: 0.5284\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1814, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 4.0132\n",
      "Epoch [181/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1736, D_X Fake: 0.1652, D_X Total: 0.1694\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0402, D_Y Total: 0.0340\n",
      "Generator Losses:\n",
      "  G Adv: 0.8643, F Adv: 0.4683\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1843\n",
      "  Total G Loss: 3.6519\n",
      "Epoch [181/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.1223, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0299, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9218, F Adv: 0.4482\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1241, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.4352\n",
      "Epoch [181/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3883, D_X Fake: 0.0773, D_X Total: 0.2328\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0457, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.8431, F Adv: 0.8375\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1577, Perceptual Monet: 0.1861\n",
      "  Total G Loss: 4.0598\n",
      "Epoch [181/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0588, D_X Fake: 0.1607, D_X Total: 0.1098\n",
      "  D_Y Real: 0.0523, D_Y Fake: 0.0517, D_Y Total: 0.0520\n",
      "Generator Losses:\n",
      "  G Adv: 1.0020, F Adv: 0.5197\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1306, Perceptual Monet: 0.1564\n",
      "  Total G Loss: 3.4671\n",
      "Epoch [181/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2508, D_X Fake: 0.0750, D_X Total: 0.1629\n",
      "  D_Y Real: 0.0426, D_Y Fake: 0.0298, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8256, F Adv: 0.7123\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1542, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.8135\n",
      "Epoch [181/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0478, D_X Fake: 0.0962, D_X Total: 0.0720\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.1060, D_Y Total: 0.0637\n",
      "Generator Losses:\n",
      "  G Adv: 0.8118, F Adv: 0.6046\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1170, Perceptual Monet: 0.1698\n",
      "  Total G Loss: 3.3912\n",
      "Epoch [181/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1081, D_X Fake: 0.0861, D_X Total: 0.0971\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0344, D_Y Total: 0.0286\n",
      "Generator Losses:\n",
      "  G Adv: 0.9492, F Adv: 0.6947\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1415, Perceptual Monet: 0.1552\n",
      "  Total G Loss: 3.6608\n",
      "Epoch [181/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0869, D_X Fake: 0.1817, D_X Total: 0.1343\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0490, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.8476, F Adv: 0.4490\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1095, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.2300\n",
      "Epoch [181/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2704, D_X Fake: 0.1042, D_X Total: 0.1873\n",
      "  D_Y Real: 0.0360, D_Y Fake: 0.0507, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 0.7886, F Adv: 0.5769\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1631, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.6357\n",
      "Epoch [181/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0819, D_X Fake: 0.1082, D_X Total: 0.0950\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0477, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 1.0716, F Adv: 0.4389\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0198\n",
      "  Perceptual Photo: 0.1583, Perceptual Monet: 0.1233\n",
      "  Total G Loss: 3.4104\n",
      "Epoch [181/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1671, D_X Fake: 0.0933, D_X Total: 0.1302\n",
      "  D_Y Real: 0.0802, D_Y Fake: 0.0380, D_Y Total: 0.0591\n",
      "Generator Losses:\n",
      "  G Adv: 0.7245, F Adv: 0.5931\n",
      "  Cycle Photo: 0.0350, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1924, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.7528\n",
      "Epoch [181/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1619, D_X Fake: 0.1064, D_X Total: 0.1341\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0540, D_Y Total: 0.0458\n",
      "Generator Losses:\n",
      "  G Adv: 0.9661, F Adv: 0.5651\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1600, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.7276\n",
      "Epoch [181/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2571, D_X Fake: 0.0536, D_X Total: 0.1554\n",
      "  D_Y Real: 0.0267, D_Y Fake: 0.0443, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.8460, F Adv: 0.5178\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1442, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.4334\n",
      "Epoch [181/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0618, D_X Fake: 0.1238, D_X Total: 0.0928\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0938, D_Y Total: 0.0590\n",
      "Generator Losses:\n",
      "  G Adv: 0.9225, F Adv: 0.5747\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0217\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1354\n",
      "  Total G Loss: 3.3890\n",
      "Epoch [181/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2141, D_X Fake: 0.0952, D_X Total: 0.1547\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0506, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 1.1024, F Adv: 0.5776\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1311, Perceptual Monet: 0.1782\n",
      "  Total G Loss: 3.8230\n",
      "Epoch [181/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2723, D_X Fake: 0.0985, D_X Total: 0.1854\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0350, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8636, F Adv: 0.6312\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1625, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.6782\n",
      "Epoch [181/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1774, D_X Fake: 0.1526, D_X Total: 0.1650\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0450, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 0.9184, F Adv: 0.5228\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1406, Perceptual Monet: 0.1626\n",
      "  Total G Loss: 3.5700\n",
      "Epoch [181/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1149, D_X Fake: 0.0858, D_X Total: 0.1004\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0428, D_Y Total: 0.0308\n",
      "Generator Losses:\n",
      "  G Adv: 0.9495, F Adv: 0.6693\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1151, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.4765\n",
      "Epoch [181/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0559, D_X Fake: 0.0781, D_X Total: 0.0670\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0807, D_Y Total: 0.0511\n",
      "Generator Losses:\n",
      "  G Adv: 0.9123, F Adv: 0.5632\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1867\n",
      "  Total G Loss: 3.5763\n",
      "Epoch [181/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0737, D_X Fake: 0.0782, D_X Total: 0.0759\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0535, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.9184, F Adv: 0.5854\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1451, Perceptual Monet: 0.1757\n",
      "  Total G Loss: 3.7772\n",
      "Epoch [181/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1117, D_X Fake: 0.0839, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0375, D_Y Fake: 0.0546, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.8402, F Adv: 0.6777\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.7880\n",
      "Epoch [181/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2804, D_X Fake: 0.0772, D_X Total: 0.1788\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0644, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.7505, F Adv: 0.6745\n",
      "  Cycle Photo: 0.0254, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1717\n",
      "  Total G Loss: 3.5142\n",
      "Epoch [181/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1109, D_X Fake: 0.0537, D_X Total: 0.0823\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0708, D_Y Total: 0.0451\n",
      "Generator Losses:\n",
      "  G Adv: 1.0089, F Adv: 0.7599\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1651, Perceptual Monet: 0.1913\n",
      "  Total G Loss: 4.1942\n",
      "Epoch [182/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1261, D_X Fake: 0.0803, D_X Total: 0.1032\n",
      "  D_Y Real: 0.0276, D_Y Fake: 0.0498, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.9004, F Adv: 0.6835\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1386, Perceptual Monet: 0.1790\n",
      "  Total G Loss: 3.7622\n",
      "Epoch [182/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0794, D_X Fake: 0.1468, D_X Total: 0.1131\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0532, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.6752, F Adv: 0.5138\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0214\n",
      "  Perceptual Photo: 0.1252, Perceptual Monet: 0.1410\n",
      "  Total G Loss: 2.9701\n",
      "Epoch [182/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0686, D_X Fake: 0.0595, D_X Total: 0.0641\n",
      "  D_Y Real: 0.0140, D_Y Fake: 0.0416, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.8749, F Adv: 0.6588\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1684\n",
      "  Total G Loss: 3.5139\n",
      "Epoch [182/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0912, D_X Fake: 0.0713, D_X Total: 0.0813\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0375, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9150, F Adv: 0.6975\n",
      "  Cycle Photo: 0.0224, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1100, Perceptual Monet: 0.1755\n",
      "  Total G Loss: 3.5853\n",
      "Epoch [182/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0481, D_X Fake: 0.0778, D_X Total: 0.0630\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0541, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8382, F Adv: 0.5913\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.2060\n",
      "  Total G Loss: 3.8230\n",
      "Epoch [182/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0907, D_X Fake: 0.0582, D_X Total: 0.0745\n",
      "  D_Y Real: 0.0397, D_Y Fake: 0.0352, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.9464, F Adv: 0.7115\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1325, Perceptual Monet: 0.1621\n",
      "  Total G Loss: 3.6839\n",
      "Epoch [182/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2092, D_X Fake: 0.0677, D_X Total: 0.1384\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0644, D_Y Total: 0.0401\n",
      "Generator Losses:\n",
      "  G Adv: 0.9259, F Adv: 0.7221\n",
      "  Cycle Photo: 0.0370, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1930, Perceptual Monet: 0.1392\n",
      "  Total G Loss: 3.9238\n",
      "Epoch [182/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1446, D_X Fake: 0.0812, D_X Total: 0.1129\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0228, D_Y Total: 0.0254\n",
      "Generator Losses:\n",
      "  G Adv: 0.9574, F Adv: 0.5396\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1601, Perceptual Monet: 0.1562\n",
      "  Total G Loss: 3.6436\n",
      "Epoch [182/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0777, D_X Fake: 0.1473, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0691, D_Y Total: 0.0494\n",
      "Generator Losses:\n",
      "  G Adv: 0.8317, F Adv: 0.6031\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0212\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1451\n",
      "  Total G Loss: 3.2924\n",
      "Epoch [182/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2221, D_X Fake: 0.1036, D_X Total: 0.1628\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0478, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.7870, F Adv: 0.4907\n",
      "  Cycle Photo: 0.0439, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.2050, Perceptual Monet: 0.1955\n",
      "  Total G Loss: 4.0874\n",
      "Epoch [182/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0919, D_X Fake: 0.0980, D_X Total: 0.0950\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0622, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.8342, F Adv: 0.5550\n",
      "  Cycle Photo: 0.0347, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1679, Perceptual Monet: 0.1631\n",
      "  Total G Loss: 3.6525\n",
      "Epoch [182/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1229, D_X Fake: 0.0941, D_X Total: 0.1085\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0512, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 0.8329, F Adv: 0.5556\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.1775\n",
      "  Total G Loss: 3.6348\n",
      "Epoch [182/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0636, D_X Fake: 0.1233, D_X Total: 0.0934\n",
      "  D_Y Real: 0.0265, D_Y Fake: 0.0398, D_Y Total: 0.0331\n",
      "Generator Losses:\n",
      "  G Adv: 0.9282, F Adv: 0.5310\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0361\n",
      "  Perceptual Photo: 0.1616, Perceptual Monet: 0.1928\n",
      "  Total G Loss: 3.9364\n",
      "Epoch [182/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2421, D_X Fake: 0.1070, D_X Total: 0.1746\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.0363, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9194, F Adv: 0.6457\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1804\n",
      "  Total G Loss: 3.8066\n",
      "Epoch [182/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0762, D_X Fake: 0.1364, D_X Total: 0.1063\n",
      "  D_Y Real: 0.0452, D_Y Fake: 0.0323, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 0.9821, F Adv: 0.5006\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1898\n",
      "  Total G Loss: 3.7810\n",
      "Epoch [182/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2270, D_X Fake: 0.0605, D_X Total: 0.1437\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0342, D_Y Total: 0.0351\n",
      "Generator Losses:\n",
      "  G Adv: 0.9337, F Adv: 0.7098\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1326, Perceptual Monet: 0.1627\n",
      "  Total G Loss: 3.6840\n",
      "Epoch [182/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1539, D_X Fake: 0.0943, D_X Total: 0.1241\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.0487, D_Y Total: 0.0462\n",
      "Generator Losses:\n",
      "  G Adv: 0.7631, F Adv: 0.6073\n",
      "  Cycle Photo: 0.0232, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1305, Perceptual Monet: 0.1453\n",
      "  Total G Loss: 3.2168\n",
      "Epoch [182/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2567, D_X Fake: 0.0832, D_X Total: 0.1699\n",
      "  D_Y Real: 0.0314, D_Y Fake: 0.0382, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9146, F Adv: 0.6334\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.5480\n",
      "Epoch [182/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0521, D_X Fake: 0.1234, D_X Total: 0.0877\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0564, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.7601, F Adv: 0.4915\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0387\n",
      "  Perceptual Photo: 0.1192, Perceptual Monet: 0.1999\n",
      "  Total G Loss: 3.5183\n",
      "Epoch [182/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1118, D_X Fake: 0.1487, D_X Total: 0.1302\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0474, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 1.0935, F Adv: 0.4722\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.7799\n",
      "Epoch [182/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2050, D_X Fake: 0.1099, D_X Total: 0.1575\n",
      "  D_Y Real: 0.0302, D_Y Fake: 0.0578, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 1.0807, F Adv: 0.5343\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1720\n",
      "  Total G Loss: 3.8234\n",
      "Epoch [182/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1269, D_X Fake: 0.0746, D_X Total: 0.1007\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0442, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.9561, F Adv: 0.6744\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1278, Perceptual Monet: 0.1636\n",
      "  Total G Loss: 3.6415\n",
      "Epoch [182/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2155, D_X Fake: 0.0924, D_X Total: 0.1539\n",
      "  D_Y Real: 0.0300, D_Y Fake: 0.0673, D_Y Total: 0.0487\n",
      "Generator Losses:\n",
      "  G Adv: 0.7535, F Adv: 0.7556\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1476, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.7323\n",
      "Epoch [182/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1772, D_X Fake: 0.0950, D_X Total: 0.1361\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0356, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8060, F Adv: 0.6534\n",
      "  Cycle Photo: 0.0426, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.2017, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 4.0138\n",
      "Epoch [183/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1809, D_X Fake: 0.0881, D_X Total: 0.1345\n",
      "  D_Y Real: 0.0389, D_Y Fake: 0.0404, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 1.0018, F Adv: 0.5650\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.8360\n",
      "Epoch [183/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0516, D_X Fake: 0.1178, D_X Total: 0.0847\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0412, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.8895, F Adv: 0.6558\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1186, Perceptual Monet: 0.2067\n",
      "  Total G Loss: 3.7827\n",
      "Epoch [183/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1395, D_X Fake: 0.0726, D_X Total: 0.1060\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0552, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.7609, F Adv: 0.5908\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1383, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 3.5023\n",
      "Epoch [183/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1303, D_X Fake: 0.1244, D_X Total: 0.1274\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0347, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 0.9587, F Adv: 0.4555\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0336\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.1808\n",
      "  Total G Loss: 3.7234\n",
      "Epoch [183/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1493, D_X Fake: 0.0838, D_X Total: 0.1165\n",
      "  D_Y Real: 0.0427, D_Y Fake: 0.0732, D_Y Total: 0.0579\n",
      "Generator Losses:\n",
      "  G Adv: 0.9684, F Adv: 0.6882\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0369\n",
      "  Perceptual Photo: 0.1186, Perceptual Monet: 0.1803\n",
      "  Total G Loss: 3.7414\n",
      "Epoch [183/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1016, D_X Fake: 0.1321, D_X Total: 0.1169\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0316, D_Y Total: 0.0254\n",
      "Generator Losses:\n",
      "  G Adv: 0.7403, F Adv: 0.6770\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1394, Perceptual Monet: 0.1391\n",
      "  Total G Loss: 3.3022\n",
      "Epoch [183/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1510, D_X Fake: 0.0600, D_X Total: 0.1055\n",
      "  D_Y Real: 0.0169, D_Y Fake: 0.0635, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.7210, F Adv: 0.5795\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1728\n",
      "  Total G Loss: 3.5054\n",
      "Epoch [183/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0703, D_X Fake: 0.1782, D_X Total: 0.1243\n",
      "  D_Y Real: 0.0255, D_Y Fake: 0.0670, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 0.9468, F Adv: 0.4583\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1667, Perceptual Monet: 0.1670\n",
      "  Total G Loss: 3.6733\n",
      "Epoch [183/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1724, D_X Fake: 0.0695, D_X Total: 0.1209\n",
      "  D_Y Real: 0.0426, D_Y Fake: 0.0536, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.9011, F Adv: 0.5561\n",
      "  Cycle Photo: 0.0383, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1772, Perceptual Monet: 0.1512\n",
      "  Total G Loss: 3.7467\n",
      "Epoch [183/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1052, D_X Fake: 0.0929, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0221, D_Y Fake: 0.0313, D_Y Total: 0.0267\n",
      "Generator Losses:\n",
      "  G Adv: 0.9988, F Adv: 0.5610\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1865\n",
      "  Total G Loss: 3.9144\n",
      "Epoch [183/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2112, D_X Fake: 0.0869, D_X Total: 0.1490\n",
      "  D_Y Real: 0.0255, D_Y Fake: 0.0362, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.9098, F Adv: 0.6895\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0232\n",
      "  Perceptual Photo: 0.1648, Perceptual Monet: 0.1427\n",
      "  Total G Loss: 3.6781\n",
      "Epoch [183/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1692, D_X Fake: 0.0767, D_X Total: 0.1230\n",
      "  D_Y Real: 0.0274, D_Y Fake: 0.0491, D_Y Total: 0.0382\n",
      "Generator Losses:\n",
      "  G Adv: 0.8459, F Adv: 0.6507\n",
      "  Cycle Photo: 0.0355, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1809, Perceptual Monet: 0.2069\n",
      "  Total G Loss: 4.1542\n",
      "Epoch [183/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0722, D_X Fake: 0.1179, D_X Total: 0.0951\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0523, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.7633, F Adv: 0.5385\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1351, Perceptual Monet: 0.1488\n",
      "  Total G Loss: 3.2371\n",
      "Epoch [183/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1220, D_X Fake: 0.0947, D_X Total: 0.1083\n",
      "  D_Y Real: 0.0159, D_Y Fake: 0.0394, D_Y Total: 0.0276\n",
      "Generator Losses:\n",
      "  G Adv: 0.8395, F Adv: 0.6486\n",
      "  Cycle Photo: 0.0224, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1835\n",
      "  Total G Loss: 3.5378\n",
      "Epoch [183/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3373, D_X Fake: 0.0923, D_X Total: 0.2148\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0394, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 1.0148, F Adv: 0.6135\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1780, Perceptual Monet: 0.1730\n",
      "  Total G Loss: 4.0351\n",
      "Epoch [183/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0498, D_X Fake: 0.0979, D_X Total: 0.0739\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0471, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.9591, F Adv: 0.6751\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1592\n",
      "  Total G Loss: 3.7294\n",
      "Epoch [183/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1694, D_X Fake: 0.1945, D_X Total: 0.1820\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0978, D_Y Total: 0.0631\n",
      "Generator Losses:\n",
      "  G Adv: 0.8255, F Adv: 0.4752\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.1694\n",
      "  Total G Loss: 3.5821\n",
      "Epoch [183/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1737, D_X Fake: 0.0955, D_X Total: 0.1346\n",
      "  D_Y Real: 0.0146, D_Y Fake: 0.0330, D_Y Total: 0.0238\n",
      "Generator Losses:\n",
      "  G Adv: 0.8056, F Adv: 0.7304\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1522, Perceptual Monet: 0.1919\n",
      "  Total G Loss: 3.8932\n",
      "Epoch [183/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1445, D_X Fake: 0.1045, D_X Total: 0.1245\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0537, D_Y Total: 0.0364\n",
      "Generator Losses:\n",
      "  G Adv: 0.7549, F Adv: 0.5823\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1197, Perceptual Monet: 0.1876\n",
      "  Total G Loss: 3.4767\n",
      "Epoch [183/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0594, D_X Fake: 0.1586, D_X Total: 0.1090\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0336, D_Y Total: 0.0300\n",
      "Generator Losses:\n",
      "  G Adv: 0.8213, F Adv: 0.4833\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0408\n",
      "  Perceptual Photo: 0.1602, Perceptual Monet: 0.1975\n",
      "  Total G Loss: 3.7988\n",
      "Epoch [183/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1057, D_X Fake: 0.1762, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0371, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 1.0474, F Adv: 0.4983\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.1589\n",
      "  Total G Loss: 3.5895\n",
      "Epoch [183/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0547, D_X Fake: 0.1237, D_X Total: 0.0892\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0420, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.8067, F Adv: 0.6075\n",
      "  Cycle Photo: 0.0336, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1214, Perceptual Monet: 0.1689\n",
      "  Total G Loss: 3.5085\n",
      "Epoch [183/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.0968, D_X Total: 0.1142\n",
      "  D_Y Real: 0.0408, D_Y Fake: 0.0370, D_Y Total: 0.0389\n",
      "Generator Losses:\n",
      "  G Adv: 0.8293, F Adv: 0.5446\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1196, Perceptual Monet: 0.1629\n",
      "  Total G Loss: 3.3587\n",
      "Epoch [183/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1044, D_X Fake: 0.1264, D_X Total: 0.1154\n",
      "  D_Y Real: 0.0448, D_Y Fake: 0.0771, D_Y Total: 0.0610\n",
      "Generator Losses:\n",
      "  G Adv: 0.8466, F Adv: 0.4058\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1452, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.4019\n",
      "Epoch [184/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0795, D_X Fake: 0.0892, D_X Total: 0.0844\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0436, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9413, F Adv: 0.5228\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1542\n",
      "  Total G Loss: 3.5022\n",
      "Epoch [184/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1705, D_X Fake: 0.1152, D_X Total: 0.1428\n",
      "  D_Y Real: 0.0156, D_Y Fake: 0.0392, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.8606, F Adv: 0.6400\n",
      "  Cycle Photo: 0.0388, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1546, Perceptual Monet: 0.1487\n",
      "  Total G Loss: 3.6627\n",
      "Epoch [184/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0542, D_X Fake: 0.0920, D_X Total: 0.0731\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0442, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 0.8736, F Adv: 0.5368\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1445, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 3.3962\n",
      "Epoch [184/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0879, D_X Fake: 0.1161, D_X Total: 0.1020\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0336, D_Y Total: 0.0315\n",
      "Generator Losses:\n",
      "  G Adv: 0.8110, F Adv: 0.5403\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1469, Perceptual Monet: 0.1821\n",
      "  Total G Loss: 3.5945\n",
      "Epoch [184/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2103, D_X Fake: 0.0811, D_X Total: 0.1457\n",
      "  D_Y Real: 0.0323, D_Y Fake: 0.0345, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 1.0347, F Adv: 0.6974\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1000, Perceptual Monet: 0.1410\n",
      "  Total G Loss: 3.3631\n",
      "Epoch [184/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1292, D_X Fake: 0.1023, D_X Total: 0.1157\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.0496, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.8844, F Adv: 0.6504\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0400\n",
      "  Perceptual Photo: 0.1662, Perceptual Monet: 0.1938\n",
      "  Total G Loss: 4.0468\n",
      "Epoch [184/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1251, D_X Fake: 0.0949, D_X Total: 0.1100\n",
      "  D_Y Real: 0.0361, D_Y Fake: 0.0372, D_Y Total: 0.0366\n",
      "Generator Losses:\n",
      "  G Adv: 0.8502, F Adv: 0.6487\n",
      "  Cycle Photo: 0.0395, Cycle Monet: 0.0413\n",
      "  Perceptual Photo: 0.1883, Perceptual Monet: 0.1918\n",
      "  Total G Loss: 4.2078\n",
      "Epoch [184/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1780, D_X Fake: 0.1406, D_X Total: 0.1593\n",
      "  D_Y Real: 0.0212, D_Y Fake: 0.0307, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9113, F Adv: 0.5416\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.4805\n",
      "Epoch [184/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2009, D_X Fake: 0.0711, D_X Total: 0.1360\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0525, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.8803, F Adv: 0.5868\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1495, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.5512\n",
      "Epoch [184/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1977, D_X Fake: 0.1205, D_X Total: 0.1591\n",
      "  D_Y Real: 0.0165, D_Y Fake: 0.0365, D_Y Total: 0.0265\n",
      "Generator Losses:\n",
      "  G Adv: 1.1274, F Adv: 0.5694\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1315, Perceptual Monet: 0.1836\n",
      "  Total G Loss: 3.8839\n",
      "Epoch [184/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0745, D_X Fake: 0.1530, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0369, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 1.0206, F Adv: 0.6159\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1420, Perceptual Monet: 0.1744\n",
      "  Total G Loss: 3.7617\n",
      "Epoch [184/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1117, D_X Fake: 0.0798, D_X Total: 0.0957\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0364, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.8351, F Adv: 0.7384\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1222, Perceptual Monet: 0.1765\n",
      "  Total G Loss: 3.5869\n",
      "Epoch [184/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0863, D_X Fake: 0.0565, D_X Total: 0.0714\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0610, D_Y Total: 0.0421\n",
      "Generator Losses:\n",
      "  G Adv: 0.9356, F Adv: 0.8479\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1174, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.8304\n",
      "Epoch [184/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1722, D_X Fake: 0.1436, D_X Total: 0.1579\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0401, D_Y Total: 0.0342\n",
      "Generator Losses:\n",
      "  G Adv: 0.9356, F Adv: 0.5450\n",
      "  Cycle Photo: 0.0343, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1722, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.7064\n",
      "Epoch [184/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2512, D_X Fake: 0.0886, D_X Total: 0.1699\n",
      "  D_Y Real: 0.0493, D_Y Fake: 0.0574, D_Y Total: 0.0534\n",
      "Generator Losses:\n",
      "  G Adv: 0.8116, F Adv: 0.6001\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1537\n",
      "  Total G Loss: 3.3678\n",
      "Epoch [184/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1863, D_X Fake: 0.1225, D_X Total: 0.1544\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0444, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.9003, F Adv: 0.4347\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1454, Perceptual Monet: 0.1682\n",
      "  Total G Loss: 3.5391\n",
      "Epoch [184/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1661, D_X Fake: 0.0745, D_X Total: 0.1203\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0361, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 1.0314, F Adv: 0.7274\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0401\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.2008\n",
      "  Total G Loss: 4.0163\n",
      "Epoch [184/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0998, D_X Fake: 0.1118, D_X Total: 0.1058\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0339, D_Y Total: 0.0265\n",
      "Generator Losses:\n",
      "  G Adv: 0.8729, F Adv: 0.7068\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1689, Perceptual Monet: 0.1698\n",
      "  Total G Loss: 3.8887\n",
      "Epoch [184/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1938, D_X Fake: 0.1118, D_X Total: 0.1528\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0335, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9880, F Adv: 0.5360\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.4801\n",
      "Epoch [184/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0710, D_X Fake: 0.1101, D_X Total: 0.0906\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0702, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.8481, F Adv: 0.5783\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1121, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.3547\n",
      "Epoch [184/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1031, D_X Fake: 0.1383, D_X Total: 0.1207\n",
      "  D_Y Real: 0.0261, D_Y Fake: 0.0433, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.8597, F Adv: 0.5032\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1349, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.4200\n",
      "Epoch [184/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2076, D_X Fake: 0.1117, D_X Total: 0.1597\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0516, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.8348, F Adv: 0.5641\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1212, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.4954\n",
      "Epoch [184/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1338, D_X Fake: 0.1501, D_X Total: 0.1419\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0270, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9977, F Adv: 0.5237\n",
      "  Cycle Photo: 0.0354, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1621, Perceptual Monet: 0.1609\n",
      "  Total G Loss: 3.7367\n",
      "Epoch [184/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1271, D_X Fake: 0.0918, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0143, D_Y Fake: 0.0586, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 0.8341, F Adv: 0.5686\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1263, Perceptual Monet: 0.1459\n",
      "  Total G Loss: 3.2507\n",
      "Epoch [185/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1127, D_X Fake: 0.0699, D_X Total: 0.0913\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0550, D_Y Total: 0.0483\n",
      "Generator Losses:\n",
      "  G Adv: 0.8482, F Adv: 0.6970\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1782\n",
      "  Total G Loss: 3.7886\n",
      "Epoch [185/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0901, D_X Fake: 0.1037, D_X Total: 0.0969\n",
      "  D_Y Real: 0.0359, D_Y Fake: 0.0333, D_Y Total: 0.0346\n",
      "Generator Losses:\n",
      "  G Adv: 1.0437, F Adv: 0.4675\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1195, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 3.4454\n",
      "Epoch [185/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1765, D_X Fake: 0.0684, D_X Total: 0.1225\n",
      "  D_Y Real: 0.0241, D_Y Fake: 0.0546, D_Y Total: 0.0394\n",
      "Generator Losses:\n",
      "  G Adv: 0.8697, F Adv: 0.7295\n",
      "  Cycle Photo: 0.0209, Cycle Monet: 0.0388\n",
      "  Perceptual Photo: 0.1014, Perceptual Monet: 0.2018\n",
      "  Total G Loss: 3.7125\n",
      "Epoch [185/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2198, D_X Fake: 0.0998, D_X Total: 0.1598\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0293, D_Y Total: 0.0262\n",
      "Generator Losses:\n",
      "  G Adv: 0.8603, F Adv: 0.4937\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1374, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.3372\n",
      "Epoch [185/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1109, D_X Fake: 0.0797, D_X Total: 0.0953\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0662, D_Y Total: 0.0460\n",
      "Generator Losses:\n",
      "  G Adv: 0.8211, F Adv: 0.6593\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.0888, Perceptual Monet: 0.1781\n",
      "  Total G Loss: 3.3601\n",
      "Epoch [185/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1031, D_X Fake: 0.0729, D_X Total: 0.0880\n",
      "  D_Y Real: 0.0206, D_Y Fake: 0.0400, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.7688, F Adv: 0.7215\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1742\n",
      "  Total G Loss: 3.7062\n",
      "Epoch [185/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0675, D_X Fake: 0.0536, D_X Total: 0.0606\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0612, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.8511, F Adv: 0.8643\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1198, Perceptual Monet: 0.1828\n",
      "  Total G Loss: 3.8052\n",
      "Epoch [185/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1574, D_X Fake: 0.0775, D_X Total: 0.1174\n",
      "  D_Y Real: 0.0162, D_Y Fake: 0.0582, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.7372, F Adv: 0.7384\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1830\n",
      "  Total G Loss: 3.5515\n",
      "Epoch [185/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2579, D_X Fake: 0.0892, D_X Total: 0.1736\n",
      "  D_Y Real: 0.0349, D_Y Fake: 0.0384, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 0.9619, F Adv: 0.6234\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0220\n",
      "  Perceptual Photo: 0.1379, Perceptual Monet: 0.1449\n",
      "  Total G Loss: 3.4968\n",
      "Epoch [185/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1552, D_X Fake: 0.0799, D_X Total: 0.1176\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0355, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.9798, F Adv: 0.6542\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1756\n",
      "  Total G Loss: 3.6830\n",
      "Epoch [185/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0995, D_X Fake: 0.0792, D_X Total: 0.0894\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0272, D_Y Total: 0.0233\n",
      "Generator Losses:\n",
      "  G Adv: 1.1049, F Adv: 0.5843\n",
      "  Cycle Photo: 0.0399, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1910, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 4.0073\n",
      "Epoch [185/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0703, D_X Fake: 0.1396, D_X Total: 0.1050\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0491, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.9005, F Adv: 0.6051\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0372\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.2101\n",
      "  Total G Loss: 4.0612\n",
      "Epoch [185/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0838, D_X Fake: 0.1126, D_X Total: 0.0982\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0237, D_Y Total: 0.0267\n",
      "Generator Losses:\n",
      "  G Adv: 0.8891, F Adv: 0.5386\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1285, Perceptual Monet: 0.1446\n",
      "  Total G Loss: 3.2963\n",
      "Epoch [185/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1915, D_X Fake: 0.0788, D_X Total: 0.1351\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0341, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.9353, F Adv: 0.6068\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1203, Perceptual Monet: 0.1323\n",
      "  Total G Loss: 3.2441\n",
      "Epoch [185/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0856, D_X Fake: 0.1096, D_X Total: 0.0976\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.0385, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.8368, F Adv: 0.5225\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1434, Perceptual Monet: 0.1545\n",
      "  Total G Loss: 3.4043\n",
      "Epoch [185/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1290, D_X Fake: 0.0803, D_X Total: 0.1047\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0433, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8178, F Adv: 0.7082\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0327\n",
      "  Perceptual Photo: 0.1243, Perceptual Monet: 0.1919\n",
      "  Total G Loss: 3.7190\n",
      "Epoch [185/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1025, D_X Fake: 0.1084, D_X Total: 0.1055\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.1068, D_Y Total: 0.0668\n",
      "Generator Losses:\n",
      "  G Adv: 0.8271, F Adv: 0.5403\n",
      "  Cycle Photo: 0.0305, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1429, Perceptual Monet: 0.1940\n",
      "  Total G Loss: 3.7125\n",
      "Epoch [185/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1358, D_X Fake: 0.1410, D_X Total: 0.1384\n",
      "  D_Y Real: 0.0218, D_Y Fake: 0.0411, D_Y Total: 0.0314\n",
      "Generator Losses:\n",
      "  G Adv: 0.8586, F Adv: 0.4796\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0290\n",
      "  Perceptual Photo: 0.1230, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.3811\n",
      "Epoch [185/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1744, D_X Fake: 0.0857, D_X Total: 0.1300\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0392, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.8834, F Adv: 0.6779\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1634, Perceptual Monet: 0.2030\n",
      "  Total G Loss: 4.0579\n",
      "Epoch [185/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1313, D_X Fake: 0.0981, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0533, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 1.0625, F Adv: 0.6031\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1279, Perceptual Monet: 0.1939\n",
      "  Total G Loss: 3.9413\n",
      "Epoch [185/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1574, D_X Fake: 0.1281, D_X Total: 0.1428\n",
      "  D_Y Real: 0.0287, D_Y Fake: 0.0325, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9199, F Adv: 0.5553\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1379, Perceptual Monet: 0.1596\n",
      "  Total G Loss: 3.5232\n",
      "Epoch [185/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1018, D_X Fake: 0.0574, D_X Total: 0.0796\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0475, D_Y Total: 0.0365\n",
      "Generator Losses:\n",
      "  G Adv: 1.1222, F Adv: 0.6494\n",
      "  Cycle Photo: 0.0375, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1363, Perceptual Monet: 0.1562\n",
      "  Total G Loss: 3.8515\n",
      "Epoch [185/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1358, D_X Fake: 0.0983, D_X Total: 0.1170\n",
      "  D_Y Real: 0.0449, D_Y Fake: 0.0347, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.9498, F Adv: 0.6250\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0229\n",
      "  Perceptual Photo: 0.1078, Perceptual Monet: 0.1421\n",
      "  Total G Loss: 3.2954\n",
      "Epoch [185/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0956, D_X Fake: 0.0946, D_X Total: 0.0951\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0555, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.7950, F Adv: 0.5035\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1217, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.3214\n",
      "Epoch [186/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0619, D_X Fake: 0.1163, D_X Total: 0.0891\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0673, D_Y Total: 0.0449\n",
      "Generator Losses:\n",
      "  G Adv: 0.7471, F Adv: 0.5415\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1152, Perceptual Monet: 0.1599\n",
      "  Total G Loss: 3.2209\n",
      "Epoch [186/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0596, D_X Fake: 0.0574, D_X Total: 0.0585\n",
      "  D_Y Real: 0.0305, D_Y Fake: 0.0630, D_Y Total: 0.0468\n",
      "Generator Losses:\n",
      "  G Adv: 1.0120, F Adv: 0.8421\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1113, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.7617\n",
      "Epoch [186/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0876, D_X Fake: 0.1397, D_X Total: 0.1136\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0402, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.9774, F Adv: 0.4535\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1316, Perceptual Monet: 0.1614\n",
      "  Total G Loss: 3.4480\n",
      "Epoch [186/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1112, D_X Fake: 0.0546, D_X Total: 0.0829\n",
      "  D_Y Real: 0.0294, D_Y Fake: 0.0312, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.8480, F Adv: 0.7397\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1416, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.6966\n",
      "Epoch [186/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1565, D_X Fake: 0.0811, D_X Total: 0.1188\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.1089, D_Y Total: 0.0649\n",
      "Generator Losses:\n",
      "  G Adv: 0.8328, F Adv: 0.5424\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.1561\n",
      "  Total G Loss: 3.6189\n",
      "Epoch [186/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1799, D_X Fake: 0.1194, D_X Total: 0.1497\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0311, D_Y Total: 0.0242\n",
      "Generator Losses:\n",
      "  G Adv: 0.7612, F Adv: 0.7182\n",
      "  Cycle Photo: 0.0245, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1344, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.5542\n",
      "Epoch [186/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2180, D_X Fake: 0.1463, D_X Total: 0.1822\n",
      "  D_Y Real: 0.0240, D_Y Fake: 0.0355, D_Y Total: 0.0297\n",
      "Generator Losses:\n",
      "  G Adv: 0.8369, F Adv: 0.4871\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.5561\n",
      "Epoch [186/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2848, D_X Fake: 0.1404, D_X Total: 0.2126\n",
      "  D_Y Real: 0.0346, D_Y Fake: 0.0524, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.8105, F Adv: 0.5176\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1263, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 3.4475\n",
      "Epoch [186/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1040, D_X Fake: 0.0620, D_X Total: 0.0830\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0636, D_Y Total: 0.0407\n",
      "Generator Losses:\n",
      "  G Adv: 0.7586, F Adv: 0.6595\n",
      "  Cycle Photo: 0.0192, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1160, Perceptual Monet: 0.1785\n",
      "  Total G Loss: 3.3748\n",
      "Epoch [186/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1687, D_X Fake: 0.1320, D_X Total: 0.1504\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.0381, D_Y Total: 0.0416\n",
      "Generator Losses:\n",
      "  G Adv: 0.8705, F Adv: 0.4950\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1272, Perceptual Monet: 0.1798\n",
      "  Total G Loss: 3.4710\n",
      "Epoch [186/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0820, D_X Fake: 0.0677, D_X Total: 0.0748\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0841, D_Y Total: 0.0560\n",
      "Generator Losses:\n",
      "  G Adv: 0.8804, F Adv: 0.6823\n",
      "  Cycle Photo: 0.0223, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1239, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.5517\n",
      "Epoch [186/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0636, D_X Fake: 0.1202, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0441, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.9863, F Adv: 0.5585\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1164, Perceptual Monet: 0.1699\n",
      "  Total G Loss: 3.4842\n",
      "Epoch [186/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1656, D_X Fake: 0.0715, D_X Total: 0.1185\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0498, D_Y Total: 0.0412\n",
      "Generator Losses:\n",
      "  G Adv: 0.8666, F Adv: 0.6052\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1461, Perceptual Monet: 0.1383\n",
      "  Total G Loss: 3.4274\n",
      "Epoch [186/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.1061, D_X Total: 0.1265\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0349, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.9102, F Adv: 0.6236\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1163, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.4463\n",
      "Epoch [186/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2148, D_X Fake: 0.0931, D_X Total: 0.1540\n",
      "  D_Y Real: 0.0148, D_Y Fake: 0.0653, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.9449, F Adv: 0.6206\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0218\n",
      "  Perceptual Photo: 0.1588, Perceptual Monet: 0.1424\n",
      "  Total G Loss: 3.5605\n",
      "Epoch [186/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1282, D_X Fake: 0.0704, D_X Total: 0.0993\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0530, D_Y Total: 0.0393\n",
      "Generator Losses:\n",
      "  G Adv: 0.8497, F Adv: 0.7446\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1233, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.5164\n",
      "Epoch [186/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1717, D_X Fake: 0.0641, D_X Total: 0.1179\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0271, D_Y Total: 0.0255\n",
      "Generator Losses:\n",
      "  G Adv: 1.0052, F Adv: 0.5424\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1326, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.6117\n",
      "Epoch [186/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1211, D_X Fake: 0.0996, D_X Total: 0.1103\n",
      "  D_Y Real: 0.0190, D_Y Fake: 0.0840, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 0.7849, F Adv: 0.5800\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0308\n",
      "  Perceptual Photo: 0.1597, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.5867\n",
      "Epoch [186/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0664, D_X Fake: 0.1658, D_X Total: 0.1161\n",
      "  D_Y Real: 0.0302, D_Y Fake: 0.0753, D_Y Total: 0.0527\n",
      "Generator Losses:\n",
      "  G Adv: 0.7262, F Adv: 0.4013\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0198\n",
      "  Perceptual Photo: 0.0948, Perceptual Monet: 0.1376\n",
      "  Total G Loss: 2.7641\n",
      "Epoch [186/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1623, D_X Fake: 0.0784, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0438, D_Y Fake: 0.0529, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.8029, F Adv: 0.6962\n",
      "  Cycle Photo: 0.0279, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1437, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 3.7187\n",
      "Epoch [186/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2050, D_X Fake: 0.0822, D_X Total: 0.1436\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0288, D_Y Total: 0.0295\n",
      "Generator Losses:\n",
      "  G Adv: 0.8573, F Adv: 0.5463\n",
      "  Cycle Photo: 0.0357, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1676, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.6560\n",
      "Epoch [186/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1219, D_X Fake: 0.1074, D_X Total: 0.1147\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0540, D_Y Total: 0.0416\n",
      "Generator Losses:\n",
      "  G Adv: 0.8068, F Adv: 0.6115\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0375\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.2084\n",
      "  Total G Loss: 3.7397\n",
      "Epoch [186/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1425, D_X Fake: 0.1358, D_X Total: 0.1391\n",
      "  D_Y Real: 0.0299, D_Y Fake: 0.0626, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 0.8939, F Adv: 0.5865\n",
      "  Cycle Photo: 0.0443, Cycle Monet: 0.0192\n",
      "  Perceptual Photo: 0.1940, Perceptual Monet: 0.1260\n",
      "  Total G Loss: 3.7160\n",
      "Epoch [186/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0557, D_X Fake: 0.1295, D_X Total: 0.0926\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0334, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.9904, F Adv: 0.5193\n",
      "  Cycle Photo: 0.0242, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.0921, Perceptual Monet: 0.1566\n",
      "  Total G Loss: 3.3135\n",
      "Epoch [187/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1138, D_X Fake: 0.1277, D_X Total: 0.1207\n",
      "  D_Y Real: 0.0144, D_Y Fake: 0.0648, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.8011, F Adv: 0.5597\n",
      "  Cycle Photo: 0.0209, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1192, Perceptual Monet: 0.1403\n",
      "  Total G Loss: 3.1026\n",
      "Epoch [187/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2302, D_X Fake: 0.1538, D_X Total: 0.1920\n",
      "  D_Y Real: 0.0218, D_Y Fake: 0.0468, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.9012, F Adv: 0.4586\n",
      "  Cycle Photo: 0.0408, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1876, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.8544\n",
      "Epoch [187/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1370, D_X Fake: 0.1628, D_X Total: 0.1499\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0387, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.8667, F Adv: 0.5181\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1653\n",
      "  Total G Loss: 3.5359\n",
      "Epoch [187/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0839, D_X Fake: 0.1612, D_X Total: 0.1225\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0448, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.9137, F Adv: 0.4962\n",
      "  Cycle Photo: 0.0265, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1443, Perceptual Monet: 0.1801\n",
      "  Total G Loss: 3.5830\n",
      "Epoch [187/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0707, D_X Fake: 0.1036, D_X Total: 0.0871\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0583, D_Y Total: 0.0391\n",
      "Generator Losses:\n",
      "  G Adv: 1.0139, F Adv: 0.5593\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1041, Perceptual Monet: 0.1579\n",
      "  Total G Loss: 3.3906\n",
      "Epoch [187/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1199, D_X Fake: 0.0882, D_X Total: 0.1040\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0677, D_Y Total: 0.0438\n",
      "Generator Losses:\n",
      "  G Adv: 0.8710, F Adv: 0.5938\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0263\n",
      "  Perceptual Photo: 0.1318, Perceptual Monet: 0.1549\n",
      "  Total G Loss: 3.4238\n",
      "Epoch [187/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0660, D_X Fake: 0.0954, D_X Total: 0.0807\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0502, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.7991, F Adv: 0.5881\n",
      "  Cycle Photo: 0.0306, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1240, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.3886\n",
      "Epoch [187/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0851, D_X Fake: 0.1305, D_X Total: 0.1078\n",
      "  D_Y Real: 0.0321, D_Y Fake: 0.0465, D_Y Total: 0.0393\n",
      "Generator Losses:\n",
      "  G Adv: 0.9526, F Adv: 0.4382\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1486, Perceptual Monet: 0.1476\n",
      "  Total G Loss: 3.4394\n",
      "Epoch [187/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3215, D_X Fake: 0.1002, D_X Total: 0.2108\n",
      "  D_Y Real: 0.0281, D_Y Fake: 0.0458, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.7941, F Adv: 0.5811\n",
      "  Cycle Photo: 0.0312, Cycle Monet: 0.0204\n",
      "  Perceptual Photo: 0.1685, Perceptual Monet: 0.1414\n",
      "  Total G Loss: 3.4411\n",
      "Epoch [187/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0846, D_X Fake: 0.0957, D_X Total: 0.0902\n",
      "  D_Y Real: 0.0260, D_Y Fake: 0.0364, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 1.0286, F Adv: 0.5740\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0274\n",
      "  Perceptual Photo: 0.1478, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.7060\n",
      "Epoch [187/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0879, D_X Fake: 0.0819, D_X Total: 0.0849\n",
      "  D_Y Real: 0.0301, D_Y Fake: 0.0392, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.8934, F Adv: 0.6475\n",
      "  Cycle Photo: 0.0363, Cycle Monet: 0.0374\n",
      "  Perceptual Photo: 0.1813, Perceptual Monet: 0.2124\n",
      "  Total G Loss: 4.2464\n",
      "Epoch [187/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1636, D_X Fake: 0.0791, D_X Total: 0.1214\n",
      "  D_Y Real: 0.0391, D_Y Fake: 0.0578, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.8766, F Adv: 0.6673\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1414, Perceptual Monet: 0.1607\n",
      "  Total G Loss: 3.6572\n",
      "Epoch [187/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1193, D_X Fake: 0.1166, D_X Total: 0.1179\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0376, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.8407, F Adv: 0.6195\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0318\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1704\n",
      "  Total G Loss: 3.7485\n",
      "Epoch [187/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2441, D_X Fake: 0.1635, D_X Total: 0.2038\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0344, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.9034, F Adv: 0.5506\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1140, Perceptual Monet: 0.1690\n",
      "  Total G Loss: 3.3812\n",
      "Epoch [187/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1538, D_X Fake: 0.1194, D_X Total: 0.1366\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0431, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.9075, F Adv: 0.6106\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0236\n",
      "  Perceptual Photo: 0.1489, Perceptual Monet: 0.1488\n",
      "  Total G Loss: 3.5582\n",
      "Epoch [187/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1036, D_X Fake: 0.1002, D_X Total: 0.1019\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0501, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.8200, F Adv: 0.5658\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1100, Perceptual Monet: 0.1616\n",
      "  Total G Loss: 3.2672\n",
      "Epoch [187/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2628, D_X Fake: 0.0490, D_X Total: 0.1559\n",
      "  D_Y Real: 0.0475, D_Y Fake: 0.0481, D_Y Total: 0.0478\n",
      "Generator Losses:\n",
      "  G Adv: 0.8754, F Adv: 0.7629\n",
      "  Cycle Photo: 0.0410, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1733, Perceptual Monet: 0.1967\n",
      "  Total G Loss: 4.2078\n",
      "Epoch [187/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0820, D_X Fake: 0.1000, D_X Total: 0.0910\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0312, D_Y Total: 0.0272\n",
      "Generator Losses:\n",
      "  G Adv: 1.0078, F Adv: 0.5925\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1279, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.5601\n",
      "Epoch [187/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1339, D_X Fake: 0.0995, D_X Total: 0.1167\n",
      "  D_Y Real: 0.0310, D_Y Fake: 0.0341, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9525, F Adv: 0.6188\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0194\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1296\n",
      "  Total G Loss: 3.3271\n",
      "Epoch [187/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0833, D_X Fake: 0.1147, D_X Total: 0.0990\n",
      "  D_Y Real: 0.0256, D_Y Fake: 0.0465, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.8651, F Adv: 0.5297\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0368\n",
      "  Perceptual Photo: 0.1356, Perceptual Monet: 0.2077\n",
      "  Total G Loss: 3.7453\n",
      "Epoch [187/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2607, D_X Fake: 0.1173, D_X Total: 0.1890\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0449, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 0.9526, F Adv: 0.4753\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0234\n",
      "  Perceptual Photo: 0.1137, Perceptual Monet: 0.1529\n",
      "  Total G Loss: 3.2309\n",
      "Epoch [187/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0967, D_X Fake: 0.0843, D_X Total: 0.0905\n",
      "  D_Y Real: 0.0483, D_Y Fake: 0.0271, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 1.0215, F Adv: 0.5951\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1396, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.7422\n",
      "Epoch [187/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1066, D_X Fake: 0.1122, D_X Total: 0.1094\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0308, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.9936, F Adv: 0.6045\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1369, Perceptual Monet: 0.1674\n",
      "  Total G Loss: 3.6742\n",
      "Epoch [187/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0816, D_X Fake: 0.1274, D_X Total: 0.1045\n",
      "  D_Y Real: 0.0308, D_Y Fake: 0.0417, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.9703, F Adv: 0.6318\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1512, Perceptual Monet: 0.1617\n",
      "  Total G Loss: 3.7146\n",
      "Epoch [188/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2020, D_X Fake: 0.0801, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0542, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 1.0430, F Adv: 0.6605\n",
      "  Cycle Photo: 0.0401, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1905, Perceptual Monet: 0.1597\n",
      "  Total G Loss: 4.1427\n",
      "Epoch [188/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1651, D_X Fake: 0.0426, D_X Total: 0.1038\n",
      "  D_Y Real: 0.0300, D_Y Fake: 0.0457, D_Y Total: 0.0379\n",
      "Generator Losses:\n",
      "  G Adv: 1.1097, F Adv: 0.7360\n",
      "  Cycle Photo: 0.0358, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1862, Perceptual Monet: 0.1729\n",
      "  Total G Loss: 4.3025\n",
      "Epoch [188/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0949, D_X Fake: 0.0788, D_X Total: 0.0869\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0493, D_Y Total: 0.0393\n",
      "Generator Losses:\n",
      "  G Adv: 0.7822, F Adv: 0.5502\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1462, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.4036\n",
      "Epoch [188/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1591, D_X Fake: 0.1179, D_X Total: 0.1385\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0366, D_Y Total: 0.0283\n",
      "Generator Losses:\n",
      "  G Adv: 0.9628, F Adv: 0.5282\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1709, Perceptual Monet: 0.1784\n",
      "  Total G Loss: 3.8553\n",
      "Epoch [188/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2307, D_X Fake: 0.1644, D_X Total: 0.1975\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0408, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 0.8246, F Adv: 0.4420\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.4130\n",
      "Epoch [188/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1149, D_X Fake: 0.0766, D_X Total: 0.0958\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0448, D_Y Total: 0.0341\n",
      "Generator Losses:\n",
      "  G Adv: 0.8434, F Adv: 0.5981\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1497, Perceptual Monet: 0.1655\n",
      "  Total G Loss: 3.5691\n",
      "Epoch [188/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1418, D_X Fake: 0.0793, D_X Total: 0.1105\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0490, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.8427, F Adv: 0.6577\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1436, Perceptual Monet: 0.1736\n",
      "  Total G Loss: 3.6608\n",
      "Epoch [188/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0933, D_X Fake: 0.0997, D_X Total: 0.0965\n",
      "  D_Y Real: 0.0329, D_Y Fake: 0.0461, D_Y Total: 0.0395\n",
      "Generator Losses:\n",
      "  G Adv: 0.9362, F Adv: 0.5863\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1923\n",
      "  Total G Loss: 3.7512\n",
      "Epoch [188/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0820, D_X Fake: 0.1329, D_X Total: 0.1074\n",
      "  D_Y Real: 0.0325, D_Y Fake: 0.0397, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.9203, F Adv: 0.5342\n",
      "  Cycle Photo: 0.0227, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1178, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.4750\n",
      "Epoch [188/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1031, D_X Fake: 0.1219, D_X Total: 0.1125\n",
      "  D_Y Real: 0.0414, D_Y Fake: 0.0665, D_Y Total: 0.0540\n",
      "Generator Losses:\n",
      "  G Adv: 0.7912, F Adv: 0.5421\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1210, Perceptual Monet: 0.1451\n",
      "  Total G Loss: 3.1870\n",
      "Epoch [188/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1206, D_X Fake: 0.1297, D_X Total: 0.1252\n",
      "  D_Y Real: 0.0139, D_Y Fake: 0.0419, D_Y Total: 0.0279\n",
      "Generator Losses:\n",
      "  G Adv: 0.9509, F Adv: 0.6297\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1371, Perceptual Monet: 0.1470\n",
      "  Total G Loss: 3.4774\n",
      "Epoch [188/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1401, D_X Fake: 0.1145, D_X Total: 0.1273\n",
      "  D_Y Real: 0.0176, D_Y Fake: 0.0711, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.8148, F Adv: 0.5332\n",
      "  Cycle Photo: 0.0310, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1501, Perceptual Monet: 0.1658\n",
      "  Total G Loss: 3.4979\n",
      "Epoch [188/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0637, D_X Fake: 0.1226, D_X Total: 0.0931\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0490, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 1.0394, F Adv: 0.6165\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1768\n",
      "  Total G Loss: 3.8433\n",
      "Epoch [188/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0849, D_X Fake: 0.0839, D_X Total: 0.0844\n",
      "  D_Y Real: 0.0324, D_Y Fake: 0.0417, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.7952, F Adv: 0.6189\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1881\n",
      "  Total G Loss: 3.8114\n",
      "Epoch [188/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2214, D_X Fake: 0.0673, D_X Total: 0.1444\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0474, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.8556, F Adv: 0.6514\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1760, Perceptual Monet: 0.1642\n",
      "  Total G Loss: 3.8143\n",
      "Epoch [188/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.0809, D_X Total: 0.0800\n",
      "  D_Y Real: 0.0268, D_Y Fake: 0.0451, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 0.9881, F Adv: 0.6792\n",
      "  Cycle Photo: 0.0214, Cycle Monet: 0.0373\n",
      "  Perceptual Photo: 0.1120, Perceptual Monet: 0.1925\n",
      "  Total G Loss: 3.7777\n",
      "Epoch [188/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1242, D_X Fake: 0.1496, D_X Total: 0.1369\n",
      "  D_Y Real: 0.0322, D_Y Fake: 0.0402, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 1.0696, F Adv: 0.4566\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0331\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1823\n",
      "  Total G Loss: 3.7830\n",
      "Epoch [188/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1115, D_X Fake: 0.0501, D_X Total: 0.0808\n",
      "  D_Y Real: 0.0376, D_Y Fake: 0.0473, D_Y Total: 0.0425\n",
      "Generator Losses:\n",
      "  G Adv: 0.7999, F Adv: 0.6065\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1273, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.4881\n",
      "Epoch [188/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1887, D_X Fake: 0.1281, D_X Total: 0.1584\n",
      "  D_Y Real: 0.0239, D_Y Fake: 0.0523, D_Y Total: 0.0381\n",
      "Generator Losses:\n",
      "  G Adv: 0.7955, F Adv: 0.5770\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.3704\n",
      "Epoch [188/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1280, D_X Fake: 0.1182, D_X Total: 0.1231\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0354, D_Y Total: 0.0324\n",
      "Generator Losses:\n",
      "  G Adv: 0.9536, F Adv: 0.4901\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1130, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.4137\n",
      "Epoch [188/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0684, D_X Fake: 0.0719, D_X Total: 0.0701\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0256, D_Y Total: 0.0265\n",
      "Generator Losses:\n",
      "  G Adv: 0.8383, F Adv: 0.6408\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1139, Perceptual Monet: 0.1929\n",
      "  Total G Loss: 3.5796\n",
      "Epoch [188/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1648, D_X Fake: 0.1049, D_X Total: 0.1349\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0576, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 1.0178, F Adv: 0.5464\n",
      "  Cycle Photo: 0.0418, Cycle Monet: 0.0326\n",
      "  Perceptual Photo: 0.1927, Perceptual Monet: 0.1865\n",
      "  Total G Loss: 4.2042\n",
      "Epoch [188/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1327, D_X Fake: 0.0399, D_X Total: 0.0863\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0503, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.9036, F Adv: 0.7536\n",
      "  Cycle Photo: 0.0364, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1630, Perceptual Monet: 0.1423\n",
      "  Total G Loss: 3.7763\n",
      "Epoch [188/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0966, D_X Fake: 0.0418, D_X Total: 0.0692\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0720, D_Y Total: 0.0447\n",
      "Generator Losses:\n",
      "  G Adv: 0.9651, F Adv: 0.5318\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1815, Perceptual Monet: 0.1551\n",
      "  Total G Loss: 3.8366\n",
      "Epoch [189/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1083, D_X Fake: 0.1198, D_X Total: 0.1140\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0775, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.6714, F Adv: 0.5648\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1251, Perceptual Monet: 0.2043\n",
      "  Total G Loss: 3.4978\n",
      "Epoch [189/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0641, D_X Fake: 0.0714, D_X Total: 0.0678\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0440, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.8143, F Adv: 0.5158\n",
      "  Cycle Photo: 0.0202, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.0966, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.0947\n",
      "Epoch [189/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0572, D_X Fake: 0.1232, D_X Total: 0.0902\n",
      "  D_Y Real: 0.0201, D_Y Fake: 0.0299, D_Y Total: 0.0250\n",
      "Generator Losses:\n",
      "  G Adv: 0.9493, F Adv: 0.5570\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1737\n",
      "  Total G Loss: 3.6640\n",
      "Epoch [189/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3159, D_X Fake: 0.0738, D_X Total: 0.1948\n",
      "  D_Y Real: 0.0225, D_Y Fake: 0.0370, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.8820, F Adv: 0.6494\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1550, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.6827\n",
      "Epoch [189/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1595, D_X Fake: 0.0770, D_X Total: 0.1183\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0411, D_Y Total: 0.0322\n",
      "Generator Losses:\n",
      "  G Adv: 0.9904, F Adv: 0.8394\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.1645\n",
      "  Total G Loss: 3.8853\n",
      "Epoch [189/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1870, D_X Fake: 0.0896, D_X Total: 0.1383\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0363, D_Y Total: 0.0268\n",
      "Generator Losses:\n",
      "  G Adv: 0.8969, F Adv: 0.5419\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0193\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1232\n",
      "  Total G Loss: 3.2506\n",
      "Epoch [189/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1093, D_X Fake: 0.1309, D_X Total: 0.1201\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0346, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.9391, F Adv: 0.4994\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1701, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.8018\n",
      "Epoch [189/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1653, D_X Fake: 0.1190, D_X Total: 0.1421\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0387, D_Y Total: 0.0346\n",
      "Generator Losses:\n",
      "  G Adv: 0.8866, F Adv: 0.6104\n",
      "  Cycle Photo: 0.0274, Cycle Monet: 0.0267\n",
      "  Perceptual Photo: 0.1389, Perceptual Monet: 0.1520\n",
      "  Total G Loss: 3.4937\n",
      "Epoch [189/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0916, D_X Fake: 0.1141, D_X Total: 0.1029\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0368, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.8405, F Adv: 0.6254\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1213, Perceptual Monet: 0.1884\n",
      "  Total G Loss: 3.5974\n",
      "Epoch [189/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0561, D_X Fake: 0.1010, D_X Total: 0.0785\n",
      "  D_Y Real: 0.0140, D_Y Fake: 0.0446, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.8996, F Adv: 0.6940\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1941, Perceptual Monet: 0.1551\n",
      "  Total G Loss: 3.9707\n",
      "Epoch [189/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0896, D_X Fake: 0.1157, D_X Total: 0.1027\n",
      "  D_Y Real: 0.0553, D_Y Fake: 0.0509, D_Y Total: 0.0531\n",
      "Generator Losses:\n",
      "  G Adv: 0.9457, F Adv: 0.5991\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1204, Perceptual Monet: 0.1604\n",
      "  Total G Loss: 3.4699\n",
      "Epoch [189/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3376, D_X Fake: 0.1465, D_X Total: 0.2420\n",
      "  D_Y Real: 0.0391, D_Y Fake: 0.0716, D_Y Total: 0.0553\n",
      "Generator Losses:\n",
      "  G Adv: 0.7463, F Adv: 0.5645\n",
      "  Cycle Photo: 0.0339, Cycle Monet: 0.0251\n",
      "  Perceptual Photo: 0.1687, Perceptual Monet: 0.1418\n",
      "  Total G Loss: 3.4526\n",
      "Epoch [189/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1065, D_X Fake: 0.0888, D_X Total: 0.0977\n",
      "  D_Y Real: 0.0401, D_Y Fake: 0.0677, D_Y Total: 0.0539\n",
      "Generator Losses:\n",
      "  G Adv: 0.7418, F Adv: 0.6737\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1168, Perceptual Monet: 0.1881\n",
      "  Total G Loss: 3.5633\n",
      "Epoch [189/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2237, D_X Fake: 0.1326, D_X Total: 0.1781\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0373, D_Y Total: 0.0271\n",
      "Generator Losses:\n",
      "  G Adv: 0.7917, F Adv: 0.5382\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0264\n",
      "  Perceptual Photo: 0.1428, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 3.4445\n",
      "Epoch [189/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1797, D_X Fake: 0.0499, D_X Total: 0.1148\n",
      "  D_Y Real: 0.0290, D_Y Fake: 0.0379, D_Y Total: 0.0334\n",
      "Generator Losses:\n",
      "  G Adv: 0.9848, F Adv: 0.6849\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1387, Perceptual Monet: 0.1396\n",
      "  Total G Loss: 3.5954\n",
      "Epoch [189/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0530, D_X Fake: 0.0877, D_X Total: 0.0704\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.0586, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.8743, F Adv: 0.5722\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0178\n",
      "  Perceptual Photo: 0.1146, Perceptual Monet: 0.1188\n",
      "  Total G Loss: 3.0330\n",
      "Epoch [189/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1568, D_X Fake: 0.0915, D_X Total: 0.1241\n",
      "  D_Y Real: 0.0215, D_Y Fake: 0.0258, D_Y Total: 0.0236\n",
      "Generator Losses:\n",
      "  G Adv: 0.9226, F Adv: 0.6128\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0312\n",
      "  Perceptual Photo: 0.1560, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.8768\n",
      "Epoch [189/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2234, D_X Fake: 0.0815, D_X Total: 0.1525\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0693, D_Y Total: 0.0437\n",
      "Generator Losses:\n",
      "  G Adv: 0.8566, F Adv: 0.6374\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1458, Perceptual Monet: 0.1675\n",
      "  Total G Loss: 3.6582\n",
      "Epoch [189/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0712, D_X Fake: 0.1064, D_X Total: 0.0888\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0564, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.8109, F Adv: 0.5527\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0303\n",
      "  Perceptual Photo: 0.1234, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.4467\n",
      "Epoch [189/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3481, D_X Fake: 0.1579, D_X Total: 0.2530\n",
      "  D_Y Real: 0.0392, D_Y Fake: 0.0316, D_Y Total: 0.0354\n",
      "Generator Losses:\n",
      "  G Adv: 0.8395, F Adv: 0.4808\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1769, Perceptual Monet: 0.1591\n",
      "  Total G Loss: 3.6690\n",
      "Epoch [189/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2215, D_X Fake: 0.1178, D_X Total: 0.1696\n",
      "  D_Y Real: 0.0408, D_Y Fake: 0.0414, D_Y Total: 0.0411\n",
      "Generator Losses:\n",
      "  G Adv: 1.0857, F Adv: 0.5495\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1589, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.9431\n",
      "Epoch [189/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1031, D_X Fake: 0.1174, D_X Total: 0.1102\n",
      "  D_Y Real: 0.0149, D_Y Fake: 0.0483, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 1.1650, F Adv: 0.5832\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1722\n",
      "  Total G Loss: 3.9361\n",
      "Epoch [189/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0643, D_X Fake: 0.1349, D_X Total: 0.0996\n",
      "  D_Y Real: 0.0292, D_Y Fake: 0.0425, D_Y Total: 0.0358\n",
      "Generator Losses:\n",
      "  G Adv: 0.8698, F Adv: 0.5491\n",
      "  Cycle Photo: 0.0293, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1632, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.7476\n",
      "Epoch [189/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2413, D_X Fake: 0.1126, D_X Total: 0.1769\n",
      "  D_Y Real: 0.0389, D_Y Fake: 0.0580, D_Y Total: 0.0484\n",
      "Generator Losses:\n",
      "  G Adv: 0.9133, F Adv: 0.5413\n",
      "  Cycle Photo: 0.0446, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.2245, Perceptual Monet: 0.1871\n",
      "  Total G Loss: 4.2689\n",
      "Epoch [190/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0389, D_X Fake: 0.0923, D_X Total: 0.0656\n",
      "  D_Y Real: 0.0312, D_Y Fake: 0.0382, D_Y Total: 0.0347\n",
      "Generator Losses:\n",
      "  G Adv: 0.7323, F Adv: 0.6941\n",
      "  Cycle Photo: 0.0362, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.1119, Perceptual Monet: 0.1874\n",
      "  Total G Loss: 3.6676\n",
      "Epoch [190/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0732, D_X Fake: 0.1062, D_X Total: 0.0897\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0339, D_Y Total: 0.0348\n",
      "Generator Losses:\n",
      "  G Adv: 0.9305, F Adv: 0.5262\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1320, Perceptual Monet: 0.1992\n",
      "  Total G Loss: 3.7554\n",
      "Epoch [190/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1190, D_X Fake: 0.1324, D_X Total: 0.1257\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0382, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 1.0115, F Adv: 0.5329\n",
      "  Cycle Photo: 0.0209, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1107, Perceptual Monet: 0.1709\n",
      "  Total G Loss: 3.4445\n",
      "Epoch [190/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1204, D_X Fake: 0.1800, D_X Total: 0.1502\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0292, D_Y Total: 0.0246\n",
      "Generator Losses:\n",
      "  G Adv: 0.9879, F Adv: 0.4636\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.5406\n",
      "Epoch [190/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1127, D_X Fake: 0.1052, D_X Total: 0.1089\n",
      "  D_Y Real: 0.0306, D_Y Fake: 0.0334, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8431, F Adv: 0.5259\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1241, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.3975\n",
      "Epoch [190/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1972, D_X Fake: 0.0621, D_X Total: 0.1296\n",
      "  D_Y Real: 0.0320, D_Y Fake: 0.0476, D_Y Total: 0.0398\n",
      "Generator Losses:\n",
      "  G Adv: 0.9875, F Adv: 0.6508\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1433, Perceptual Monet: 0.1652\n",
      "  Total G Loss: 3.7374\n",
      "Epoch [190/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1162, D_X Fake: 0.1163, D_X Total: 0.1163\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0648, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 0.7096, F Adv: 0.4908\n",
      "  Cycle Photo: 0.0227, Cycle Monet: 0.0260\n",
      "  Perceptual Photo: 0.1265, Perceptual Monet: 0.1578\n",
      "  Total G Loss: 3.1092\n",
      "Epoch [190/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0608, D_X Fake: 0.1028, D_X Total: 0.0818\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0467, D_Y Total: 0.0430\n",
      "Generator Losses:\n",
      "  G Adv: 0.8888, F Adv: 0.6255\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0310\n",
      "  Perceptual Photo: 0.1313, Perceptual Monet: 0.1829\n",
      "  Total G Loss: 3.7435\n",
      "Epoch [190/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2048, D_X Fake: 0.0460, D_X Total: 0.1254\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0337, D_Y Total: 0.0280\n",
      "Generator Losses:\n",
      "  G Adv: 1.0154, F Adv: 0.5589\n",
      "  Cycle Photo: 0.0332, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1439\n",
      "  Total G Loss: 3.6104\n",
      "Epoch [190/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2826, D_X Fake: 0.0869, D_X Total: 0.1848\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0639, D_Y Total: 0.0471\n",
      "Generator Losses:\n",
      "  G Adv: 0.9196, F Adv: 0.7833\n",
      "  Cycle Photo: 0.0342, Cycle Monet: 0.0384\n",
      "  Perceptual Photo: 0.1893, Perceptual Monet: 0.1930\n",
      "  Total G Loss: 4.3403\n",
      "Epoch [190/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1897, D_X Fake: 0.0908, D_X Total: 0.1403\n",
      "  D_Y Real: 0.0351, D_Y Fake: 0.0469, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 0.8848, F Adv: 0.6130\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1881, Perceptual Monet: 0.1870\n",
      "  Total G Loss: 4.0797\n",
      "Epoch [190/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0643, D_X Fake: 0.0825, D_X Total: 0.0734\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0405, D_Y Total: 0.0312\n",
      "Generator Losses:\n",
      "  G Adv: 1.0547, F Adv: 0.6468\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1146, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.7084\n",
      "Epoch [190/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1184, D_X Fake: 0.0692, D_X Total: 0.0938\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0437, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.9309, F Adv: 0.6504\n",
      "  Cycle Photo: 0.0308, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1518, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 3.8464\n",
      "Epoch [190/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1717, D_X Fake: 0.1119, D_X Total: 0.1418\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0301, D_Y Total: 0.0244\n",
      "Generator Losses:\n",
      "  G Adv: 0.8963, F Adv: 0.5655\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1341, Perceptual Monet: 0.1672\n",
      "  Total G Loss: 3.4982\n",
      "Epoch [190/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3195, D_X Fake: 0.0658, D_X Total: 0.1927\n",
      "  D_Y Real: 0.0140, D_Y Fake: 0.0356, D_Y Total: 0.0248\n",
      "Generator Losses:\n",
      "  G Adv: 0.8804, F Adv: 0.6298\n",
      "  Cycle Photo: 0.0236, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1264, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 3.4090\n",
      "Epoch [190/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1469, D_X Fake: 0.0881, D_X Total: 0.1175\n",
      "  D_Y Real: 0.0155, D_Y Fake: 0.0442, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.8825, F Adv: 0.6258\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0370\n",
      "  Perceptual Photo: 0.1449, Perceptual Monet: 0.1876\n",
      "  Total G Loss: 3.8327\n",
      "Epoch [190/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2277, D_X Fake: 0.0783, D_X Total: 0.1530\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0309, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.8099, F Adv: 0.5082\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0367\n",
      "  Perceptual Photo: 0.1322, Perceptual Monet: 0.2104\n",
      "  Total G Loss: 3.6932\n",
      "Epoch [190/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1705, D_X Fake: 0.0948, D_X Total: 0.1327\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0381, D_Y Total: 0.0270\n",
      "Generator Losses:\n",
      "  G Adv: 0.9699, F Adv: 0.6396\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1185, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 3.6609\n",
      "Epoch [190/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1322, D_X Fake: 0.0776, D_X Total: 0.1049\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0670, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.8219, F Adv: 0.5599\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1133, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.4244\n",
      "Epoch [190/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1593, D_X Fake: 0.0442, D_X Total: 0.1018\n",
      "  D_Y Real: 0.0187, D_Y Fake: 0.0384, D_Y Total: 0.0285\n",
      "Generator Losses:\n",
      "  G Adv: 0.7961, F Adv: 0.6222\n",
      "  Cycle Photo: 0.0201, Cycle Monet: 0.0382\n",
      "  Perceptual Photo: 0.0942, Perceptual Monet: 0.1889\n",
      "  Total G Loss: 3.4170\n",
      "Epoch [190/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1149, D_X Fake: 0.0904, D_X Total: 0.1026\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.0401, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.8123, F Adv: 0.5576\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1329, Perceptual Monet: 0.2181\n",
      "  Total G Loss: 3.7521\n",
      "Epoch [190/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1002, D_X Fake: 0.1183, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0287, D_Y Total: 0.0238\n",
      "Generator Losses:\n",
      "  G Adv: 0.9871, F Adv: 0.5442\n",
      "  Cycle Photo: 0.0320, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1784, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.8741\n",
      "Epoch [190/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1485, D_X Fake: 0.0782, D_X Total: 0.1133\n",
      "  D_Y Real: 0.0364, D_Y Fake: 0.0301, D_Y Total: 0.0333\n",
      "Generator Losses:\n",
      "  G Adv: 1.0374, F Adv: 0.5855\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1097, Perceptual Monet: 0.1677\n",
      "  Total G Loss: 3.5406\n",
      "Epoch [190/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0587, D_X Fake: 0.0984, D_X Total: 0.0786\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0433, D_Y Total: 0.0338\n",
      "Generator Losses:\n",
      "  G Adv: 0.8902, F Adv: 0.6145\n",
      "  Cycle Photo: 0.0280, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1459, Perceptual Monet: 0.1416\n",
      "  Total G Loss: 3.4504\n",
      "Epoch [191/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1494, D_X Fake: 0.0665, D_X Total: 0.1079\n",
      "  D_Y Real: 0.0221, D_Y Fake: 0.0279, D_Y Total: 0.0250\n",
      "Generator Losses:\n",
      "  G Adv: 0.9817, F Adv: 0.6223\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1557, Perceptual Monet: 0.1562\n",
      "  Total G Loss: 3.7540\n",
      "Epoch [191/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0759, D_X Fake: 0.0958, D_X Total: 0.0858\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0941, D_Y Total: 0.0575\n",
      "Generator Losses:\n",
      "  G Adv: 0.7835, F Adv: 0.5545\n",
      "  Cycle Photo: 0.0386, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1790, Perceptual Monet: 0.1669\n",
      "  Total G Loss: 3.7506\n",
      "Epoch [191/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2039, D_X Fake: 0.0951, D_X Total: 0.1495\n",
      "  D_Y Real: 0.0548, D_Y Fake: 0.0333, D_Y Total: 0.0441\n",
      "Generator Losses:\n",
      "  G Adv: 0.8873, F Adv: 0.5536\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1823, Perceptual Monet: 0.1406\n",
      "  Total G Loss: 3.6932\n",
      "Epoch [191/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3260, D_X Fake: 0.0997, D_X Total: 0.2129\n",
      "  D_Y Real: 0.0715, D_Y Fake: 0.0463, D_Y Total: 0.0589\n",
      "Generator Losses:\n",
      "  G Adv: 0.8277, F Adv: 0.5960\n",
      "  Cycle Photo: 0.0423, Cycle Monet: 0.0252\n",
      "  Perceptual Photo: 0.1792, Perceptual Monet: 0.1509\n",
      "  Total G Loss: 3.7489\n",
      "Epoch [191/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1176, D_X Fake: 0.0824, D_X Total: 0.1000\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0370, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.7859, F Adv: 0.6296\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1774\n",
      "  Total G Loss: 3.5325\n",
      "Epoch [191/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1271, D_X Fake: 0.1213, D_X Total: 0.1242\n",
      "  D_Y Real: 0.0291, D_Y Fake: 0.0720, D_Y Total: 0.0505\n",
      "Generator Losses:\n",
      "  G Adv: 0.8290, F Adv: 0.5556\n",
      "  Cycle Photo: 0.0329, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1172, Perceptual Monet: 0.1705\n",
      "  Total G Loss: 3.4295\n",
      "Epoch [191/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1741, D_X Fake: 0.0651, D_X Total: 0.1196\n",
      "  D_Y Real: 0.0214, D_Y Fake: 0.0346, D_Y Total: 0.0280\n",
      "Generator Losses:\n",
      "  G Adv: 0.9448, F Adv: 0.5841\n",
      "  Cycle Photo: 0.0259, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1521, Perceptual Monet: 0.1644\n",
      "  Total G Loss: 3.6721\n",
      "Epoch [191/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2200, D_X Fake: 0.0619, D_X Total: 0.1410\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0939, D_Y Total: 0.0595\n",
      "Generator Losses:\n",
      "  G Adv: 1.0233, F Adv: 0.6946\n",
      "  Cycle Photo: 0.0524, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.2184, Perceptual Monet: 0.1902\n",
      "  Total G Loss: 4.6067\n",
      "Epoch [191/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0786, D_X Fake: 0.1354, D_X Total: 0.1070\n",
      "  D_Y Real: 0.0220, D_Y Fake: 0.0480, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.9092, F Adv: 0.6836\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.7352\n",
      "Epoch [191/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1975, D_X Fake: 0.1149, D_X Total: 0.1562\n",
      "  D_Y Real: 0.0196, D_Y Fake: 0.0580, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.7949, F Adv: 0.5948\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1530, Perceptual Monet: 0.1711\n",
      "  Total G Loss: 3.6562\n",
      "Epoch [191/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0555, D_X Fake: 0.0818, D_X Total: 0.0686\n",
      "  D_Y Real: 0.0275, D_Y Fake: 0.1106, D_Y Total: 0.0691\n",
      "Generator Losses:\n",
      "  G Adv: 0.6834, F Adv: 0.5782\n",
      "  Cycle Photo: 0.0617, Cycle Monet: 0.0311\n",
      "  Perceptual Photo: 0.1194, Perceptual Monet: 0.1867\n",
      "  Total G Loss: 3.7199\n",
      "Epoch [191/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1648, D_X Fake: 0.0741, D_X Total: 0.1194\n",
      "  D_Y Real: 0.0143, D_Y Fake: 0.0508, D_Y Total: 0.0326\n",
      "Generator Losses:\n",
      "  G Adv: 0.7277, F Adv: 0.5744\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0313\n",
      "  Perceptual Photo: 0.1562, Perceptual Monet: 0.1786\n",
      "  Total G Loss: 3.6109\n",
      "Epoch [191/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1628, D_X Fake: 0.1003, D_X Total: 0.1316\n",
      "  D_Y Real: 0.0228, D_Y Fake: 0.0597, D_Y Total: 0.0412\n",
      "Generator Losses:\n",
      "  G Adv: 0.7523, F Adv: 0.4893\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1337, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.3253\n",
      "Epoch [191/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0869, D_X Fake: 0.0891, D_X Total: 0.0880\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0279, D_Y Total: 0.0242\n",
      "Generator Losses:\n",
      "  G Adv: 0.9096, F Adv: 0.7980\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1296, Perceptual Monet: 0.1612\n",
      "  Total G Loss: 3.6956\n",
      "Epoch [191/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1302, D_X Fake: 0.1046, D_X Total: 0.1174\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0515, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 1.0496, F Adv: 0.5137\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1310, Perceptual Monet: 0.1352\n",
      "  Total G Loss: 3.3912\n",
      "Epoch [191/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1626, D_X Fake: 0.1072, D_X Total: 0.1349\n",
      "  D_Y Real: 0.0335, D_Y Fake: 0.0343, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.9115, F Adv: 0.5350\n",
      "  Cycle Photo: 0.0474, Cycle Monet: 0.0360\n",
      "  Perceptual Photo: 0.1926, Perceptual Monet: 0.1878\n",
      "  Total G Loss: 4.1821\n",
      "Epoch [191/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0921, D_X Fake: 0.1874, D_X Total: 0.1397\n",
      "  D_Y Real: 0.0229, D_Y Fake: 0.0546, D_Y Total: 0.0388\n",
      "Generator Losses:\n",
      "  G Adv: 0.8570, F Adv: 0.3963\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1354, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.3473\n",
      "Epoch [191/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0963, D_X Fake: 0.1117, D_X Total: 0.1040\n",
      "  D_Y Real: 0.0332, D_Y Fake: 0.0366, D_Y Total: 0.0349\n",
      "Generator Losses:\n",
      "  G Adv: 0.9122, F Adv: 0.6256\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1582, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 3.7539\n",
      "Epoch [191/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1135, D_X Fake: 0.1417, D_X Total: 0.1276\n",
      "  D_Y Real: 0.0285, D_Y Fake: 0.0356, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.9263, F Adv: 0.4768\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1439, Perceptual Monet: 0.1854\n",
      "  Total G Loss: 3.5982\n",
      "Epoch [191/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0759, D_X Fake: 0.1215, D_X Total: 0.0987\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0295, D_Y Total: 0.0241\n",
      "Generator Losses:\n",
      "  G Adv: 1.0372, F Adv: 0.5325\n",
      "  Cycle Photo: 0.0276, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1324, Perceptual Monet: 0.1639\n",
      "  Total G Loss: 3.6207\n",
      "Epoch [191/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1875, D_X Fake: 0.1025, D_X Total: 0.1450\n",
      "  D_Y Real: 0.0227, D_Y Fake: 0.0518, D_Y Total: 0.0372\n",
      "Generator Losses:\n",
      "  G Adv: 0.8295, F Adv: 0.6045\n",
      "  Cycle Photo: 0.0315, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1611\n",
      "  Total G Loss: 3.6130\n",
      "Epoch [191/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0977, D_X Fake: 0.0959, D_X Total: 0.0968\n",
      "  D_Y Real: 0.0437, D_Y Fake: 0.0598, D_Y Total: 0.0517\n",
      "Generator Losses:\n",
      "  G Adv: 1.0173, F Adv: 0.5875\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0217\n",
      "  Perceptual Photo: 0.1713, Perceptual Monet: 0.1434\n",
      "  Total G Loss: 3.6886\n",
      "Epoch [191/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1311, D_X Fake: 0.1006, D_X Total: 0.1159\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0328, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.7767, F Adv: 0.6368\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1549, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.6188\n",
      "Epoch [191/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1126, D_X Fake: 0.1307, D_X Total: 0.1217\n",
      "  D_Y Real: 0.0416, D_Y Fake: 0.0422, D_Y Total: 0.0419\n",
      "Generator Losses:\n",
      "  G Adv: 1.1253, F Adv: 0.4571\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0225\n",
      "  Perceptual Photo: 0.1241, Perceptual Monet: 0.1540\n",
      "  Total G Loss: 3.4240\n",
      "Epoch [192/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1143, D_X Fake: 0.1185, D_X Total: 0.1164\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.0632, D_Y Total: 0.0399\n",
      "Generator Losses:\n",
      "  G Adv: 0.6696, F Adv: 0.4994\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1625, Perceptual Monet: 0.1731\n",
      "  Total G Loss: 3.4346\n",
      "Epoch [192/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2585, D_X Fake: 0.0701, D_X Total: 0.1643\n",
      "  D_Y Real: 0.0345, D_Y Fake: 0.0492, D_Y Total: 0.0418\n",
      "Generator Losses:\n",
      "  G Adv: 0.8105, F Adv: 0.7072\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1014, Perceptual Monet: 0.1671\n",
      "  Total G Loss: 3.3686\n",
      "Epoch [192/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1484, D_X Fake: 0.1067, D_X Total: 0.1276\n",
      "  D_Y Real: 0.0451, D_Y Fake: 0.0413, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 1.0870, F Adv: 0.5827\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1333, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.7686\n",
      "Epoch [192/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1797, D_X Fake: 0.0928, D_X Total: 0.1362\n",
      "  D_Y Real: 0.0249, D_Y Fake: 0.0393, D_Y Total: 0.0321\n",
      "Generator Losses:\n",
      "  G Adv: 0.7645, F Adv: 0.5261\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1526\n",
      "  Total G Loss: 3.3532\n",
      "Epoch [192/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1732, D_X Fake: 0.0460, D_X Total: 0.1096\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0389, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 0.9639, F Adv: 0.7236\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1576\n",
      "  Total G Loss: 3.6853\n",
      "Epoch [192/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1654, D_X Fake: 0.0982, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0703, D_Y Total: 0.0448\n",
      "Generator Losses:\n",
      "  G Adv: 0.9508, F Adv: 0.7129\n",
      "  Cycle Photo: 0.0266, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1511, Perceptual Monet: 0.1615\n",
      "  Total G Loss: 3.7812\n",
      "Epoch [192/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1860, D_X Fake: 0.1239, D_X Total: 0.1549\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0367, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.7972, F Adv: 0.5416\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1710, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.6482\n",
      "Epoch [192/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1368, D_X Fake: 0.0893, D_X Total: 0.1131\n",
      "  D_Y Real: 0.0197, D_Y Fake: 0.0503, D_Y Total: 0.0350\n",
      "Generator Losses:\n",
      "  G Adv: 0.9592, F Adv: 0.6195\n",
      "  Cycle Photo: 0.0219, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1370\n",
      "  Total G Loss: 3.3787\n",
      "Epoch [192/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2575, D_X Fake: 0.0653, D_X Total: 0.1614\n",
      "  D_Y Real: 0.0366, D_Y Fake: 0.0625, D_Y Total: 0.0495\n",
      "Generator Losses:\n",
      "  G Adv: 0.7906, F Adv: 0.6068\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1409\n",
      "  Total G Loss: 3.2748\n",
      "Epoch [192/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0987, D_X Fake: 0.0923, D_X Total: 0.0955\n",
      "  D_Y Real: 0.0271, D_Y Fake: 0.0340, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9228, F Adv: 0.6171\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1146, Perceptual Monet: 0.1407\n",
      "  Total G Loss: 3.3145\n",
      "Epoch [192/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1674, D_X Fake: 0.0822, D_X Total: 0.1248\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0368, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.8171, F Adv: 0.6331\n",
      "  Cycle Photo: 0.0353, Cycle Monet: 0.0272\n",
      "  Perceptual Photo: 0.1595, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.7403\n",
      "Epoch [192/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0366, D_X Fake: 0.0868, D_X Total: 0.0617\n",
      "  D_Y Real: 0.0210, D_Y Fake: 0.0545, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.8706, F Adv: 0.4424\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1107, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.1811\n",
      "Epoch [192/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0560, D_X Fake: 0.1051, D_X Total: 0.0805\n",
      "  D_Y Real: 0.0216, D_Y Fake: 0.0282, D_Y Total: 0.0249\n",
      "Generator Losses:\n",
      "  G Adv: 0.9934, F Adv: 0.5894\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0346\n",
      "  Perceptual Photo: 0.1166, Perceptual Monet: 0.1891\n",
      "  Total G Loss: 3.6820\n",
      "Epoch [192/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0940, D_X Fake: 0.1043, D_X Total: 0.0991\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0511, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.8643, F Adv: 0.5907\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1294, Perceptual Monet: 0.1716\n",
      "  Total G Loss: 3.5582\n",
      "Epoch [192/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0760, D_X Fake: 0.0676, D_X Total: 0.0718\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0387, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.8537, F Adv: 0.8442\n",
      "  Cycle Photo: 0.0253, Cycle Monet: 0.0284\n",
      "  Perceptual Photo: 0.1391, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.8244\n",
      "Epoch [192/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0870, D_X Fake: 0.1007, D_X Total: 0.0939\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0832, D_Y Total: 0.0513\n",
      "Generator Losses:\n",
      "  G Adv: 0.9368, F Adv: 0.5526\n",
      "  Cycle Photo: 0.0300, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1407, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.6452\n",
      "Epoch [192/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1354, D_X Fake: 0.0841, D_X Total: 0.1098\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0501, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.8831, F Adv: 0.5649\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1721, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 3.7536\n",
      "Epoch [192/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0862, D_X Fake: 0.1238, D_X Total: 0.1050\n",
      "  D_Y Real: 0.0356, D_Y Fake: 0.0399, D_Y Total: 0.0378\n",
      "Generator Losses:\n",
      "  G Adv: 1.0471, F Adv: 0.5603\n",
      "  Cycle Photo: 0.0211, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.0986, Perceptual Monet: 0.1796\n",
      "  Total G Loss: 3.5510\n",
      "Epoch [192/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.0872, D_X Total: 0.1001\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0280, D_Y Total: 0.0236\n",
      "Generator Losses:\n",
      "  G Adv: 0.9120, F Adv: 0.5147\n",
      "  Cycle Photo: 0.0261, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1376, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.5256\n",
      "Epoch [192/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2300, D_X Fake: 0.0863, D_X Total: 0.1582\n",
      "  D_Y Real: 0.0342, D_Y Fake: 0.0368, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.8949, F Adv: 0.6592\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0334\n",
      "  Perceptual Photo: 0.1694, Perceptual Monet: 0.1841\n",
      "  Total G Loss: 3.9440\n",
      "Epoch [192/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3824, D_X Fake: 0.1446, D_X Total: 0.2635\n",
      "  D_Y Real: 0.0262, D_Y Fake: 0.0452, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.9069, F Adv: 0.5652\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1808, Perceptual Monet: 0.1676\n",
      "  Total G Loss: 3.8489\n",
      "Epoch [192/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0470, D_X Fake: 0.1072, D_X Total: 0.0771\n",
      "  D_Y Real: 0.0244, D_Y Fake: 0.0287, D_Y Total: 0.0266\n",
      "Generator Losses:\n",
      "  G Adv: 0.6627, F Adv: 0.5227\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1019, Perceptual Monet: 0.1723\n",
      "  Total G Loss: 3.1450\n",
      "Epoch [192/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1783, D_X Fake: 0.1003, D_X Total: 0.1393\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0334, D_Y Total: 0.0255\n",
      "Generator Losses:\n",
      "  G Adv: 0.7108, F Adv: 0.5417\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0359\n",
      "  Perceptual Photo: 0.1423, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.5699\n",
      "Epoch [192/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2706, D_X Fake: 0.0913, D_X Total: 0.1809\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0422, D_Y Total: 0.0323\n",
      "Generator Losses:\n",
      "  G Adv: 0.9921, F Adv: 0.6524\n",
      "  Cycle Photo: 0.0381, Cycle Monet: 0.0202\n",
      "  Perceptual Photo: 0.1904, Perceptual Monet: 0.1242\n",
      "  Total G Loss: 3.8000\n",
      "Epoch [193/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0390, D_X Fake: 0.2293, D_X Total: 0.1341\n",
      "  D_Y Real: 0.0136, D_Y Fake: 0.0656, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 0.7198, F Adv: 0.3715\n",
      "  Cycle Photo: 0.0286, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.1261, Perceptual Monet: 0.1506\n",
      "  Total G Loss: 2.9934\n",
      "Epoch [193/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1431, D_X Fake: 0.0873, D_X Total: 0.1152\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0490, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.7194, F Adv: 0.6131\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0216\n",
      "  Perceptual Photo: 0.1429, Perceptual Monet: 0.1473\n",
      "  Total G Loss: 3.3187\n",
      "Epoch [193/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0916, D_X Fake: 0.0618, D_X Total: 0.0767\n",
      "  D_Y Real: 0.0251, D_Y Fake: 0.0535, D_Y Total: 0.0393\n",
      "Generator Losses:\n",
      "  G Adv: 0.8429, F Adv: 0.7481\n",
      "  Cycle Photo: 0.0304, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1098, Perceptual Monet: 0.1778\n",
      "  Total G Loss: 3.6298\n",
      "Epoch [193/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0969, D_X Fake: 0.1132, D_X Total: 0.1050\n",
      "  D_Y Real: 0.0274, D_Y Fake: 0.0290, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 1.1626, F Adv: 0.6455\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1271, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.9547\n",
      "Epoch [193/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1717, D_X Fake: 0.0976, D_X Total: 0.1347\n",
      "  D_Y Real: 0.0208, D_Y Fake: 0.0561, D_Y Total: 0.0384\n",
      "Generator Losses:\n",
      "  G Adv: 0.8128, F Adv: 0.6324\n",
      "  Cycle Photo: 0.0194, Cycle Monet: 0.0399\n",
      "  Perceptual Photo: 0.0914, Perceptual Monet: 0.1879\n",
      "  Total G Loss: 3.4355\n",
      "Epoch [193/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.0820, D_X Total: 0.0815\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0684, D_Y Total: 0.0481\n",
      "Generator Losses:\n",
      "  G Adv: 0.7276, F Adv: 0.6141\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0351\n",
      "  Perceptual Photo: 0.1207, Perceptual Monet: 0.1792\n",
      "  Total G Loss: 3.4259\n",
      "Epoch [193/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0772, D_X Fake: 0.1033, D_X Total: 0.0903\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0436, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.9006, F Adv: 0.6966\n",
      "  Cycle Photo: 0.0292, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1119, Perceptual Monet: 0.1856\n",
      "  Total G Loss: 3.7163\n",
      "Epoch [193/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0806, D_X Fake: 0.0964, D_X Total: 0.0885\n",
      "  D_Y Real: 0.0181, D_Y Fake: 0.0334, D_Y Total: 0.0258\n",
      "Generator Losses:\n",
      "  G Adv: 0.8173, F Adv: 0.5926\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.0876, Perceptual Monet: 0.1764\n",
      "  Total G Loss: 3.2479\n",
      "Epoch [193/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1686, D_X Fake: 0.0772, D_X Total: 0.1229\n",
      "  D_Y Real: 0.0242, D_Y Fake: 0.0409, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.8585, F Adv: 0.5089\n",
      "  Cycle Photo: 0.0287, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1015, Perceptual Monet: 0.1762\n",
      "  Total G Loss: 3.3434\n",
      "Epoch [193/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1048, D_X Fake: 0.0896, D_X Total: 0.0972\n",
      "  D_Y Real: 0.0231, D_Y Fake: 0.0511, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.8005, F Adv: 0.5774\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0275\n",
      "  Perceptual Photo: 0.1579, Perceptual Monet: 0.1719\n",
      "  Total G Loss: 3.6087\n",
      "Epoch [193/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1898, D_X Fake: 0.1059, D_X Total: 0.1478\n",
      "  D_Y Real: 0.0153, D_Y Fake: 0.0425, D_Y Total: 0.0289\n",
      "Generator Losses:\n",
      "  G Adv: 0.8945, F Adv: 0.5644\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1368, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.5661\n",
      "Epoch [193/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0610, D_X Fake: 0.1296, D_X Total: 0.0953\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0481, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.8684, F Adv: 0.4932\n",
      "  Cycle Photo: 0.0322, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1514, Perceptual Monet: 0.1680\n",
      "  Total G Loss: 3.5756\n",
      "Epoch [193/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1317, D_X Fake: 0.1215, D_X Total: 0.1266\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0490, D_Y Total: 0.0363\n",
      "Generator Losses:\n",
      "  G Adv: 0.8197, F Adv: 0.5684\n",
      "  Cycle Photo: 0.0282, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.1427, Perceptual Monet: 0.1660\n",
      "  Total G Loss: 3.5145\n",
      "Epoch [193/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1751, D_X Fake: 0.0881, D_X Total: 0.1316\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0763, D_Y Total: 0.0463\n",
      "Generator Losses:\n",
      "  G Adv: 0.8708, F Adv: 0.5680\n",
      "  Cycle Photo: 0.0346, Cycle Monet: 0.0277\n",
      "  Perceptual Photo: 0.1610, Perceptual Monet: 0.1598\n",
      "  Total G Loss: 3.6656\n",
      "Epoch [193/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2151, D_X Fake: 0.0790, D_X Total: 0.1470\n",
      "  D_Y Real: 0.0161, D_Y Fake: 0.0376, D_Y Total: 0.0269\n",
      "Generator Losses:\n",
      "  G Adv: 0.8270, F Adv: 0.6504\n",
      "  Cycle Photo: 0.0314, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1308\n",
      "  Total G Loss: 3.4174\n",
      "Epoch [193/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0396, D_X Fake: 0.0791, D_X Total: 0.0594\n",
      "  D_Y Real: 0.0454, D_Y Fake: 0.0375, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.9661, F Adv: 0.5563\n",
      "  Cycle Photo: 0.0390, Cycle Monet: 0.0273\n",
      "  Perceptual Photo: 0.1616, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.8245\n",
      "Epoch [193/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1928, D_X Fake: 0.1104, D_X Total: 0.1516\n",
      "  D_Y Real: 0.0178, D_Y Fake: 0.0461, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8857, F Adv: 0.5477\n",
      "  Cycle Photo: 0.0251, Cycle Monet: 0.0286\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1727\n",
      "  Total G Loss: 3.5031\n",
      "Epoch [193/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0915, D_X Fake: 0.1500, D_X Total: 0.1208\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0709, D_Y Total: 0.0432\n",
      "Generator Losses:\n",
      "  G Adv: 0.6902, F Adv: 0.4753\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1241, Perceptual Monet: 0.1554\n",
      "  Total G Loss: 3.0865\n",
      "Epoch [193/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0532, D_X Fake: 0.1050, D_X Total: 0.0791\n",
      "  D_Y Real: 0.0238, D_Y Fake: 0.0504, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.9552, F Adv: 0.5120\n",
      "  Cycle Photo: 0.0228, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1130, Perceptual Monet: 0.1447\n",
      "  Total G Loss: 3.2299\n",
      "Epoch [193/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0772, D_X Fake: 0.2053, D_X Total: 0.1412\n",
      "  D_Y Real: 0.0166, D_Y Fake: 0.1065, D_Y Total: 0.0615\n",
      "Generator Losses:\n",
      "  G Adv: 0.7653, F Adv: 0.5047\n",
      "  Cycle Photo: 0.0243, Cycle Monet: 0.0242\n",
      "  Perceptual Photo: 0.1181, Perceptual Monet: 0.1496\n",
      "  Total G Loss: 3.0935\n",
      "Epoch [193/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1212, D_X Fake: 0.1118, D_X Total: 0.1165\n",
      "  D_Y Real: 0.0193, D_Y Fake: 0.0647, D_Y Total: 0.0420\n",
      "Generator Losses:\n",
      "  G Adv: 0.9045, F Adv: 0.5588\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1250, Perceptual Monet: 0.1482\n",
      "  Total G Loss: 3.3123\n",
      "Epoch [193/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0966, D_X Fake: 0.1011, D_X Total: 0.0988\n",
      "  D_Y Real: 0.0143, D_Y Fake: 0.0928, D_Y Total: 0.0536\n",
      "Generator Losses:\n",
      "  G Adv: 0.8292, F Adv: 0.5244\n",
      "  Cycle Photo: 0.0212, Cycle Monet: 0.0283\n",
      "  Perceptual Photo: 0.1167, Perceptual Monet: 0.1687\n",
      "  Total G Loss: 3.2755\n",
      "Epoch [193/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1022, D_X Fake: 0.1210, D_X Total: 0.1116\n",
      "  D_Y Real: 0.0158, D_Y Fake: 0.0529, D_Y Total: 0.0343\n",
      "Generator Losses:\n",
      "  G Adv: 0.7256, F Adv: 0.5335\n",
      "  Cycle Photo: 0.0319, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1471, Perceptual Monet: 0.1753\n",
      "  Total G Loss: 3.4745\n",
      "Epoch [193/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1578, D_X Fake: 0.0575, D_X Total: 0.1077\n",
      "  D_Y Real: 0.0188, D_Y Fake: 0.0292, D_Y Total: 0.0240\n",
      "Generator Losses:\n",
      "  G Adv: 0.9105, F Adv: 0.6415\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1640, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.7777\n",
      "Epoch [194/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0784, D_X Fake: 0.1222, D_X Total: 0.1003\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.0353, D_Y Total: 0.0318\n",
      "Generator Losses:\n",
      "  G Adv: 1.1525, F Adv: 0.4889\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0282\n",
      "  Perceptual Photo: 0.1245, Perceptual Monet: 0.1741\n",
      "  Total G Loss: 3.7049\n",
      "Epoch [194/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1444, D_X Fake: 0.0657, D_X Total: 0.1051\n",
      "  D_Y Real: 0.0230, D_Y Fake: 0.0674, D_Y Total: 0.0452\n",
      "Generator Losses:\n",
      "  G Adv: 0.8689, F Adv: 0.6990\n",
      "  Cycle Photo: 0.0249, Cycle Monet: 0.0323\n",
      "  Perceptual Photo: 0.1111, Perceptual Monet: 0.1794\n",
      "  Total G Loss: 3.5920\n",
      "Epoch [194/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0485, D_X Fake: 0.0879, D_X Total: 0.0682\n",
      "  D_Y Real: 0.0171, D_Y Fake: 0.0484, D_Y Total: 0.0328\n",
      "Generator Losses:\n",
      "  G Adv: 0.9095, F Adv: 0.5301\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1583\n",
      "  Total G Loss: 3.4228\n",
      "Epoch [194/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2710, D_X Fake: 0.0579, D_X Total: 0.1644\n",
      "  D_Y Real: 0.0156, D_Y Fake: 0.0318, D_Y Total: 0.0237\n",
      "Generator Losses:\n",
      "  G Adv: 0.8446, F Adv: 0.7313\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1585, Perceptual Monet: 0.1544\n",
      "  Total G Loss: 3.7327\n",
      "Epoch [194/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1825, D_X Fake: 0.0805, D_X Total: 0.1315\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0451, D_Y Total: 0.0369\n",
      "Generator Losses:\n",
      "  G Adv: 0.8848, F Adv: 0.6235\n",
      "  Cycle Photo: 0.0216, Cycle Monet: 0.0363\n",
      "  Perceptual Photo: 0.1146, Perceptual Monet: 0.2006\n",
      "  Total G Loss: 3.6624\n",
      "Epoch [194/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2086, D_X Fake: 0.0664, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0289, D_Y Fake: 0.0424, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.7799, F Adv: 0.6587\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1643\n",
      "  Total G Loss: 3.6312\n",
      "Epoch [194/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2019, D_X Fake: 0.1118, D_X Total: 0.1568\n",
      "  D_Y Real: 0.0236, D_Y Fake: 0.0635, D_Y Total: 0.0436\n",
      "Generator Losses:\n",
      "  G Adv: 0.8108, F Adv: 0.5917\n",
      "  Cycle Photo: 0.0348, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1645, Perceptual Monet: 0.1530\n",
      "  Total G Loss: 3.6069\n",
      "Epoch [194/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1584, D_X Fake: 0.0631, D_X Total: 0.1107\n",
      "  D_Y Real: 0.0608, D_Y Fake: 0.0537, D_Y Total: 0.0572\n",
      "Generator Losses:\n",
      "  G Adv: 0.9614, F Adv: 0.6685\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1491, Perceptual Monet: 0.2059\n",
      "  Total G Loss: 4.0640\n",
      "Epoch [194/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3668, D_X Fake: 0.0415, D_X Total: 0.2041\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0826, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.7435, F Adv: 0.7566\n",
      "  Cycle Photo: 0.0298, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1586\n",
      "  Total G Loss: 3.6375\n",
      "Epoch [194/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1741, D_X Fake: 0.1047, D_X Total: 0.1394\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.1037, D_Y Total: 0.0602\n",
      "Generator Losses:\n",
      "  G Adv: 0.6782, F Adv: 0.5714\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0214\n",
      "  Perceptual Photo: 0.1631, Perceptual Monet: 0.1393\n",
      "  Total G Loss: 3.2475\n",
      "Epoch [194/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1873, D_X Fake: 0.0892, D_X Total: 0.1383\n",
      "  D_Y Real: 0.0418, D_Y Fake: 0.0352, D_Y Total: 0.0385\n",
      "Generator Losses:\n",
      "  G Adv: 0.9743, F Adv: 0.5526\n",
      "  Cycle Photo: 0.0301, Cycle Monet: 0.0306\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1751\n",
      "  Total G Loss: 3.8122\n",
      "Epoch [194/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0818, D_X Fake: 0.1067, D_X Total: 0.0942\n",
      "  D_Y Real: 0.0293, D_Y Fake: 0.0513, D_Y Total: 0.0403\n",
      "Generator Losses:\n",
      "  G Adv: 0.7507, F Adv: 0.5488\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1734\n",
      "  Total G Loss: 3.5529\n",
      "Epoch [194/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0687, D_X Fake: 0.0818, D_X Total: 0.0752\n",
      "  D_Y Real: 0.0379, D_Y Fake: 0.0340, D_Y Total: 0.0360\n",
      "Generator Losses:\n",
      "  G Adv: 1.0126, F Adv: 0.6173\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0233\n",
      "  Perceptual Photo: 0.2157, Perceptual Monet: 0.1536\n",
      "  Total G Loss: 4.1311\n",
      "Epoch [194/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1246, D_X Fake: 0.1161, D_X Total: 0.1204\n",
      "  D_Y Real: 0.0147, D_Y Fake: 0.0681, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.7756, F Adv: 0.5061\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1535, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.3669\n",
      "Epoch [194/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1056, D_X Fake: 0.1091, D_X Total: 0.1074\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0409, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 1.1020, F Adv: 0.5729\n",
      "  Cycle Photo: 0.0334, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1836, Perceptual Monet: 0.1646\n",
      "  Total G Loss: 4.0291\n",
      "Epoch [194/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0988, D_X Fake: 0.0616, D_X Total: 0.0802\n",
      "  D_Y Real: 0.0390, D_Y Fake: 0.0640, D_Y Total: 0.0515\n",
      "Generator Losses:\n",
      "  G Adv: 0.8624, F Adv: 0.7583\n",
      "  Cycle Photo: 0.0325, Cycle Monet: 0.0320\n",
      "  Perceptual Photo: 0.1554, Perceptual Monet: 0.1761\n",
      "  Total G Loss: 3.9234\n",
      "Epoch [194/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1720, D_X Fake: 0.0848, D_X Total: 0.1284\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0402, D_Y Total: 0.0289\n",
      "Generator Losses:\n",
      "  G Adv: 0.9875, F Adv: 0.6108\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1281, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 3.7091\n",
      "Epoch [194/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1724, D_X Fake: 0.0996, D_X Total: 0.1360\n",
      "  D_Y Real: 0.0330, D_Y Fake: 0.0329, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 1.0207, F Adv: 0.5162\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0280\n",
      "  Perceptual Photo: 0.1623, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.7651\n",
      "Epoch [194/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1827, D_X Fake: 0.0701, D_X Total: 0.1264\n",
      "  D_Y Real: 0.0527, D_Y Fake: 0.0714, D_Y Total: 0.0620\n",
      "Generator Losses:\n",
      "  G Adv: 0.7577, F Adv: 0.7141\n",
      "  Cycle Photo: 0.0340, Cycle Monet: 0.0240\n",
      "  Perceptual Photo: 0.1408, Perceptual Monet: 0.1490\n",
      "  Total G Loss: 3.5009\n",
      "Epoch [194/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1143, D_X Fake: 0.1966, D_X Total: 0.1555\n",
      "  D_Y Real: 0.0546, D_Y Fake: 0.0350, D_Y Total: 0.0448\n",
      "Generator Losses:\n",
      "  G Adv: 0.8810, F Adv: 0.5087\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1275, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.5127\n",
      "Epoch [194/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1385, D_X Fake: 0.1033, D_X Total: 0.1209\n",
      "  D_Y Real: 0.0259, D_Y Fake: 0.0515, D_Y Total: 0.0387\n",
      "Generator Losses:\n",
      "  G Adv: 1.0608, F Adv: 0.6231\n",
      "  Cycle Photo: 0.0335, Cycle Monet: 0.0339\n",
      "  Perceptual Photo: 0.1603, Perceptual Monet: 0.1852\n",
      "  Total G Loss: 4.0852\n",
      "Epoch [194/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1314, D_X Fake: 0.1372, D_X Total: 0.1343\n",
      "  D_Y Real: 0.0234, D_Y Fake: 0.0323, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.9347, F Adv: 0.5796\n",
      "  Cycle Photo: 0.0341, Cycle Monet: 0.0246\n",
      "  Perceptual Photo: 0.1636, Perceptual Monet: 0.1572\n",
      "  Total G Loss: 3.7052\n",
      "Epoch [194/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0988, D_X Fake: 0.0614, D_X Total: 0.0801\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0382, D_Y Total: 0.0266\n",
      "Generator Losses:\n",
      "  G Adv: 0.9504, F Adv: 0.6353\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0357\n",
      "  Perceptual Photo: 0.1144, Perceptual Monet: 0.1953\n",
      "  Total G Loss: 3.7296\n",
      "Epoch [194/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1211, D_X Fake: 0.0975, D_X Total: 0.1093\n",
      "  D_Y Real: 0.0327, D_Y Fake: 0.0426, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.9787, F Adv: 0.5457\n",
      "  Cycle Photo: 0.0380, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1601\n",
      "  Total G Loss: 3.7184\n",
      "Epoch [195/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1330, D_X Fake: 0.0693, D_X Total: 0.1012\n",
      "  D_Y Real: 0.0330, D_Y Fake: 0.0516, D_Y Total: 0.0423\n",
      "Generator Losses:\n",
      "  G Adv: 1.0326, F Adv: 0.7536\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1129, Perceptual Monet: 0.1662\n",
      "  Total G Loss: 3.7646\n",
      "Epoch [195/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1573, D_X Fake: 0.0382, D_X Total: 0.0977\n",
      "  D_Y Real: 0.0207, D_Y Fake: 0.0388, D_Y Total: 0.0297\n",
      "Generator Losses:\n",
      "  G Adv: 0.9125, F Adv: 0.8940\n",
      "  Cycle Photo: 0.0297, Cycle Monet: 0.0258\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.7618\n",
      "Epoch [195/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1198, D_X Fake: 0.1185, D_X Total: 0.1191\n",
      "  D_Y Real: 0.0194, D_Y Fake: 0.0531, D_Y Total: 0.0362\n",
      "Generator Losses:\n",
      "  G Adv: 0.8618, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0260, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1389, Perceptual Monet: 0.1813\n",
      "  Total G Loss: 3.5202\n",
      "Epoch [195/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1308, D_X Fake: 0.0926, D_X Total: 0.1117\n",
      "  D_Y Real: 0.0219, D_Y Fake: 0.0328, D_Y Total: 0.0274\n",
      "Generator Losses:\n",
      "  G Adv: 0.9880, F Adv: 0.5621\n",
      "  Cycle Photo: 0.0207, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.0915, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.3893\n",
      "Epoch [195/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1315, D_X Fake: 0.1076, D_X Total: 0.1195\n",
      "  D_Y Real: 0.0150, D_Y Fake: 0.0429, D_Y Total: 0.0290\n",
      "Generator Losses:\n",
      "  G Adv: 0.7991, F Adv: 0.5490\n",
      "  Cycle Photo: 0.0288, Cycle Monet: 0.0215\n",
      "  Perceptual Photo: 0.1503, Perceptual Monet: 0.1477\n",
      "  Total G Loss: 3.3412\n",
      "Epoch [195/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1792, D_X Fake: 0.0827, D_X Total: 0.1310\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0311, D_Y Total: 0.0280\n",
      "Generator Losses:\n",
      "  G Adv: 0.9196, F Adv: 0.7755\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0392\n",
      "  Perceptual Photo: 0.1813, Perceptual Monet: 0.1909\n",
      "  Total G Loss: 4.3269\n",
      "Epoch [195/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1162, D_X Fake: 0.1121, D_X Total: 0.1142\n",
      "  D_Y Real: 0.0173, D_Y Fake: 0.0539, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 0.7924, F Adv: 0.5751\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1061, Perceptual Monet: 0.1587\n",
      "  Total G Loss: 3.2168\n",
      "Epoch [195/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2958, D_X Fake: 0.1337, D_X Total: 0.2147\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0524, D_Y Total: 0.0375\n",
      "Generator Losses:\n",
      "  G Adv: 0.7453, F Adv: 0.5398\n",
      "  Cycle Photo: 0.0337, Cycle Monet: 0.0223\n",
      "  Perceptual Photo: 0.1553, Perceptual Monet: 0.1418\n",
      "  Total G Loss: 3.3314\n",
      "Epoch [195/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2116, D_X Fake: 0.0782, D_X Total: 0.1449\n",
      "  D_Y Real: 0.0500, D_Y Fake: 0.0255, D_Y Total: 0.0377\n",
      "Generator Losses:\n",
      "  G Adv: 0.8630, F Adv: 0.6215\n",
      "  Cycle Photo: 0.0333, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1465, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.7143\n",
      "Epoch [195/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0884, D_X Fake: 0.0791, D_X Total: 0.0838\n",
      "  D_Y Real: 0.0199, D_Y Fake: 0.0725, D_Y Total: 0.0462\n",
      "Generator Losses:\n",
      "  G Adv: 0.6274, F Adv: 0.5523\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0324\n",
      "  Perceptual Photo: 0.1516, Perceptual Monet: 0.1665\n",
      "  Total G Loss: 3.3936\n",
      "Epoch [195/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1669, D_X Fake: 0.1095, D_X Total: 0.1382\n",
      "  D_Y Real: 0.0144, D_Y Fake: 0.0469, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 0.8160, F Adv: 0.6000\n",
      "  Cycle Photo: 0.0203, Cycle Monet: 0.0265\n",
      "  Perceptual Photo: 0.1080, Perceptual Monet: 0.1713\n",
      "  Total G Loss: 3.2800\n",
      "Epoch [195/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1762, D_X Fake: 0.1429, D_X Total: 0.1596\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0322, D_Y Total: 0.0238\n",
      "Generator Losses:\n",
      "  G Adv: 0.9573, F Adv: 0.4682\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0230\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1502\n",
      "  Total G Loss: 3.4535\n",
      "Epoch [195/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2232, D_X Fake: 0.0568, D_X Total: 0.1400\n",
      "  D_Y Real: 0.0344, D_Y Fake: 0.0598, D_Y Total: 0.0471\n",
      "Generator Losses:\n",
      "  G Adv: 0.9334, F Adv: 0.7311\n",
      "  Cycle Photo: 0.0311, Cycle Monet: 0.0325\n",
      "  Perceptual Photo: 0.1075, Perceptual Monet: 0.1848\n",
      "  Total G Loss: 3.7620\n",
      "Epoch [195/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2599, D_X Fake: 0.1106, D_X Total: 0.1853\n",
      "  D_Y Real: 0.0233, D_Y Fake: 0.0340, D_Y Total: 0.0287\n",
      "Generator Losses:\n",
      "  G Adv: 0.8490, F Adv: 0.6156\n",
      "  Cycle Photo: 0.0323, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1675, Perceptual Monet: 0.1580\n",
      "  Total G Loss: 3.6601\n",
      "Epoch [195/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1477, D_X Fake: 0.0970, D_X Total: 0.1224\n",
      "  D_Y Real: 0.0174, D_Y Fake: 0.0439, D_Y Total: 0.0307\n",
      "Generator Losses:\n",
      "  G Adv: 1.0372, F Adv: 0.5580\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1301, Perceptual Monet: 0.1693\n",
      "  Total G Loss: 3.6174\n",
      "Epoch [195/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2586, D_X Fake: 0.0708, D_X Total: 0.1647\n",
      "  D_Y Real: 0.0217, D_Y Fake: 0.0359, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.9736, F Adv: 0.6810\n",
      "  Cycle Photo: 0.0231, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1448, Perceptual Monet: 0.1634\n",
      "  Total G Loss: 3.7060\n",
      "Epoch [195/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1689, D_X Fake: 0.0946, D_X Total: 0.1318\n",
      "  D_Y Real: 0.0168, D_Y Fake: 0.0505, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.8356, F Adv: 0.5712\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0343\n",
      "  Perceptual Photo: 0.1367, Perceptual Monet: 0.1889\n",
      "  Total G Loss: 3.6487\n",
      "Epoch [195/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2696, D_X Fake: 0.0743, D_X Total: 0.1719\n",
      "  D_Y Real: 0.0114, D_Y Fake: 0.0343, D_Y Total: 0.0229\n",
      "Generator Losses:\n",
      "  G Adv: 0.9090, F Adv: 0.6885\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1922\n",
      "  Total G Loss: 3.9040\n",
      "Epoch [195/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0736, D_X Fake: 0.1308, D_X Total: 0.1022\n",
      "  D_Y Real: 0.0237, D_Y Fake: 0.0366, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 1.1295, F Adv: 0.4340\n",
      "  Cycle Photo: 0.0309, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1500, Perceptual Monet: 0.1407\n",
      "  Total G Loss: 3.5580\n",
      "Epoch [195/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1723, D_X Fake: 0.1030, D_X Total: 0.1377\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0345, D_Y Total: 0.0272\n",
      "Generator Losses:\n",
      "  G Adv: 1.2026, F Adv: 0.5953\n",
      "  Cycle Photo: 0.0267, Cycle Monet: 0.0344\n",
      "  Perceptual Photo: 0.1392, Perceptual Monet: 0.1925\n",
      "  Total G Loss: 4.0679\n",
      "Epoch [195/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1917, D_X Fake: 0.0790, D_X Total: 0.1354\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0321, D_Y Total: 0.0263\n",
      "Generator Losses:\n",
      "  G Adv: 0.7355, F Adv: 0.5348\n",
      "  Cycle Photo: 0.0278, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1599, Perceptual Monet: 0.1657\n",
      "  Total G Loss: 3.4695\n",
      "Epoch [195/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1065, D_X Fake: 0.0994, D_X Total: 0.1029\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0293, D_Y Total: 0.0234\n",
      "Generator Losses:\n",
      "  G Adv: 0.8950, F Adv: 0.5460\n",
      "  Cycle Photo: 0.0530, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1446, Perceptual Monet: 0.1524\n",
      "  Total G Loss: 3.7159\n",
      "Epoch [195/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0344, D_X Fake: 0.0760, D_X Total: 0.0552\n",
      "  D_Y Real: 0.0253, D_Y Fake: 0.0404, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8627, F Adv: 0.6956\n",
      "  Cycle Photo: 0.0344, Cycle Monet: 0.0366\n",
      "  Perceptual Photo: 0.1295, Perceptual Monet: 0.1940\n",
      "  Total G Loss: 3.8858\n",
      "Epoch [195/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0656, D_X Fake: 0.1071, D_X Total: 0.0863\n",
      "  D_Y Real: 0.0209, D_Y Fake: 0.0751, D_Y Total: 0.0480\n",
      "Generator Losses:\n",
      "  G Adv: 0.8150, F Adv: 0.6108\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0270\n",
      "  Perceptual Photo: 0.1404, Perceptual Monet: 0.1659\n",
      "  Total G Loss: 3.4974\n",
      "Epoch [196/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1170, D_X Fake: 0.1458, D_X Total: 0.1314\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0358, D_Y Total: 0.0306\n",
      "Generator Losses:\n",
      "  G Adv: 0.9844, F Adv: 0.4325\n",
      "  Cycle Photo: 0.0230, Cycle Monet: 0.0307\n",
      "  Perceptual Photo: 0.1248, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.4234\n",
      "Epoch [196/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1731, D_X Fake: 0.0993, D_X Total: 0.1362\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0334, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.9762, F Adv: 0.5532\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1283, Perceptual Monet: 0.1726\n",
      "  Total G Loss: 3.5904\n",
      "Epoch [196/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0806, D_X Fake: 0.0741, D_X Total: 0.0774\n",
      "  D_Y Real: 0.0163, D_Y Fake: 0.0444, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 0.7886, F Adv: 0.5877\n",
      "  Cycle Photo: 0.0262, Cycle Monet: 0.0209\n",
      "  Perceptual Photo: 0.1438, Perceptual Monet: 0.1342\n",
      "  Total G Loss: 3.2370\n",
      "Epoch [196/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0911, D_X Fake: 0.0662, D_X Total: 0.0787\n",
      "  D_Y Real: 0.0311, D_Y Fake: 0.0360, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 0.7942, F Adv: 0.6964\n",
      "  Cycle Photo: 0.0238, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1041, Perceptual Monet: 0.1703\n",
      "  Total G Loss: 3.3758\n",
      "Epoch [196/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2377, D_X Fake: 0.1181, D_X Total: 0.1779\n",
      "  D_Y Real: 0.0202, D_Y Fake: 0.0549, D_Y Total: 0.0376\n",
      "Generator Losses:\n",
      "  G Adv: 0.9402, F Adv: 0.5622\n",
      "  Cycle Photo: 0.0387, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1970, Perceptual Monet: 0.1735\n",
      "  Total G Loss: 4.0348\n",
      "Epoch [196/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0650, D_X Fake: 0.1006, D_X Total: 0.0828\n",
      "  D_Y Real: 0.0295, D_Y Fake: 0.0338, D_Y Total: 0.0316\n",
      "Generator Losses:\n",
      "  G Adv: 0.9589, F Adv: 0.6540\n",
      "  Cycle Photo: 0.0252, Cycle Monet: 0.0315\n",
      "  Perceptual Photo: 0.1309, Perceptual Monet: 0.1818\n",
      "  Total G Loss: 3.7427\n",
      "Epoch [196/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1620, D_X Fake: 0.1585, D_X Total: 0.1602\n",
      "  D_Y Real: 0.0252, D_Y Fake: 0.0557, D_Y Total: 0.0405\n",
      "Generator Losses:\n",
      "  G Adv: 0.8731, F Adv: 0.4994\n",
      "  Cycle Photo: 0.0263, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1472, Perceptual Monet: 0.1899\n",
      "  Total G Loss: 3.6201\n",
      "Epoch [196/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0643, D_X Fake: 0.1007, D_X Total: 0.0825\n",
      "  D_Y Real: 0.0245, D_Y Fake: 0.1054, D_Y Total: 0.0650\n",
      "Generator Losses:\n",
      "  G Adv: 0.8043, F Adv: 0.5750\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.1205, Perceptual Monet: 0.1691\n",
      "  Total G Loss: 3.4016\n",
      "Epoch [196/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.1224, D_X Total: 0.1008\n",
      "  D_Y Real: 0.0419, D_Y Fake: 0.0329, D_Y Total: 0.0374\n",
      "Generator Losses:\n",
      "  G Adv: 1.0789, F Adv: 0.5186\n",
      "  Cycle Photo: 0.0290, Cycle Monet: 0.0300\n",
      "  Perceptual Photo: 0.1370, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.7294\n",
      "Epoch [196/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0670, D_X Fake: 0.0690, D_X Total: 0.0680\n",
      "  D_Y Real: 0.0151, D_Y Fake: 0.0715, D_Y Total: 0.0433\n",
      "Generator Losses:\n",
      "  G Adv: 0.9131, F Adv: 0.6903\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1225, Perceptual Monet: 0.1815\n",
      "  Total G Loss: 3.7030\n",
      "Epoch [196/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0989, D_X Fake: 0.0874, D_X Total: 0.0932\n",
      "  D_Y Real: 0.0272, D_Y Fake: 0.0529, D_Y Total: 0.0400\n",
      "Generator Losses:\n",
      "  G Adv: 0.9422, F Adv: 0.5336\n",
      "  Cycle Photo: 0.0264, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1378, Perceptual Monet: 0.1606\n",
      "  Total G Loss: 3.4981\n",
      "Epoch [196/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1023, D_X Fake: 0.0933, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0682, D_Y Total: 0.0443\n",
      "Generator Losses:\n",
      "  G Adv: 0.9905, F Adv: 0.6089\n",
      "  Cycle Photo: 0.0225, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1070, Perceptual Monet: 0.1807\n",
      "  Total G Loss: 3.6529\n",
      "Epoch [196/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2694, D_X Fake: 0.1194, D_X Total: 0.1944\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0479, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 0.8742, F Adv: 0.6089\n",
      "  Cycle Photo: 0.0210, Cycle Monet: 0.0317\n",
      "  Perceptual Photo: 0.1141, Perceptual Monet: 0.1802\n",
      "  Total G Loss: 3.4807\n",
      "Epoch [196/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0750, D_X Fake: 0.0781, D_X Total: 0.0766\n",
      "  D_Y Real: 0.0269, D_Y Fake: 0.0441, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 1.0389, F Adv: 0.6746\n",
      "  Cycle Photo: 0.0318, Cycle Monet: 0.0281\n",
      "  Perceptual Photo: 0.1447, Perceptual Monet: 0.1700\n",
      "  Total G Loss: 3.8855\n",
      "Epoch [196/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1191, D_X Fake: 0.0681, D_X Total: 0.0936\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0365, D_Y Total: 0.0267\n",
      "Generator Losses:\n",
      "  G Adv: 0.9200, F Adv: 0.6801\n",
      "  Cycle Photo: 0.0284, Cycle Monet: 0.0276\n",
      "  Perceptual Photo: 0.1413, Perceptual Monet: 0.1701\n",
      "  Total G Loss: 3.7173\n",
      "Epoch [196/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1467, D_X Fake: 0.1514, D_X Total: 0.1491\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0550, D_Y Total: 0.0402\n",
      "Generator Losses:\n",
      "  G Adv: 0.8494, F Adv: 0.4237\n",
      "  Cycle Photo: 0.0430, Cycle Monet: 0.0321\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1920\n",
      "  Total G Loss: 3.7975\n",
      "Epoch [196/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0577, D_X Fake: 0.0777, D_X Total: 0.0677\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0475, D_Y Total: 0.0332\n",
      "Generator Losses:\n",
      "  G Adv: 0.8235, F Adv: 0.6365\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1330, Perceptual Monet: 0.1758\n",
      "  Total G Loss: 3.5396\n",
      "Epoch [196/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1464, D_X Fake: 0.1185, D_X Total: 0.1324\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0337, D_Y Total: 0.0305\n",
      "Generator Losses:\n",
      "  G Adv: 1.0254, F Adv: 0.4948\n",
      "  Cycle Photo: 0.0206, Cycle Monet: 0.0298\n",
      "  Perceptual Photo: 0.1143, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 3.4793\n",
      "Epoch [196/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1176, D_X Fake: 0.1495, D_X Total: 0.1336\n",
      "  D_Y Real: 0.0167, D_Y Fake: 0.0401, D_Y Total: 0.0284\n",
      "Generator Losses:\n",
      "  G Adv: 1.0732, F Adv: 0.6756\n",
      "  Cycle Photo: 0.0239, Cycle Monet: 0.0338\n",
      "  Perceptual Photo: 0.1197, Perceptual Monet: 0.1743\n",
      "  Total G Loss: 3.7951\n",
      "Epoch [196/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1386, D_X Fake: 0.0584, D_X Total: 0.0985\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0760, D_Y Total: 0.0471\n",
      "Generator Losses:\n",
      "  G Adv: 0.7901, F Adv: 0.7456\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0322\n",
      "  Perceptual Photo: 0.1581, Perceptual Monet: 0.1783\n",
      "  Total G Loss: 3.8347\n",
      "Epoch [196/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0766, D_X Fake: 0.1123, D_X Total: 0.0945\n",
      "  D_Y Real: 0.0179, D_Y Fake: 0.0378, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.7557, F Adv: 0.5912\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1176, Perceptual Monet: 0.1415\n",
      "  Total G Loss: 3.1789\n",
      "Epoch [196/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0587, D_X Fake: 0.0868, D_X Total: 0.0728\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0473, D_Y Total: 0.0396\n",
      "Generator Losses:\n",
      "  G Adv: 1.1009, F Adv: 0.6373\n",
      "  Cycle Photo: 0.0237, Cycle Monet: 0.0289\n",
      "  Perceptual Photo: 0.1138, Perceptual Monet: 0.1815\n",
      "  Total G Loss: 3.7409\n",
      "Epoch [196/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1025, D_X Fake: 0.0993, D_X Total: 0.1009\n",
      "  D_Y Real: 0.0304, D_Y Fake: 0.0679, D_Y Total: 0.0492\n",
      "Generator Losses:\n",
      "  G Adv: 0.6732, F Adv: 0.4601\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0305\n",
      "  Perceptual Photo: 0.1224, Perceptual Monet: 0.1724\n",
      "  Total G Loss: 3.2279\n",
      "Epoch [196/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2026, D_X Fake: 0.1021, D_X Total: 0.1523\n",
      "  D_Y Real: 0.0288, D_Y Fake: 0.0331, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.9629, F Adv: 0.5908\n",
      "  Cycle Photo: 0.0246, Cycle Monet: 0.0292\n",
      "  Perceptual Photo: 0.1317, Perceptual Monet: 0.1668\n",
      "  Total G Loss: 3.5840\n",
      "Epoch [197/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1641, D_X Fake: 0.1025, D_X Total: 0.1333\n",
      "  D_Y Real: 0.0386, D_Y Fake: 0.0532, D_Y Total: 0.0459\n",
      "Generator Losses:\n",
      "  G Adv: 0.9580, F Adv: 0.5497\n",
      "  Cycle Photo: 0.0379, Cycle Monet: 0.0211\n",
      "  Perceptual Photo: 0.1807, Perceptual Monet: 0.1349\n",
      "  Total G Loss: 3.6759\n",
      "Epoch [197/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1813, D_X Fake: 0.0673, D_X Total: 0.1243\n",
      "  D_Y Real: 0.0226, D_Y Fake: 0.0349, D_Y Total: 0.0288\n",
      "Generator Losses:\n",
      "  G Adv: 0.8637, F Adv: 0.5866\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0297\n",
      "  Perceptual Photo: 0.1498, Perceptual Monet: 0.1773\n",
      "  Total G Loss: 3.6644\n",
      "Epoch [197/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2621, D_X Fake: 0.0889, D_X Total: 0.1755\n",
      "  D_Y Real: 0.0394, D_Y Fake: 0.0489, D_Y Total: 0.0442\n",
      "Generator Losses:\n",
      "  G Adv: 0.9034, F Adv: 0.6875\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1477, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.7299\n",
      "Epoch [197/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1907, D_X Fake: 0.0772, D_X Total: 0.1339\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0497, D_Y Total: 0.0337\n",
      "Generator Losses:\n",
      "  G Adv: 0.7928, F Adv: 0.5754\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0285\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1567\n",
      "  Total G Loss: 3.4958\n",
      "Epoch [197/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0561, D_X Fake: 0.1060, D_X Total: 0.0811\n",
      "  D_Y Real: 0.0200, D_Y Fake: 0.0519, D_Y Total: 0.0359\n",
      "Generator Losses:\n",
      "  G Adv: 1.0562, F Adv: 0.5234\n",
      "  Cycle Photo: 0.0295, Cycle Monet: 0.0350\n",
      "  Perceptual Photo: 0.1719, Perceptual Monet: 0.1877\n",
      "  Total G Loss: 4.0219\n",
      "Epoch [197/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2460, D_X Fake: 0.0598, D_X Total: 0.1529\n",
      "  D_Y Real: 0.0527, D_Y Fake: 0.0434, D_Y Total: 0.0480\n",
      "Generator Losses:\n",
      "  G Adv: 0.7339, F Adv: 0.7482\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0330\n",
      "  Perceptual Photo: 0.1525, Perceptual Monet: 0.1745\n",
      "  Total G Loss: 3.7429\n",
      "Epoch [197/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1337, D_X Fake: 0.1009, D_X Total: 0.1173\n",
      "  D_Y Real: 0.0191, D_Y Fake: 0.1209, D_Y Total: 0.0700\n",
      "Generator Losses:\n",
      "  G Adv: 0.5928, F Adv: 0.6083\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0341\n",
      "  Perceptual Photo: 0.1774, Perceptual Monet: 0.2019\n",
      "  Total G Loss: 3.7558\n",
      "Epoch [197/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0818, D_X Fake: 0.1127, D_X Total: 0.0973\n",
      "  D_Y Real: 0.0303, D_Y Fake: 0.0366, D_Y Total: 0.0335\n",
      "Generator Losses:\n",
      "  G Adv: 1.1580, F Adv: 0.4728\n",
      "  Cycle Photo: 0.0307, Cycle Monet: 0.0259\n",
      "  Perceptual Photo: 0.1355, Perceptual Monet: 0.1588\n",
      "  Total G Loss: 3.6685\n",
      "Epoch [197/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0995, D_X Fake: 0.0732, D_X Total: 0.0863\n",
      "  D_Y Real: 0.0177, D_Y Fake: 0.0441, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.7938, F Adv: 0.6957\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1594, Perceptual Monet: 0.1603\n",
      "  Total G Loss: 3.6661\n",
      "Epoch [197/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0897, D_X Fake: 0.0695, D_X Total: 0.0796\n",
      "  D_Y Real: 0.0283, D_Y Fake: 0.1186, D_Y Total: 0.0735\n",
      "Generator Losses:\n",
      "  G Adv: 0.6397, F Adv: 0.7727\n",
      "  Cycle Photo: 0.0221, Cycle Monet: 0.0353\n",
      "  Perceptual Photo: 0.1226, Perceptual Monet: 0.1805\n",
      "  Total G Loss: 3.5023\n",
      "Epoch [197/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1447, D_X Fake: 0.1039, D_X Total: 0.1243\n",
      "  D_Y Real: 0.0508, D_Y Fake: 0.0354, D_Y Total: 0.0431\n",
      "Generator Losses:\n",
      "  G Adv: 0.9955, F Adv: 0.5938\n",
      "  Cycle Photo: 0.0272, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1488, Perceptual Monet: 0.1679\n",
      "  Total G Loss: 3.7123\n",
      "Epoch [197/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3917, D_X Fake: 0.0773, D_X Total: 0.2345\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0403, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.8909, F Adv: 0.6382\n",
      "  Cycle Photo: 0.0402, Cycle Monet: 0.0301\n",
      "  Perceptual Photo: 0.2018, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 4.1102\n",
      "Epoch [197/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0811, D_X Fake: 0.1350, D_X Total: 0.1081\n",
      "  D_Y Real: 0.0221, D_Y Fake: 0.0375, D_Y Total: 0.0298\n",
      "Generator Losses:\n",
      "  G Adv: 0.8490, F Adv: 0.5631\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0291\n",
      "  Perceptual Photo: 0.1627, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.6227\n",
      "Epoch [197/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0819, D_X Fake: 0.0971, D_X Total: 0.0895\n",
      "  D_Y Real: 0.0262, D_Y Fake: 0.0451, D_Y Total: 0.0357\n",
      "Generator Losses:\n",
      "  G Adv: 0.9051, F Adv: 0.5894\n",
      "  Cycle Photo: 0.0366, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1745, Perceptual Monet: 0.1864\n",
      "  Total G Loss: 3.9580\n",
      "Epoch [197/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1251, D_X Fake: 0.1084, D_X Total: 0.1167\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0469, D_Y Total: 0.0367\n",
      "Generator Losses:\n",
      "  G Adv: 1.1165, F Adv: 0.6274\n",
      "  Cycle Photo: 0.0313, Cycle Monet: 0.0293\n",
      "  Perceptual Photo: 0.1703, Perceptual Monet: 0.1647\n",
      "  Total G Loss: 4.0248\n",
      "Epoch [197/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1021, D_X Fake: 0.0526, D_X Total: 0.0773\n",
      "  D_Y Real: 0.0284, D_Y Fake: 0.0439, D_Y Total: 0.0361\n",
      "Generator Losses:\n",
      "  G Adv: 0.7829, F Adv: 0.6935\n",
      "  Cycle Photo: 0.0271, Cycle Monet: 0.0245\n",
      "  Perceptual Photo: 0.1190, Perceptual Monet: 0.1586\n",
      "  Total G Loss: 3.3811\n",
      "Epoch [197/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0958, D_X Fake: 0.1236, D_X Total: 0.1097\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0653, D_Y Total: 0.0414\n",
      "Generator Losses:\n",
      "  G Adv: 0.8289, F Adv: 0.4977\n",
      "  Cycle Photo: 0.0393, Cycle Monet: 0.0247\n",
      "  Perceptual Photo: 0.1432, Perceptual Monet: 0.1370\n",
      "  Total G Loss: 3.3674\n",
      "Epoch [197/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2011, D_X Fake: 0.0609, D_X Total: 0.1310\n",
      "  D_Y Real: 0.0154, D_Y Fake: 0.0437, D_Y Total: 0.0296\n",
      "Generator Losses:\n",
      "  G Adv: 0.8201, F Adv: 0.7621\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0295\n",
      "  Perceptual Photo: 0.1347, Perceptual Monet: 0.1706\n",
      "  Total G Loss: 3.6886\n",
      "Epoch [197/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2862, D_X Fake: 0.0750, D_X Total: 0.1806\n",
      "  D_Y Real: 0.0277, D_Y Fake: 0.0382, D_Y Total: 0.0329\n",
      "Generator Losses:\n",
      "  G Adv: 1.0819, F Adv: 0.6093\n",
      "  Cycle Photo: 0.0317, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1528, Perceptual Monet: 0.2026\n",
      "  Total G Loss: 4.1750\n",
      "Epoch [197/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0801, D_X Fake: 0.1523, D_X Total: 0.1162\n",
      "  D_Y Real: 0.0339, D_Y Fake: 0.0723, D_Y Total: 0.0531\n",
      "Generator Losses:\n",
      "  G Adv: 0.7765, F Adv: 0.5028\n",
      "  Cycle Photo: 0.0400, Cycle Monet: 0.0287\n",
      "  Perceptual Photo: 0.1537, Perceptual Monet: 0.1666\n",
      "  Total G Loss: 3.5676\n",
      "Epoch [197/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1743, D_X Fake: 0.1413, D_X Total: 0.1578\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.1178, D_Y Total: 0.0674\n",
      "Generator Losses:\n",
      "  G Adv: 0.7972, F Adv: 0.6489\n",
      "  Cycle Photo: 0.0302, Cycle Monet: 0.0268\n",
      "  Perceptual Photo: 0.1485, Perceptual Monet: 0.1695\n",
      "  Total G Loss: 3.6059\n",
      "Epoch [197/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0544, D_X Fake: 0.1227, D_X Total: 0.0886\n",
      "  D_Y Real: 0.0279, D_Y Fake: 0.0372, D_Y Total: 0.0325\n",
      "Generator Losses:\n",
      "  G Adv: 0.9983, F Adv: 0.5903\n",
      "  Cycle Photo: 0.0222, Cycle Monet: 0.0299\n",
      "  Perceptual Photo: 0.1210, Perceptual Monet: 0.1632\n",
      "  Total G Loss: 3.5310\n",
      "Epoch [197/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2151, D_X Fake: 0.1061, D_X Total: 0.1606\n",
      "  D_Y Real: 0.0250, D_Y Fake: 0.0428, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.9762, F Adv: 0.5028\n",
      "  Cycle Photo: 0.0281, Cycle Monet: 0.0288\n",
      "  Perceptual Photo: 0.1350, Perceptual Monet: 0.1630\n",
      "  Total G Loss: 3.5376\n",
      "Epoch [197/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2376, D_X Fake: 0.1168, D_X Total: 0.1772\n",
      "  D_Y Real: 0.0316, D_Y Fake: 0.0503, D_Y Total: 0.0410\n",
      "Generator Losses:\n",
      "  G Adv: 0.9690, F Adv: 0.7248\n",
      "  Cycle Photo: 0.0289, Cycle Monet: 0.0352\n",
      "  Perceptual Photo: 0.1480, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 4.0094\n",
      "Epoch [198/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2068, D_X Fake: 0.1008, D_X Total: 0.1538\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0306, D_Y Total: 0.0282\n",
      "Generator Losses:\n",
      "  G Adv: 0.8792, F Adv: 0.5840\n",
      "  Cycle Photo: 0.0303, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.1494, Perceptual Monet: 0.1559\n",
      "  Total G Loss: 3.5544\n",
      "Epoch [198/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1333, D_X Fake: 0.0737, D_X Total: 0.1035\n",
      "  D_Y Real: 0.0315, D_Y Fake: 0.0395, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 1.0619, F Adv: 0.6321\n",
      "  Cycle Photo: 0.0296, Cycle Monet: 0.0340\n",
      "  Perceptual Photo: 0.1586, Perceptual Monet: 0.1767\n",
      "  Total G Loss: 4.0060\n",
      "Epoch [198/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1693, D_X Fake: 0.1371, D_X Total: 0.1532\n",
      "  D_Y Real: 0.0412, D_Y Fake: 0.0662, D_Y Total: 0.0537\n",
      "Generator Losses:\n",
      "  G Adv: 0.8943, F Adv: 0.4939\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0249\n",
      "  Perceptual Photo: 0.1388, Perceptual Monet: 0.1602\n",
      "  Total G Loss: 3.4019\n",
      "Epoch [198/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2265, D_X Fake: 0.1380, D_X Total: 0.1823\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0314, D_Y Total: 0.0256\n",
      "Generator Losses:\n",
      "  G Adv: 0.8299, F Adv: 0.5396\n",
      "  Cycle Photo: 0.0233, Cycle Monet: 0.0278\n",
      "  Perceptual Photo: 0.1403, Perceptual Monet: 0.1745\n",
      "  Total G Loss: 3.4551\n",
      "Epoch [198/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1447, D_X Fake: 0.1197, D_X Total: 0.1322\n",
      "  D_Y Real: 0.0248, D_Y Fake: 0.0459, D_Y Total: 0.0353\n",
      "Generator Losses:\n",
      "  G Adv: 0.9272, F Adv: 0.5426\n",
      "  Cycle Photo: 0.0316, Cycle Monet: 0.0253\n",
      "  Perceptual Photo: 0.1499, Perceptual Monet: 0.1590\n",
      "  Total G Loss: 3.5830\n",
      "Epoch [198/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1222, D_X Fake: 0.0888, D_X Total: 0.1055\n",
      "  D_Y Real: 0.0222, D_Y Fake: 0.0417, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 1.1197, F Adv: 0.4747\n",
      "  Cycle Photo: 0.0273, Cycle Monet: 0.0335\n",
      "  Perceptual Photo: 0.1428, Perceptual Monet: 0.1921\n",
      "  Total G Loss: 3.8766\n",
      "Epoch [198/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0621, D_X Fake: 0.0985, D_X Total: 0.0803\n",
      "  D_Y Real: 0.0203, D_Y Fake: 0.0385, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 1.0400, F Adv: 0.5207\n",
      "  Cycle Photo: 0.0244, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1138, Perceptual Monet: 0.1814\n",
      "  Total G Loss: 3.5898\n",
      "Epoch [198/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1435, D_X Fake: 0.2383, D_X Total: 0.1909\n",
      "  D_Y Real: 0.0353, D_Y Fake: 0.0472, D_Y Total: 0.0413\n",
      "Generator Losses:\n",
      "  G Adv: 0.9046, F Adv: 0.3666\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0262\n",
      "  Perceptual Photo: 0.1473, Perceptual Monet: 0.1697\n",
      "  Total G Loss: 3.3855\n",
      "Epoch [198/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0622, D_X Fake: 0.1216, D_X Total: 0.0919\n",
      "  D_Y Real: 0.0157, D_Y Fake: 0.0337, D_Y Total: 0.0247\n",
      "Generator Losses:\n",
      "  G Adv: 0.9064, F Adv: 0.4876\n",
      "  Cycle Photo: 0.0330, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1493, Perceptual Monet: 0.1466\n",
      "  Total G Loss: 3.4310\n",
      "Epoch [198/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0433, D_X Fake: 0.0678, D_X Total: 0.0556\n",
      "  D_Y Real: 0.0273, D_Y Fake: 0.0486, D_Y Total: 0.0380\n",
      "Generator Losses:\n",
      "  G Adv: 0.8604, F Adv: 0.7180\n",
      "  Cycle Photo: 0.0211, Cycle Monet: 0.0248\n",
      "  Perceptual Photo: 0.1070, Perceptual Monet: 0.1462\n",
      "  Total G Loss: 3.3025\n",
      "Epoch [198/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1432, D_X Fake: 0.0758, D_X Total: 0.1095\n",
      "  D_Y Real: 0.0254, D_Y Fake: 0.0898, D_Y Total: 0.0576\n",
      "Generator Losses:\n",
      "  G Adv: 0.8281, F Adv: 0.6352\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0279\n",
      "  Perceptual Photo: 0.1150, Perceptual Monet: 0.1625\n",
      "  Total G Loss: 3.3858\n",
      "Epoch [198/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1961, D_X Fake: 0.1386, D_X Total: 0.1674\n",
      "  D_Y Real: 0.0258, D_Y Fake: 0.0340, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.8587, F Adv: 0.5606\n",
      "  Cycle Photo: 0.0228, Cycle Monet: 0.0304\n",
      "  Perceptual Photo: 0.1304, Perceptual Monet: 0.1739\n",
      "  Total G Loss: 3.4725\n",
      "Epoch [198/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1730, D_X Fake: 0.0862, D_X Total: 0.1296\n",
      "  D_Y Real: 0.0409, D_Y Fake: 0.0281, D_Y Total: 0.0345\n",
      "Generator Losses:\n",
      "  G Adv: 0.8496, F Adv: 0.7946\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0423\n",
      "  Perceptual Photo: 0.1533, Perceptual Monet: 0.2091\n",
      "  Total G Loss: 4.1289\n",
      "Epoch [198/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1922, D_X Fake: 0.1149, D_X Total: 0.1536\n",
      "  D_Y Real: 0.0307, D_Y Fake: 0.0763, D_Y Total: 0.0535\n",
      "Generator Losses:\n",
      "  G Adv: 0.8003, F Adv: 0.6057\n",
      "  Cycle Photo: 0.0248, Cycle Monet: 0.0365\n",
      "  Perceptual Photo: 0.1283, Perceptual Monet: 0.1863\n",
      "  Total G Loss: 3.5911\n",
      "Epoch [198/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1373, D_X Fake: 0.0990, D_X Total: 0.1181\n",
      "  D_Y Real: 0.0360, D_Y Fake: 0.0420, D_Y Total: 0.0390\n",
      "Generator Losses:\n",
      "  G Adv: 0.8890, F Adv: 0.6587\n",
      "  Cycle Photo: 0.0328, Cycle Monet: 0.0219\n",
      "  Perceptual Photo: 0.1650, Perceptual Monet: 0.1327\n",
      "  Total G Loss: 3.5835\n",
      "Epoch [198/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1536, D_X Fake: 0.0958, D_X Total: 0.1247\n",
      "  D_Y Real: 0.0298, D_Y Fake: 0.0414, D_Y Total: 0.0356\n",
      "Generator Losses:\n",
      "  G Adv: 1.0458, F Adv: 0.5637\n",
      "  Cycle Photo: 0.0268, Cycle Monet: 0.0266\n",
      "  Perceptual Photo: 0.1242, Perceptual Monet: 0.1519\n",
      "  Total G Loss: 3.5239\n",
      "Epoch [198/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0611, D_X Fake: 0.0909, D_X Total: 0.0760\n",
      "  D_Y Real: 0.0296, D_Y Fake: 0.0726, D_Y Total: 0.0511\n",
      "Generator Losses:\n",
      "  G Adv: 0.8679, F Adv: 0.5444\n",
      "  Cycle Photo: 0.0241, Cycle Monet: 0.0332\n",
      "  Perceptual Photo: 0.1116, Perceptual Monet: 0.1928\n",
      "  Total G Loss: 3.5076\n",
      "Epoch [198/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1116, D_X Fake: 0.0823, D_X Total: 0.0969\n",
      "  D_Y Real: 0.0182, D_Y Fake: 0.0335, D_Y Total: 0.0259\n",
      "Generator Losses:\n",
      "  G Adv: 0.9194, F Adv: 0.6238\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0356\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1748\n",
      "  Total G Loss: 3.7577\n",
      "Epoch [198/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1777, D_X Fake: 0.1252, D_X Total: 0.1515\n",
      "  D_Y Real: 0.0205, D_Y Fake: 0.0377, D_Y Total: 0.0291\n",
      "Generator Losses:\n",
      "  G Adv: 0.8728, F Adv: 0.5460\n",
      "  Cycle Photo: 0.0250, Cycle Monet: 0.0228\n",
      "  Perceptual Photo: 0.1430, Perceptual Monet: 0.1488\n",
      "  Total G Loss: 3.3557\n",
      "Epoch [198/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0941, D_X Fake: 0.0500, D_X Total: 0.0720\n",
      "  D_Y Real: 0.0192, D_Y Fake: 0.0518, D_Y Total: 0.0355\n",
      "Generator Losses:\n",
      "  G Adv: 0.9046, F Adv: 0.7752\n",
      "  Cycle Photo: 0.0258, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1110, Perceptual Monet: 0.1913\n",
      "  Total G Loss: 3.7829\n",
      "Epoch [198/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2258, D_X Fake: 0.0566, D_X Total: 0.1412\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0243, D_Y Total: 0.0234\n",
      "Generator Losses:\n",
      "  G Adv: 0.8926, F Adv: 0.6506\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0269\n",
      "  Perceptual Photo: 0.1441, Perceptual Monet: 0.1732\n",
      "  Total G Loss: 3.6545\n",
      "Epoch [198/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1634, D_X Fake: 0.1067, D_X Total: 0.1350\n",
      "  D_Y Real: 0.0159, D_Y Fake: 0.0459, D_Y Total: 0.0309\n",
      "Generator Losses:\n",
      "  G Adv: 0.8987, F Adv: 0.5666\n",
      "  Cycle Photo: 0.0283, Cycle Monet: 0.0238\n",
      "  Perceptual Photo: 0.1455, Perceptual Monet: 0.1443\n",
      "  Total G Loss: 3.4349\n",
      "Epoch [198/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1578, D_X Fake: 0.1084, D_X Total: 0.1331\n",
      "  D_Y Real: 0.0497, D_Y Fake: 0.0358, D_Y Total: 0.0427\n",
      "Generator Losses:\n",
      "  G Adv: 0.9969, F Adv: 0.5211\n",
      "  Cycle Photo: 0.0372, Cycle Monet: 0.0244\n",
      "  Perceptual Photo: 0.1680, Perceptual Monet: 0.1573\n",
      "  Total G Loss: 3.7608\n",
      "Epoch [198/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3035, D_X Fake: 0.0573, D_X Total: 0.1804\n",
      "  D_Y Real: 0.0243, D_Y Fake: 0.0398, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 1.0177, F Adv: 0.4899\n",
      "  Cycle Photo: 0.0421, Cycle Monet: 0.0256\n",
      "  Perceptual Photo: 0.1690, Perceptual Monet: 0.1582\n",
      "  Total G Loss: 3.8207\n",
      "Epoch [199/200] Batch [0/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1783, D_X Fake: 0.0967, D_X Total: 0.1375\n",
      "  D_Y Real: 0.0424, D_Y Fake: 0.0447, D_Y Total: 0.0435\n",
      "Generator Losses:\n",
      "  G Adv: 0.8665, F Adv: 0.7055\n",
      "  Cycle Photo: 0.0324, Cycle Monet: 0.0347\n",
      "  Perceptual Photo: 0.1605, Perceptual Monet: 0.1869\n",
      "  Total G Loss: 3.9810\n",
      "Epoch [199/200] Batch [100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.3422, D_X Fake: 0.1304, D_X Total: 0.2363\n",
      "  D_Y Real: 0.0195, D_Y Fake: 0.0402, D_Y Total: 0.0299\n",
      "Generator Losses:\n",
      "  G Adv: 0.9928, F Adv: 0.5279\n",
      "  Cycle Photo: 0.0294, Cycle Monet: 0.0319\n",
      "  Perceptual Photo: 0.1506, Perceptual Monet: 0.1746\n",
      "  Total G Loss: 3.7595\n",
      "Epoch [199/200] Batch [200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0662, D_X Fake: 0.0629, D_X Total: 0.0645\n",
      "  D_Y Real: 0.0170, D_Y Fake: 0.0614, D_Y Total: 0.0392\n",
      "Generator Losses:\n",
      "  G Adv: 0.7479, F Adv: 0.6332\n",
      "  Cycle Photo: 0.0255, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1353, Perceptual Monet: 0.1593\n",
      "  Total G Loss: 3.3522\n",
      "Epoch [199/200] Batch [300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0751, D_X Fake: 0.0918, D_X Total: 0.0835\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0492, D_Y Total: 0.0339\n",
      "Generator Losses:\n",
      "  G Adv: 0.9449, F Adv: 0.6145\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0390\n",
      "  Perceptual Photo: 0.1479, Perceptual Monet: 0.1873\n",
      "  Total G Loss: 3.8825\n",
      "Epoch [199/200] Batch [400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2688, D_X Fake: 0.0332, D_X Total: 0.1510\n",
      "  D_Y Real: 0.0319, D_Y Fake: 0.0644, D_Y Total: 0.0482\n",
      "Generator Losses:\n",
      "  G Adv: 0.8248, F Adv: 0.7464\n",
      "  Cycle Photo: 0.0385, Cycle Monet: 0.0243\n",
      "  Perceptual Photo: 0.1835, Perceptual Monet: 0.1556\n",
      "  Total G Loss: 3.8943\n",
      "Epoch [199/200] Batch [500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0482, D_X Fake: 0.0589, D_X Total: 0.0536\n",
      "  D_Y Real: 0.0247, D_Y Fake: 0.0339, D_Y Total: 0.0293\n",
      "Generator Losses:\n",
      "  G Adv: 0.9716, F Adv: 0.7782\n",
      "  Cycle Photo: 0.0277, Cycle Monet: 0.0296\n",
      "  Perceptual Photo: 0.1144, Perceptual Monet: 0.1696\n",
      "  Total G Loss: 3.7437\n",
      "Epoch [199/200] Batch [600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1130, D_X Fake: 0.1043, D_X Total: 0.1087\n",
      "  D_Y Real: 0.0358, D_Y Fake: 0.0717, D_Y Total: 0.0538\n",
      "Generator Losses:\n",
      "  G Adv: 0.9388, F Adv: 0.5789\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0309\n",
      "  Perceptual Photo: 0.1340, Perceptual Monet: 0.1747\n",
      "  Total G Loss: 3.6104\n",
      "Epoch [199/200] Batch [700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0743, D_X Fake: 0.1114, D_X Total: 0.0928\n",
      "  D_Y Real: 0.0264, D_Y Fake: 0.0308, D_Y Total: 0.0286\n",
      "Generator Losses:\n",
      "  G Adv: 0.9136, F Adv: 0.4833\n",
      "  Cycle Photo: 0.0275, Cycle Monet: 0.0294\n",
      "  Perceptual Photo: 0.1266, Perceptual Monet: 0.1714\n",
      "  Total G Loss: 3.4551\n",
      "Epoch [199/200] Batch [800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1154, D_X Fake: 0.0801, D_X Total: 0.0978\n",
      "  D_Y Real: 0.0184, D_Y Fake: 0.0370, D_Y Total: 0.0277\n",
      "Generator Losses:\n",
      "  G Adv: 0.9989, F Adv: 0.5707\n",
      "  Cycle Photo: 0.0291, Cycle Monet: 0.0237\n",
      "  Perceptual Photo: 0.1545, Perceptual Monet: 0.1485\n",
      "  Total G Loss: 3.6122\n",
      "Epoch [199/200] Batch [900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1612, D_X Fake: 0.0480, D_X Total: 0.1046\n",
      "  D_Y Real: 0.0147, D_Y Fake: 0.0494, D_Y Total: 0.0320\n",
      "Generator Losses:\n",
      "  G Adv: 0.8902, F Adv: 0.8439\n",
      "  Cycle Photo: 0.0327, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1561, Perceptual Monet: 0.1809\n",
      "  Total G Loss: 4.0477\n",
      "Epoch [199/200] Batch [1000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2065, D_X Fake: 0.0698, D_X Total: 0.1382\n",
      "  D_Y Real: 0.0146, D_Y Fake: 0.0458, D_Y Total: 0.0302\n",
      "Generator Losses:\n",
      "  G Adv: 0.8320, F Adv: 0.6941\n",
      "  Cycle Photo: 0.0270, Cycle Monet: 0.0271\n",
      "  Perceptual Photo: 0.0904, Perceptual Monet: 0.1641\n",
      "  Total G Loss: 3.3392\n",
      "Epoch [199/200] Batch [1100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1561, D_X Fake: 0.0973, D_X Total: 0.1267\n",
      "  D_Y Real: 0.0175, D_Y Fake: 0.0479, D_Y Total: 0.0327\n",
      "Generator Losses:\n",
      "  G Adv: 0.8174, F Adv: 0.5605\n",
      "  Cycle Photo: 0.0361, Cycle Monet: 0.0241\n",
      "  Perceptual Photo: 0.1418, Perceptual Monet: 0.1503\n",
      "  Total G Loss: 3.4402\n",
      "Epoch [199/200] Batch [1200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0640, D_X Fake: 0.0764, D_X Total: 0.0702\n",
      "  D_Y Real: 0.0172, D_Y Fake: 0.0384, D_Y Total: 0.0278\n",
      "Generator Losses:\n",
      "  G Adv: 0.9668, F Adv: 0.6582\n",
      "  Cycle Photo: 0.0256, Cycle Monet: 0.0250\n",
      "  Perceptual Photo: 0.1314, Perceptual Monet: 0.1408\n",
      "  Total G Loss: 3.4922\n",
      "Epoch [199/200] Batch [1300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1641, D_X Fake: 0.0964, D_X Total: 0.1302\n",
      "  D_Y Real: 0.0142, D_Y Fake: 0.0817, D_Y Total: 0.0480\n",
      "Generator Losses:\n",
      "  G Adv: 0.9138, F Adv: 0.5759\n",
      "  Cycle Photo: 0.0409, Cycle Monet: 0.0261\n",
      "  Perceptual Photo: 0.2004, Perceptual Monet: 0.1621\n",
      "  Total G Loss: 3.9728\n",
      "Epoch [199/200] Batch [1400/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1462, D_X Fake: 0.0815, D_X Total: 0.1138\n",
      "  D_Y Real: 0.0204, D_Y Fake: 0.0539, D_Y Total: 0.0371\n",
      "Generator Losses:\n",
      "  G Adv: 0.8338, F Adv: 0.5841\n",
      "  Cycle Photo: 0.0285, Cycle Monet: 0.0257\n",
      "  Perceptual Photo: 0.1323, Perceptual Monet: 0.1692\n",
      "  Total G Loss: 3.4673\n",
      "Epoch [199/200] Batch [1500/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0971, D_X Fake: 0.0889, D_X Total: 0.0930\n",
      "  D_Y Real: 0.0198, D_Y Fake: 0.0542, D_Y Total: 0.0370\n",
      "Generator Losses:\n",
      "  G Adv: 0.8697, F Adv: 0.6354\n",
      "  Cycle Photo: 0.0299, Cycle Monet: 0.0302\n",
      "  Perceptual Photo: 0.1604, Perceptual Monet: 0.1810\n",
      "  Total G Loss: 3.8127\n",
      "Epoch [199/200] Batch [1600/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1127, D_X Fake: 0.1941, D_X Total: 0.1534\n",
      "  D_Y Real: 0.0186, D_Y Fake: 0.0586, D_Y Total: 0.0386\n",
      "Generator Losses:\n",
      "  G Adv: 0.8087, F Adv: 0.4012\n",
      "  Cycle Photo: 0.0235, Cycle Monet: 0.0221\n",
      "  Perceptual Photo: 0.1321, Perceptual Monet: 0.1347\n",
      "  Total G Loss: 2.9998\n",
      "Epoch [199/200] Batch [1700/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0802, D_X Fake: 0.0887, D_X Total: 0.0844\n",
      "  D_Y Real: 0.0224, D_Y Fake: 0.0296, D_Y Total: 0.0260\n",
      "Generator Losses:\n",
      "  G Adv: 1.0772, F Adv: 0.6187\n",
      "  Cycle Photo: 0.0257, Cycle Monet: 0.0329\n",
      "  Perceptual Photo: 0.1336, Perceptual Monet: 0.1870\n",
      "  Total G Loss: 3.8852\n",
      "Epoch [199/200] Batch [1800/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2150, D_X Fake: 0.0835, D_X Total: 0.1493\n",
      "  D_Y Real: 0.0543, D_Y Fake: 0.0337, D_Y Total: 0.0440\n",
      "Generator Losses:\n",
      "  G Adv: 1.0216, F Adv: 0.7108\n",
      "  Cycle Photo: 0.0240, Cycle Monet: 0.0395\n",
      "  Perceptual Photo: 0.1342, Perceptual Monet: 0.1969\n",
      "  Total G Loss: 4.0230\n",
      "Epoch [199/200] Batch [1900/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0611, D_X Fake: 0.0711, D_X Total: 0.0661\n",
      "  D_Y Real: 0.0270, D_Y Fake: 0.0356, D_Y Total: 0.0313\n",
      "Generator Losses:\n",
      "  G Adv: 0.9195, F Adv: 0.6095\n",
      "  Cycle Photo: 0.0331, Cycle Monet: 0.0371\n",
      "  Perceptual Photo: 0.1425, Perceptual Monet: 0.1906\n",
      "  Total G Loss: 3.8966\n",
      "Epoch [199/200] Batch [2000/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0792, D_X Fake: 0.0824, D_X Total: 0.0808\n",
      "  D_Y Real: 0.0138, D_Y Fake: 0.0469, D_Y Total: 0.0303\n",
      "Generator Losses:\n",
      "  G Adv: 1.1416, F Adv: 0.6096\n",
      "  Cycle Photo: 0.0367, Cycle Monet: 0.0231\n",
      "  Perceptual Photo: 0.1613, Perceptual Monet: 0.1328\n",
      "  Total G Loss: 3.8196\n",
      "Epoch [199/200] Batch [2100/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.0655, D_X Fake: 0.0750, D_X Total: 0.0703\n",
      "  D_Y Real: 0.0189, D_Y Fake: 0.0482, D_Y Total: 0.0336\n",
      "Generator Losses:\n",
      "  G Adv: 0.6384, F Adv: 0.6180\n",
      "  Cycle Photo: 0.0196, Cycle Monet: 0.0314\n",
      "  Perceptual Photo: 0.1135, Perceptual Monet: 0.1788\n",
      "  Total G Loss: 3.2276\n",
      "Epoch [199/200] Batch [2200/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.1137, D_X Fake: 0.1142, D_X Total: 0.1140\n",
      "  D_Y Real: 0.0232, D_Y Fake: 0.0356, D_Y Total: 0.0294\n",
      "Generator Losses:\n",
      "  G Adv: 0.9255, F Adv: 0.4825\n",
      "  Cycle Photo: 0.0359, Cycle Monet: 0.0393\n",
      "  Perceptual Photo: 0.1639, Perceptual Monet: 0.1902\n",
      "  Total G Loss: 3.9302\n",
      "Epoch [199/200] Batch [2300/2346]\n",
      "Discriminator Losses:\n",
      "  D_X Real: 0.2398, D_X Fake: 0.1286, D_X Total: 0.1842\n",
      "  D_Y Real: 0.0278, D_Y Fake: 0.0946, D_Y Total: 0.0612\n",
      "Generator Losses:\n",
      "  G Adv: 0.8630, F Adv: 0.5910\n",
      "  Cycle Photo: 0.0226, Cycle Monet: 0.0333\n",
      "  Perceptual Photo: 0.1248, Perceptual Monet: 0.1857\n",
      "  Total G Loss: 3.5659\n",
      "Saved checkpoint at epoch 199\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    PHOTO_DIR = \"photo\"\n",
    "    MONET_DIR = \"monet\"\n",
    "    OUTPUT_DIR = \"Final_models\"  # For final model\n",
    "    MODELS_DIR = \"models\"           # For model checkpoints\n",
    "    SUBMISSION_DIR = \"submission\"   # For final submission images\n",
    "\n",
    "    train_cycle_gan(PHOTO_DIR, MONET_DIR, OUTPUT_DIR, MODELS_DIR)\n",
    "    generate_submission(PHOTO_DIR, SUBMISSION_DIR, f\"{MODELS_DIR}/checkpoint_epoch_{NUM_EPOCHS-1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
